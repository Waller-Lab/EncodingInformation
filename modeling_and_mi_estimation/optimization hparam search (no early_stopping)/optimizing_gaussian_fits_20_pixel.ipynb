{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solve for Gaussian approximations using optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening BSCCM\n",
      "Opened BSCCM\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# this only works on startup!\n",
    "from jax import config\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "from gpu_utils import limit_gpu_memory_growth\n",
    "limit_gpu_memory_growth()\n",
    "\n",
    "from cleanplots import *\n",
    "from tqdm import tqdm\n",
    "from information_estimation import *\n",
    "from image_utils import *\n",
    "from gaussian_process_utils import *\n",
    "\n",
    "from led_array.bsccm_utils import *\n",
    "from bsccm import BSCCM\n",
    "from jax import jit\n",
    "import numpy as onp\n",
    "import jax.numpy as np\n",
    "\n",
    "bsccm = BSCCM('/home/hpinkard_waller/data/BSCCM/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images, extract patches, and compute cov mats\n",
    "edge_crop = 32\n",
    "patch_size = 20\n",
    "num_images = 20000\n",
    "num_patches = 1000\n",
    "channel = 'LED119'\n",
    "eigenvalue_floor = 1e0\n",
    "\n",
    "images = load_bsccm_images(bsccm, channel=channel, num_images=num_images, edge_crop=edge_crop, median_filter=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search through hyperparameter combos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss:  1405663.069315428\n",
      "best loss: 1213584.55\t\tLearning rate: 1.624e-03, Batch size: 47, Momentum: 4.732e-01\n",
      "Initial loss:  1236283.0570866575\n",
      "best loss: 81392.61\t\tLearning rate: 2.637e-07, Batch size: 39, Momentum: 1.577e-01\n",
      "Initial loss:  121888.29746743452\n",
      "best loss: 1783.17\t\tLearning rate: 2.336e-06, Batch size: 17, Momentum: 7.887e-01\n",
      "Initial loss:  601628.0376138617\n",
      "best loss: 3075.61\t\tLearning rate: 2.069e-05, Batch size: 2, Momentum: 4.732e-01\n",
      "Initial loss:  257936.13077799967\n",
      "best loss: 3626.99\t\tLearning rate: 1.833e-04, Batch size: 37, Momentum: 9.464e-01\n",
      "Initial loss:  96484.46934036847\n",
      "best loss: 3870.65\t\tLearning rate: 1.624e-03, Batch size: 4, Momentum: 7.887e-01\n",
      "Initial loss:  299957.18864992226\n",
      "best loss: 5684.87\t\tLearning rate: 3.360e+00, Batch size: 44, Momentum: 9.464e-01\n",
      "Initial loss:  646669.6595893062\n",
      "best loss: 225296.33\t\tLearning rate: 2.069e-05, Batch size: 17, Momentum: 0.000e+00\n",
      "Initial loss:  1198738.0557458473\n",
      "best loss: 5126.40\t\tLearning rate: 3.793e-01, Batch size: 37, Momentum: 8.413e-01\n",
      "Initial loss:  327147.94995430484\n",
      "best loss: 3821.15\t\tLearning rate: 4.833e-03, Batch size: 12, Momentum: 3.681e-01\n",
      "Initial loss:  1622091.3889257207\n",
      "best loss: 3874.54\t\tLearning rate: 4.833e-03, Batch size: 17, Momentum: 2.629e-01\n",
      "Initial loss:  2552628.3916081404\n",
      "best loss: 3237.51\t\tLearning rate: 6.158e-05, Batch size: 9, Momentum: 6.309e-01\n",
      "Initial loss:  1850886.972254939\n",
      "best loss: 212229.90\t\tLearning rate: 8.859e-08, Batch size: 42, Momentum: 5.784e-01\n",
      "Initial loss:  500486.20938859304\n",
      "best loss: 3325.04\t\tLearning rate: 5.456e-04, Batch size: 2, Momentum: 1.052e-01\n",
      "Initial loss:  1792.5793486643704\n",
      "best loss: 1787.50\t\tLearning rate: 5.456e-04, Batch size: 27, Momentum: 3.155e-01\n",
      "Initial loss:  1516982.6901116483\n",
      "best loss: 62924.41\t\tLearning rate: 1.438e-02, Batch size: 4, Momentum: 0.000e+00\n",
      "Initial loss:  290709.29330675665\n",
      "best loss: 5731.73\t\tLearning rate: 3.360e+00, Batch size: 9, Momentum: 9.990e-01\n",
      "Initial loss:  155108.02784268692\n",
      "best loss: 27058.79\t\tLearning rate: 2.976e-08, Batch size: 24, Momentum: 5.258e-02\n",
      "Initial loss:  1711597.421948002\n",
      "best loss: 17796749.42\t\tLearning rate: 1.274e-01, Batch size: 9, Momentum: 5.258e-01\n",
      "Initial loss:  1803.5152957904847\n",
      "best loss: 1782.36\t\tLearning rate: 8.859e-08, Batch size: 27, Momentum: 3.681e-01\n",
      "Initial loss:  2747901.321652208\n",
      "best loss: 5307.05\t\tLearning rate: 3.360e+00, Batch size: 34, Momentum: 4.206e-01\n",
      "Initial loss:  1798.7254130223494\n",
      "best loss: 1775.32\t\tLearning rate: 4.833e-03, Batch size: 22, Momentum: 4.206e-01\n",
      "Initial loss:  1500547.8523800904\n",
      "best loss: 287234.04\t\tLearning rate: 2.976e-08, Batch size: 14, Momentum: 5.258e-01\n",
      "Initial loss:  1572340.1116839661\n",
      "best loss: 1239950.17\t\tLearning rate: 1.438e-02, Batch size: 4, Momentum: 5.258e-02\n",
      "Initial loss:  84843.8684458122\n",
      "best loss: 1816.95\t\tLearning rate: 2.637e-07, Batch size: 47, Momentum: 4.206e-01\n",
      "Initial loss:  1976382.2151807032\n",
      "best loss: 86673.67\t\tLearning rate: 2.976e-08, Batch size: 19, Momentum: 3.681e-01\n",
      "Initial loss:  353858.6843499866\n",
      "best loss: 1840.20\t\tLearning rate: 2.336e-06, Batch size: 29, Momentum: 3.155e-01\n",
      "Initial loss:  780951.928539372\n",
      "best loss: 3843.29\t\tLearning rate: 4.833e-03, Batch size: 34, Momentum: 3.155e-01\n",
      "Initial loss:  1120295.513949991\n",
      "best loss: 88464.89\t\tLearning rate: 1.000e+01, Batch size: 29, Momentum: 0.000e+00\n",
      "Initial loss:  1277958.5740909947\n",
      "best loss: 4598.61\t\tLearning rate: 1.274e-01, Batch size: 47, Momentum: 5.258e-01\n",
      "Initial loss:  1578339.3881836936\n",
      "best loss: 3074.91\t\tLearning rate: 6.158e-05, Batch size: 37, Momentum: 4.206e-01\n",
      "Initial loss:  1243778.561071542\n",
      "best loss: 4170.79\t\tLearning rate: 4.833e-03, Batch size: 27, Momentum: 7.361e-01\n",
      "Initial loss:  1794.03872086407\n",
      "best loss: 1776.54\t\tLearning rate: 3.360e+00, Batch size: 37, Momentum: 2.103e-01\n",
      "Initial loss:  1819.3852593414208\n",
      "best loss: 1765.91\t\tLearning rate: 3.360e+00, Batch size: 37, Momentum: 4.732e-01\n",
      "Initial loss:  1387862.2041941253\n",
      "best loss: 2987.88\t\tLearning rate: 6.158e-05, Batch size: 24, Momentum: 4.206e-01\n",
      "Initial loss:  1710728.49242373\n",
      "best loss: 589528.31\t\tLearning rate: 3.793e-01, Batch size: 24, Momentum: 3.155e-01\n",
      "Initial loss:  664343.4581367992\n",
      "best loss: 1771.36\t\tLearning rate: 7.848e-07, Batch size: 32, Momentum: 9.464e-01\n",
      "Initial loss:  640819.7038891539\n",
      "best loss: 4207.21\t\tLearning rate: 4.833e-03, Batch size: 42, Momentum: 7.887e-01\n",
      "Initial loss:  920179.7971679282\n",
      "best loss: 32798.03\t\tLearning rate: 2.976e-08, Batch size: 7, Momentum: 5.258e-02\n",
      "Initial loss:  2081563.7248490313\n",
      "best loss: 5147.78\t\tLearning rate: 3.793e-01, Batch size: 14, Momentum: 8.938e-01\n",
      "Initial loss:  2401756.3637390817\n",
      "best loss: 3249.42\t\tLearning rate: 6.158e-05, Batch size: 44, Momentum: 9.464e-01\n",
      "Initial loss:  302627.88620003505\n",
      "best loss: 2668.65\t\tLearning rate: 2.069e-05, Batch size: 39, Momentum: 5.258e-02\n",
      "Initial loss:  229059.8885272558\n",
      "best loss: 2818.45\t\tLearning rate: 2.069e-05, Batch size: 50, Momentum: 4.206e-01\n",
      "Initial loss:  352494.9339863636\n",
      "best loss: 1796.09\t\tLearning rate: 2.336e-06, Batch size: 14, Momentum: 2.629e-01\n",
      "Initial loss:  602809.1917163037\n",
      "best loss: 113178.14\t\tLearning rate: 2.976e-08, Batch size: 39, Momentum: 6.835e-01\n",
      "Initial loss:  2294113.1898025684\n",
      "best loss: 4677.78\t\tLearning rate: 1.274e-01, Batch size: 29, Momentum: 2.629e-01\n",
      "Initial loss:  569010.5620569264\n",
      "best loss: 3685.05\t\tLearning rate: 1.624e-03, Batch size: 32, Momentum: 2.629e-01\n",
      "Initial loss:  1006942.0454522109\n",
      "best loss: 1900.46\t\tLearning rate: 7.848e-07, Batch size: 29, Momentum: 7.887e-01\n",
      "Initial loss:  1894370.2033979497\n",
      "best loss: 3518.83\t\tLearning rate: 5.456e-04, Batch size: 24, Momentum: 4.732e-01\n",
      "Initial loss:  686690.2761319537\n",
      "best loss: 5117.63\t\tLearning rate: 1.129e+00, Batch size: 32, Momentum: 5.258e-01\n",
      "Initial loss:  1848983.4572186237\n",
      "best loss: 3419.47\t\tLearning rate: 5.456e-04, Batch size: 50, Momentum: 3.155e-01\n",
      "Initial loss:  1117667.9189547857\n",
      "best loss: 2554.96\t\tLearning rate: 6.952e-06, Batch size: 29, Momentum: 5.258e-01\n",
      "Initial loss:  1213254.999027708\n",
      "best loss: 98022.92\t\tLearning rate: 2.976e-08, Batch size: 12, Momentum: 1.577e-01\n",
      "Initial loss:  442171.42606927466\n",
      "best loss: 4442.93\t\tLearning rate: 1.274e-01, Batch size: 44, Momentum: 1.577e-01\n",
      "Initial loss:  31833.729513826413\n",
      "best loss: 5113.35\t\tLearning rate: 3.793e-01, Batch size: 7, Momentum: 7.887e-01\n",
      "Initial loss:  1389849.6438764918\n",
      "best loss: 37142.94\t\tLearning rate: 3.360e+00, Batch size: 24, Momentum: 2.103e-01\n",
      "Initial loss:  1868943.324372807\n",
      "best loss: 179384.81\t\tLearning rate: 2.637e-07, Batch size: 37, Momentum: 1.052e-01\n",
      "Initial loss:  1464401.459105811\n",
      "best loss: 1913349.52\t\tLearning rate: 1.833e-04, Batch size: 19, Momentum: 5.258e-02\n",
      "Initial loss:  1495023.1031914344\n",
      "best loss: 2892.87\t\tLearning rate: 2.069e-05, Batch size: 2, Momentum: 3.681e-01\n",
      "Initial loss:  737860.8036847527\n",
      "best loss: 3319.23\t\tLearning rate: 6.158e-05, Batch size: 27, Momentum: 9.990e-01\n",
      "Initial loss:  123870.62265941301\n",
      "best loss: 5354.07\t\tLearning rate: 3.360e+00, Batch size: 19, Momentum: 6.835e-01\n",
      "Initial loss:  1776.4329383488002\n",
      "best loss: 1747.73\t\tLearning rate: 2.637e-07, Batch size: 7, Momentum: 8.413e-01\n",
      "Initial loss:  716794.1615044718\n",
      "best loss: 3337.88\t\tLearning rate: 1.833e-04, Batch size: 24, Momentum: 4.732e-01\n",
      "Initial loss:  895575.83275242\n",
      "best loss: 4341.25\t\tLearning rate: 1.438e-02, Batch size: 37, Momentum: 7.887e-01\n",
      "Initial loss:  1184387.1068912132\n",
      "best loss: 1015666.59\t\tLearning rate: 4.281e-02, Batch size: 27, Momentum: 0.000e+00\n",
      "Initial loss:  968010.9009782188\n",
      "best loss: 5740.98\t\tLearning rate: 1.000e+01, Batch size: 44, Momentum: 7.887e-01\n",
      "Initial loss:  1101915.9845707854\n",
      "best loss: 886650.32\t\tLearning rate: 2.069e-05, Batch size: 29, Momentum: 3.155e-01\n",
      "Initial loss:  1142896.9116567718\n",
      "best loss: 4881.08\t\tLearning rate: 3.793e-01, Batch size: 7, Momentum: 3.681e-01\n",
      "Initial loss:  1365378.511989496\n",
      "best loss: 3239.04\t\tLearning rate: 1.833e-04, Batch size: 44, Momentum: 3.681e-01\n",
      "Initial loss:  1546082.7620297475\n",
      "best loss: 5226.78\t\tLearning rate: 3.793e-01, Batch size: 34, Momentum: 9.464e-01\n",
      "Initial loss:  1011997.7093837922\n",
      "best loss: 4888.88\t\tLearning rate: 3.793e-01, Batch size: 44, Momentum: 5.784e-01\n",
      "Initial loss:  2012552.681493904\n",
      "best loss: 12648.80\t\tLearning rate: 1.000e-08, Batch size: 4, Momentum: 5.258e-02\n",
      "Initial loss:  1811.4442966190902\n",
      "best loss: 1782.83\t\tLearning rate: 6.158e-05, Batch size: 24, Momentum: 6.309e-01\n",
      "Initial loss:  746335.8764790697\n",
      "best loss: 4741.98\t\tLearning rate: 3.793e-01, Batch size: 50, Momentum: 3.681e-01\n",
      "Initial loss:  629518.5029641289\n",
      "best loss: 3068.83\t\tLearning rate: 1.833e-04, Batch size: 39, Momentum: 1.577e-01\n",
      "Initial loss:  246537.95265922463\n",
      "best loss: 4838.55\t\tLearning rate: 3.793e-01, Batch size: 12, Momentum: 5.784e-01\n",
      "Initial loss:  370454.9636741311\n",
      "best loss: 1757.63\t\tLearning rate: 2.637e-07, Batch size: 4, Momentum: 2.103e-01\n",
      "Initial loss:  303712.75526783266\n",
      "best loss: 1793.98\t\tLearning rate: 8.859e-08, Batch size: 19, Momentum: 5.258e-01\n",
      "Initial loss:  420979.0921900942\n",
      "best loss: 2510.22\t\tLearning rate: 2.336e-06, Batch size: 50, Momentum: 8.938e-01\n",
      "Initial loss:  540613.0851769558\n",
      "best loss: 56791.82\t\tLearning rate: 1.438e-02, Batch size: 17, Momentum: 3.155e-01\n",
      "Initial loss:  669664.4094663862\n",
      "best loss: 4637.39\t\tLearning rate: 3.793e-01, Batch size: 7, Momentum: 1.577e-01\n",
      "Initial loss:  1303860.575957717\n",
      "best loss: 5833.79\t\tLearning rate: 1.000e+01, Batch size: 2, Momentum: 8.413e-01\n",
      "Initial loss:  830012.8142557908\n",
      "best loss: 5130.67\t\tLearning rate: 1.129e+00, Batch size: 29, Momentum: 6.309e-01\n",
      "Initial loss:  578085.7800187629\n",
      "best loss: 5595.95\t\tLearning rate: 1.000e+01, Batch size: 37, Momentum: 5.784e-01\n",
      "Initial loss:  1220945.1299349598\n",
      "best loss: 4207.75\t\tLearning rate: 4.281e-02, Batch size: 50, Momentum: 2.103e-01\n",
      "Initial loss:  196836.9849647989\n",
      "best loss: 8461.97\t\tLearning rate: 4.833e-03, Batch size: 2, Momentum: 1.577e-01\n",
      "Initial loss:  1481799.3186056518\n",
      "best loss: 1836.51\t\tLearning rate: 2.976e-08, Batch size: 19, Momentum: 5.258e-01\n",
      "Initial loss:  131880.52991634762\n",
      "best loss: 5383.33\t\tLearning rate: 1.129e+00, Batch size: 50, Momentum: 9.464e-01\n",
      "Initial loss:  718558.1809961975\n",
      "best loss: 2900.95\t\tLearning rate: 6.158e-05, Batch size: 44, Momentum: 3.155e-01\n",
      "Initial loss:  704440.5304401328\n",
      "best loss: 135767.82\t\tLearning rate: 3.360e+00, Batch size: 9, Momentum: 3.681e-01\n",
      "Initial loss:  598896.7663018127\n",
      "best loss: 4461.62\t\tLearning rate: 4.281e-02, Batch size: 39, Momentum: 4.732e-01\n",
      "Initial loss:  1168325.4604087602\n",
      "best loss: 1882.67\t\tLearning rate: 2.637e-07, Batch size: 47, Momentum: 5.258e-02\n",
      "Initial loss:  1889439.9377760722\n",
      "best loss: 4932.56\t\tLearning rate: 1.129e+00, Batch size: 4, Momentum: 2.103e-01\n",
      "Initial loss:  1135674.5487619063\n",
      "best loss: 4245.89\t\tLearning rate: 4.281e-02, Batch size: 32, Momentum: 3.155e-01\n",
      "Initial loss:  828297.1369594254\n",
      "best loss: 196431.36\t\tLearning rate: 1.624e-03, Batch size: 2, Momentum: 3.155e-01\n",
      "Initial loss:  522924.9862873645\n",
      "best loss: 1843.31\t\tLearning rate: 2.976e-08, Batch size: 37, Momentum: 7.361e-01\n",
      "Initial loss:  1273123.3435468609\n",
      "best loss: 3165.48\t\tLearning rate: 6.158e-05, Batch size: 27, Momentum: 4.206e-01\n",
      "Initial loss:  389826.48164887185\n",
      "best loss: 3127.78\t\tLearning rate: 2.069e-05, Batch size: 47, Momentum: 7.887e-01\n",
      "Initial loss:  2014193.0549124554\n",
      "best loss: 2252.11\t\tLearning rate: 2.336e-06, Batch size: 22, Momentum: 7.361e-01\n",
      "Initial loss:  1730424.6142680172\n",
      "best loss: 3827.68\t\tLearning rate: 5.456e-04, Batch size: 9, Momentum: 9.464e-01\n",
      "Initial loss:  1296594.6177513269\n",
      "best loss: 3376.47\t\tLearning rate: 5.456e-04, Batch size: 12, Momentum: 2.103e-01\n",
      "Initial loss:  1209287.2469510692\n",
      "best loss: 4912.30\t\tLearning rate: 3.793e-01, Batch size: 50, Momentum: 6.309e-01\n",
      "Initial loss:  553192.0120123104\n",
      "best loss: 3955.24\t\tLearning rate: 1.624e-03, Batch size: 50, Momentum: 7.887e-01\n",
      "Initial loss:  68153.44808887507\n",
      "best loss: 50994.03\t\tLearning rate: 1.000e-08, Batch size: 32, Momentum: 3.155e-01\n",
      "Initial loss:  1072358.420798004\n",
      "best loss: 4491.04\t\tLearning rate: 1.274e-01, Batch size: 50, Momentum: 2.103e-01\n",
      "Initial loss:  1795.400282209729\n",
      "best loss: 1768.22\t\tLearning rate: 1.000e+01, Batch size: 27, Momentum: 2.629e-01\n",
      "Initial loss:  2683882.1783791\n",
      "best loss: 5057.62\t\tLearning rate: 1.274e-01, Batch size: 50, Momentum: 9.990e-01\n",
      "Initial loss:  1788.6512250224841\n",
      "best loss: 1771.05\t\tLearning rate: 6.952e-06, Batch size: 32, Momentum: 7.887e-01\n",
      "Initial loss:  1820.2513365270884\n",
      "best loss: 1716.63\t\tLearning rate: 1.624e-03, Batch size: 2, Momentum: 1.052e-01\n",
      "Initial loss:  1263052.1353460748\n",
      "best loss: 1994.38\t\tLearning rate: 2.336e-06, Batch size: 9, Momentum: 4.206e-01\n",
      "Initial loss:  625790.6334593914\n",
      "best loss: 3524.32\t\tLearning rate: 1.833e-04, Batch size: 39, Momentum: 7.361e-01\n",
      "Initial loss:  260940.19217457855\n",
      "best loss: 3858.18\t\tLearning rate: 5.456e-04, Batch size: 4, Momentum: 9.464e-01\n",
      "Initial loss:  432743.5893636916\n",
      "best loss: 3894.38\t\tLearning rate: 4.833e-03, Batch size: 39, Momentum: 3.681e-01\n",
      "Initial loss:  306319.52610196907\n",
      "best loss: 13196.67\t\tLearning rate: 8.859e-08, Batch size: 17, Momentum: 5.784e-01\n",
      "Initial loss:  779893.8139400702\n",
      "best loss: 2553.11\t\tLearning rate: 2.069e-05, Batch size: 39, Momentum: 1.052e-01\n",
      "Initial loss:  1481029.3931405752\n",
      "best loss: 2935639.11\t\tLearning rate: 2.069e-05, Batch size: 27, Momentum: 4.206e-01\n",
      "Initial loss:  254281.84416513925\n",
      "best loss: 1733.78\t\tLearning rate: 2.637e-07, Batch size: 4, Momentum: 3.681e-01\n",
      "Initial loss:  1833965.4779084006\n",
      "best loss: 4690.52\t\tLearning rate: 1.438e-02, Batch size: 27, Momentum: 9.990e-01\n",
      "Initial loss:  1150884.1679621355\n",
      "best loss: 3679.42\t\tLearning rate: 5.456e-04, Batch size: 34, Momentum: 7.887e-01\n",
      "Initial loss:  2189823.6904203002\n",
      "best loss: 3429.04\t\tLearning rate: 5.456e-04, Batch size: 32, Momentum: 3.681e-01\n",
      "Initial loss:  352380.62651242496\n",
      "best loss: 1771.70\t\tLearning rate: 2.637e-07, Batch size: 9, Momentum: 8.413e-01\n",
      "Initial loss:  277364.52907891007\n",
      "best loss: 5164.62\t\tLearning rate: 3.793e-01, Batch size: 39, Momentum: 9.464e-01\n",
      "Initial loss:  803427.6759473118\n",
      "best loss: 1773.45\t\tLearning rate: 2.976e-08, Batch size: 9, Momentum: 7.361e-01\n",
      "Initial loss:  1150884.8185315272\n",
      "best loss: 3222.01\t\tLearning rate: 5.456e-04, Batch size: 9, Momentum: 2.629e-01\n",
      "Initial loss:  1846045.6486527114\n",
      "best loss: 29175.92\t\tLearning rate: 2.976e-08, Batch size: 12, Momentum: 8.413e-01\n",
      "Initial loss:  124579.89333901802\n",
      "best loss: 4370.67\t\tLearning rate: 4.281e-02, Batch size: 22, Momentum: 5.258e-01\n",
      "Initial loss:  1009162.341317106\n",
      "best loss: 5720.46\t\tLearning rate: 1.000e+01, Batch size: 34, Momentum: 7.887e-01\n",
      "Initial loss:  557109.7156035495\n",
      "best loss: 3534.23\t\tLearning rate: 5.456e-04, Batch size: 7, Momentum: 4.206e-01\n",
      "Initial loss:  675936.1117301092\n",
      "best loss: 4386.26\t\tLearning rate: 4.281e-02, Batch size: 44, Momentum: 4.206e-01\n",
      "Initial loss:  1952545.6611307156\n",
      "best loss: 3640.81\t\tLearning rate: 1.833e-04, Batch size: 44, Momentum: 7.887e-01\n",
      "Initial loss:  450950.2102095783\n",
      "best loss: 4446.49\t\tLearning rate: 1.438e-02, Batch size: 44, Momentum: 8.413e-01\n",
      "Initial loss:  777349.9066799675\n",
      "best loss: 3884.80\t\tLearning rate: 1.624e-03, Batch size: 32, Momentum: 9.464e-01\n",
      "Initial loss:  426663.6011761122\n",
      "best loss: 3274.59\t\tLearning rate: 1.833e-04, Batch size: 4, Momentum: 3.681e-01\n",
      "Initial loss:  1401512.9317593544\n",
      "best loss: 2641.03\t\tLearning rate: 2.336e-06, Batch size: 14, Momentum: 9.464e-01\n",
      "Initial loss:  1806.8025746143155\n",
      "best loss: 1807.68\t\tLearning rate: 2.336e-06, Batch size: 27, Momentum: 6.309e-01\n",
      "Initial loss:  1322331.3733465606\n",
      "best loss: 5470.67\t\tLearning rate: 1.129e+00, Batch size: 24, Momentum: 9.990e-01\n",
      "Initial loss:  1656691.169887301\n",
      "best loss: 4532.28\t\tLearning rate: 1.274e-01, Batch size: 4, Momentum: 3.681e-01\n",
      "Initial loss:  2031824.9873530364\n",
      "best loss: 1485476.30\t\tLearning rate: 2.069e-05, Batch size: 50, Momentum: 3.155e-01\n",
      "Initial loss:  1409565.1928678388\n",
      "best loss: 344459.41\t\tLearning rate: 8.859e-08, Batch size: 34, Momentum: 5.784e-01\n",
      "Initial loss:  873155.8624958753\n",
      "best loss: 125937.10\t\tLearning rate: 1.000e-08, Batch size: 42, Momentum: 5.784e-01\n",
      "Initial loss:  1529304.1960835813\n",
      "best loss: 9566.93\t\tLearning rate: 6.158e-05, Batch size: 4, Momentum: 5.258e-02\n",
      "Initial loss:  542802.1712053298\n",
      "best loss: 4894.23\t\tLearning rate: 3.793e-01, Batch size: 19, Momentum: 8.938e-01\n",
      "Initial loss:  656024.4089330914\n",
      "best loss: 6583909.96\t\tLearning rate: 1.438e-02, Batch size: 44, Momentum: 3.155e-01\n",
      "Initial loss:  1826246.1326605792\n",
      "best loss: 3956.47\t\tLearning rate: 1.624e-03, Batch size: 50, Momentum: 8.938e-01\n",
      "Initial loss:  755557.1785985051\n",
      "best loss: 1863.22\t\tLearning rate: 2.637e-07, Batch size: 47, Momentum: 1.577e-01\n",
      "Initial loss:  1407361.5534041242\n",
      "best loss: 3272.93\t\tLearning rate: 5.456e-04, Batch size: 9, Momentum: 5.258e-02\n",
      "Initial loss:  620268.1939308667\n",
      "best loss: 412141.73\t\tLearning rate: 1.833e-04, Batch size: 42, Momentum: 3.155e-01\n",
      "Initial loss:  505512.4367380079\n",
      "best loss: 1992032.50\t\tLearning rate: 4.281e-02, Batch size: 7, Momentum: 1.052e-01\n",
      "Initial loss:  578414.2625382533\n",
      "best loss: 5089.60\t\tLearning rate: 1.129e+00, Batch size: 44, Momentum: 5.784e-01\n",
      "Initial loss:  689341.9831388564\n",
      "best loss: 1757.76\t\tLearning rate: 2.637e-07, Batch size: 9, Momentum: 3.681e-01\n",
      "Initial loss:  183288.09043019896\n",
      "best loss: 1802.86\t\tLearning rate: 7.848e-07, Batch size: 19, Momentum: 5.258e-01\n",
      "Initial loss:  1356387.7946332237\n",
      "best loss: 2888.35\t\tLearning rate: 6.952e-06, Batch size: 27, Momentum: 7.887e-01\n",
      "Initial loss:  577312.9069790597\n",
      "best loss: 109617.35\t\tLearning rate: 1.000e-08, Batch size: 17, Momentum: 1.052e-01\n",
      "Initial loss:  1509246.2834490526\n",
      "best loss: 5183.08\t\tLearning rate: 3.360e+00, Batch size: 44, Momentum: 3.681e-01\n",
      "Initial loss:  684272.3732907737\n",
      "best loss: 1772.53\t\tLearning rate: 8.859e-08, Batch size: 4, Momentum: 5.784e-01\n",
      "Initial loss:  2501557.789975825\n",
      "best loss: 884320.92\t\tLearning rate: 4.281e-02, Batch size: 44, Momentum: 2.629e-01\n",
      "Initial loss:  1380777.6824564028\n",
      "best loss: 1927.55\t\tLearning rate: 7.848e-07, Batch size: 37, Momentum: 9.464e-01\n",
      "Initial loss:  1809731.961274682\n",
      "best loss: 4489.63\t\tLearning rate: 1.274e-01, Batch size: 9, Momentum: 3.681e-01\n",
      "Initial loss:  707239.9526190225\n",
      "best loss: 3421.02\t\tLearning rate: 5.456e-04, Batch size: 4, Momentum: 3.155e-01\n",
      "Initial loss:  1274680.6095557823\n",
      "best loss: 3119.85\t\tLearning rate: 1.833e-04, Batch size: 32, Momentum: 1.577e-01\n",
      "Initial loss:  180586.087055057\n",
      "best loss: 1774.61\t\tLearning rate: 7.848e-07, Batch size: 27, Momentum: 5.258e-02\n",
      "Initial loss:  297115.7353533744\n",
      "best loss: 2727.05\t\tLearning rate: 6.952e-06, Batch size: 17, Momentum: 4.732e-01\n",
      "Initial loss:  2417973.366090773\n",
      "best loss: 101484.17\t\tLearning rate: 1.000e-08, Batch size: 47, Momentum: 3.155e-01\n",
      "Initial loss:  1674334.715777549\n",
      "best loss: 3714.50\t\tLearning rate: 1.624e-03, Batch size: 9, Momentum: 4.206e-01\n",
      "Initial loss:  3153147.542349105\n",
      "best loss: 2742.37\t\tLearning rate: 2.069e-05, Batch size: 9, Momentum: 1.577e-01\n",
      "Initial loss:  1352305.2428372346\n",
      "best loss: 1805.13\t\tLearning rate: 2.336e-06, Batch size: 27, Momentum: 1.577e-01\n",
      "Initial loss:  586278.2575904062\n",
      "best loss: 11872639.83\t\tLearning rate: 3.360e+00, Batch size: 44, Momentum: 2.103e-01\n",
      "Initial loss:  1430102.1605667416\n",
      "best loss: 4020.73\t\tLearning rate: 4.833e-03, Batch size: 44, Momentum: 8.413e-01\n",
      "Initial loss:  1506001.652582446\n",
      "best loss: 2785.69\t\tLearning rate: 2.336e-06, Batch size: 12, Momentum: 9.464e-01\n",
      "Initial loss:  1062926.1243424884\n",
      "best loss: 5651.95\t\tLearning rate: 1.000e+01, Batch size: 17, Momentum: 6.835e-01\n",
      "Initial loss:  273005.38628316607\n",
      "best loss: 4520.30\t\tLearning rate: 1.274e-01, Batch size: 9, Momentum: 3.155e-01\n",
      "Initial loss:  1200830.0033835196\n",
      "best loss: 4529.38\t\tLearning rate: 4.281e-02, Batch size: 50, Momentum: 7.361e-01\n",
      "Initial loss:  236361.25949756955\n",
      "best loss: 497084.48\t\tLearning rate: 4.833e-03, Batch size: 22, Momentum: 5.258e-02\n",
      "Initial loss:  780292.19152829\n",
      "best loss: 47029.85\t\tLearning rate: 2.637e-07, Batch size: 50, Momentum: 5.258e-01\n",
      "Initial loss:  377827.47420016327\n",
      "best loss: 76508.28\t\tLearning rate: 2.976e-08, Batch size: 12, Momentum: 7.361e-01\n",
      "Initial loss:  1288877.9456964424\n",
      "best loss: 1752.28\t\tLearning rate: 8.859e-08, Batch size: 7, Momentum: 7.887e-01\n",
      "Initial loss:  252461.30003103658\n",
      "best loss: 3820.20\t\tLearning rate: 5.456e-04, Batch size: 22, Momentum: 8.938e-01\n",
      "Initial loss:  1183936.0035941782\n",
      "best loss: 51970.30\t\tLearning rate: 2.976e-08, Batch size: 37, Momentum: 7.887e-01\n",
      "Initial loss:  141884.0235056231\n",
      "best loss: 4420.76\t\tLearning rate: 1.438e-02, Batch size: 4, Momentum: 9.464e-01\n",
      "Initial loss:  468619.4276525286\n",
      "best loss: 3443.37\t\tLearning rate: 5.456e-04, Batch size: 14, Momentum: 4.206e-01\n",
      "Initial loss:  2271046.611945817\n",
      "best loss: 2918.73\t\tLearning rate: 6.158e-05, Batch size: 27, Momentum: 4.732e-01\n",
      "Initial loss:  2612505.6094422936\n",
      "best loss: 769895.95\t\tLearning rate: 2.976e-08, Batch size: 50, Momentum: 2.629e-01\n",
      "Initial loss:  3369038.478788433\n",
      "best loss: 5816.34\t\tLearning rate: 1.000e+01, Batch size: 14, Momentum: 8.413e-01\n",
      "Initial loss:  788998.1229438877\n",
      "best loss: 3549.23\t\tLearning rate: 1.833e-04, Batch size: 39, Momentum: 8.413e-01\n",
      "Initial loss:  87949.25230804052\n",
      "best loss: 4461.82\t\tLearning rate: 4.281e-02, Batch size: 9, Momentum: 5.784e-01\n",
      "Initial loss:  1518008.221932015\n",
      "best loss: 3183.61\t\tLearning rate: 6.158e-05, Batch size: 4, Momentum: 9.464e-01\n",
      "Initial loss:  1564814.3801180515\n",
      "best loss: 64461.15\t\tLearning rate: 2.976e-08, Batch size: 14, Momentum: 0.000e+00\n",
      "Initial loss:  1899.7273853633972\n",
      "best loss: 1823.05\t\tLearning rate: 2.069e-05, Batch size: 17, Momentum: 6.309e-01\n",
      "Initial loss:  1048893.1466446875\n",
      "best loss: 5055.59\t\tLearning rate: 3.793e-01, Batch size: 32, Momentum: 7.361e-01\n",
      "Initial loss:  941182.8871181417\n",
      "best loss: 255963.54\t\tLearning rate: 1.129e+00, Batch size: 14, Momentum: 1.577e-01\n",
      "Initial loss:  1686486.4891978183\n",
      "best loss: 5700.99\t\tLearning rate: 1.000e+01, Batch size: 44, Momentum: 7.361e-01\n",
      "Initial loss:  1256057.6274916083\n",
      "best loss: 3666.68\t\tLearning rate: 1.624e-03, Batch size: 4, Momentum: 3.681e-01\n",
      "Initial loss:  1700664.3248463287\n",
      "best loss: 4973.33\t\tLearning rate: 1.129e+00, Batch size: 44, Momentum: 3.155e-01\n",
      "Initial loss:  2123883.302635113\n",
      "best loss: 3993.04\t\tLearning rate: 4.833e-03, Batch size: 12, Momentum: 6.309e-01\n",
      "Initial loss:  1775.257137200291\n",
      "best loss: 1710.50\t\tLearning rate: 1.000e+01, Batch size: 2, Momentum: 7.887e-01\n",
      "Initial loss:  806612.1092473648\n",
      "best loss: 4794.72\t\tLearning rate: 3.793e-01, Batch size: 9, Momentum: 1.577e-01\n",
      "Initial loss:  533278.3534296403\n",
      "best loss: 3234.79\t\tLearning rate: 6.158e-05, Batch size: 39, Momentum: 6.309e-01\n",
      "Initial loss:  1777130.0539389853\n",
      "best loss: 5248.89\t\tLearning rate: 1.129e+00, Batch size: 22, Momentum: 8.413e-01\n",
      "Initial loss:  405371.2950280146\n",
      "best loss: 342082.14\t\tLearning rate: 1.000e+01, Batch size: 19, Momentum: 0.000e+00\n",
      "Initial loss:  1152057.8948243016\n",
      "best loss: 1826.59\t\tLearning rate: 2.336e-06, Batch size: 39, Momentum: 1.577e-01\n",
      "Initial loss:  55933.60182359405\n",
      "best loss: 2797.20\t\tLearning rate: 2.336e-06, Batch size: 50, Momentum: 9.990e-01\n",
      "Initial loss:  853584.7519136019\n",
      "best loss: 5531.36\t\tLearning rate: 3.360e+00, Batch size: 50, Momentum: 8.413e-01\n",
      "Initial loss:  1779.20919705947\n",
      "best loss: 1766.07\t\tLearning rate: 2.069e-05, Batch size: 39, Momentum: 9.464e-01\n",
      "Initial loss:  948734.94082806\n",
      "best loss: 4078.87\t\tLearning rate: 4.833e-03, Batch size: 32, Momentum: 7.887e-01\n",
      "Initial loss:  450923.4637118145\n",
      "best loss: 2951.68\t\tLearning rate: 2.069e-05, Batch size: 14, Momentum: 3.681e-01\n",
      "Initial loss:  794784.0339373971\n",
      "best loss: 1761.20\t\tLearning rate: 2.637e-07, Batch size: 9, Momentum: 6.309e-01\n",
      "Initial loss:  713036.1428640177\n",
      "best loss: 1787.93\t\tLearning rate: 8.859e-08, Batch size: 19, Momentum: 6.835e-01\n",
      "Initial loss:  72544.79459111499\n",
      "best loss: 3931.17\t\tLearning rate: 4.833e-03, Batch size: 27, Momentum: 6.309e-01\n",
      "Initial loss:  1403960.138678518\n",
      "best loss: 135882.73\t\tLearning rate: 8.859e-08, Batch size: 27, Momentum: 4.732e-01\n",
      "Initial loss:  577617.4324260753\n",
      "best loss: 5130.44\t\tLearning rate: 1.129e+00, Batch size: 39, Momentum: 6.835e-01\n",
      "Initial loss:  525747.7539435762\n",
      "best loss: 2766.42\t\tLearning rate: 6.952e-06, Batch size: 44, Momentum: 6.309e-01\n",
      "Initial loss:  1792.080268623788\n",
      "best loss: 1778.81\t\tLearning rate: 4.281e-02, Batch size: 34, Momentum: 6.835e-01\n",
      "Initial loss:  990563.4730044308\n",
      "best loss: 3838.58\t\tLearning rate: 1.624e-03, Batch size: 17, Momentum: 7.361e-01\n",
      "Initial loss:  1713936.8916299636\n",
      "best loss: 39698.77\t\tLearning rate: 2.069e-05, Batch size: 14, Momentum: 5.784e-01\n",
      "Initial loss:  773878.1149578247\n",
      "best loss: 3383.52\t\tLearning rate: 2.069e-05, Batch size: 14, Momentum: 9.990e-01\n",
      "Initial loss:  1399986.6213738564\n",
      "best loss: 313885.67\t\tLearning rate: 4.281e-02, Batch size: 22, Momentum: 2.103e-01\n",
      "Initial loss:  1174074.7111197794\n",
      "best loss: 599018.91\t\tLearning rate: 6.952e-06, Batch size: 34, Momentum: 2.103e-01\n",
      "Initial loss:  1584259.8433841204\n",
      "best loss: 4402.68\t\tLearning rate: 1.438e-02, Batch size: 9, Momentum: 8.413e-01\n",
      "Initial loss:  1839.7140044703622\n",
      "best loss: 1800.65\t\tLearning rate: 7.848e-07, Batch size: 7, Momentum: 1.052e-01\n",
      "Initial loss:  1950977.4974511636\n",
      "best loss: 2908.10\t\tLearning rate: 2.069e-05, Batch size: 32, Momentum: 6.835e-01\n",
      "Initial loss:  1215582.474924503\n",
      "best loss: 3032.61\t\tLearning rate: 6.952e-06, Batch size: 22, Momentum: 9.464e-01\n",
      "Initial loss:  1781838.6129587498\n",
      "best loss: 4348.49\t\tLearning rate: 1.274e-01, Batch size: 32, Momentum: 1.577e-01\n",
      "Initial loss:  531254.43913664\n",
      "best loss: 4253.86\t\tLearning rate: 4.281e-02, Batch size: 47, Momentum: 2.629e-01\n",
      "Initial loss:  1536528.2052032347\n",
      "best loss: 5928.86\t\tLearning rate: 1.000e+01, Batch size: 24, Momentum: 9.990e-01\n",
      "Initial loss:  715724.1289298988\n",
      "best loss: 1825.93\t\tLearning rate: 7.848e-07, Batch size: 44, Momentum: 9.464e-01\n",
      "Initial loss:  1462795.8224412357\n",
      "best loss: 5453.04\t\tLearning rate: 3.360e+00, Batch size: 29, Momentum: 8.938e-01\n",
      "Initial loss:  1569395.9349930459\n",
      "best loss: 3959.91\t\tLearning rate: 1.624e-03, Batch size: 4, Momentum: 9.464e-01\n",
      "Initial loss:  277361.14644433267\n",
      "best loss: 5092.59\t\tLearning rate: 3.793e-01, Batch size: 24, Momentum: 8.413e-01\n",
      "Initial loss:  678651.8492161218\n",
      "best loss: 5326.00\t\tLearning rate: 3.360e+00, Batch size: 29, Momentum: 5.258e-01\n",
      "Initial loss:  670298.0581159692\n",
      "best loss: 4097.69\t\tLearning rate: 4.833e-03, Batch size: 37, Momentum: 7.361e-01\n",
      "Initial loss:  2016461.5449612776\n",
      "best loss: 4672.48\t\tLearning rate: 3.793e-01, Batch size: 32, Momentum: 1.577e-01\n",
      "Initial loss:  2487825.6777183297\n",
      "best loss: 3943.61\t\tLearning rate: 1.438e-02, Batch size: 2, Momentum: 1.577e-01\n",
      "Initial loss:  1226270.2019990897\n",
      "best loss: 425030.40\t\tLearning rate: 4.833e-03, Batch size: 34, Momentum: 0.000e+00\n",
      "Initial loss:  759479.7077579087\n",
      "best loss: 4492.85\t\tLearning rate: 1.274e-01, Batch size: 19, Momentum: 5.258e-01\n",
      "Initial loss:  1754.1326146111096\n",
      "best loss: 1677.30\t\tLearning rate: 1.000e-08, Batch size: 2, Momentum: 3.681e-01\n",
      "Initial loss:  2053261.1568233275\n",
      "best loss: 3707.91\t\tLearning rate: 1.624e-03, Batch size: 50, Momentum: 3.155e-01\n",
      "Initial loss:  1739.1563099786656\n",
      "best loss: 1712.38\t\tLearning rate: 1.274e-01, Batch size: 2, Momentum: 2.103e-01\n",
      "Initial loss:  1320917.0424276062\n",
      "best loss: 2528.55\t\tLearning rate: 2.069e-05, Batch size: 22, Momentum: 1.052e-01\n",
      "Initial loss:  87425.50449687683\n",
      "best loss: 2019.18\t\tLearning rate: 8.859e-08, Batch size: 50, Momentum: 1.052e-01\n",
      "Initial loss:  1532826.1600144906\n",
      "best loss: 1772.25\t\tLearning rate: 7.848e-07, Batch size: 14, Momentum: 5.258e-02\n",
      "Initial loss:  575025.6439167844\n",
      "best loss: 3931.11\t\tLearning rate: 1.624e-03, Batch size: 9, Momentum: 6.835e-01\n",
      "Initial loss:  1785.3328567716808\n",
      "best loss: 1767.63\t\tLearning rate: 1.438e-02, Batch size: 27, Momentum: 4.206e-01\n",
      "Initial loss:  1450901.1629746598\n",
      "best loss: 2667.74\t\tLearning rate: 2.069e-05, Batch size: 50, Momentum: 1.577e-01\n",
      "Initial loss:  1691563.9531933533\n",
      "best loss: 3893347.19\t\tLearning rate: 3.793e-01, Batch size: 27, Momentum: 4.732e-01\n",
      "Initial loss:  2364678.4490410527\n",
      "best loss: 4009.44\t\tLearning rate: 4.833e-03, Batch size: 50, Momentum: 6.309e-01\n",
      "Initial loss:  1659256.849341883\n",
      "best loss: 59757.87\t\tLearning rate: 5.456e-04, Batch size: 17, Momentum: 2.629e-01\n",
      "Initial loss:  1156110.3167378395\n",
      "best loss: 347270.33\t\tLearning rate: 1.624e-03, Batch size: 47, Momentum: 0.000e+00\n",
      "Initial loss:  1234678.7162671427\n",
      "best loss: 5779.39\t\tLearning rate: 1.000e+01, Batch size: 12, Momentum: 7.887e-01\n",
      "Initial loss:  1857436.1570289019\n",
      "best loss: 3343.58\t\tLearning rate: 1.833e-04, Batch size: 2, Momentum: 5.258e-01\n",
      "Initial loss:  1213011.2142726064\n",
      "best loss: 1781.54\t\tLearning rate: 2.976e-08, Batch size: 24, Momentum: 9.990e-01\n",
      "Initial loss:  140452.0087383038\n",
      "best loss: 1792.11\t\tLearning rate: 7.848e-07, Batch size: 39, Momentum: 9.464e-01\n",
      "Initial loss:  1304464.8857326587\n",
      "best loss: 1783.49\t\tLearning rate: 7.848e-07, Batch size: 22, Momentum: 8.938e-01\n",
      "Initial loss:  160009.21606450045\n",
      "best loss: 3900.67\t\tLearning rate: 1.624e-03, Batch size: 17, Momentum: 8.413e-01\n",
      "Initial loss:  813539.5666283595\n",
      "best loss: 4270.89\t\tLearning rate: 4.281e-02, Batch size: 32, Momentum: 5.258e-01\n",
      "Initial loss:  492506.9223282469\n",
      "best loss: 4295.21\t\tLearning rate: 4.281e-02, Batch size: 7, Momentum: 6.835e-01\n",
      "Initial loss:  1276661.6694470923\n",
      "best loss: 1057827.40\t\tLearning rate: 4.281e-02, Batch size: 42, Momentum: 3.681e-01\n",
      "Initial loss:  1208558.419189644\n",
      "best loss: 160883.37\t\tLearning rate: 8.859e-08, Batch size: 27, Momentum: 5.258e-02\n",
      "Initial loss:  2057031.1940480534\n",
      "best loss: 407865.73\t\tLearning rate: 1.000e-08, Batch size: 32, Momentum: 1.577e-01\n",
      "Initial loss:  365509.02323866007\n",
      "best loss: 2865.06\t\tLearning rate: 2.069e-05, Batch size: 12, Momentum: 6.309e-01\n",
      "Initial loss:  1757.353417130951\n",
      "best loss: 1716.37\t\tLearning rate: 6.158e-05, Batch size: 2, Momentum: 6.309e-01\n",
      "Initial loss:  1111919.741069342\n",
      "best loss: 116458.73\t\tLearning rate: 2.976e-08, Batch size: 7, Momentum: 3.155e-01\n",
      "Initial loss:  913081.3994858608\n",
      "best loss: 3114.29\t\tLearning rate: 2.069e-05, Batch size: 50, Momentum: 8.413e-01\n",
      "Initial loss:  1627539.112914512\n",
      "best loss: 3696.04\t\tLearning rate: 5.456e-04, Batch size: 34, Momentum: 7.887e-01\n",
      "Initial loss:  257694.50990456552\n",
      "best loss: 3339.53\t\tLearning rate: 6.158e-05, Batch size: 14, Momentum: 9.464e-01\n",
      "Initial loss:  1094351.7788148345\n",
      "best loss: 5365.96\t\tLearning rate: 3.360e+00, Batch size: 42, Momentum: 6.309e-01\n",
      "Initial loss:  1782.4780435273217\n",
      "best loss: 1769.74\t\tLearning rate: 6.158e-05, Batch size: 34, Momentum: 6.309e-01\n",
      "Initial loss:  3135778.957689689\n",
      "best loss: 4682.94\t\tLearning rate: 1.274e-01, Batch size: 9, Momentum: 6.835e-01\n",
      "Initial loss:  1835.0435741760584\n",
      "best loss: 1796.93\t\tLearning rate: 1.000e+01, Batch size: 7, Momentum: 2.629e-01\n",
      "Initial loss:  428215.30138411047\n",
      "best loss: 5368.17\t\tLearning rate: 1.000e+01, Batch size: 12, Momentum: 3.681e-01\n",
      "Initial loss:  1797.4718028071932\n",
      "best loss: 1766.93\t\tLearning rate: 5.456e-04, Batch size: 14, Momentum: 5.784e-01\n",
      "Initial loss:  1345134.444054347\n",
      "best loss: 25896.27\t\tLearning rate: 2.976e-08, Batch size: 14, Momentum: 5.784e-01\n",
      "Initial loss:  994818.5808725959\n",
      "best loss: 2175.93\t\tLearning rate: 7.848e-07, Batch size: 24, Momentum: 9.464e-01\n",
      "Initial loss:  1024362.8977563367\n",
      "best loss: 5248.57\t\tLearning rate: 3.793e-01, Batch size: 32, Momentum: 9.990e-01\n",
      "Initial loss:  700156.9373786324\n",
      "best loss: 2904.69\t\tLearning rate: 6.158e-05, Batch size: 9, Momentum: 5.258e-02\n",
      "Initial loss:  1085054.0744112104\n",
      "best loss: 4595.83\t\tLearning rate: 1.274e-01, Batch size: 39, Momentum: 4.732e-01\n",
      "Initial loss:  755498.0644479978\n",
      "best loss: 12175916.22\t\tLearning rate: 5.456e-04, Batch size: 2, Momentum: 1.052e-01\n",
      "Initial loss:  1491205.069944417\n",
      "best loss: 2362.39\t\tLearning rate: 6.952e-06, Batch size: 19, Momentum: 1.577e-01\n",
      "Initial loss:  1843.200878623955\n",
      "best loss: 1801.54\t\tLearning rate: 4.833e-03, Batch size: 22, Momentum: 4.732e-01\n",
      "Initial loss:  477921.42554048024\n",
      "best loss: 3375.18\t\tLearning rate: 5.456e-04, Batch size: 27, Momentum: 2.629e-01\n",
      "Initial loss:  2061402.0455125442\n",
      "best loss: 2103.24\t\tLearning rate: 6.952e-06, Batch size: 24, Momentum: 2.103e-01\n",
      "Initial loss:  1493411.0645331081\n",
      "best loss: 4138.85\t\tLearning rate: 1.624e-03, Batch size: 9, Momentum: 9.990e-01\n",
      "Initial loss:  815447.4472118545\n",
      "best loss: 168204.68\t\tLearning rate: 1.129e+00, Batch size: 44, Momentum: 4.206e-01\n",
      "Initial loss:  1248689.679935535\n",
      "best loss: 1775.87\t\tLearning rate: 2.637e-07, Batch size: 9, Momentum: 5.258e-01\n",
      "Initial loss:  1030681.9652673807\n",
      "best loss: 3323.46\t\tLearning rate: 5.456e-04, Batch size: 27, Momentum: 1.052e-01\n",
      "Initial loss:  728341.65398629\n",
      "best loss: 5012.09\t\tLearning rate: 3.793e-01, Batch size: 29, Momentum: 7.887e-01\n",
      "Initial loss:  954540.8958328922\n",
      "best loss: 5039.35\t\tLearning rate: 1.129e+00, Batch size: 4, Momentum: 4.732e-01\n",
      "Initial loss:  1067063.5225735337\n",
      "best loss: 4564.70\t\tLearning rate: 1.274e-01, Batch size: 17, Momentum: 6.309e-01\n",
      "Initial loss:  1996319.5924678128\n",
      "best loss: 1775.05\t\tLearning rate: 2.336e-06, Batch size: 12, Momentum: 2.629e-01\n",
      "Initial loss:  1345188.2228825833\n",
      "best loss: 1806.35\t\tLearning rate: 7.848e-07, Batch size: 17, Momentum: 8.413e-01\n",
      "Initial loss:  1318122.8666658772\n",
      "best loss: 54922.77\t\tLearning rate: 3.793e-01, Batch size: 37, Momentum: 0.000e+00\n",
      "Initial loss:  281628.49812195264\n",
      "best loss: 4588.91\t\tLearning rate: 3.793e-01, Batch size: 14, Momentum: 3.155e-01\n",
      "Initial loss:  410187.5767320434\n",
      "best loss: 1850.40\t\tLearning rate: 2.976e-08, Batch size: 9, Momentum: 6.309e-01\n",
      "Initial loss:  540670.0649937533\n",
      "best loss: 1883.88\t\tLearning rate: 2.637e-07, Batch size: 19, Momentum: 3.155e-01\n",
      "Initial loss:  1796.0231512232263\n",
      "best loss: 1744.23\t\tLearning rate: 1.129e+00, Batch size: 12, Momentum: 5.784e-01\n",
      "Initial loss:  1965756.410092495\n",
      "best loss: 330813.87\t\tLearning rate: 2.976e-08, Batch size: 42, Momentum: 6.835e-01\n",
      "Initial loss:  693001.9713932999\n",
      "best loss: 265759.82\t\tLearning rate: 1.129e+00, Batch size: 47, Momentum: 5.258e-02\n",
      "Initial loss:  2374368.872170452\n",
      "best loss: 71122.17\t\tLearning rate: 3.793e-01, Batch size: 7, Momentum: 5.258e-02\n",
      "Initial loss:  1229074.4928500247\n",
      "best loss: 4638.97\t\tLearning rate: 4.281e-02, Batch size: 47, Momentum: 8.413e-01\n",
      "Initial loss:  1643538.9175532572\n",
      "best loss: 2982.41\t\tLearning rate: 6.158e-05, Batch size: 7, Momentum: 3.155e-01\n",
      "Initial loss:  2473244.728772337\n",
      "best loss: 912777.54\t\tLearning rate: 2.976e-08, Batch size: 34, Momentum: 2.103e-01\n",
      "Initial loss:  1376622.5933650166\n",
      "best loss: 3472.81\t\tLearning rate: 5.456e-04, Batch size: 44, Momentum: 4.206e-01\n",
      "Initial loss:  1033138.6281538949\n",
      "best loss: 2934.35\t\tLearning rate: 6.952e-06, Batch size: 17, Momentum: 9.464e-01\n",
      "Initial loss:  738634.7796621172\n",
      "best loss: 1776.75\t\tLearning rate: 7.848e-07, Batch size: 44, Momentum: 6.309e-01\n",
      "Initial loss:  757115.0424686044\n",
      "best loss: 2510129.51\t\tLearning rate: 1.000e+01, Batch size: 47, Momentum: 0.000e+00\n",
      "Initial loss:  858037.9534651529\n",
      "best loss: 3103.99\t\tLearning rate: 6.158e-05, Batch size: 17, Momentum: 5.258e-01\n",
      "Initial loss:  1100168.1557481713\n",
      "best loss: 5200.43\t\tLearning rate: 1.129e+00, Batch size: 34, Momentum: 6.835e-01\n",
      "Initial loss:  1698053.7814903667\n",
      "best loss: 440054.23\t\tLearning rate: 1.624e-03, Batch size: 32, Momentum: 5.258e-02\n",
      "Initial loss:  428046.1565980796\n",
      "best loss: 4637.67\t\tLearning rate: 4.281e-02, Batch size: 9, Momentum: 8.413e-01\n",
      "Initial loss:  1186747.3707134724\n",
      "best loss: 3926.28\t\tLearning rate: 5.456e-04, Batch size: 19, Momentum: 9.464e-01\n",
      "Initial loss:  530464.8532546662\n",
      "best loss: 5615.59\t\tLearning rate: 3.360e+00, Batch size: 50, Momentum: 9.464e-01\n",
      "Initial loss:  1252031.9668921868\n",
      "best loss: 1787.53\t\tLearning rate: 2.637e-07, Batch size: 19, Momentum: 5.784e-01\n",
      "Initial loss:  835345.8973498665\n",
      "best loss: 4364.35\t\tLearning rate: 1.438e-02, Batch size: 37, Momentum: 6.835e-01\n",
      "Initial loss:  1629906.5885252964\n",
      "best loss: 3793.30\t\tLearning rate: 1.833e-04, Batch size: 7, Momentum: 9.990e-01\n",
      "Initial loss:  1240629.38886929\n",
      "best loss: 16480.78\t\tLearning rate: 3.793e-01, Batch size: 7, Momentum: 3.681e-01\n",
      "Initial loss:  1776766.4064185238\n",
      "best loss: 45411.47\t\tLearning rate: 2.976e-08, Batch size: 32, Momentum: 6.309e-01\n",
      "Initial loss:  1852655.0172761902\n",
      "best loss: 358384.93\t\tLearning rate: 2.637e-07, Batch size: 24, Momentum: 2.629e-01\n",
      "Initial loss:  913480.4890610222\n",
      "best loss: 4558.68\t\tLearning rate: 1.274e-01, Batch size: 2, Momentum: 3.681e-01\n",
      "Initial loss:  1782.2023495782964\n",
      "best loss: 1725.65\t\tLearning rate: 5.456e-04, Batch size: 2, Momentum: 1.577e-01\n",
      "Initial loss:  1028456.5684272852\n",
      "best loss: 4682.23\t\tLearning rate: 4.281e-02, Batch size: 27, Momentum: 8.413e-01\n",
      "Initial loss:  2366828.93297318\n",
      "best loss: 3880.85\t\tLearning rate: 4.833e-03, Batch size: 4, Momentum: 3.155e-01\n",
      "Initial loss:  1777.171146254155\n",
      "best loss: 1767.89\t\tLearning rate: 6.952e-06, Batch size: 27, Momentum: 2.629e-01\n",
      "Initial loss:  440880.14869359846\n",
      "best loss: 3694.85\t\tLearning rate: 2.976e-08, Batch size: 17, Momentum: 3.155e-01\n",
      "Initial loss:  574944.8965705867\n",
      "best loss: 1818.31\t\tLearning rate: 7.848e-07, Batch size: 44, Momentum: 1.052e-01\n",
      "Initial loss:  953808.9852591779\n",
      "best loss: 5025.33\t\tLearning rate: 1.129e+00, Batch size: 47, Momentum: 3.681e-01\n",
      "Initial loss:  64862.11329100906\n",
      "best loss: 4389511.56\t\tLearning rate: 1.624e-03, Batch size: 42, Momentum: 0.000e+00\n",
      "Initial loss:  136050.4538234687\n",
      "best loss: 5507673.74\t\tLearning rate: 4.281e-02, Batch size: 34, Momentum: 0.000e+00\n",
      "Initial loss:  743887.1112148545\n",
      "best loss: 148098.49\t\tLearning rate: 1.833e-04, Batch size: 12, Momentum: 1.052e-01\n",
      "Initial loss:  906670.1008186849\n",
      "best loss: 4164.26\t\tLearning rate: 1.438e-02, Batch size: 32, Momentum: 2.103e-01\n",
      "Initial loss:  376725.0409370731\n",
      "best loss: 1904.58\t\tLearning rate: 2.976e-08, Batch size: 17, Momentum: 5.258e-02\n",
      "Initial loss:  1369948.257584548\n",
      "best loss: 2292.08\t\tLearning rate: 6.952e-06, Batch size: 12, Momentum: 5.784e-01\n",
      "Initial loss:  1287202.6541970887\n",
      "best loss: 2890.94\t\tLearning rate: 6.158e-05, Batch size: 47, Momentum: 0.000e+00\n",
      "Initial loss:  1768.4331708154816\n",
      "best loss: 1753.96\t\tLearning rate: 1.833e-04, Batch size: 12, Momentum: 8.413e-01\n",
      "Initial loss:  813655.3446011802\n",
      "best loss: 1777.36\t\tLearning rate: 2.976e-08, Batch size: 9, Momentum: 9.990e-01\n",
      "Initial loss:  319446.28091698105\n",
      "best loss: 1856.37\t\tLearning rate: 8.859e-08, Batch size: 37, Momentum: 3.155e-01\n",
      "Initial loss:  1787.8086682086862\n",
      "best loss: 1778.42\t\tLearning rate: 1.624e-03, Batch size: 47, Momentum: 5.784e-01\n",
      "Initial loss:  938714.2709796571\n",
      "best loss: 2484.36\t\tLearning rate: 2.336e-06, Batch size: 50, Momentum: 7.887e-01\n",
      "Initial loss:  174927.17905880668\n",
      "best loss: 35771.62\t\tLearning rate: 2.976e-08, Batch size: 19, Momentum: 0.000e+00\n",
      "Initial loss:  477791.44201027363\n",
      "best loss: 6024.08\t\tLearning rate: 1.000e+01, Batch size: 47, Momentum: 9.990e-01\n",
      "Initial loss:  567963.7801308082\n",
      "best loss: 4037.42\t\tLearning rate: 1.438e-02, Batch size: 9, Momentum: 2.103e-01\n",
      "Initial loss:  297586.3448937326\n",
      "best loss: 2477.17\t\tLearning rate: 2.336e-06, Batch size: 29, Momentum: 8.938e-01\n",
      "Initial loss:  1349995.0897895051\n",
      "best loss: 4140529.83\t\tLearning rate: 1.438e-02, Batch size: 9, Momentum: 0.000e+00\n",
      "Initial loss:  1011885.0872326473\n",
      "best loss: 4168.78\t\tLearning rate: 1.438e-02, Batch size: 39, Momentum: 4.732e-01\n",
      "Initial loss:  1778.0702191177468\n",
      "best loss: 1769.89\t\tLearning rate: 2.336e-06, Batch size: 47, Momentum: 1.052e-01\n",
      "Initial loss:  1045631.731805397\n",
      "best loss: 3527.75\t\tLearning rate: 5.456e-04, Batch size: 50, Momentum: 4.206e-01\n",
      "Initial loss:  2357461.1289528464\n",
      "best loss: 1780.95\t\tLearning rate: 7.848e-07, Batch size: 7, Momentum: 5.258e-02\n",
      "Initial loss:  1796.0213716391759\n",
      "best loss: 1741.91\t\tLearning rate: 1.000e-08, Batch size: 4, Momentum: 9.990e-01\n",
      "Initial loss:  1431333.5987747794\n",
      "best loss: 4781.95\t\tLearning rate: 1.274e-01, Batch size: 47, Momentum: 7.887e-01\n",
      "Initial loss:  1851.8180459923062\n",
      "best loss: 1791.68\t\tLearning rate: 2.336e-06, Batch size: 17, Momentum: 6.309e-01\n",
      "Initial loss:  956200.388093867\n",
      "best loss: 259627.67\t\tLearning rate: 2.069e-05, Batch size: 32, Momentum: 5.258e-01\n",
      "Initial loss:  1945467.5815171073\n",
      "best loss: 457751.04\t\tLearning rate: 6.158e-05, Batch size: 34, Momentum: 4.732e-01\n",
      "Initial loss:  1109313.5031694388\n",
      "best loss: 93882.77\t\tLearning rate: 3.360e+00, Batch size: 32, Momentum: 1.052e-01\n",
      "Initial loss:  616696.2069489388\n",
      "best loss: 141979.90\t\tLearning rate: 2.976e-08, Batch size: 44, Momentum: 1.052e-01\n",
      "Initial loss:  1612913.9045119835\n",
      "best loss: 2778.20\t\tLearning rate: 6.952e-06, Batch size: 12, Momentum: 5.784e-01\n",
      "Initial loss:  1906367.4663917338\n",
      "best loss: 407647.29\t\tLearning rate: 8.859e-08, Batch size: 32, Momentum: 6.835e-01\n",
      "Initial loss:  1658555.9432543044\n",
      "best loss: 1774.15\t\tLearning rate: 8.859e-08, Batch size: 29, Momentum: 9.464e-01\n",
      "Initial loss:  1936539.0583754065\n",
      "best loss: 2673.58\t\tLearning rate: 6.158e-05, Batch size: 34, Momentum: 0.000e+00\n",
      "Initial loss:  201239.6008621109\n",
      "best loss: 5677.15\t\tLearning rate: 1.000e+01, Batch size: 17, Momentum: 7.361e-01\n",
      "Initial loss:  1095827.595555064\n",
      "best loss: 1797.17\t\tLearning rate: 8.859e-08, Batch size: 12, Momentum: 2.103e-01\n",
      "Initial loss:  2713630.9758081115\n",
      "best loss: 5059.51\t\tLearning rate: 1.274e-01, Batch size: 47, Momentum: 9.464e-01\n",
      "Initial loss:  670783.0473374347\n",
      "best loss: 4191.31\t\tLearning rate: 4.281e-02, Batch size: 9, Momentum: 2.103e-01\n",
      "Initial loss:  617765.6258870118\n",
      "best loss: 4228.28\t\tLearning rate: 1.438e-02, Batch size: 34, Momentum: 5.258e-01\n",
      "Initial loss:  454461.6809693137\n",
      "best loss: 3091.88\t\tLearning rate: 6.158e-05, Batch size: 12, Momentum: 3.681e-01\n",
      "Initial loss:  268243.64637272246\n",
      "best loss: 4262.86\t\tLearning rate: 1.438e-02, Batch size: 37, Momentum: 5.784e-01\n",
      "Initial loss:  1798.5040222482148\n",
      "best loss: 1765.30\t\tLearning rate: 7.848e-07, Batch size: 19, Momentum: 2.103e-01\n",
      "Initial loss:  1372399.478137858\n",
      "best loss: 3854.72\t\tLearning rate: 4.833e-03, Batch size: 22, Momentum: 2.629e-01\n",
      "Initial loss:  194983.7493138421\n",
      "best loss: 4034.41\t\tLearning rate: 1.624e-03, Batch size: 24, Momentum: 8.938e-01\n",
      "Initial loss:  1853465.930692351\n",
      "best loss: 5190.42\t\tLearning rate: 3.793e-01, Batch size: 14, Momentum: 9.464e-01\n",
      "Initial loss:  1773.2538300725175\n",
      "best loss: 1762.13\t\tLearning rate: 1.129e+00, Batch size: 27, Momentum: 6.835e-01\n",
      "Initial loss:  1826.5258351933498\n",
      "best loss: 1805.75\t\tLearning rate: 7.848e-07, Batch size: 39, Momentum: 2.629e-01\n",
      "Initial loss:  1835172.2404329125\n",
      "best loss: 2965675.66\t\tLearning rate: 1.624e-03, Batch size: 34, Momentum: 5.258e-02\n",
      "Initial loss:  1349511.9588247198\n",
      "best loss: 2573.80\t\tLearning rate: 6.952e-06, Batch size: 32, Momentum: 1.052e-01\n",
      "Initial loss:  1065607.5030343055\n",
      "best loss: 5448.16\t\tLearning rate: 1.000e+01, Batch size: 37, Momentum: 3.681e-01\n",
      "Initial loss:  1324922.2923294648\n",
      "best loss: 4047270.65\t\tLearning rate: 3.360e+00, Batch size: 42, Momentum: 6.835e-01\n",
      "Initial loss:  234790.4780040914\n",
      "best loss: 5101.17\t\tLearning rate: 3.360e+00, Batch size: 29, Momentum: 2.629e-01\n",
      "Initial loss:  2846167.2640506653\n",
      "best loss: 2997.45\t\tLearning rate: 6.158e-05, Batch size: 24, Momentum: 3.681e-01\n",
      "Initial loss:  1418978.0725000252\n",
      "best loss: 920751.89\t\tLearning rate: 1.000e+01, Batch size: 47, Momentum: 2.103e-01\n",
      "Initial loss:  2314905.9768107333\n",
      "best loss: 3919.51\t\tLearning rate: 1.624e-03, Batch size: 7, Momentum: 7.361e-01\n",
      "Initial loss:  1141748.1029286827\n",
      "best loss: 3449.88\t\tLearning rate: 5.456e-04, Batch size: 12, Momentum: 4.206e-01\n",
      "Initial loss:  1897880.6059121147\n",
      "best loss: 4256.17\t\tLearning rate: 4.281e-02, Batch size: 14, Momentum: 3.681e-01\n",
      "Initial loss:  505100.9994394009\n",
      "best loss: 113975.21\t\tLearning rate: 6.158e-05, Batch size: 17, Momentum: 1.577e-01\n",
      "Initial loss:  159200.52142150133\n",
      "best loss: 4085.76\t\tLearning rate: 1.624e-03, Batch size: 39, Momentum: 9.464e-01\n",
      "Initial loss:  141926.93249433188\n",
      "best loss: 1850.72\t\tLearning rate: 2.976e-08, Batch size: 42, Momentum: 5.258e-01\n",
      "Initial loss:  2141903.120267185\n",
      "best loss: 544547.16\t\tLearning rate: 2.976e-08, Batch size: 27, Momentum: 5.784e-01\n",
      "Initial loss:  728065.4719064613\n",
      "best loss: 4633.64\t\tLearning rate: 4.281e-02, Batch size: 19, Momentum: 7.887e-01\n",
      "Initial loss:  1650448.0234676288\n",
      "best loss: 4067.53\t\tLearning rate: 1.624e-03, Batch size: 34, Momentum: 8.938e-01\n",
      "Initial loss:  129758.07424885343\n",
      "best loss: 1805.21\t\tLearning rate: 2.976e-08, Batch size: 47, Momentum: 8.938e-01\n",
      "Initial loss:  804097.6436491235\n",
      "best loss: 3016867.83\t\tLearning rate: 6.158e-05, Batch size: 37, Momentum: 1.052e-01\n",
      "Initial loss:  1706132.8975134443\n",
      "best loss: 2712.15\t\tLearning rate: 6.952e-06, Batch size: 27, Momentum: 7.361e-01\n",
      "Initial loss:  379969.9996964469\n",
      "best loss: 5589.72\t\tLearning rate: 1.000e+01, Batch size: 22, Momentum: 4.732e-01\n",
      "Initial loss:  868474.7907204407\n",
      "best loss: 4312.14\t\tLearning rate: 1.274e-01, Batch size: 24, Momentum: 5.258e-02\n",
      "Initial loss:  1763414.1834540206\n",
      "best loss: 314617.90\t\tLearning rate: 2.637e-07, Batch size: 17, Momentum: 4.206e-01\n",
      "Initial loss:  487545.84333508904\n",
      "best loss: 77859.16\t\tLearning rate: 8.859e-08, Batch size: 14, Momentum: 3.681e-01\n",
      "Initial loss:  868853.8583432392\n",
      "best loss: 4266.77\t\tLearning rate: 4.281e-02, Batch size: 12, Momentum: 2.103e-01\n",
      "Initial loss:  384180.3884611485\n",
      "best loss: 3682.75\t\tLearning rate: 5.456e-04, Batch size: 29, Momentum: 6.835e-01\n",
      "Initial loss:  355882.85065672133\n",
      "best loss: 3159.19\t\tLearning rate: 1.833e-04, Batch size: 14, Momentum: 2.629e-01\n",
      "Initial loss:  1318997.9124311171\n",
      "best loss: 1752.41\t\tLearning rate: 1.000e-08, Batch size: 9, Momentum: 9.990e-01\n",
      "Initial loss:  327158.37594420847\n",
      "best loss: 2021942.56\t\tLearning rate: 6.158e-05, Batch size: 37, Momentum: 5.258e-02\n",
      "Initial loss:  220687.17408502722\n",
      "best loss: 1860.69\t\tLearning rate: 2.637e-07, Batch size: 42, Momentum: 6.835e-01\n",
      "Initial loss:  1424961.0888191327\n",
      "best loss: 5416.21\t\tLearning rate: 3.360e+00, Batch size: 19, Momentum: 6.835e-01\n",
      "Initial loss:  1089526.8695405705\n",
      "best loss: 5388.22\t\tLearning rate: 1.000e+01, Batch size: 37, Momentum: 2.103e-01\n",
      "Initial loss:  563209.6852509193\n",
      "best loss: 1797.88\t\tLearning rate: 8.859e-08, Batch size: 24, Momentum: 7.361e-01\n",
      "Initial loss:  1309841.2619868652\n",
      "best loss: 196484.28\t\tLearning rate: 2.976e-08, Batch size: 50, Momentum: 6.309e-01\n",
      "Initial loss:  836833.4274950073\n",
      "best loss: 1777.23\t\tLearning rate: 2.336e-06, Batch size: 50, Momentum: 4.206e-01\n",
      "Initial loss:  579279.9864856512\n",
      "best loss: 2207.42\t\tLearning rate: 6.952e-06, Batch size: 39, Momentum: 0.000e+00\n",
      "Initial loss:  1105298.6364536202\n",
      "best loss: 3005.17\t\tLearning rate: 2.069e-05, Batch size: 14, Momentum: 7.361e-01\n",
      "Initial loss:  801383.1600074295\n",
      "best loss: 3213.16\t\tLearning rate: 6.158e-05, Batch size: 39, Momentum: 6.835e-01\n",
      "Initial loss:  107530.79313731748\n",
      "best loss: 2665.34\t\tLearning rate: 6.952e-06, Batch size: 42, Momentum: 2.629e-01\n",
      "Initial loss:  186152.94696116378\n",
      "best loss: 20354.27\t\tLearning rate: 2.069e-05, Batch size: 17, Momentum: 5.784e-01\n",
      "Initial loss:  529230.6631681104\n",
      "best loss: 1829.86\t\tLearning rate: 2.336e-06, Batch size: 17, Momentum: 0.000e+00\n",
      "Initial loss:  510691.4873524602\n",
      "best loss: 1771.31\t\tLearning rate: 2.336e-06, Batch size: 50, Momentum: 3.155e-01\n",
      "Initial loss:  1067599.2750828927\n",
      "best loss: 1879.94\t\tLearning rate: 6.952e-06, Batch size: 7, Momentum: 5.258e-02\n",
      "Initial loss:  1781.853335357231\n",
      "best loss: 1769.00\t\tLearning rate: 4.281e-02, Batch size: 22, Momentum: 8.938e-01\n",
      "Initial loss:  264047.4607136463\n",
      "best loss: 1794.89\t\tLearning rate: 8.859e-08, Batch size: 50, Momentum: 8.413e-01\n",
      "Initial loss:  1802.5418902398933\n",
      "best loss: 1777.31\t\tLearning rate: 3.360e+00, Batch size: 24, Momentum: 9.990e-01\n",
      "Initial loss:  607706.0685576852\n",
      "best loss: 1758.07\t\tLearning rate: 2.637e-07, Batch size: 9, Momentum: 5.784e-01\n",
      "Initial loss:  320565.06609992846\n",
      "best loss: 3307.88\t\tLearning rate: 1.833e-04, Batch size: 4, Momentum: 5.258e-01\n",
      "Initial loss:  1112753.6849207305\n",
      "best loss: 2661.25\t\tLearning rate: 2.336e-06, Batch size: 19, Momentum: 8.938e-01\n",
      "Initial loss:  1930.1973654962044\n",
      "best loss: 1713.47\t\tLearning rate: 1.438e-02, Batch size: 2, Momentum: 7.887e-01\n",
      "Initial loss:  896598.1083569794\n",
      "best loss: 1761.85\t\tLearning rate: 2.976e-08, Batch size: 7, Momentum: 8.413e-01\n",
      "Initial loss:  803999.8701447038\n",
      "best loss: 3279520.96\t\tLearning rate: 4.281e-02, Batch size: 17, Momentum: 1.577e-01\n",
      "Initial loss:  54448.63863121658\n",
      "best loss: 2471216.21\t\tLearning rate: 4.833e-03, Batch size: 22, Momentum: 0.000e+00\n",
      "Initial loss:  1095503.174325871\n",
      "best loss: 4188.27\t\tLearning rate: 4.833e-03, Batch size: 22, Momentum: 8.938e-01\n",
      "Initial loss:  622809.8202670428\n",
      "best loss: 143285.94\t\tLearning rate: 1.000e-08, Batch size: 27, Momentum: 4.206e-01\n",
      "Initial loss:  937129.4223717209\n",
      "best loss: 1808.53\t\tLearning rate: 7.848e-07, Batch size: 9, Momentum: 9.464e-01\n",
      "Initial loss:  1372327.5543973937\n",
      "best loss: 5117.62\t\tLearning rate: 3.360e+00, Batch size: 12, Momentum: 4.206e-01\n",
      "Initial loss:  1104213.1474629522\n",
      "best loss: 4346.86\t\tLearning rate: 4.281e-02, Batch size: 34, Momentum: 6.309e-01\n",
      "Initial loss:  72683.6603179411\n",
      "best loss: 4070.79\t\tLearning rate: 1.624e-03, Batch size: 7, Momentum: 9.990e-01\n",
      "Initial loss:  1890.7000069862588\n",
      "best loss: 1838.19\t\tLearning rate: 2.976e-08, Batch size: 39, Momentum: 6.835e-01\n",
      "Initial loss:  1439261.644963915\n",
      "best loss: 4884.17\t\tLearning rate: 1.129e+00, Batch size: 47, Momentum: 2.629e-01\n",
      "Initial loss:  1838335.175172975\n",
      "best loss: 4377.48\t\tLearning rate: 1.438e-02, Batch size: 47, Momentum: 7.361e-01\n",
      "Initial loss:  602970.5659232162\n",
      "best loss: 3521.59\t\tLearning rate: 1.833e-04, Batch size: 24, Momentum: 7.887e-01\n",
      "Initial loss:  365658.37726056157\n",
      "best loss: 1784.90\t\tLearning rate: 7.848e-07, Batch size: 42, Momentum: 8.938e-01\n",
      "Initial loss:  200084.59001100008\n",
      "best loss: 4991.80\t\tLearning rate: 1.274e-01, Batch size: 47, Momentum: 9.990e-01\n",
      "Initial loss:  744966.8009244883\n",
      "best loss: 2796.72\t\tLearning rate: 2.069e-05, Batch size: 27, Momentum: 4.732e-01\n",
      "Initial loss:  624528.0257611463\n",
      "best loss: 4816.07\t\tLearning rate: 1.274e-01, Batch size: 4, Momentum: 8.938e-01\n",
      "Initial loss:  1802.6652282545365\n",
      "best loss: 1762.47\t\tLearning rate: 1.000e+01, Batch size: 27, Momentum: 1.052e-01\n",
      "Initial loss:  947799.205312804\n",
      "best loss: 3227.57\t\tLearning rate: 1.833e-04, Batch size: 17, Momentum: 2.629e-01\n",
      "Initial loss:  119827.82828739929\n",
      "best loss: 3550.97\t\tLearning rate: 5.456e-04, Batch size: 27, Momentum: 4.206e-01\n",
      "Initial loss:  1353451.0036960281\n",
      "best loss: 1758.90\t\tLearning rate: 2.336e-06, Batch size: 9, Momentum: 1.577e-01\n",
      "Initial loss:  1725614.080694647\n",
      "best loss: 4681.94\t\tLearning rate: 3.793e-01, Batch size: 37, Momentum: 2.103e-01\n",
      "Initial loss:  1563912.9965646095\n",
      "best loss: 5218.70\t\tLearning rate: 1.129e+00, Batch size: 47, Momentum: 7.887e-01\n",
      "Initial loss:  546579.9566206287\n",
      "best loss: 170491.27\t\tLearning rate: 5.456e-04, Batch size: 12, Momentum: 0.000e+00\n",
      "Initial loss:  1151466.6887136318\n",
      "best loss: 3892.28\t\tLearning rate: 4.833e-03, Batch size: 44, Momentum: 3.155e-01\n",
      "Initial loss:  2273420.5471830023\n",
      "best loss: 2702.86\t\tLearning rate: 2.069e-05, Batch size: 12, Momentum: 3.681e-01\n",
      "Initial loss:  949756.6739568225\n",
      "best loss: 8570.43\t\tLearning rate: 8.859e-08, Batch size: 4, Momentum: 6.309e-01\n",
      "Initial loss:  710459.3707181626\n",
      "best loss: 1775.50\t\tLearning rate: 8.859e-08, Batch size: 19, Momentum: 6.835e-01\n",
      "Initial loss:  743947.0932849522\n",
      "best loss: 3262.29\t\tLearning rate: 1.833e-04, Batch size: 24, Momentum: 3.155e-01\n",
      "Initial loss:  527661.9687391213\n",
      "best loss: 4805.91\t\tLearning rate: 3.793e-01, Batch size: 44, Momentum: 4.206e-01\n",
      "Initial loss:  1425446.2052876563\n",
      "best loss: 4003.40\t\tLearning rate: 4.833e-03, Batch size: 32, Momentum: 4.732e-01\n",
      "Initial loss:  771469.1212339189\n",
      "best loss: 1771.36\t\tLearning rate: 2.336e-06, Batch size: 14, Momentum: 4.732e-01\n",
      "Initial loss:  1806217.0419624958\n",
      "best loss: 3969.50\t\tLearning rate: 4.833e-03, Batch size: 42, Momentum: 5.784e-01\n",
      "Initial loss:  1983045.196088131\n",
      "best loss: 3985.42\t\tLearning rate: 4.833e-03, Batch size: 24, Momentum: 4.732e-01\n",
      "Initial loss:  589097.1728849346\n",
      "best loss: 3081.24\t\tLearning rate: 6.952e-06, Batch size: 32, Momentum: 9.990e-01\n",
      "Initial loss:  773357.9401137658\n",
      "best loss: 4308.54\t\tLearning rate: 1.438e-02, Batch size: 17, Momentum: 6.309e-01\n",
      "Initial loss:  1136328.6032647036\n",
      "best loss: 1776.71\t\tLearning rate: 2.336e-06, Batch size: 39, Momentum: 5.258e-01\n",
      "Initial loss:  1775.6160426145752\n",
      "best loss: 1767.58\t\tLearning rate: 1.000e+01, Batch size: 22, Momentum: 8.938e-01\n",
      "Initial loss:  586977.4018767726\n",
      "best loss: 1786.93\t\tLearning rate: 2.336e-06, Batch size: 50, Momentum: 4.732e-01\n",
      "Initial loss:  353211.2390797645\n",
      "best loss: 2951.75\t\tLearning rate: 2.069e-05, Batch size: 14, Momentum: 7.361e-01\n",
      "Initial loss:  856656.3971742529\n",
      "best loss: 511248.74\t\tLearning rate: 2.069e-05, Batch size: 42, Momentum: 1.577e-01\n",
      "Initial loss:  1922985.324060376\n",
      "best loss: 4027.26\t\tLearning rate: 1.438e-02, Batch size: 2, Momentum: 0.000e+00\n",
      "Initial loss:  1668409.0391971874\n",
      "best loss: 4111.19\t\tLearning rate: 4.833e-03, Batch size: 47, Momentum: 6.835e-01\n",
      "Initial loss:  1399277.6064126773\n",
      "best loss: 3858.26\t\tLearning rate: 4.833e-03, Batch size: 29, Momentum: 2.103e-01\n",
      "Initial loss:  1552744.5210607299\n",
      "best loss: 55652.48\t\tLearning rate: 2.637e-07, Batch size: 29, Momentum: 3.681e-01\n",
      "Initial loss:  166233.2859429071\n",
      "best loss: 1875.25\t\tLearning rate: 1.000e-08, Batch size: 9, Momentum: 2.629e-01\n",
      "Initial loss:  1646804.9180505518\n",
      "best loss: 1882.42\t\tLearning rate: 2.637e-07, Batch size: 24, Momentum: 3.155e-01\n",
      "Initial loss:  1793729.424847716\n",
      "best loss: 4769.88\t\tLearning rate: 3.793e-01, Batch size: 22, Momentum: 1.577e-01\n",
      "Initial loss:  1813186.7150503946\n",
      "best loss: 4901.19\t\tLearning rate: 1.274e-01, Batch size: 37, Momentum: 9.464e-01\n",
      "Initial loss:  213610.13525850672\n",
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/hpinkard_waller/mambaforge/envs/phenotypes/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3378, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_12112/3563418900.py\", line 18, in <module>\n",
      "    best_cov_mat, cov_mat_initial, mean_vec, best_loss = run_optimization(patches, momentum, learning_rate, batch_size, eigenvalue_floor=1e-3)\n",
      "  File \"/home/hpinkard_waller/GitRepos/EncodingInformation/gaussian_process_utils.py\", line 488, in run_optimization\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hpinkard_waller/mambaforge/envs/phenotypes/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 1997, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/home/hpinkard_waller/mambaforge/envs/phenotypes/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1112, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/home/hpinkard_waller/mambaforge/envs/phenotypes/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1006, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/home/hpinkard_waller/mambaforge/envs/phenotypes/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 859, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/home/hpinkard_waller/mambaforge/envs/phenotypes/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 812, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(r))\n",
      "  File \"/home/hpinkard_waller/mambaforge/envs/phenotypes/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 730, in format_record\n",
      "    result += ''.join(_format_traceback_lines(frame_info.lines, Colors, self.has_colors, lvals))\n",
      "  File \"/home/hpinkard_waller/mambaforge/envs/phenotypes/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/hpinkard_waller/mambaforge/envs/phenotypes/lib/python3.10/site-packages/stack_data/core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/home/hpinkard_waller/mambaforge/envs/phenotypes/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/hpinkard_waller/mambaforge/envs/phenotypes/lib/python3.10/site-packages/stack_data/core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/home/hpinkard_waller/mambaforge/envs/phenotypes/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/hpinkard_waller/mambaforge/envs/phenotypes/lib/python3.10/site-packages/stack_data/core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "  File \"/home/hpinkard_waller/mambaforge/envs/phenotypes/lib/python3.10/site-packages/executing/executing.py\", line 168, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "learning_rates = np.logspace(1, -8, 20)\n",
    "batch_sizes = np.linspace(2, 50, 20).astype(int)\n",
    "momentums = np.linspace(0, 0.999, 20)\n",
    "\n",
    "# generate tuples of random hyperparameters\n",
    "hyperparameter_tuples = []\n",
    "for i in range(10000):\n",
    "    lr = onp.random.choice(learning_rates)\n",
    "    bs = onp.random.choice(batch_sizes)\n",
    "    m = onp.random.choice(momentums)\n",
    "    hyperparameter_tuples.append((lr, bs, m))\n",
    "\n",
    "results = {}\n",
    "for i, (learning_rate, batch_size, momentum) in enumerate(hyperparameter_tuples):\n",
    "    best_hp_loss = np.inf\n",
    "\n",
    "    patches = extract_patches(images, patch_size, num_patches=num_patches, seed=i)\n",
    "    best_cov_mat, cov_mat_initial, mean_vec, best_loss = run_optimization(patches, momentum, learning_rate, batch_size, eigenvalue_floor=1e-3)\n",
    "\n",
    "    if best_loss < best_hp_loss:\n",
    "        best_hp_loss = best_loss\n",
    "        best_hp = (learning_rate, batch_size, momentum)\n",
    "        \n",
    "    # collect results\n",
    "    results[(learning_rate, batch_size, momentum)] = best_loss\n",
    "\n",
    "    # print hyperparameters and their best loss\n",
    "    print(f\"best loss: {best_loss:.2f}\\t\\tLearning rate: {learning_rate:.3e}, Batch size: {batch_size}, Momentum: {momentum:.3e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best loss: 1677.30\t\tLearning rate: 1.000e-08, Batch size: 2, Momentum: 3.681e-01\n",
      "best loss: 1710.50\t\tLearning rate: 1.000e+01, Batch size: 2, Momentum: 7.887e-01\n",
      "best loss: 1712.38\t\tLearning rate: 1.274e-01, Batch size: 2, Momentum: 2.103e-01\n",
      "best loss: 1713.47\t\tLearning rate: 1.438e-02, Batch size: 2, Momentum: 7.887e-01\n",
      "best loss: 1716.37\t\tLearning rate: 6.158e-05, Batch size: 2, Momentum: 6.309e-01\n",
      "best loss: 1716.63\t\tLearning rate: 1.624e-03, Batch size: 2, Momentum: 1.052e-01\n",
      "best loss: 1725.65\t\tLearning rate: 5.456e-04, Batch size: 2, Momentum: 1.577e-01\n",
      "best loss: 1733.78\t\tLearning rate: 2.637e-07, Batch size: 4, Momentum: 3.681e-01\n",
      "best loss: 1741.91\t\tLearning rate: 1.000e-08, Batch size: 4, Momentum: 9.990e-01\n",
      "best loss: 1744.23\t\tLearning rate: 1.129e+00, Batch size: 12, Momentum: 5.784e-01\n",
      "best loss: 1747.73\t\tLearning rate: 2.637e-07, Batch size: 7, Momentum: 8.413e-01\n",
      "best loss: 1752.28\t\tLearning rate: 8.859e-08, Batch size: 7, Momentum: 7.887e-01\n",
      "best loss: 1752.41\t\tLearning rate: 1.000e-08, Batch size: 9, Momentum: 9.990e-01\n",
      "best loss: 1753.96\t\tLearning rate: 1.833e-04, Batch size: 12, Momentum: 8.413e-01\n",
      "best loss: 1757.63\t\tLearning rate: 2.637e-07, Batch size: 4, Momentum: 2.103e-01\n",
      "best loss: 1757.76\t\tLearning rate: 2.637e-07, Batch size: 9, Momentum: 3.681e-01\n",
      "best loss: 1758.07\t\tLearning rate: 2.637e-07, Batch size: 9, Momentum: 5.784e-01\n",
      "best loss: 1758.90\t\tLearning rate: 2.336e-06, Batch size: 9, Momentum: 1.577e-01\n",
      "best loss: 1761.20\t\tLearning rate: 2.637e-07, Batch size: 9, Momentum: 6.309e-01\n",
      "best loss: 1761.85\t\tLearning rate: 2.976e-08, Batch size: 7, Momentum: 8.413e-01\n",
      "best loss: 1762.13\t\tLearning rate: 1.129e+00, Batch size: 27, Momentum: 6.835e-01\n",
      "best loss: 1762.47\t\tLearning rate: 1.000e+01, Batch size: 27, Momentum: 1.052e-01\n",
      "best loss: 1765.30\t\tLearning rate: 7.848e-07, Batch size: 19, Momentum: 2.103e-01\n",
      "best loss: 1765.91\t\tLearning rate: 3.360e+00, Batch size: 37, Momentum: 4.732e-01\n",
      "best loss: 1766.07\t\tLearning rate: 2.069e-05, Batch size: 39, Momentum: 9.464e-01\n",
      "best loss: 1766.93\t\tLearning rate: 5.456e-04, Batch size: 14, Momentum: 5.784e-01\n",
      "best loss: 1767.58\t\tLearning rate: 1.000e+01, Batch size: 22, Momentum: 8.938e-01\n",
      "best loss: 1767.63\t\tLearning rate: 1.438e-02, Batch size: 27, Momentum: 4.206e-01\n",
      "best loss: 1767.89\t\tLearning rate: 6.952e-06, Batch size: 27, Momentum: 2.629e-01\n",
      "best loss: 1768.22\t\tLearning rate: 1.000e+01, Batch size: 27, Momentum: 2.629e-01\n",
      "best loss: 1769.00\t\tLearning rate: 4.281e-02, Batch size: 22, Momentum: 8.938e-01\n",
      "best loss: 1769.74\t\tLearning rate: 6.158e-05, Batch size: 34, Momentum: 6.309e-01\n",
      "best loss: 1769.89\t\tLearning rate: 2.336e-06, Batch size: 47, Momentum: 1.052e-01\n",
      "best loss: 1771.05\t\tLearning rate: 6.952e-06, Batch size: 32, Momentum: 7.887e-01\n",
      "best loss: 1771.31\t\tLearning rate: 2.336e-06, Batch size: 50, Momentum: 3.155e-01\n",
      "best loss: 1771.36\t\tLearning rate: 7.848e-07, Batch size: 32, Momentum: 9.464e-01\n",
      "best loss: 1771.36\t\tLearning rate: 2.336e-06, Batch size: 14, Momentum: 4.732e-01\n",
      "best loss: 1771.70\t\tLearning rate: 2.637e-07, Batch size: 9, Momentum: 8.413e-01\n",
      "best loss: 1772.25\t\tLearning rate: 7.848e-07, Batch size: 14, Momentum: 5.258e-02\n",
      "best loss: 1772.53\t\tLearning rate: 8.859e-08, Batch size: 4, Momentum: 5.784e-01\n",
      "best loss: 1773.45\t\tLearning rate: 2.976e-08, Batch size: 9, Momentum: 7.361e-01\n",
      "best loss: 1774.15\t\tLearning rate: 8.859e-08, Batch size: 29, Momentum: 9.464e-01\n",
      "best loss: 1774.61\t\tLearning rate: 7.848e-07, Batch size: 27, Momentum: 5.258e-02\n",
      "best loss: 1775.05\t\tLearning rate: 2.336e-06, Batch size: 12, Momentum: 2.629e-01\n",
      "best loss: 1775.32\t\tLearning rate: 4.833e-03, Batch size: 22, Momentum: 4.206e-01\n",
      "best loss: 1775.50\t\tLearning rate: 8.859e-08, Batch size: 19, Momentum: 6.835e-01\n",
      "best loss: 1775.87\t\tLearning rate: 2.637e-07, Batch size: 9, Momentum: 5.258e-01\n",
      "best loss: 1776.54\t\tLearning rate: 3.360e+00, Batch size: 37, Momentum: 2.103e-01\n",
      "best loss: 1776.71\t\tLearning rate: 2.336e-06, Batch size: 39, Momentum: 5.258e-01\n",
      "best loss: 1776.75\t\tLearning rate: 7.848e-07, Batch size: 44, Momentum: 6.309e-01\n",
      "best loss: 1777.23\t\tLearning rate: 2.336e-06, Batch size: 50, Momentum: 4.206e-01\n",
      "best loss: 1777.31\t\tLearning rate: 3.360e+00, Batch size: 24, Momentum: 9.990e-01\n",
      "best loss: 1777.36\t\tLearning rate: 2.976e-08, Batch size: 9, Momentum: 9.990e-01\n",
      "best loss: 1778.42\t\tLearning rate: 1.624e-03, Batch size: 47, Momentum: 5.784e-01\n",
      "best loss: 1778.81\t\tLearning rate: 4.281e-02, Batch size: 34, Momentum: 6.835e-01\n",
      "best loss: 1780.95\t\tLearning rate: 7.848e-07, Batch size: 7, Momentum: 5.258e-02\n",
      "best loss: 1781.54\t\tLearning rate: 2.976e-08, Batch size: 24, Momentum: 9.990e-01\n",
      "best loss: 1782.36\t\tLearning rate: 8.859e-08, Batch size: 27, Momentum: 3.681e-01\n",
      "best loss: 1782.83\t\tLearning rate: 6.158e-05, Batch size: 24, Momentum: 6.309e-01\n",
      "best loss: 1783.17\t\tLearning rate: 2.336e-06, Batch size: 17, Momentum: 7.887e-01\n",
      "best loss: 1783.49\t\tLearning rate: 7.848e-07, Batch size: 22, Momentum: 8.938e-01\n",
      "best loss: 1784.90\t\tLearning rate: 7.848e-07, Batch size: 42, Momentum: 8.938e-01\n",
      "best loss: 1786.93\t\tLearning rate: 2.336e-06, Batch size: 50, Momentum: 4.732e-01\n",
      "best loss: 1787.50\t\tLearning rate: 5.456e-04, Batch size: 27, Momentum: 3.155e-01\n",
      "best loss: 1787.53\t\tLearning rate: 2.637e-07, Batch size: 19, Momentum: 5.784e-01\n",
      "best loss: 1791.68\t\tLearning rate: 2.336e-06, Batch size: 17, Momentum: 6.309e-01\n",
      "best loss: 1792.11\t\tLearning rate: 7.848e-07, Batch size: 39, Momentum: 9.464e-01\n",
      "best loss: 1793.98\t\tLearning rate: 8.859e-08, Batch size: 19, Momentum: 5.258e-01\n",
      "best loss: 1794.89\t\tLearning rate: 8.859e-08, Batch size: 50, Momentum: 8.413e-01\n",
      "best loss: 1796.09\t\tLearning rate: 2.336e-06, Batch size: 14, Momentum: 2.629e-01\n",
      "best loss: 1796.93\t\tLearning rate: 1.000e+01, Batch size: 7, Momentum: 2.629e-01\n",
      "best loss: 1797.17\t\tLearning rate: 8.859e-08, Batch size: 12, Momentum: 2.103e-01\n",
      "best loss: 1797.88\t\tLearning rate: 8.859e-08, Batch size: 24, Momentum: 7.361e-01\n",
      "best loss: 1800.65\t\tLearning rate: 7.848e-07, Batch size: 7, Momentum: 1.052e-01\n",
      "best loss: 1801.54\t\tLearning rate: 4.833e-03, Batch size: 22, Momentum: 4.732e-01\n",
      "best loss: 1802.86\t\tLearning rate: 7.848e-07, Batch size: 19, Momentum: 5.258e-01\n",
      "best loss: 1805.13\t\tLearning rate: 2.336e-06, Batch size: 27, Momentum: 1.577e-01\n",
      "best loss: 1805.21\t\tLearning rate: 2.976e-08, Batch size: 47, Momentum: 8.938e-01\n",
      "best loss: 1805.75\t\tLearning rate: 7.848e-07, Batch size: 39, Momentum: 2.629e-01\n",
      "best loss: 1806.35\t\tLearning rate: 7.848e-07, Batch size: 17, Momentum: 8.413e-01\n",
      "best loss: 1807.68\t\tLearning rate: 2.336e-06, Batch size: 27, Momentum: 6.309e-01\n",
      "best loss: 1808.53\t\tLearning rate: 7.848e-07, Batch size: 9, Momentum: 9.464e-01\n",
      "best loss: 1816.95\t\tLearning rate: 2.637e-07, Batch size: 47, Momentum: 4.206e-01\n",
      "best loss: 1818.31\t\tLearning rate: 7.848e-07, Batch size: 44, Momentum: 1.052e-01\n",
      "best loss: 1823.05\t\tLearning rate: 2.069e-05, Batch size: 17, Momentum: 6.309e-01\n",
      "best loss: 1825.93\t\tLearning rate: 7.848e-07, Batch size: 44, Momentum: 9.464e-01\n",
      "best loss: 1826.59\t\tLearning rate: 2.336e-06, Batch size: 39, Momentum: 1.577e-01\n",
      "best loss: 1829.86\t\tLearning rate: 2.336e-06, Batch size: 17, Momentum: 0.000e+00\n",
      "best loss: 1836.51\t\tLearning rate: 2.976e-08, Batch size: 19, Momentum: 5.258e-01\n",
      "best loss: 1838.19\t\tLearning rate: 2.976e-08, Batch size: 39, Momentum: 6.835e-01\n",
      "best loss: 1840.20\t\tLearning rate: 2.336e-06, Batch size: 29, Momentum: 3.155e-01\n",
      "best loss: 1843.31\t\tLearning rate: 2.976e-08, Batch size: 37, Momentum: 7.361e-01\n",
      "best loss: 1850.40\t\tLearning rate: 2.976e-08, Batch size: 9, Momentum: 6.309e-01\n",
      "best loss: 1850.72\t\tLearning rate: 2.976e-08, Batch size: 42, Momentum: 5.258e-01\n",
      "best loss: 1856.37\t\tLearning rate: 8.859e-08, Batch size: 37, Momentum: 3.155e-01\n",
      "best loss: 1860.69\t\tLearning rate: 2.637e-07, Batch size: 42, Momentum: 6.835e-01\n",
      "best loss: 1863.22\t\tLearning rate: 2.637e-07, Batch size: 47, Momentum: 1.577e-01\n",
      "best loss: 1875.25\t\tLearning rate: 1.000e-08, Batch size: 9, Momentum: 2.629e-01\n",
      "best loss: 1879.94\t\tLearning rate: 6.952e-06, Batch size: 7, Momentum: 5.258e-02\n",
      "best loss: 1882.42\t\tLearning rate: 2.637e-07, Batch size: 24, Momentum: 3.155e-01\n",
      "best loss: 1882.67\t\tLearning rate: 2.637e-07, Batch size: 47, Momentum: 5.258e-02\n",
      "best loss: 1883.88\t\tLearning rate: 2.637e-07, Batch size: 19, Momentum: 3.155e-01\n",
      "best loss: 1900.46\t\tLearning rate: 7.848e-07, Batch size: 29, Momentum: 7.887e-01\n",
      "best loss: 1904.58\t\tLearning rate: 2.976e-08, Batch size: 17, Momentum: 5.258e-02\n",
      "best loss: 1927.55\t\tLearning rate: 7.848e-07, Batch size: 37, Momentum: 9.464e-01\n",
      "best loss: 1994.38\t\tLearning rate: 2.336e-06, Batch size: 9, Momentum: 4.206e-01\n",
      "best loss: 2019.18\t\tLearning rate: 8.859e-08, Batch size: 50, Momentum: 1.052e-01\n",
      "best loss: 2103.24\t\tLearning rate: 6.952e-06, Batch size: 24, Momentum: 2.103e-01\n",
      "best loss: 2175.93\t\tLearning rate: 7.848e-07, Batch size: 24, Momentum: 9.464e-01\n",
      "best loss: 2207.42\t\tLearning rate: 6.952e-06, Batch size: 39, Momentum: 0.000e+00\n",
      "best loss: 2252.11\t\tLearning rate: 2.336e-06, Batch size: 22, Momentum: 7.361e-01\n",
      "best loss: 2362.39\t\tLearning rate: 6.952e-06, Batch size: 19, Momentum: 1.577e-01\n",
      "best loss: 2477.17\t\tLearning rate: 2.336e-06, Batch size: 29, Momentum: 8.938e-01\n",
      "best loss: 2484.36\t\tLearning rate: 2.336e-06, Batch size: 50, Momentum: 7.887e-01\n",
      "best loss: 2510.22\t\tLearning rate: 2.336e-06, Batch size: 50, Momentum: 8.938e-01\n",
      "best loss: 2528.55\t\tLearning rate: 2.069e-05, Batch size: 22, Momentum: 1.052e-01\n",
      "best loss: 2553.11\t\tLearning rate: 2.069e-05, Batch size: 39, Momentum: 1.052e-01\n",
      "best loss: 2554.96\t\tLearning rate: 6.952e-06, Batch size: 29, Momentum: 5.258e-01\n",
      "best loss: 2573.80\t\tLearning rate: 6.952e-06, Batch size: 32, Momentum: 1.052e-01\n",
      "best loss: 2641.03\t\tLearning rate: 2.336e-06, Batch size: 14, Momentum: 9.464e-01\n",
      "best loss: 2661.25\t\tLearning rate: 2.336e-06, Batch size: 19, Momentum: 8.938e-01\n",
      "best loss: 2665.34\t\tLearning rate: 6.952e-06, Batch size: 42, Momentum: 2.629e-01\n",
      "best loss: 2667.74\t\tLearning rate: 2.069e-05, Batch size: 50, Momentum: 1.577e-01\n",
      "best loss: 2668.65\t\tLearning rate: 2.069e-05, Batch size: 39, Momentum: 5.258e-02\n",
      "best loss: 2673.58\t\tLearning rate: 6.158e-05, Batch size: 34, Momentum: 0.000e+00\n",
      "best loss: 2702.86\t\tLearning rate: 2.069e-05, Batch size: 12, Momentum: 3.681e-01\n",
      "best loss: 2712.15\t\tLearning rate: 6.952e-06, Batch size: 27, Momentum: 7.361e-01\n",
      "best loss: 2727.05\t\tLearning rate: 6.952e-06, Batch size: 17, Momentum: 4.732e-01\n",
      "best loss: 2742.37\t\tLearning rate: 2.069e-05, Batch size: 9, Momentum: 1.577e-01\n",
      "best loss: 2766.42\t\tLearning rate: 6.952e-06, Batch size: 44, Momentum: 6.309e-01\n",
      "best loss: 2778.20\t\tLearning rate: 6.952e-06, Batch size: 12, Momentum: 5.784e-01\n",
      "best loss: 2785.69\t\tLearning rate: 2.336e-06, Batch size: 12, Momentum: 9.464e-01\n",
      "best loss: 2796.72\t\tLearning rate: 2.069e-05, Batch size: 27, Momentum: 4.732e-01\n",
      "best loss: 2797.20\t\tLearning rate: 2.336e-06, Batch size: 50, Momentum: 9.990e-01\n",
      "best loss: 2818.45\t\tLearning rate: 2.069e-05, Batch size: 50, Momentum: 4.206e-01\n",
      "best loss: 2865.06\t\tLearning rate: 2.069e-05, Batch size: 12, Momentum: 6.309e-01\n",
      "best loss: 2888.35\t\tLearning rate: 6.952e-06, Batch size: 27, Momentum: 7.887e-01\n",
      "best loss: 2890.94\t\tLearning rate: 6.158e-05, Batch size: 47, Momentum: 0.000e+00\n",
      "best loss: 2892.87\t\tLearning rate: 2.069e-05, Batch size: 2, Momentum: 3.681e-01\n",
      "best loss: 2900.95\t\tLearning rate: 6.158e-05, Batch size: 44, Momentum: 3.155e-01\n",
      "best loss: 2904.69\t\tLearning rate: 6.158e-05, Batch size: 9, Momentum: 5.258e-02\n",
      "best loss: 2908.10\t\tLearning rate: 2.069e-05, Batch size: 32, Momentum: 6.835e-01\n",
      "best loss: 2918.73\t\tLearning rate: 6.158e-05, Batch size: 27, Momentum: 4.732e-01\n",
      "best loss: 2934.35\t\tLearning rate: 6.952e-06, Batch size: 17, Momentum: 9.464e-01\n",
      "best loss: 2951.68\t\tLearning rate: 2.069e-05, Batch size: 14, Momentum: 3.681e-01\n",
      "best loss: 2951.75\t\tLearning rate: 2.069e-05, Batch size: 14, Momentum: 7.361e-01\n",
      "best loss: 2982.41\t\tLearning rate: 6.158e-05, Batch size: 7, Momentum: 3.155e-01\n",
      "best loss: 2987.88\t\tLearning rate: 6.158e-05, Batch size: 24, Momentum: 4.206e-01\n",
      "best loss: 2997.45\t\tLearning rate: 6.158e-05, Batch size: 24, Momentum: 3.681e-01\n",
      "best loss: 3032.61\t\tLearning rate: 6.952e-06, Batch size: 22, Momentum: 9.464e-01\n",
      "best loss: 3068.83\t\tLearning rate: 1.833e-04, Batch size: 39, Momentum: 1.577e-01\n",
      "best loss: 3074.91\t\tLearning rate: 6.158e-05, Batch size: 37, Momentum: 4.206e-01\n",
      "best loss: 3075.61\t\tLearning rate: 2.069e-05, Batch size: 2, Momentum: 4.732e-01\n",
      "best loss: 3081.24\t\tLearning rate: 6.952e-06, Batch size: 32, Momentum: 9.990e-01\n",
      "best loss: 3091.88\t\tLearning rate: 6.158e-05, Batch size: 12, Momentum: 3.681e-01\n",
      "best loss: 3103.99\t\tLearning rate: 6.158e-05, Batch size: 17, Momentum: 5.258e-01\n",
      "best loss: 3114.29\t\tLearning rate: 2.069e-05, Batch size: 50, Momentum: 8.413e-01\n",
      "best loss: 3119.85\t\tLearning rate: 1.833e-04, Batch size: 32, Momentum: 1.577e-01\n",
      "best loss: 3127.78\t\tLearning rate: 2.069e-05, Batch size: 47, Momentum: 7.887e-01\n",
      "best loss: 3159.19\t\tLearning rate: 1.833e-04, Batch size: 14, Momentum: 2.629e-01\n",
      "best loss: 3165.48\t\tLearning rate: 6.158e-05, Batch size: 27, Momentum: 4.206e-01\n",
      "best loss: 3183.61\t\tLearning rate: 6.158e-05, Batch size: 4, Momentum: 9.464e-01\n",
      "best loss: 3213.16\t\tLearning rate: 6.158e-05, Batch size: 39, Momentum: 6.835e-01\n",
      "best loss: 3222.01\t\tLearning rate: 5.456e-04, Batch size: 9, Momentum: 2.629e-01\n",
      "best loss: 3227.57\t\tLearning rate: 1.833e-04, Batch size: 17, Momentum: 2.629e-01\n",
      "best loss: 3234.79\t\tLearning rate: 6.158e-05, Batch size: 39, Momentum: 6.309e-01\n",
      "best loss: 3237.51\t\tLearning rate: 6.158e-05, Batch size: 9, Momentum: 6.309e-01\n",
      "best loss: 3239.04\t\tLearning rate: 1.833e-04, Batch size: 44, Momentum: 3.681e-01\n",
      "best loss: 3249.42\t\tLearning rate: 6.158e-05, Batch size: 44, Momentum: 9.464e-01\n",
      "best loss: 3262.29\t\tLearning rate: 1.833e-04, Batch size: 24, Momentum: 3.155e-01\n",
      "best loss: 3272.93\t\tLearning rate: 5.456e-04, Batch size: 9, Momentum: 5.258e-02\n",
      "best loss: 3274.59\t\tLearning rate: 1.833e-04, Batch size: 4, Momentum: 3.681e-01\n",
      "best loss: 3307.88\t\tLearning rate: 1.833e-04, Batch size: 4, Momentum: 5.258e-01\n",
      "best loss: 3319.23\t\tLearning rate: 6.158e-05, Batch size: 27, Momentum: 9.990e-01\n",
      "best loss: 3323.46\t\tLearning rate: 5.456e-04, Batch size: 27, Momentum: 1.052e-01\n",
      "best loss: 3337.88\t\tLearning rate: 1.833e-04, Batch size: 24, Momentum: 4.732e-01\n",
      "best loss: 3339.53\t\tLearning rate: 6.158e-05, Batch size: 14, Momentum: 9.464e-01\n",
      "best loss: 3343.58\t\tLearning rate: 1.833e-04, Batch size: 2, Momentum: 5.258e-01\n",
      "best loss: 3375.18\t\tLearning rate: 5.456e-04, Batch size: 27, Momentum: 2.629e-01\n",
      "best loss: 3376.47\t\tLearning rate: 5.456e-04, Batch size: 12, Momentum: 2.103e-01\n",
      "best loss: 3383.52\t\tLearning rate: 2.069e-05, Batch size: 14, Momentum: 9.990e-01\n",
      "best loss: 3419.47\t\tLearning rate: 5.456e-04, Batch size: 50, Momentum: 3.155e-01\n",
      "best loss: 3421.02\t\tLearning rate: 5.456e-04, Batch size: 4, Momentum: 3.155e-01\n",
      "best loss: 3429.04\t\tLearning rate: 5.456e-04, Batch size: 32, Momentum: 3.681e-01\n",
      "best loss: 3443.37\t\tLearning rate: 5.456e-04, Batch size: 14, Momentum: 4.206e-01\n",
      "best loss: 3449.88\t\tLearning rate: 5.456e-04, Batch size: 12, Momentum: 4.206e-01\n",
      "best loss: 3472.81\t\tLearning rate: 5.456e-04, Batch size: 44, Momentum: 4.206e-01\n",
      "best loss: 3518.83\t\tLearning rate: 5.456e-04, Batch size: 24, Momentum: 4.732e-01\n",
      "best loss: 3521.59\t\tLearning rate: 1.833e-04, Batch size: 24, Momentum: 7.887e-01\n",
      "best loss: 3524.32\t\tLearning rate: 1.833e-04, Batch size: 39, Momentum: 7.361e-01\n",
      "best loss: 3527.75\t\tLearning rate: 5.456e-04, Batch size: 50, Momentum: 4.206e-01\n",
      "best loss: 3534.23\t\tLearning rate: 5.456e-04, Batch size: 7, Momentum: 4.206e-01\n",
      "best loss: 3549.23\t\tLearning rate: 1.833e-04, Batch size: 39, Momentum: 8.413e-01\n",
      "best loss: 3550.97\t\tLearning rate: 5.456e-04, Batch size: 27, Momentum: 4.206e-01\n",
      "best loss: 3626.99\t\tLearning rate: 1.833e-04, Batch size: 37, Momentum: 9.464e-01\n",
      "best loss: 3640.81\t\tLearning rate: 1.833e-04, Batch size: 44, Momentum: 7.887e-01\n",
      "best loss: 3666.68\t\tLearning rate: 1.624e-03, Batch size: 4, Momentum: 3.681e-01\n",
      "best loss: 3682.75\t\tLearning rate: 5.456e-04, Batch size: 29, Momentum: 6.835e-01\n",
      "best loss: 3685.05\t\tLearning rate: 1.624e-03, Batch size: 32, Momentum: 2.629e-01\n",
      "best loss: 3694.85\t\tLearning rate: 2.976e-08, Batch size: 17, Momentum: 3.155e-01\n",
      "best loss: 3696.04\t\tLearning rate: 5.456e-04, Batch size: 34, Momentum: 7.887e-01\n",
      "best loss: 3707.91\t\tLearning rate: 1.624e-03, Batch size: 50, Momentum: 3.155e-01\n",
      "best loss: 3714.50\t\tLearning rate: 1.624e-03, Batch size: 9, Momentum: 4.206e-01\n",
      "best loss: 3793.30\t\tLearning rate: 1.833e-04, Batch size: 7, Momentum: 9.990e-01\n",
      "best loss: 3820.20\t\tLearning rate: 5.456e-04, Batch size: 22, Momentum: 8.938e-01\n",
      "best loss: 3821.15\t\tLearning rate: 4.833e-03, Batch size: 12, Momentum: 3.681e-01\n",
      "best loss: 3827.68\t\tLearning rate: 5.456e-04, Batch size: 9, Momentum: 9.464e-01\n",
      "best loss: 3838.58\t\tLearning rate: 1.624e-03, Batch size: 17, Momentum: 7.361e-01\n",
      "best loss: 3843.29\t\tLearning rate: 4.833e-03, Batch size: 34, Momentum: 3.155e-01\n",
      "best loss: 3854.72\t\tLearning rate: 4.833e-03, Batch size: 22, Momentum: 2.629e-01\n",
      "best loss: 3858.18\t\tLearning rate: 5.456e-04, Batch size: 4, Momentum: 9.464e-01\n",
      "best loss: 3858.26\t\tLearning rate: 4.833e-03, Batch size: 29, Momentum: 2.103e-01\n",
      "best loss: 3870.65\t\tLearning rate: 1.624e-03, Batch size: 4, Momentum: 7.887e-01\n",
      "best loss: 3874.54\t\tLearning rate: 4.833e-03, Batch size: 17, Momentum: 2.629e-01\n",
      "best loss: 3880.85\t\tLearning rate: 4.833e-03, Batch size: 4, Momentum: 3.155e-01\n",
      "best loss: 3884.80\t\tLearning rate: 1.624e-03, Batch size: 32, Momentum: 9.464e-01\n",
      "best loss: 3892.28\t\tLearning rate: 4.833e-03, Batch size: 44, Momentum: 3.155e-01\n",
      "best loss: 3894.38\t\tLearning rate: 4.833e-03, Batch size: 39, Momentum: 3.681e-01\n",
      "best loss: 3900.67\t\tLearning rate: 1.624e-03, Batch size: 17, Momentum: 8.413e-01\n",
      "best loss: 3919.51\t\tLearning rate: 1.624e-03, Batch size: 7, Momentum: 7.361e-01\n",
      "best loss: 3926.28\t\tLearning rate: 5.456e-04, Batch size: 19, Momentum: 9.464e-01\n",
      "best loss: 3931.11\t\tLearning rate: 1.624e-03, Batch size: 9, Momentum: 6.835e-01\n",
      "best loss: 3931.17\t\tLearning rate: 4.833e-03, Batch size: 27, Momentum: 6.309e-01\n",
      "best loss: 3943.61\t\tLearning rate: 1.438e-02, Batch size: 2, Momentum: 1.577e-01\n",
      "best loss: 3955.24\t\tLearning rate: 1.624e-03, Batch size: 50, Momentum: 7.887e-01\n",
      "best loss: 3956.47\t\tLearning rate: 1.624e-03, Batch size: 50, Momentum: 8.938e-01\n",
      "best loss: 3959.91\t\tLearning rate: 1.624e-03, Batch size: 4, Momentum: 9.464e-01\n",
      "best loss: 3969.50\t\tLearning rate: 4.833e-03, Batch size: 42, Momentum: 5.784e-01\n",
      "best loss: 3985.42\t\tLearning rate: 4.833e-03, Batch size: 24, Momentum: 4.732e-01\n",
      "best loss: 3993.04\t\tLearning rate: 4.833e-03, Batch size: 12, Momentum: 6.309e-01\n",
      "best loss: 4003.40\t\tLearning rate: 4.833e-03, Batch size: 32, Momentum: 4.732e-01\n",
      "best loss: 4009.44\t\tLearning rate: 4.833e-03, Batch size: 50, Momentum: 6.309e-01\n",
      "best loss: 4020.73\t\tLearning rate: 4.833e-03, Batch size: 44, Momentum: 8.413e-01\n",
      "best loss: 4027.26\t\tLearning rate: 1.438e-02, Batch size: 2, Momentum: 0.000e+00\n",
      "best loss: 4034.41\t\tLearning rate: 1.624e-03, Batch size: 24, Momentum: 8.938e-01\n",
      "best loss: 4037.42\t\tLearning rate: 1.438e-02, Batch size: 9, Momentum: 2.103e-01\n",
      "best loss: 4067.53\t\tLearning rate: 1.624e-03, Batch size: 34, Momentum: 8.938e-01\n",
      "best loss: 4070.79\t\tLearning rate: 1.624e-03, Batch size: 7, Momentum: 9.990e-01\n",
      "best loss: 4078.87\t\tLearning rate: 4.833e-03, Batch size: 32, Momentum: 7.887e-01\n",
      "best loss: 4085.76\t\tLearning rate: 1.624e-03, Batch size: 39, Momentum: 9.464e-01\n",
      "best loss: 4097.69\t\tLearning rate: 4.833e-03, Batch size: 37, Momentum: 7.361e-01\n",
      "best loss: 4111.19\t\tLearning rate: 4.833e-03, Batch size: 47, Momentum: 6.835e-01\n",
      "best loss: 4138.85\t\tLearning rate: 1.624e-03, Batch size: 9, Momentum: 9.990e-01\n",
      "best loss: 4164.26\t\tLearning rate: 1.438e-02, Batch size: 32, Momentum: 2.103e-01\n",
      "best loss: 4168.78\t\tLearning rate: 1.438e-02, Batch size: 39, Momentum: 4.732e-01\n",
      "best loss: 4170.79\t\tLearning rate: 4.833e-03, Batch size: 27, Momentum: 7.361e-01\n",
      "best loss: 4188.27\t\tLearning rate: 4.833e-03, Batch size: 22, Momentum: 8.938e-01\n",
      "best loss: 4191.31\t\tLearning rate: 4.281e-02, Batch size: 9, Momentum: 2.103e-01\n",
      "best loss: 4207.21\t\tLearning rate: 4.833e-03, Batch size: 42, Momentum: 7.887e-01\n",
      "best loss: 4207.75\t\tLearning rate: 4.281e-02, Batch size: 50, Momentum: 2.103e-01\n",
      "best loss: 4228.28\t\tLearning rate: 1.438e-02, Batch size: 34, Momentum: 5.258e-01\n",
      "best loss: 4245.89\t\tLearning rate: 4.281e-02, Batch size: 32, Momentum: 3.155e-01\n",
      "best loss: 4253.86\t\tLearning rate: 4.281e-02, Batch size: 47, Momentum: 2.629e-01\n",
      "best loss: 4256.17\t\tLearning rate: 4.281e-02, Batch size: 14, Momentum: 3.681e-01\n",
      "best loss: 4262.86\t\tLearning rate: 1.438e-02, Batch size: 37, Momentum: 5.784e-01\n",
      "best loss: 4266.77\t\tLearning rate: 4.281e-02, Batch size: 12, Momentum: 2.103e-01\n",
      "best loss: 4270.89\t\tLearning rate: 4.281e-02, Batch size: 32, Momentum: 5.258e-01\n",
      "best loss: 4295.21\t\tLearning rate: 4.281e-02, Batch size: 7, Momentum: 6.835e-01\n",
      "best loss: 4308.54\t\tLearning rate: 1.438e-02, Batch size: 17, Momentum: 6.309e-01\n",
      "best loss: 4312.14\t\tLearning rate: 1.274e-01, Batch size: 24, Momentum: 5.258e-02\n",
      "best loss: 4341.25\t\tLearning rate: 1.438e-02, Batch size: 37, Momentum: 7.887e-01\n",
      "best loss: 4346.86\t\tLearning rate: 4.281e-02, Batch size: 34, Momentum: 6.309e-01\n",
      "best loss: 4348.49\t\tLearning rate: 1.274e-01, Batch size: 32, Momentum: 1.577e-01\n",
      "best loss: 4364.35\t\tLearning rate: 1.438e-02, Batch size: 37, Momentum: 6.835e-01\n",
      "best loss: 4370.67\t\tLearning rate: 4.281e-02, Batch size: 22, Momentum: 5.258e-01\n",
      "best loss: 4377.48\t\tLearning rate: 1.438e-02, Batch size: 47, Momentum: 7.361e-01\n",
      "best loss: 4386.26\t\tLearning rate: 4.281e-02, Batch size: 44, Momentum: 4.206e-01\n",
      "best loss: 4402.68\t\tLearning rate: 1.438e-02, Batch size: 9, Momentum: 8.413e-01\n",
      "best loss: 4420.76\t\tLearning rate: 1.438e-02, Batch size: 4, Momentum: 9.464e-01\n",
      "best loss: 4442.93\t\tLearning rate: 1.274e-01, Batch size: 44, Momentum: 1.577e-01\n",
      "best loss: 4446.49\t\tLearning rate: 1.438e-02, Batch size: 44, Momentum: 8.413e-01\n",
      "best loss: 4461.62\t\tLearning rate: 4.281e-02, Batch size: 39, Momentum: 4.732e-01\n",
      "best loss: 4461.82\t\tLearning rate: 4.281e-02, Batch size: 9, Momentum: 5.784e-01\n",
      "best loss: 4489.63\t\tLearning rate: 1.274e-01, Batch size: 9, Momentum: 3.681e-01\n",
      "best loss: 4491.04\t\tLearning rate: 1.274e-01, Batch size: 50, Momentum: 2.103e-01\n",
      "best loss: 4492.85\t\tLearning rate: 1.274e-01, Batch size: 19, Momentum: 5.258e-01\n",
      "best loss: 4520.30\t\tLearning rate: 1.274e-01, Batch size: 9, Momentum: 3.155e-01\n",
      "best loss: 4529.38\t\tLearning rate: 4.281e-02, Batch size: 50, Momentum: 7.361e-01\n",
      "best loss: 4532.28\t\tLearning rate: 1.274e-01, Batch size: 4, Momentum: 3.681e-01\n",
      "best loss: 4558.68\t\tLearning rate: 1.274e-01, Batch size: 2, Momentum: 3.681e-01\n",
      "best loss: 4564.70\t\tLearning rate: 1.274e-01, Batch size: 17, Momentum: 6.309e-01\n",
      "best loss: 4588.91\t\tLearning rate: 3.793e-01, Batch size: 14, Momentum: 3.155e-01\n",
      "best loss: 4595.83\t\tLearning rate: 1.274e-01, Batch size: 39, Momentum: 4.732e-01\n",
      "best loss: 4598.61\t\tLearning rate: 1.274e-01, Batch size: 47, Momentum: 5.258e-01\n",
      "best loss: 4633.64\t\tLearning rate: 4.281e-02, Batch size: 19, Momentum: 7.887e-01\n",
      "best loss: 4637.39\t\tLearning rate: 3.793e-01, Batch size: 7, Momentum: 1.577e-01\n",
      "best loss: 4637.67\t\tLearning rate: 4.281e-02, Batch size: 9, Momentum: 8.413e-01\n",
      "best loss: 4638.97\t\tLearning rate: 4.281e-02, Batch size: 47, Momentum: 8.413e-01\n",
      "best loss: 4672.48\t\tLearning rate: 3.793e-01, Batch size: 32, Momentum: 1.577e-01\n",
      "best loss: 4677.78\t\tLearning rate: 1.274e-01, Batch size: 29, Momentum: 2.629e-01\n",
      "best loss: 4681.94\t\tLearning rate: 3.793e-01, Batch size: 37, Momentum: 2.103e-01\n",
      "best loss: 4682.23\t\tLearning rate: 4.281e-02, Batch size: 27, Momentum: 8.413e-01\n",
      "best loss: 4682.94\t\tLearning rate: 1.274e-01, Batch size: 9, Momentum: 6.835e-01\n",
      "best loss: 4690.52\t\tLearning rate: 1.438e-02, Batch size: 27, Momentum: 9.990e-01\n",
      "best loss: 4741.98\t\tLearning rate: 3.793e-01, Batch size: 50, Momentum: 3.681e-01\n",
      "best loss: 4769.88\t\tLearning rate: 3.793e-01, Batch size: 22, Momentum: 1.577e-01\n",
      "best loss: 4781.95\t\tLearning rate: 1.274e-01, Batch size: 47, Momentum: 7.887e-01\n",
      "best loss: 4794.72\t\tLearning rate: 3.793e-01, Batch size: 9, Momentum: 1.577e-01\n",
      "best loss: 4805.91\t\tLearning rate: 3.793e-01, Batch size: 44, Momentum: 4.206e-01\n",
      "best loss: 4816.07\t\tLearning rate: 1.274e-01, Batch size: 4, Momentum: 8.938e-01\n",
      "best loss: 4838.55\t\tLearning rate: 3.793e-01, Batch size: 12, Momentum: 5.784e-01\n",
      "best loss: 4884.17\t\tLearning rate: 1.129e+00, Batch size: 47, Momentum: 2.629e-01\n",
      "best loss: 4888.88\t\tLearning rate: 3.793e-01, Batch size: 44, Momentum: 5.784e-01\n",
      "best loss: 4894.23\t\tLearning rate: 3.793e-01, Batch size: 19, Momentum: 8.938e-01\n",
      "best loss: 4901.19\t\tLearning rate: 1.274e-01, Batch size: 37, Momentum: 9.464e-01\n",
      "best loss: 4912.30\t\tLearning rate: 3.793e-01, Batch size: 50, Momentum: 6.309e-01\n",
      "best loss: 4932.56\t\tLearning rate: 1.129e+00, Batch size: 4, Momentum: 2.103e-01\n",
      "best loss: 4973.33\t\tLearning rate: 1.129e+00, Batch size: 44, Momentum: 3.155e-01\n",
      "best loss: 4991.80\t\tLearning rate: 1.274e-01, Batch size: 47, Momentum: 9.990e-01\n",
      "best loss: 5012.09\t\tLearning rate: 3.793e-01, Batch size: 29, Momentum: 7.887e-01\n",
      "best loss: 5025.33\t\tLearning rate: 1.129e+00, Batch size: 47, Momentum: 3.681e-01\n",
      "best loss: 5039.35\t\tLearning rate: 1.129e+00, Batch size: 4, Momentum: 4.732e-01\n",
      "best loss: 5055.59\t\tLearning rate: 3.793e-01, Batch size: 32, Momentum: 7.361e-01\n",
      "best loss: 5057.62\t\tLearning rate: 1.274e-01, Batch size: 50, Momentum: 9.990e-01\n",
      "best loss: 5059.51\t\tLearning rate: 1.274e-01, Batch size: 47, Momentum: 9.464e-01\n",
      "best loss: 5089.60\t\tLearning rate: 1.129e+00, Batch size: 44, Momentum: 5.784e-01\n",
      "best loss: 5092.59\t\tLearning rate: 3.793e-01, Batch size: 24, Momentum: 8.413e-01\n",
      "best loss: 5101.17\t\tLearning rate: 3.360e+00, Batch size: 29, Momentum: 2.629e-01\n",
      "best loss: 5113.35\t\tLearning rate: 3.793e-01, Batch size: 7, Momentum: 7.887e-01\n",
      "best loss: 5117.62\t\tLearning rate: 3.360e+00, Batch size: 12, Momentum: 4.206e-01\n",
      "best loss: 5117.63\t\tLearning rate: 1.129e+00, Batch size: 32, Momentum: 5.258e-01\n",
      "best loss: 5126.40\t\tLearning rate: 3.793e-01, Batch size: 37, Momentum: 8.413e-01\n",
      "best loss: 5130.44\t\tLearning rate: 1.129e+00, Batch size: 39, Momentum: 6.835e-01\n",
      "best loss: 5130.67\t\tLearning rate: 1.129e+00, Batch size: 29, Momentum: 6.309e-01\n",
      "best loss: 5147.78\t\tLearning rate: 3.793e-01, Batch size: 14, Momentum: 8.938e-01\n",
      "best loss: 5164.62\t\tLearning rate: 3.793e-01, Batch size: 39, Momentum: 9.464e-01\n",
      "best loss: 5183.08\t\tLearning rate: 3.360e+00, Batch size: 44, Momentum: 3.681e-01\n",
      "best loss: 5190.42\t\tLearning rate: 3.793e-01, Batch size: 14, Momentum: 9.464e-01\n",
      "best loss: 5200.43\t\tLearning rate: 1.129e+00, Batch size: 34, Momentum: 6.835e-01\n",
      "best loss: 5218.70\t\tLearning rate: 1.129e+00, Batch size: 47, Momentum: 7.887e-01\n",
      "best loss: 5226.78\t\tLearning rate: 3.793e-01, Batch size: 34, Momentum: 9.464e-01\n",
      "best loss: 5248.57\t\tLearning rate: 3.793e-01, Batch size: 32, Momentum: 9.990e-01\n",
      "best loss: 5248.89\t\tLearning rate: 1.129e+00, Batch size: 22, Momentum: 8.413e-01\n",
      "best loss: 5307.05\t\tLearning rate: 3.360e+00, Batch size: 34, Momentum: 4.206e-01\n",
      "best loss: 5326.00\t\tLearning rate: 3.360e+00, Batch size: 29, Momentum: 5.258e-01\n",
      "best loss: 5365.96\t\tLearning rate: 3.360e+00, Batch size: 42, Momentum: 6.309e-01\n",
      "best loss: 5368.17\t\tLearning rate: 1.000e+01, Batch size: 12, Momentum: 3.681e-01\n",
      "best loss: 5383.33\t\tLearning rate: 1.129e+00, Batch size: 50, Momentum: 9.464e-01\n",
      "best loss: 5388.22\t\tLearning rate: 1.000e+01, Batch size: 37, Momentum: 2.103e-01\n",
      "best loss: 5416.21\t\tLearning rate: 3.360e+00, Batch size: 19, Momentum: 6.835e-01\n",
      "best loss: 5448.16\t\tLearning rate: 1.000e+01, Batch size: 37, Momentum: 3.681e-01\n",
      "best loss: 5453.04\t\tLearning rate: 3.360e+00, Batch size: 29, Momentum: 8.938e-01\n",
      "best loss: 5470.67\t\tLearning rate: 1.129e+00, Batch size: 24, Momentum: 9.990e-01\n",
      "best loss: 5531.36\t\tLearning rate: 3.360e+00, Batch size: 50, Momentum: 8.413e-01\n",
      "best loss: 5589.72\t\tLearning rate: 1.000e+01, Batch size: 22, Momentum: 4.732e-01\n",
      "best loss: 5595.95\t\tLearning rate: 1.000e+01, Batch size: 37, Momentum: 5.784e-01\n",
      "best loss: 5615.59\t\tLearning rate: 3.360e+00, Batch size: 50, Momentum: 9.464e-01\n",
      "best loss: 5651.95\t\tLearning rate: 1.000e+01, Batch size: 17, Momentum: 6.835e-01\n",
      "best loss: 5677.15\t\tLearning rate: 1.000e+01, Batch size: 17, Momentum: 7.361e-01\n",
      "best loss: 5684.87\t\tLearning rate: 3.360e+00, Batch size: 44, Momentum: 9.464e-01\n",
      "best loss: 5700.99\t\tLearning rate: 1.000e+01, Batch size: 44, Momentum: 7.361e-01\n",
      "best loss: 5720.46\t\tLearning rate: 1.000e+01, Batch size: 34, Momentum: 7.887e-01\n",
      "best loss: 5731.73\t\tLearning rate: 3.360e+00, Batch size: 9, Momentum: 9.990e-01\n",
      "best loss: 5740.98\t\tLearning rate: 1.000e+01, Batch size: 44, Momentum: 7.887e-01\n",
      "best loss: 5779.39\t\tLearning rate: 1.000e+01, Batch size: 12, Momentum: 7.887e-01\n",
      "best loss: 5816.34\t\tLearning rate: 1.000e+01, Batch size: 14, Momentum: 8.413e-01\n",
      "best loss: 5833.79\t\tLearning rate: 1.000e+01, Batch size: 2, Momentum: 8.413e-01\n",
      "best loss: 5928.86\t\tLearning rate: 1.000e+01, Batch size: 24, Momentum: 9.990e-01\n",
      "best loss: 6024.08\t\tLearning rate: 1.000e+01, Batch size: 47, Momentum: 9.990e-01\n",
      "best loss: 8461.97\t\tLearning rate: 4.833e-03, Batch size: 2, Momentum: 1.577e-01\n",
      "best loss: 8570.43\t\tLearning rate: 8.859e-08, Batch size: 4, Momentum: 6.309e-01\n",
      "best loss: 9566.93\t\tLearning rate: 6.158e-05, Batch size: 4, Momentum: 5.258e-02\n",
      "best loss: 12648.80\t\tLearning rate: 1.000e-08, Batch size: 4, Momentum: 5.258e-02\n",
      "best loss: 13196.67\t\tLearning rate: 8.859e-08, Batch size: 17, Momentum: 5.784e-01\n",
      "best loss: 16480.78\t\tLearning rate: 3.793e-01, Batch size: 7, Momentum: 3.681e-01\n",
      "best loss: 20354.27\t\tLearning rate: 2.069e-05, Batch size: 17, Momentum: 5.784e-01\n",
      "best loss: 25896.27\t\tLearning rate: 2.976e-08, Batch size: 14, Momentum: 5.784e-01\n",
      "best loss: 27058.79\t\tLearning rate: 2.976e-08, Batch size: 24, Momentum: 5.258e-02\n",
      "best loss: 29175.92\t\tLearning rate: 2.976e-08, Batch size: 12, Momentum: 8.413e-01\n",
      "best loss: 32798.03\t\tLearning rate: 2.976e-08, Batch size: 7, Momentum: 5.258e-02\n",
      "best loss: 35771.62\t\tLearning rate: 2.976e-08, Batch size: 19, Momentum: 0.000e+00\n",
      "best loss: 37142.94\t\tLearning rate: 3.360e+00, Batch size: 24, Momentum: 2.103e-01\n",
      "best loss: 39698.77\t\tLearning rate: 2.069e-05, Batch size: 14, Momentum: 5.784e-01\n",
      "best loss: 45411.47\t\tLearning rate: 2.976e-08, Batch size: 32, Momentum: 6.309e-01\n",
      "best loss: 47029.85\t\tLearning rate: 2.637e-07, Batch size: 50, Momentum: 5.258e-01\n",
      "best loss: 50994.03\t\tLearning rate: 1.000e-08, Batch size: 32, Momentum: 3.155e-01\n",
      "best loss: 51970.30\t\tLearning rate: 2.976e-08, Batch size: 37, Momentum: 7.887e-01\n",
      "best loss: 54922.77\t\tLearning rate: 3.793e-01, Batch size: 37, Momentum: 0.000e+00\n",
      "best loss: 55652.48\t\tLearning rate: 2.637e-07, Batch size: 29, Momentum: 3.681e-01\n",
      "best loss: 56791.82\t\tLearning rate: 1.438e-02, Batch size: 17, Momentum: 3.155e-01\n",
      "best loss: 59757.87\t\tLearning rate: 5.456e-04, Batch size: 17, Momentum: 2.629e-01\n",
      "best loss: 62924.41\t\tLearning rate: 1.438e-02, Batch size: 4, Momentum: 0.000e+00\n",
      "best loss: 64461.15\t\tLearning rate: 2.976e-08, Batch size: 14, Momentum: 0.000e+00\n",
      "best loss: 71122.17\t\tLearning rate: 3.793e-01, Batch size: 7, Momentum: 5.258e-02\n",
      "best loss: 76508.28\t\tLearning rate: 2.976e-08, Batch size: 12, Momentum: 7.361e-01\n",
      "best loss: 77859.16\t\tLearning rate: 8.859e-08, Batch size: 14, Momentum: 3.681e-01\n",
      "best loss: 81392.61\t\tLearning rate: 2.637e-07, Batch size: 39, Momentum: 1.577e-01\n",
      "best loss: 86673.67\t\tLearning rate: 2.976e-08, Batch size: 19, Momentum: 3.681e-01\n",
      "best loss: 88464.89\t\tLearning rate: 1.000e+01, Batch size: 29, Momentum: 0.000e+00\n",
      "best loss: 93882.77\t\tLearning rate: 3.360e+00, Batch size: 32, Momentum: 1.052e-01\n",
      "best loss: 98022.92\t\tLearning rate: 2.976e-08, Batch size: 12, Momentum: 1.577e-01\n",
      "best loss: 101484.17\t\tLearning rate: 1.000e-08, Batch size: 47, Momentum: 3.155e-01\n",
      "best loss: 109617.35\t\tLearning rate: 1.000e-08, Batch size: 17, Momentum: 1.052e-01\n",
      "best loss: 113975.21\t\tLearning rate: 6.158e-05, Batch size: 17, Momentum: 1.577e-01\n",
      "best loss: 116458.73\t\tLearning rate: 2.976e-08, Batch size: 7, Momentum: 3.155e-01\n",
      "best loss: 125937.10\t\tLearning rate: 1.000e-08, Batch size: 42, Momentum: 5.784e-01\n",
      "best loss: 135767.82\t\tLearning rate: 3.360e+00, Batch size: 9, Momentum: 3.681e-01\n",
      "best loss: 135882.73\t\tLearning rate: 8.859e-08, Batch size: 27, Momentum: 4.732e-01\n",
      "best loss: 141979.90\t\tLearning rate: 2.976e-08, Batch size: 44, Momentum: 1.052e-01\n",
      "best loss: 143285.94\t\tLearning rate: 1.000e-08, Batch size: 27, Momentum: 4.206e-01\n",
      "best loss: 148098.49\t\tLearning rate: 1.833e-04, Batch size: 12, Momentum: 1.052e-01\n",
      "best loss: 160883.37\t\tLearning rate: 8.859e-08, Batch size: 27, Momentum: 5.258e-02\n",
      "best loss: 168204.68\t\tLearning rate: 1.129e+00, Batch size: 44, Momentum: 4.206e-01\n",
      "best loss: 170491.27\t\tLearning rate: 5.456e-04, Batch size: 12, Momentum: 0.000e+00\n",
      "best loss: 179384.81\t\tLearning rate: 2.637e-07, Batch size: 37, Momentum: 1.052e-01\n",
      "best loss: 196431.36\t\tLearning rate: 1.624e-03, Batch size: 2, Momentum: 3.155e-01\n",
      "best loss: 196484.28\t\tLearning rate: 2.976e-08, Batch size: 50, Momentum: 6.309e-01\n",
      "best loss: 212229.90\t\tLearning rate: 8.859e-08, Batch size: 42, Momentum: 5.784e-01\n",
      "best loss: 225296.33\t\tLearning rate: 2.069e-05, Batch size: 17, Momentum: 0.000e+00\n",
      "best loss: 255963.54\t\tLearning rate: 1.129e+00, Batch size: 14, Momentum: 1.577e-01\n",
      "best loss: 259627.67\t\tLearning rate: 2.069e-05, Batch size: 32, Momentum: 5.258e-01\n",
      "best loss: 265759.82\t\tLearning rate: 1.129e+00, Batch size: 47, Momentum: 5.258e-02\n",
      "best loss: 287234.04\t\tLearning rate: 2.976e-08, Batch size: 14, Momentum: 5.258e-01\n",
      "best loss: 313885.67\t\tLearning rate: 4.281e-02, Batch size: 22, Momentum: 2.103e-01\n",
      "best loss: 314617.90\t\tLearning rate: 2.637e-07, Batch size: 17, Momentum: 4.206e-01\n",
      "best loss: 330813.87\t\tLearning rate: 2.976e-08, Batch size: 42, Momentum: 6.835e-01\n",
      "best loss: 342082.14\t\tLearning rate: 1.000e+01, Batch size: 19, Momentum: 0.000e+00\n",
      "best loss: 344459.41\t\tLearning rate: 8.859e-08, Batch size: 34, Momentum: 5.784e-01\n",
      "best loss: 347270.33\t\tLearning rate: 1.624e-03, Batch size: 47, Momentum: 0.000e+00\n",
      "best loss: 358384.93\t\tLearning rate: 2.637e-07, Batch size: 24, Momentum: 2.629e-01\n",
      "best loss: 407647.29\t\tLearning rate: 8.859e-08, Batch size: 32, Momentum: 6.835e-01\n",
      "best loss: 407865.73\t\tLearning rate: 1.000e-08, Batch size: 32, Momentum: 1.577e-01\n",
      "best loss: 412141.73\t\tLearning rate: 1.833e-04, Batch size: 42, Momentum: 3.155e-01\n",
      "best loss: 425030.40\t\tLearning rate: 4.833e-03, Batch size: 34, Momentum: 0.000e+00\n",
      "best loss: 440054.23\t\tLearning rate: 1.624e-03, Batch size: 32, Momentum: 5.258e-02\n",
      "best loss: 457751.04\t\tLearning rate: 6.158e-05, Batch size: 34, Momentum: 4.732e-01\n",
      "best loss: 497084.48\t\tLearning rate: 4.833e-03, Batch size: 22, Momentum: 5.258e-02\n",
      "best loss: 511248.74\t\tLearning rate: 2.069e-05, Batch size: 42, Momentum: 1.577e-01\n",
      "best loss: 544547.16\t\tLearning rate: 2.976e-08, Batch size: 27, Momentum: 5.784e-01\n",
      "best loss: 589528.31\t\tLearning rate: 3.793e-01, Batch size: 24, Momentum: 3.155e-01\n",
      "best loss: 599018.91\t\tLearning rate: 6.952e-06, Batch size: 34, Momentum: 2.103e-01\n",
      "best loss: 769895.95\t\tLearning rate: 2.976e-08, Batch size: 50, Momentum: 2.629e-01\n",
      "best loss: 884320.92\t\tLearning rate: 4.281e-02, Batch size: 44, Momentum: 2.629e-01\n",
      "best loss: 886650.32\t\tLearning rate: 2.069e-05, Batch size: 29, Momentum: 3.155e-01\n",
      "best loss: 912777.54\t\tLearning rate: 2.976e-08, Batch size: 34, Momentum: 2.103e-01\n",
      "best loss: 920751.89\t\tLearning rate: 1.000e+01, Batch size: 47, Momentum: 2.103e-01\n",
      "best loss: 1015666.59\t\tLearning rate: 4.281e-02, Batch size: 27, Momentum: 0.000e+00\n",
      "best loss: 1057827.40\t\tLearning rate: 4.281e-02, Batch size: 42, Momentum: 3.681e-01\n",
      "best loss: 1213584.55\t\tLearning rate: 1.624e-03, Batch size: 47, Momentum: 4.732e-01\n",
      "best loss: 1239950.17\t\tLearning rate: 1.438e-02, Batch size: 4, Momentum: 5.258e-02\n",
      "best loss: 1485476.30\t\tLearning rate: 2.069e-05, Batch size: 50, Momentum: 3.155e-01\n",
      "best loss: 1913349.52\t\tLearning rate: 1.833e-04, Batch size: 19, Momentum: 5.258e-02\n",
      "best loss: 1992032.50\t\tLearning rate: 4.281e-02, Batch size: 7, Momentum: 1.052e-01\n",
      "best loss: 2021942.56\t\tLearning rate: 6.158e-05, Batch size: 37, Momentum: 5.258e-02\n",
      "best loss: 2471216.21\t\tLearning rate: 4.833e-03, Batch size: 22, Momentum: 0.000e+00\n",
      "best loss: 2510129.51\t\tLearning rate: 1.000e+01, Batch size: 47, Momentum: 0.000e+00\n",
      "best loss: 2935639.11\t\tLearning rate: 2.069e-05, Batch size: 27, Momentum: 4.206e-01\n",
      "best loss: 2965675.66\t\tLearning rate: 1.624e-03, Batch size: 34, Momentum: 5.258e-02\n",
      "best loss: 3016867.83\t\tLearning rate: 6.158e-05, Batch size: 37, Momentum: 1.052e-01\n",
      "best loss: 3279520.96\t\tLearning rate: 4.281e-02, Batch size: 17, Momentum: 1.577e-01\n",
      "best loss: 3893347.19\t\tLearning rate: 3.793e-01, Batch size: 27, Momentum: 4.732e-01\n",
      "best loss: 4047270.65\t\tLearning rate: 3.360e+00, Batch size: 42, Momentum: 6.835e-01\n",
      "best loss: 4140529.83\t\tLearning rate: 1.438e-02, Batch size: 9, Momentum: 0.000e+00\n",
      "best loss: 4389511.56\t\tLearning rate: 1.624e-03, Batch size: 42, Momentum: 0.000e+00\n",
      "best loss: 5507673.74\t\tLearning rate: 4.281e-02, Batch size: 34, Momentum: 0.000e+00\n",
      "best loss: 6583909.96\t\tLearning rate: 1.438e-02, Batch size: 44, Momentum: 3.155e-01\n",
      "best loss: 11872639.83\t\tLearning rate: 3.360e+00, Batch size: 44, Momentum: 2.103e-01\n",
      "best loss: 12175916.22\t\tLearning rate: 5.456e-04, Batch size: 2, Momentum: 1.052e-01\n",
      "best loss: 17796749.42\t\tLearning rate: 1.274e-01, Batch size: 9, Momentum: 5.258e-01\n"
     ]
    }
   ],
   "source": [
    "# print the hyperparameters ranked from best to worst\n",
    "sorted_results = sorted(results.items(), key=lambda x: x[1])\n",
    "for hp, loss in sorted_results:\n",
    "    print(f\"best loss: {loss:.2f}\\t\\tLearning rate: {hp[0]:.3e}, Batch size: {hp[1]}, Momentum: {hp[2]:.3e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phenotypes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
