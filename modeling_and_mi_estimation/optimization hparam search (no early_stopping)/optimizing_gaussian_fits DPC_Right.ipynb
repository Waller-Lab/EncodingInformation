{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solve for Gaussian approximations using optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening BSCCM\n",
      "Opened BSCCM\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# this only works on startup!\n",
    "from jax import config\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '2'\n",
    "from gpu_utils import limit_gpu_memory_growth\n",
    "limit_gpu_memory_growth()\n",
    "\n",
    "from cleanplots import *\n",
    "from tqdm import tqdm\n",
    "from information_estimation import *\n",
    "from image_utils import *\n",
    "from gaussian_process_utils import *\n",
    "\n",
    "from led_array.bsccm_utils import *\n",
    "from bsccm import BSCCM\n",
    "from jax import jit\n",
    "import numpy as onp\n",
    "import jax.numpy as np\n",
    "\n",
    "bsccm = BSCCM('/home/hpinkard_waller/data/BSCCM/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images, extract patches, and compute cov mats\n",
    "edge_crop = 32\n",
    "patch_size = 10\n",
    "num_images = 20000\n",
    "num_patches = 1000\n",
    "channel = 'DPC_Right'\n",
    "eigenvalue_floor = 1e0\n",
    "\n",
    "images = load_bsccm_images(bsccm, channel=channel, num_images=num_images, edge_crop=edge_crop, median_filter=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search through hyperparameter combos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss:  2592530.293355295\n",
      "best loss: 487.29\t\tLearning rate: 6.952e-06, Batch size: 22, Momentum: 2.103e-01\n",
      "Initial loss:  2943911.9043606557\n",
      "best loss: 1309.10\t\tLearning rate: 1.129e+00, Batch size: 24, Momentum: 4.732e-01\n",
      "Initial loss:  1441489.3996652192\n",
      "best loss: 425393.95\t\tLearning rate: 8.859e-08, Batch size: 42, Momentum: 6.835e-01\n",
      "Initial loss:  1281486.853312103\n",
      "best loss: 753.78\t\tLearning rate: 6.158e-05, Batch size: 2, Momentum: 9.464e-01\n",
      "Initial loss:  1439263.93377049\n",
      "best loss: 67436.21\t\tLearning rate: 8.859e-08, Batch size: 14, Momentum: 1.052e-01\n",
      "Initial loss:  3043936.794973596\n",
      "best loss: 492.03\t\tLearning rate: 2.336e-06, Batch size: 12, Momentum: 1.577e-01\n",
      "Initial loss:  855263.5448877309\n",
      "best loss: 494.45\t\tLearning rate: 2.336e-06, Batch size: 34, Momentum: 5.258e-01\n",
      "Initial loss:  1324093.4444038684\n",
      "best loss: 1116.55\t\tLearning rate: 4.833e-03, Batch size: 19, Momentum: 9.990e-01\n",
      "Initial loss:  2832661.020618928\n",
      "best loss: 1066.88\t\tLearning rate: 4.833e-03, Batch size: 19, Momentum: 8.938e-01\n",
      "Initial loss:  2876571.468512344\n",
      "best loss: 1323.50\t\tLearning rate: 3.360e+00, Batch size: 4, Momentum: 3.681e-01\n",
      "Initial loss:  1073364.441548315\n",
      "best loss: 1279.28\t\tLearning rate: 3.793e-01, Batch size: 12, Momentum: 8.413e-01\n",
      "Initial loss:  1641873.501730225\n",
      "best loss: 846.28\t\tLearning rate: 5.456e-04, Batch size: 4, Momentum: 7.361e-01\n",
      "Initial loss:  689411.5942745985\n",
      "best loss: 1445.29\t\tLearning rate: 1.129e+00, Batch size: 19, Momentum: 9.990e-01\n",
      "Initial loss:  2960389.0855162474\n",
      "best loss: 1157.27\t\tLearning rate: 4.281e-02, Batch size: 47, Momentum: 6.309e-01\n",
      "Initial loss:  1451084.9990372406\n",
      "best loss: 854.39\t\tLearning rate: 1.624e-03, Batch size: 22, Momentum: 5.258e-02\n",
      "Initial loss:  2536187.791279844\n",
      "best loss: 879262.24\t\tLearning rate: 1.624e-03, Batch size: 9, Momentum: 0.000e+00\n",
      "Initial loss:  1692560.731736857\n",
      "best loss: 1296.88\t\tLearning rate: 3.793e-01, Batch size: 9, Momentum: 8.413e-01\n",
      "Initial loss:  1428923.0696520943\n",
      "best loss: 495.78\t\tLearning rate: 2.637e-07, Batch size: 39, Momentum: 9.990e-01\n",
      "Initial loss:  1961157.756144241\n",
      "best loss: 1152.49\t\tLearning rate: 1.274e-01, Batch size: 17, Momentum: 3.155e-01\n",
      "Initial loss:  497.29057774942464\n",
      "best loss: 489.43\t\tLearning rate: 7.848e-07, Batch size: 34, Momentum: 6.835e-01\n",
      "Initial loss:  799730.5651120767\n",
      "best loss: 1037.18\t\tLearning rate: 1.624e-03, Batch size: 4, Momentum: 8.413e-01\n",
      "Initial loss:  547924.8723938101\n",
      "best loss: 1347.39\t\tLearning rate: 3.360e+00, Batch size: 7, Momentum: 4.732e-01\n",
      "Initial loss:  1411535.6805724134\n",
      "best loss: 647.95\t\tLearning rate: 2.069e-05, Batch size: 7, Momentum: 5.258e-01\n",
      "Initial loss:  3325867.8628421943\n",
      "best loss: 729140.94\t\tLearning rate: 2.637e-07, Batch size: 42, Momentum: 0.000e+00\n",
      "Initial loss:  405174.23279297125\n",
      "best loss: 543.19\t\tLearning rate: 2.069e-05, Batch size: 14, Momentum: 5.258e-02\n",
      "Initial loss:  3222628.3963062945\n",
      "best loss: 1450481.25\t\tLearning rate: 2.976e-08, Batch size: 50, Momentum: 2.103e-01\n",
      "Initial loss:  501.17541427870344\n",
      "best loss: 486.66\t\tLearning rate: 3.793e-01, Batch size: 22, Momentum: 7.887e-01\n",
      "Initial loss:  1137424.3029524009\n",
      "best loss: 500.36\t\tLearning rate: 2.637e-07, Batch size: 50, Momentum: 5.784e-01\n",
      "Initial loss:  4421637.626656646\n",
      "best loss: 499.04\t\tLearning rate: 7.848e-07, Batch size: 50, Momentum: 8.938e-01\n",
      "Initial loss:  351020.86941497284\n",
      "best loss: 1415.37\t\tLearning rate: 3.360e+00, Batch size: 12, Momentum: 6.835e-01\n",
      "Initial loss:  2621385.010597948\n",
      "best loss: 496.06\t\tLearning rate: 2.637e-07, Batch size: 22, Momentum: 3.155e-01\n",
      "Initial loss:  1341677.0161163807\n",
      "best loss: 1306.55\t\tLearning rate: 1.129e+00, Batch size: 14, Momentum: 6.309e-01\n",
      "Initial loss:  606583.1937731644\n",
      "best loss: 594.98\t\tLearning rate: 1.000e-08, Batch size: 12, Momentum: 4.206e-01\n",
      "Initial loss:  2760516.1665605423\n",
      "best loss: 506.40\t\tLearning rate: 2.336e-06, Batch size: 17, Momentum: 7.887e-01\n",
      "Initial loss:  687450.7497440481\n",
      "best loss: 487.06\t\tLearning rate: 7.848e-07, Batch size: 2, Momentum: 7.887e-01\n",
      "Initial loss:  2786028.5052644424\n",
      "best loss: 1391.31\t\tLearning rate: 1.000e+01, Batch size: 24, Momentum: 5.258e-01\n",
      "Initial loss:  1577741.9754467537\n",
      "best loss: 886.53\t\tLearning rate: 8.859e-08, Batch size: 32, Momentum: 0.000e+00\n",
      "Initial loss:  3420357.6584903784\n",
      "best loss: 502.62\t\tLearning rate: 2.336e-06, Batch size: 24, Momentum: 8.413e-01\n",
      "Initial loss:  1432963.1022971442\n",
      "best loss: 514.45\t\tLearning rate: 8.859e-08, Batch size: 12, Momentum: 4.206e-01\n",
      "Initial loss:  2025006.8084048165\n",
      "best loss: 1411.39\t\tLearning rate: 1.000e+01, Batch size: 14, Momentum: 3.681e-01\n",
      "Initial loss:  3896720.3577355566\n",
      "best loss: 584.61\t\tLearning rate: 6.952e-06, Batch size: 17, Momentum: 8.413e-01\n",
      "Initial loss:  1556232.6190552951\n",
      "best loss: 661.33\t\tLearning rate: 6.158e-05, Batch size: 29, Momentum: 1.577e-01\n",
      "Initial loss:  4038473.769163429\n",
      "best loss: 1392.57\t\tLearning rate: 1.000e+01, Batch size: 17, Momentum: 3.155e-01\n",
      "Initial loss:  503.7730437441486\n",
      "best loss: 476.66\t\tLearning rate: 2.637e-07, Batch size: 4, Momentum: 1.577e-01\n",
      "Initial loss:  2198186.450298734\n",
      "best loss: 609.64\t\tLearning rate: 2.637e-07, Batch size: 37, Momentum: 2.103e-01\n",
      "Initial loss:  468393.6876740135\n",
      "best loss: 1231.35\t\tLearning rate: 1.274e-01, Batch size: 42, Momentum: 8.938e-01\n",
      "Initial loss:  2624521.2622282906\n",
      "best loss: 901979.74\t\tLearning rate: 1.000e-08, Batch size: 34, Momentum: 4.206e-01\n",
      "Initial loss:  1223401.851346848\n",
      "best loss: 515.51\t\tLearning rate: 7.848e-07, Batch size: 50, Momentum: 2.629e-01\n",
      "Initial loss:  1776855.2773102624\n",
      "best loss: 484.99\t\tLearning rate: 2.336e-06, Batch size: 9, Momentum: 1.052e-01\n",
      "Initial loss:  776645.6188083092\n",
      "best loss: 4230.14\t\tLearning rate: 2.976e-08, Batch size: 4, Momentum: 5.784e-01\n",
      "Initial loss:  3713188.884724405\n",
      "best loss: 212466.66\t\tLearning rate: 2.976e-08, Batch size: 19, Momentum: 5.258e-01\n",
      "Initial loss:  1093222.5129947343\n",
      "best loss: 889.12\t\tLearning rate: 5.456e-04, Batch size: 32, Momentum: 8.938e-01\n",
      "Initial loss:  1987541.5648648106\n",
      "best loss: 480.32\t\tLearning rate: 2.976e-08, Batch size: 2, Momentum: 6.309e-01\n",
      "Initial loss:  2524484.7295946316\n",
      "best loss: 1142.87\t\tLearning rate: 1.274e-01, Batch size: 2, Momentum: 2.629e-01\n",
      "Initial loss:  232070.96523028368\n",
      "best loss: 508.04\t\tLearning rate: 7.848e-07, Batch size: 9, Momentum: 3.681e-01\n",
      "Initial loss:  3645419.283401185\n",
      "best loss: 1030.20\t\tLearning rate: 4.833e-03, Batch size: 42, Momentum: 7.887e-01\n",
      "Initial loss:  1471827.5847324529\n",
      "best loss: 147862.80\t\tLearning rate: 1.000e-08, Batch size: 50, Momentum: 1.052e-01\n",
      "Initial loss:  2805271.226270745\n",
      "best loss: 3846.40\t\tLearning rate: 1.000e-08, Batch size: 42, Momentum: 1.577e-01\n",
      "Initial loss:  2861943.810813814\n",
      "best loss: 1236.35\t\tLearning rate: 1.274e-01, Batch size: 50, Momentum: 8.938e-01\n",
      "Initial loss:  1049133.819056957\n",
      "best loss: 1003.50\t\tLearning rate: 4.281e-02, Batch size: 9, Momentum: 0.000e+00\n",
      "Initial loss:  4234196.631652136\n",
      "best loss: 695.18\t\tLearning rate: 2.976e-08, Batch size: 22, Momentum: 5.258e-02\n",
      "Initial loss:  1547129.8517277366\n",
      "best loss: 567.87\t\tLearning rate: 2.976e-08, Batch size: 9, Momentum: 5.258e-01\n",
      "Initial loss:  2765471.6748924023\n",
      "best loss: 659.83\t\tLearning rate: 1.000e-08, Batch size: 9, Momentum: 4.206e-01\n",
      "Initial loss:  1412249.487928476\n",
      "best loss: 661.83\t\tLearning rate: 2.069e-05, Batch size: 37, Momentum: 7.887e-01\n",
      "Initial loss:  132347.36432744263\n",
      "best loss: 1272.76\t\tLearning rate: 3.360e+00, Batch size: 17, Momentum: 2.103e-01\n",
      "Initial loss:  2173448.569337576\n",
      "best loss: 505.74\t\tLearning rate: 7.848e-07, Batch size: 44, Momentum: 4.732e-01\n",
      "Initial loss:  849310.4677926223\n",
      "best loss: 1053.65\t\tLearning rate: 4.833e-03, Batch size: 24, Momentum: 7.361e-01\n",
      "Initial loss:  3054154.405650938\n",
      "best loss: 618.19\t\tLearning rate: 2.069e-05, Batch size: 24, Momentum: 5.784e-01\n",
      "Initial loss:  1330216.6961065303\n",
      "best loss: 1370.81\t\tLearning rate: 1.000e+01, Batch size: 9, Momentum: 3.681e-01\n",
      "Initial loss:  1463919.0616698193\n",
      "best loss: 489.23\t\tLearning rate: 2.336e-06, Batch size: 9, Momentum: 6.835e-01\n",
      "Initial loss:  2296796.633676875\n",
      "best loss: 1340.95\t\tLearning rate: 1.129e+00, Batch size: 44, Momentum: 6.835e-01\n",
      "Initial loss:  190478.87283637744\n",
      "best loss: 1104.11\t\tLearning rate: 1.274e-01, Batch size: 9, Momentum: 2.103e-01\n",
      "Initial loss:  2268330.122817479\n",
      "best loss: 1127.53\t\tLearning rate: 1.438e-02, Batch size: 44, Momentum: 8.413e-01\n",
      "Initial loss:  1189553.053447804\n",
      "best loss: 598.02\t\tLearning rate: 1.000e-08, Batch size: 50, Momentum: 6.835e-01\n",
      "Initial loss:  1790731.7378979758\n",
      "best loss: 498.86\t\tLearning rate: 8.859e-08, Batch size: 37, Momentum: 9.990e-01\n",
      "Initial loss:  3286214.720654427\n",
      "best loss: 912.30\t\tLearning rate: 5.456e-04, Batch size: 12, Momentum: 9.990e-01\n",
      "Initial loss:  2449830.3094580364\n",
      "best loss: 1142.43\t\tLearning rate: 1.274e-01, Batch size: 42, Momentum: 1.052e-01\n",
      "Initial loss:  1551000.435354166\n",
      "best loss: 681.61\t\tLearning rate: 6.158e-05, Batch size: 19, Momentum: 5.258e-01\n",
      "Initial loss:  3593325.3639761545\n",
      "best loss: 938.58\t\tLearning rate: 2.637e-07, Batch size: 39, Momentum: 5.258e-02\n",
      "Initial loss:  3580697.850472687\n",
      "best loss: 1233.94\t\tLearning rate: 1.129e+00, Batch size: 22, Momentum: 5.258e-02\n",
      "Initial loss:  1223721.1260619923\n",
      "best loss: 941.24\t\tLearning rate: 1.624e-03, Batch size: 44, Momentum: 8.413e-01\n",
      "Initial loss:  1354296.2919288897\n",
      "best loss: 488.77\t\tLearning rate: 2.336e-06, Batch size: 12, Momentum: 4.206e-01\n",
      "Initial loss:  838939.8995950038\n",
      "best loss: 1313.34\t\tLearning rate: 1.129e+00, Batch size: 27, Momentum: 6.309e-01\n",
      "Initial loss:  862702.8930582895\n",
      "best loss: 493.27\t\tLearning rate: 2.637e-07, Batch size: 17, Momentum: 9.990e-01\n",
      "Initial loss:  4100045.3111079615\n",
      "best loss: 961.89\t\tLearning rate: 4.833e-03, Batch size: 27, Momentum: 1.052e-01\n",
      "Initial loss:  1646591.1677747094\n",
      "best loss: 492.89\t\tLearning rate: 7.848e-07, Batch size: 9, Momentum: 6.835e-01\n",
      "Initial loss:  3421425.610183866\n",
      "best loss: 1095.87\t\tLearning rate: 1.438e-02, Batch size: 22, Momentum: 6.309e-01\n",
      "Initial loss:  1703642.8372643746\n",
      "best loss: 93389.21\t\tLearning rate: 3.360e+00, Batch size: 7, Momentum: 3.681e-01\n",
      "Initial loss:  819821.318253683\n",
      "best loss: 959.97\t\tLearning rate: 5.456e-04, Batch size: 12, Momentum: 9.464e-01\n",
      "Initial loss:  1217433.6318403617\n",
      "best loss: 528.67\t\tLearning rate: 7.848e-07, Batch size: 47, Momentum: 5.258e-02\n",
      "Initial loss:  6537120.128274352\n",
      "best loss: 1006.73\t\tLearning rate: 1.438e-02, Batch size: 19, Momentum: 4.732e-01\n",
      "Initial loss:  464156.80265378556\n",
      "best loss: 910.16\t\tLearning rate: 1.624e-03, Batch size: 39, Momentum: 2.103e-01\n",
      "Initial loss:  2049743.8805240286\n",
      "best loss: 1212.55\t\tLearning rate: 4.281e-02, Batch size: 39, Momentum: 7.887e-01\n",
      "Initial loss:  2075613.5135709955\n",
      "best loss: 615.80\t\tLearning rate: 2.976e-08, Batch size: 32, Momentum: 5.784e-01\n",
      "Initial loss:  795507.0346043503\n",
      "best loss: 946.87\t\tLearning rate: 1.624e-03, Batch size: 50, Momentum: 5.258e-01\n",
      "Initial loss:  2649918.0632979614\n",
      "best loss: 504.23\t\tLearning rate: 2.336e-06, Batch size: 29, Momentum: 6.309e-01\n",
      "Initial loss:  714278.2552571329\n",
      "best loss: 1130.63\t\tLearning rate: 4.281e-02, Batch size: 7, Momentum: 4.732e-01\n",
      "Initial loss:  2693701.997437775\n",
      "best loss: 479.46\t\tLearning rate: 7.848e-07, Batch size: 4, Momentum: 6.835e-01\n",
      "Initial loss:  1731013.4232828477\n",
      "best loss: 1496492.74\t\tLearning rate: 1.274e-01, Batch size: 7, Momentum: 2.103e-01\n",
      "Initial loss:  2236448.642046285\n",
      "best loss: 730.23\t\tLearning rate: 6.158e-05, Batch size: 37, Momentum: 6.309e-01\n",
      "Initial loss:  1051273.4191572708\n",
      "best loss: 1452.47\t\tLearning rate: 1.000e+01, Batch size: 12, Momentum: 8.413e-01\n",
      "Initial loss:  1783405.7871894618\n",
      "best loss: 523.15\t\tLearning rate: 8.859e-08, Batch size: 24, Momentum: 6.835e-01\n",
      "Initial loss:  497.61150416283147\n",
      "best loss: 492.32\t\tLearning rate: 5.456e-04, Batch size: 39, Momentum: 5.258e-02\n",
      "Initial loss:  924481.2163861532\n",
      "best loss: 681.28\t\tLearning rate: 6.158e-05, Batch size: 27, Momentum: 3.681e-01\n",
      "Initial loss:  609944.9590418169\n",
      "best loss: 1035.05\t\tLearning rate: 4.833e-03, Batch size: 22, Momentum: 5.784e-01\n",
      "Initial loss:  1692251.8131741781\n",
      "best loss: 682.25\t\tLearning rate: 1.000e-08, Batch size: 42, Momentum: 5.258e-02\n",
      "Initial loss:  689116.5005688802\n",
      "best loss: 33532.86\t\tLearning rate: 3.793e-01, Batch size: 2, Momentum: 0.000e+00\n",
      "Initial loss:  889738.1346797015\n",
      "best loss: 492.19\t\tLearning rate: 2.336e-06, Batch size: 17, Momentum: 2.103e-01\n",
      "Initial loss:  736900.5127315804\n",
      "best loss: 1124.90\t\tLearning rate: 4.281e-02, Batch size: 42, Momentum: 3.155e-01\n",
      "Initial loss:  373380.8594717116\n",
      "best loss: 924.39\t\tLearning rate: 5.456e-04, Batch size: 2, Momentum: 6.835e-01\n",
      "Initial loss:  3146395.9833127186\n",
      "best loss: 1432.42\t\tLearning rate: 1.000e+01, Batch size: 24, Momentum: 6.835e-01\n",
      "Initial loss:  1892557.2332895047\n",
      "best loss: 724.59\t\tLearning rate: 6.158e-05, Batch size: 4, Momentum: 5.784e-01\n",
      "Initial loss:  769978.4522117464\n",
      "best loss: 96717.11\t\tLearning rate: 1.000e+01, Batch size: 14, Momentum: 3.681e-01\n",
      "Initial loss:  1948806.9110950152\n",
      "best loss: 1166.46\t\tLearning rate: 1.438e-02, Batch size: 14, Momentum: 9.990e-01\n",
      "Initial loss:  1047130.5958697917\n",
      "best loss: 989.80\t\tLearning rate: 4.833e-03, Batch size: 12, Momentum: 6.309e-01\n",
      "Initial loss:  1175241.802625955\n",
      "best loss: 514.37\t\tLearning rate: 7.848e-07, Batch size: 27, Momentum: 1.577e-01\n",
      "Initial loss:  2987533.123819992\n",
      "best loss: 1610686.54\t\tLearning rate: 8.859e-08, Batch size: 24, Momentum: 4.732e-01\n",
      "Initial loss:  2906341.1952211494\n",
      "best loss: 593.64\t\tLearning rate: 2.069e-05, Batch size: 32, Momentum: 5.784e-01\n",
      "Initial loss:  496.6915950922165\n",
      "best loss: 490.61\t\tLearning rate: 6.158e-05, Batch size: 32, Momentum: 2.103e-01\n",
      "Initial loss:  3048608.082569844\n",
      "best loss: 1290.48\t\tLearning rate: 1.129e+00, Batch size: 14, Momentum: 3.681e-01\n",
      "Initial loss:  1117519.1301669164\n",
      "best loss: 934.68\t\tLearning rate: 1.624e-03, Batch size: 14, Momentum: 6.835e-01\n",
      "Initial loss:  1009405.8777947933\n",
      "best loss: 1030.54\t\tLearning rate: 1.438e-02, Batch size: 27, Momentum: 4.206e-01\n",
      "Initial loss:  2547968.7369363597\n",
      "best loss: 1249.78\t\tLearning rate: 1.129e+00, Batch size: 24, Momentum: 1.052e-01\n",
      "Initial loss:  2170758.294648392\n",
      "best loss: 504.50\t\tLearning rate: 8.859e-08, Batch size: 12, Momentum: 4.732e-01\n",
      "Initial loss:  2674943.386029805\n",
      "best loss: 1102.64\t\tLearning rate: 4.281e-02, Batch size: 32, Momentum: 2.103e-01\n",
      "Initial loss:  140655.4411483471\n",
      "best loss: 1264.20\t\tLearning rate: 3.793e-01, Batch size: 24, Momentum: 5.784e-01\n",
      "Initial loss:  2086021.7218690908\n",
      "best loss: 1131.83\t\tLearning rate: 1.438e-02, Batch size: 34, Momentum: 6.309e-01\n",
      "Initial loss:  1791728.501113263\n",
      "best loss: 1316.06\t\tLearning rate: 3.360e+00, Batch size: 24, Momentum: 2.629e-01\n",
      "Initial loss:  1775224.7017281272\n",
      "best loss: 744.63\t\tLearning rate: 6.158e-05, Batch size: 29, Momentum: 7.887e-01\n",
      "Initial loss:  1726455.2870005849\n",
      "best loss: 547.74\t\tLearning rate: 8.859e-08, Batch size: 19, Momentum: 5.258e-02\n",
      "Initial loss:  632395.040312775\n",
      "best loss: 1150.16\t\tLearning rate: 1.438e-02, Batch size: 9, Momentum: 9.990e-01\n",
      "Initial loss:  3396725.327051915\n",
      "best loss: 1091.21\t\tLearning rate: 4.281e-02, Batch size: 2, Momentum: 5.258e-01\n",
      "Initial loss:  1281610.8715607594\n",
      "best loss: 486.94\t\tLearning rate: 7.848e-07, Batch size: 17, Momentum: 6.835e-01\n",
      "Initial loss:  499.67263596061525\n",
      "best loss: 492.15\t\tLearning rate: 7.848e-07, Batch size: 44, Momentum: 5.258e-02\n",
      "Initial loss:  1869373.1024603469\n",
      "best loss: 1343.64\t\tLearning rate: 1.129e+00, Batch size: 32, Momentum: 6.835e-01\n",
      "Initial loss:  1483520.6698290226\n",
      "best loss: 1298.97\t\tLearning rate: 3.360e+00, Batch size: 50, Momentum: 3.155e-01\n",
      "Initial loss:  2670570.4851277918\n",
      "best loss: 1118.85\t\tLearning rate: 1.274e-01, Batch size: 24, Momentum: 5.258e-02\n",
      "Initial loss:  1518812.3381100332\n",
      "best loss: 909.33\t\tLearning rate: 5.456e-04, Batch size: 47, Momentum: 6.835e-01\n",
      "Initial loss:  457508.8415817759\n",
      "best loss: 3193.98\t\tLearning rate: 1.000e-08, Batch size: 19, Momentum: 3.681e-01\n",
      "Initial loss:  916425.9973147985\n",
      "best loss: 536.98\t\tLearning rate: 2.336e-06, Batch size: 27, Momentum: 1.577e-01\n",
      "Initial loss:  1067033.3760059087\n",
      "best loss: 705.81\t\tLearning rate: 6.158e-05, Batch size: 7, Momentum: 8.938e-01\n",
      "Initial loss:  3289078.5722206454\n",
      "best loss: 1296.15\t\tLearning rate: 1.129e+00, Batch size: 29, Momentum: 6.309e-01\n",
      "Initial loss:  1815487.878643529\n",
      "best loss: 93153.52\t\tLearning rate: 1.000e-08, Batch size: 42, Momentum: 5.258e-01\n",
      "Initial loss:  2654105.968223104\n",
      "best loss: 665.66\t\tLearning rate: 6.158e-05, Batch size: 17, Momentum: 1.052e-01\n",
      "Initial loss:  1615152.424742502\n",
      "best loss: 1186.97\t\tLearning rate: 1.274e-01, Batch size: 37, Momentum: 7.361e-01\n",
      "Initial loss:  496.82319686084656\n",
      "best loss: 489.13\t\tLearning rate: 1.833e-04, Batch size: 12, Momentum: 7.887e-01\n",
      "Initial loss:  1217033.5144476336\n",
      "best loss: 597.60\t\tLearning rate: 2.069e-05, Batch size: 9, Momentum: 7.361e-01\n",
      "Initial loss:  1017319.3854808114\n",
      "best loss: 846.64\t\tLearning rate: 5.456e-04, Batch size: 24, Momentum: 3.155e-01\n",
      "Initial loss:  772072.4570169605\n",
      "best loss: 1301.02\t\tLearning rate: 1.000e+01, Batch size: 9, Momentum: 0.000e+00\n",
      "Initial loss:  3284066.5160074946\n",
      "best loss: 978.12\t\tLearning rate: 4.833e-03, Batch size: 19, Momentum: 6.309e-01\n",
      "Initial loss:  2624169.8239392317\n",
      "best loss: 1022.74\t\tLearning rate: 1.438e-02, Batch size: 19, Momentum: 2.103e-01\n",
      "Initial loss:  1106553.223025457\n",
      "best loss: 491.45\t\tLearning rate: 8.859e-08, Batch size: 14, Momentum: 7.887e-01\n",
      "Initial loss:  900010.636959266\n",
      "best loss: 1411.45\t\tLearning rate: 1.129e+00, Batch size: 19, Momentum: 9.990e-01\n",
      "Initial loss:  1375086.2418104757\n",
      "best loss: 642.21\t\tLearning rate: 1.000e-08, Batch size: 22, Momentum: 6.309e-01\n",
      "Initial loss:  922125.2460115931\n",
      "best loss: 491.36\t\tLearning rate: 2.336e-06, Batch size: 19, Momentum: 2.629e-01\n",
      "Initial loss:  1698486.7737880186\n",
      "best loss: 484.51\t\tLearning rate: 2.637e-07, Batch size: 14, Momentum: 9.990e-01\n",
      "Initial loss:  3269433.5931651844\n",
      "best loss: 894.95\t\tLearning rate: 5.456e-04, Batch size: 27, Momentum: 5.258e-01\n",
      "Initial loss:  1724207.2580260315\n",
      "best loss: 635.07\t\tLearning rate: 6.158e-05, Batch size: 19, Momentum: 4.732e-01\n",
      "Initial loss:  1496971.2681596007\n",
      "best loss: 608.69\t\tLearning rate: 6.952e-06, Batch size: 14, Momentum: 8.413e-01\n",
      "Initial loss:  3069530.4103064844\n",
      "best loss: 761.35\t\tLearning rate: 1.833e-04, Batch size: 12, Momentum: 1.052e-01\n",
      "Initial loss:  1884669.5518188851\n",
      "best loss: 1175.06\t\tLearning rate: 1.274e-01, Batch size: 42, Momentum: 2.629e-01\n",
      "Initial loss:  2450175.162942541\n",
      "best loss: 1414.61\t\tLearning rate: 1.000e+01, Batch size: 39, Momentum: 7.361e-01\n",
      "Initial loss:  686810.2683538233\n",
      "best loss: 570.64\t\tLearning rate: 8.859e-08, Batch size: 39, Momentum: 1.577e-01\n",
      "Initial loss:  1943553.3286231945\n",
      "best loss: 992.40\t\tLearning rate: 4.833e-03, Batch size: 14, Momentum: 2.629e-01\n",
      "Initial loss:  2298836.3370797886\n",
      "best loss: 1179.31\t\tLearning rate: 1.274e-01, Batch size: 39, Momentum: 5.784e-01\n",
      "Initial loss:  4586253.827013588\n",
      "best loss: 1087282.05\t\tLearning rate: 8.859e-08, Batch size: 7, Momentum: 3.681e-01\n",
      "Initial loss:  2101766.2123930017\n",
      "best loss: 442468.73\t\tLearning rate: 8.859e-08, Batch size: 22, Momentum: 3.681e-01\n",
      "Initial loss:  455525.1166591712\n",
      "best loss: 1219.17\t\tLearning rate: 3.793e-01, Batch size: 2, Momentum: 6.309e-01\n",
      "Initial loss:  959150.0126901316\n",
      "best loss: 1015.98\t\tLearning rate: 1.438e-02, Batch size: 27, Momentum: 2.103e-01\n",
      "Initial loss:  970560.4191607789\n",
      "best loss: 1144.59\t\tLearning rate: 4.281e-02, Batch size: 27, Momentum: 8.413e-01\n",
      "Initial loss:  17899744.66626408\n",
      "best loss: 1258.47\t\tLearning rate: 4.281e-02, Batch size: 2, Momentum: 7.887e-01\n",
      "Initial loss:  1254290.0549142272\n",
      "best loss: 697.32\t\tLearning rate: 6.158e-05, Batch size: 37, Momentum: 1.052e-01\n",
      "Initial loss:  2302839.311827528\n",
      "best loss: 1240.76\t\tLearning rate: 3.793e-01, Batch size: 22, Momentum: 3.155e-01\n",
      "Initial loss:  2453322.436674581\n",
      "best loss: 498.84\t\tLearning rate: 8.859e-08, Batch size: 44, Momentum: 7.361e-01\n",
      "Initial loss:  2014814.6439934673\n",
      "best loss: 1021.26\t\tLearning rate: 5.456e-04, Batch size: 27, Momentum: 9.990e-01\n",
      "Initial loss:  3210288.6803408754\n",
      "best loss: 523.22\t\tLearning rate: 6.952e-06, Batch size: 12, Momentum: 8.938e-01\n",
      "Initial loss:  791206.9478008207\n",
      "best loss: 510.34\t\tLearning rate: 2.637e-07, Batch size: 12, Momentum: 2.629e-01\n",
      "Initial loss:  1599540.8777715066\n",
      "best loss: 493.47\t\tLearning rate: 1.000e-08, Batch size: 12, Momentum: 9.464e-01\n",
      "Initial loss:  1514310.8866174552\n",
      "best loss: 1362.83\t\tLearning rate: 1.000e+01, Batch size: 27, Momentum: 1.577e-01\n",
      "Initial loss:  1299176.2628455972\n",
      "best loss: 1295.50\t\tLearning rate: 1.129e+00, Batch size: 32, Momentum: 2.629e-01\n",
      "Initial loss:  1725307.1692457136\n",
      "best loss: 431740.90\t\tLearning rate: 8.859e-08, Batch size: 39, Momentum: 5.258e-01\n",
      "Initial loss:  3014111.6416589743\n",
      "best loss: 662.76\t\tLearning rate: 2.069e-05, Batch size: 14, Momentum: 2.629e-01\n",
      "Initial loss:  1123426.421410068\n",
      "best loss: 861.32\t\tLearning rate: 5.456e-04, Batch size: 27, Momentum: 3.155e-01\n",
      "Initial loss:  1418639.0874057265\n",
      "best loss: 488.59\t\tLearning rate: 2.336e-06, Batch size: 14, Momentum: 3.681e-01\n",
      "Initial loss:  4196802.247310738\n",
      "best loss: 492.71\t\tLearning rate: 7.848e-07, Batch size: 14, Momentum: 1.052e-01\n",
      "Initial loss:  214304.5415189291\n",
      "best loss: 1004.25\t\tLearning rate: 4.833e-03, Batch size: 39, Momentum: 4.732e-01\n",
      "Initial loss:  2022079.539183443\n",
      "best loss: 509.20\t\tLearning rate: 7.848e-07, Batch size: 22, Momentum: 3.155e-01\n",
      "Initial loss:  3933748.2844509855\n",
      "best loss: 679.21\t\tLearning rate: 2.069e-05, Batch size: 24, Momentum: 4.732e-01\n",
      "Initial loss:  1107471.6903845265\n",
      "best loss: 184048.34\t\tLearning rate: 1.000e-08, Batch size: 14, Momentum: 5.258e-02\n",
      "Initial loss:  2153680.7442345098\n",
      "best loss: 1224.05\t\tLearning rate: 1.274e-01, Batch size: 39, Momentum: 6.309e-01\n",
      "Initial loss:  2873006.9940911643\n",
      "best loss: 671.25\t\tLearning rate: 2.069e-05, Batch size: 47, Momentum: 8.413e-01\n",
      "Initial loss:  398141.31269871845\n",
      "best loss: 1225.11\t\tLearning rate: 1.274e-01, Batch size: 32, Momentum: 7.361e-01\n",
      "Initial loss:  2057375.1238138431\n",
      "best loss: 1027.12\t\tLearning rate: 4.833e-03, Batch size: 27, Momentum: 4.732e-01\n",
      "Initial loss:  1127934.1666578026\n",
      "best loss: 1136.84\t\tLearning rate: 1.274e-01, Batch size: 44, Momentum: 1.052e-01\n",
      "Initial loss:  1550229.369662225\n",
      "best loss: 697.84\t\tLearning rate: 2.069e-05, Batch size: 32, Momentum: 5.258e-01\n",
      "Initial loss:  424730.2043489545\n",
      "best loss: 896.53\t\tLearning rate: 6.158e-05, Batch size: 47, Momentum: 8.938e-01\n",
      "Initial loss:  873378.0946796046\n",
      "best loss: 539.07\t\tLearning rate: 2.976e-08, Batch size: 7, Momentum: 5.258e-01\n",
      "Initial loss:  668284.6581552428\n",
      "best loss: 762.82\t\tLearning rate: 7.848e-07, Batch size: 9, Momentum: 5.258e-02\n",
      "Initial loss:  1995000.8277845406\n",
      "best loss: 1063.29\t\tLearning rate: 4.833e-03, Batch size: 14, Momentum: 7.361e-01\n",
      "Initial loss:  1980835.9933721726\n",
      "best loss: 79805.54\t\tLearning rate: 2.976e-08, Batch size: 4, Momentum: 9.464e-01\n",
      "Initial loss:  2116171.6405890347\n",
      "best loss: 1095.60\t\tLearning rate: 1.438e-02, Batch size: 9, Momentum: 6.309e-01\n",
      "Initial loss:  1091117.3494888188\n",
      "best loss: 1005.47\t\tLearning rate: 1.624e-03, Batch size: 32, Momentum: 8.938e-01\n",
      "Initial loss:  2751090.1695216484\n",
      "best loss: 1403.02\t\tLearning rate: 1.000e+01, Batch size: 24, Momentum: 7.887e-01\n",
      "Initial loss:  1993870.7262584323\n",
      "best loss: 755796.44\t\tLearning rate: 2.976e-08, Batch size: 27, Momentum: 2.629e-01\n",
      "Initial loss:  2229581.2486877567\n",
      "best loss: 964.17\t\tLearning rate: 5.456e-04, Batch size: 14, Momentum: 8.938e-01\n",
      "Initial loss:  497.854568827345\n",
      "best loss: 489.90\t\tLearning rate: 4.833e-03, Batch size: 29, Momentum: 3.155e-01\n",
      "Initial loss:  848672.4327241967\n",
      "best loss: 1098.72\t\tLearning rate: 1.438e-02, Batch size: 29, Momentum: 6.309e-01\n",
      "Initial loss:  2923221.283074679\n",
      "best loss: 1176.10\t\tLearning rate: 4.833e-03, Batch size: 7, Momentum: 9.990e-01\n",
      "Initial loss:  1607493.0631749427\n",
      "best loss: 546.80\t\tLearning rate: 8.859e-08, Batch size: 47, Momentum: 3.681e-01\n",
      "Initial loss:  1721511.7504115922\n",
      "best loss: 1232.34\t\tLearning rate: 1.129e+00, Batch size: 4, Momentum: 2.629e-01\n",
      "Initial loss:  3365665.5078583336\n",
      "best loss: 1285.48\t\tLearning rate: 3.793e-01, Batch size: 42, Momentum: 5.784e-01\n",
      "Initial loss:  2240687.357390385\n",
      "best loss: 507.39\t\tLearning rate: 8.859e-08, Batch size: 7, Momentum: 3.155e-01\n",
      "Initial loss:  4730615.805855097\n",
      "best loss: 991.01\t\tLearning rate: 1.438e-02, Batch size: 32, Momentum: 1.052e-01\n",
      "Initial loss:  2677445.7987755947\n",
      "best loss: 1368.09\t\tLearning rate: 1.129e+00, Batch size: 44, Momentum: 9.464e-01\n",
      "Initial loss:  1266066.025364277\n",
      "best loss: 1051.50\t\tLearning rate: 4.833e-03, Batch size: 2, Momentum: 8.413e-01\n",
      "Initial loss:  1373277.4947181074\n",
      "best loss: 705.15\t\tLearning rate: 6.158e-05, Batch size: 2, Momentum: 1.577e-01\n",
      "Initial loss:  1050805.478703711\n",
      "best loss: 801.28\t\tLearning rate: 6.158e-05, Batch size: 37, Momentum: 4.732e-01\n",
      "Initial loss:  1944706.2642049594\n",
      "best loss: 375362.24\t\tLearning rate: 1.000e-08, Batch size: 17, Momentum: 6.835e-01\n",
      "Initial loss:  2467835.009405602\n",
      "best loss: 1284.77\t\tLearning rate: 3.793e-01, Batch size: 7, Momentum: 5.258e-01\n",
      "Initial loss:  1253350.5076966325\n",
      "best loss: 917.41\t\tLearning rate: 5.456e-04, Batch size: 37, Momentum: 5.258e-01\n",
      "Initial loss:  1456066.0534463383\n",
      "best loss: 503.73\t\tLearning rate: 7.848e-07, Batch size: 9, Momentum: 2.103e-01\n",
      "Initial loss:  1062378.9990728402\n",
      "best loss: 1337.11\t\tLearning rate: 1.129e+00, Batch size: 4, Momentum: 9.990e-01\n",
      "Initial loss:  914460.3998988955\n",
      "best loss: 835.42\t\tLearning rate: 5.456e-04, Batch size: 44, Momentum: 2.629e-01\n",
      "Initial loss:  2603067.748451147\n",
      "best loss: 469.85\t\tLearning rate: 8.859e-08, Batch size: 2, Momentum: 7.361e-01\n",
      "Initial loss:  1040277.8239893554\n",
      "best loss: 1107.88\t\tLearning rate: 1.438e-02, Batch size: 17, Momentum: 7.361e-01\n",
      "Initial loss:  1527203.6279185235\n",
      "best loss: 1355.15\t\tLearning rate: 3.793e-01, Batch size: 7, Momentum: 8.413e-01\n",
      "Initial loss:  3485362.6050630272\n",
      "best loss: 507.35\t\tLearning rate: 2.637e-07, Batch size: 47, Momentum: 8.938e-01\n",
      "Initial loss:  4860932.425975153\n",
      "best loss: 499.17\t\tLearning rate: 2.336e-06, Batch size: 32, Momentum: 8.413e-01\n",
      "Initial loss:  506445.0968123272\n",
      "best loss: 979.13\t\tLearning rate: 4.833e-03, Batch size: 14, Momentum: 2.103e-01\n",
      "Initial loss:  1275177.3017266223\n",
      "best loss: 844.73\t\tLearning rate: 2.976e-08, Batch size: 29, Momentum: 2.103e-01\n",
      "Initial loss:  4344824.345660234\n",
      "best loss: 498.51\t\tLearning rate: 6.952e-06, Batch size: 47, Momentum: 5.258e-02\n",
      "Initial loss:  2753274.922951333\n",
      "best loss: 1059.30\t\tLearning rate: 4.833e-03, Batch size: 7, Momentum: 9.464e-01\n",
      "Initial loss:  885255.6361887836\n",
      "best loss: 488.71\t\tLearning rate: 2.336e-06, Batch size: 22, Momentum: 4.206e-01\n",
      "Initial loss:  513274.6557840043\n",
      "best loss: 1160.88\t\tLearning rate: 3.793e-01, Batch size: 22, Momentum: 1.577e-01\n",
      "Initial loss:  543325.1627564153\n",
      "best loss: 892.04\t\tLearning rate: 5.456e-04, Batch size: 42, Momentum: 8.938e-01\n",
      "Initial loss:  1119800.4384254047\n",
      "best loss: 1419.18\t\tLearning rate: 1.000e+01, Batch size: 34, Momentum: 5.784e-01\n",
      "Initial loss:  2251135.4313733075\n",
      "best loss: 1130.73\t\tLearning rate: 4.281e-02, Batch size: 2, Momentum: 5.784e-01\n",
      "Initial loss:  2312902.8774806093\n",
      "best loss: 1034.98\t\tLearning rate: 1.438e-02, Batch size: 2, Momentum: 3.155e-01\n",
      "Initial loss:  1015112.6774588655\n",
      "best loss: 1267.50\t\tLearning rate: 1.274e-01, Batch size: 4, Momentum: 9.990e-01\n",
      "Initial loss:  1121987.9268537385\n",
      "best loss: 1031.58\t\tLearning rate: 4.281e-02, Batch size: 19, Momentum: 5.258e-02\n",
      "Initial loss:  2332908.887288892\n",
      "best loss: 778.44\t\tLearning rate: 1.833e-04, Batch size: 14, Momentum: 5.258e-02\n",
      "Initial loss:  1118587.6986355756\n",
      "best loss: 1152.10\t\tLearning rate: 4.281e-02, Batch size: 12, Momentum: 9.990e-01\n",
      "Initial loss:  3537896.4531190433\n",
      "best loss: 549.67\t\tLearning rate: 2.336e-06, Batch size: 19, Momentum: 9.990e-01\n",
      "Initial loss:  1402160.5895615448\n",
      "best loss: 777.56\t\tLearning rate: 1.833e-04, Batch size: 4, Momentum: 4.732e-01\n",
      "Initial loss:  1444769.983043566\n",
      "best loss: 1203.09\t\tLearning rate: 3.793e-01, Batch size: 7, Momentum: 1.052e-01\n",
      "Initial loss:  1075062.928293425\n",
      "best loss: 957.45\t\tLearning rate: 4.833e-03, Batch size: 34, Momentum: 6.835e-01\n",
      "Initial loss:  1652091.835155443\n",
      "best loss: 502.47\t\tLearning rate: 7.848e-07, Batch size: 32, Momentum: 6.835e-01\n",
      "Initial loss:  496.8982540533683\n",
      "best loss: 491.61\t\tLearning rate: 2.336e-06, Batch size: 50, Momentum: 5.784e-01\n",
      "Initial loss:  2687536.0187724927\n",
      "best loss: 999.00\t\tLearning rate: 1.624e-03, Batch size: 29, Momentum: 5.784e-01\n",
      "Initial loss:  4053135.8344974816\n",
      "best loss: 1009.51\t\tLearning rate: 1.624e-03, Batch size: 19, Momentum: 9.990e-01\n",
      "Initial loss:  4447902.51880866\n",
      "best loss: 1193.26\t\tLearning rate: 1.274e-01, Batch size: 37, Momentum: 2.629e-01\n",
      "Initial loss:  2456866.3726530676\n",
      "best loss: 493.41\t\tLearning rate: 6.952e-06, Batch size: 42, Momentum: 2.629e-01\n",
      "Initial loss:  272611.2976294668\n",
      "best loss: 1072.22\t\tLearning rate: 1.624e-03, Batch size: 39, Momentum: 8.938e-01\n",
      "Initial loss:  1377396.2129653846\n",
      "best loss: 503.67\t\tLearning rate: 2.336e-06, Batch size: 4, Momentum: 9.990e-01\n",
      "Initial loss:  1590929.9890076837\n",
      "best loss: 1118.53\t\tLearning rate: 1.438e-02, Batch size: 7, Momentum: 9.990e-01\n",
      "Initial loss:  3022808.3966050074\n",
      "best loss: 493.87\t\tLearning rate: 7.848e-07, Batch size: 12, Momentum: 5.784e-01\n",
      "Initial loss:  922611.9135613701\n",
      "best loss: 1148.28\t\tLearning rate: 3.793e-01, Batch size: 4, Momentum: 0.000e+00\n",
      "Initial loss:  5111574.062034292\n",
      "best loss: 1241.31\t\tLearning rate: 1.274e-01, Batch size: 4, Momentum: 6.835e-01\n",
      "Initial loss:  634074.9649839848\n",
      "best loss: 2048.37\t\tLearning rate: 2.637e-07, Batch size: 32, Momentum: 1.052e-01\n",
      "Initial loss:  1709823.6772602426\n",
      "best loss: 1337.77\t\tLearning rate: 1.129e+00, Batch size: 50, Momentum: 7.361e-01\n",
      "Initial loss:  3687995.629160099\n",
      "best loss: 1246.29\t\tLearning rate: 1.129e+00, Batch size: 4, Momentum: 1.577e-01\n",
      "Initial loss:  1728579.5210936635\n",
      "best loss: 503.84\t\tLearning rate: 6.952e-06, Batch size: 29, Momentum: 4.732e-01\n",
      "Initial loss:  1200657.0225832416\n",
      "best loss: 823.30\t\tLearning rate: 6.158e-05, Batch size: 12, Momentum: 8.938e-01\n",
      "Initial loss:  588694.7679077468\n",
      "best loss: 1104.78\t\tLearning rate: 1.274e-01, Batch size: 47, Momentum: 1.052e-01\n",
      "Initial loss:  619633.0786900059\n",
      "best loss: 489.52\t\tLearning rate: 6.952e-06, Batch size: 22, Momentum: 3.681e-01\n",
      "Initial loss:  2681275.3456633044\n",
      "best loss: 642.97\t\tLearning rate: 2.069e-05, Batch size: 44, Momentum: 5.784e-01\n",
      "Initial loss:  1335055.284498779\n",
      "best loss: 492.92\t\tLearning rate: 2.637e-07, Batch size: 37, Momentum: 9.464e-01\n",
      "Initial loss:  1434052.213460614\n",
      "best loss: 1382.93\t\tLearning rate: 1.000e+01, Batch size: 34, Momentum: 3.681e-01\n",
      "Initial loss:  2972708.475753457\n",
      "best loss: 491.79\t\tLearning rate: 7.848e-07, Batch size: 44, Momentum: 1.577e-01\n",
      "Initial loss:  1398983.0526464605\n",
      "best loss: 942.20\t\tLearning rate: 5.456e-04, Batch size: 12, Momentum: 8.413e-01\n",
      "Initial loss:  2181107.942520663\n",
      "best loss: 900.28\t\tLearning rate: 5.456e-04, Batch size: 42, Momentum: 6.835e-01\n",
      "Initial loss:  1112376.1502153205\n",
      "best loss: 1153.13\t\tLearning rate: 1.274e-01, Batch size: 17, Momentum: 3.681e-01\n",
      "Initial loss:  2658687.1402366045\n",
      "best loss: 744286.52\t\tLearning rate: 1.000e-08, Batch size: 17, Momentum: 9.464e-01\n",
      "Initial loss:  1916836.131825759\n",
      "best loss: 1361.78\t\tLearning rate: 1.000e+01, Batch size: 7, Momentum: 5.258e-01\n",
      "Initial loss:  2316614.7191506657\n",
      "best loss: 827.68\t\tLearning rate: 6.158e-05, Batch size: 12, Momentum: 9.990e-01\n",
      "Initial loss:  1781238.9241134198\n",
      "best loss: 507.28\t\tLearning rate: 7.848e-07, Batch size: 24, Momentum: 5.784e-01\n",
      "Initial loss:  1857905.782968247\n",
      "best loss: 805.56\t\tLearning rate: 1.833e-04, Batch size: 47, Momentum: 5.258e-01\n",
      "Initial loss:  1543041.398800627\n",
      "best loss: 624.73\t\tLearning rate: 6.952e-06, Batch size: 42, Momentum: 7.887e-01\n",
      "Initial loss:  1582611.0303265448\n",
      "best loss: 705.73\t\tLearning rate: 2.069e-05, Batch size: 2, Momentum: 7.887e-01\n",
      "Initial loss:  1439514.096951875\n",
      "best loss: 1050.66\t\tLearning rate: 4.833e-03, Batch size: 47, Momentum: 7.361e-01\n",
      "Initial loss:  366644.81691761117\n",
      "best loss: 1079.85\t\tLearning rate: 4.833e-03, Batch size: 32, Momentum: 6.309e-01\n",
      "Initial loss:  1973277.0662525364\n",
      "best loss: 731.99\t\tLearning rate: 1.833e-04, Batch size: 29, Momentum: 5.258e-02\n",
      "Initial loss:  496.61744756359104\n",
      "best loss: 491.44\t\tLearning rate: 5.456e-04, Batch size: 27, Momentum: 5.784e-01\n",
      "Initial loss:  1985048.3111555628\n",
      "best loss: 1398.35\t\tLearning rate: 1.000e-08, Batch size: 14, Momentum: 4.206e-01\n",
      "Initial loss:  1098713.2282918235\n",
      "best loss: 1408.12\t\tLearning rate: 3.360e+00, Batch size: 29, Momentum: 8.413e-01\n",
      "Initial loss:  2558133.22385728\n",
      "best loss: 514.09\t\tLearning rate: 8.859e-08, Batch size: 42, Momentum: 7.361e-01\n",
      "Initial loss:  2744017.577059485\n",
      "best loss: 479.55\t\tLearning rate: 7.848e-07, Batch size: 2, Momentum: 7.361e-01\n",
      "Initial loss:  2131566.903733047\n",
      "best loss: 1142.03\t\tLearning rate: 3.793e-01, Batch size: 22, Momentum: 5.258e-02\n",
      "Initial loss:  3903153.59404074\n",
      "best loss: 811.70\t\tLearning rate: 5.456e-04, Batch size: 50, Momentum: 1.052e-01\n",
      "Initial loss:  1941759.5774050478\n",
      "best loss: 1242.63\t\tLearning rate: 3.793e-01, Batch size: 12, Momentum: 4.206e-01\n",
      "Initial loss:  1573463.8273802376\n",
      "best loss: 1230.12\t\tLearning rate: 3.793e-01, Batch size: 12, Momentum: 4.732e-01\n",
      "Initial loss:  1241746.8951718174\n",
      "best loss: 514.94\t\tLearning rate: 1.000e-08, Batch size: 50, Momentum: 8.413e-01\n",
      "Initial loss:  2729046.2479529446\n",
      "best loss: 1254.78\t\tLearning rate: 3.360e+00, Batch size: 2, Momentum: 1.577e-01\n",
      "Initial loss:  2456681.2249260927\n",
      "best loss: 1037.91\t\tLearning rate: 4.281e-02, Batch size: 2, Momentum: 2.103e-01\n",
      "Initial loss:  715498.9726725509\n",
      "best loss: 1032.96\t\tLearning rate: 4.833e-03, Batch size: 2, Momentum: 4.206e-01\n",
      "Initial loss:  433462.0001139018\n",
      "best loss: 489.72\t\tLearning rate: 7.848e-07, Batch size: 14, Momentum: 8.413e-01\n",
      "Initial loss:  2759734.981501408\n",
      "best loss: 880.83\t\tLearning rate: 5.456e-04, Batch size: 34, Momentum: 5.784e-01\n",
      "Initial loss:  1680032.9150892545\n",
      "best loss: 1183.58\t\tLearning rate: 3.793e-01, Batch size: 12, Momentum: 1.577e-01\n",
      "Initial loss:  2154284.987377475\n",
      "best loss: 1105.85\t\tLearning rate: 1.624e-03, Batch size: 47, Momentum: 9.464e-01\n",
      "Initial loss:  2197019.4466377017\n",
      "best loss: 986.99\t\tLearning rate: 1.438e-02, Batch size: 2, Momentum: 2.103e-01\n",
      "Initial loss:  1448335.7252959893\n",
      "best loss: 949.11\t\tLearning rate: 1.624e-03, Batch size: 2, Momentum: 1.577e-01\n",
      "Initial loss:  964315.4268849129\n",
      "best loss: 476158.23\t\tLearning rate: 8.859e-08, Batch size: 7, Momentum: 6.835e-01\n",
      "Initial loss:  603125.6354383308\n",
      "best loss: 1134.49\t\tLearning rate: 1.438e-02, Batch size: 47, Momentum: 9.464e-01\n",
      "Initial loss:  2950044.2999364245\n",
      "best loss: 1065.63\t\tLearning rate: 4.281e-02, Batch size: 42, Momentum: 0.000e+00\n",
      "Initial loss:  1993470.536806176\n",
      "best loss: 1340.04\t\tLearning rate: 3.793e-01, Batch size: 37, Momentum: 7.887e-01\n",
      "Initial loss:  2042359.0246107632\n",
      "best loss: 656.35\t\tLearning rate: 2.069e-05, Batch size: 19, Momentum: 1.577e-01\n",
      "Initial loss:  2125245.5056272056\n",
      "best loss: 510.68\t\tLearning rate: 6.952e-06, Batch size: 29, Momentum: 8.938e-01\n",
      "Initial loss:  498.9601053821613\n",
      "best loss: 489.73\t\tLearning rate: 5.456e-04, Batch size: 32, Momentum: 7.361e-01\n",
      "Initial loss:  1018909.096014624\n",
      "best loss: 803.70\t\tLearning rate: 1.833e-04, Batch size: 50, Momentum: 4.206e-01\n",
      "Initial loss:  5434558.1602560105\n",
      "best loss: 1084.90\t\tLearning rate: 4.833e-03, Batch size: 9, Momentum: 8.413e-01\n",
      "Initial loss:  1368387.1437384088\n",
      "best loss: 508.75\t\tLearning rate: 2.336e-06, Batch size: 22, Momentum: 0.000e+00\n",
      "Initial loss:  1508845.7413978514\n",
      "best loss: 627.89\t\tLearning rate: 8.859e-08, Batch size: 44, Momentum: 4.732e-01\n",
      "Initial loss:  3192724.851742254\n",
      "best loss: 1393.42\t\tLearning rate: 1.000e+01, Batch size: 44, Momentum: 4.206e-01\n",
      "Initial loss:  2881686.398587538\n",
      "best loss: 1284.40\t\tLearning rate: 1.129e+00, Batch size: 32, Momentum: 5.258e-01\n",
      "Initial loss:  690615.3675262436\n",
      "best loss: 1383.86\t\tLearning rate: 3.360e+00, Batch size: 17, Momentum: 3.681e-01\n",
      "Initial loss:  2623057.1656006724\n",
      "best loss: 923.50\t\tLearning rate: 1.624e-03, Batch size: 34, Momentum: 3.155e-01\n",
      "Initial loss:  1973695.993283305\n",
      "best loss: 1247.16\t\tLearning rate: 3.793e-01, Batch size: 2, Momentum: 5.784e-01\n",
      "Initial loss:  483241.06280796975\n",
      "best loss: 116603.56\t\tLearning rate: 8.859e-08, Batch size: 19, Momentum: 2.629e-01\n",
      "Initial loss:  1761368.8864879338\n",
      "best loss: 1292.43\t\tLearning rate: 1.129e+00, Batch size: 32, Momentum: 3.155e-01\n",
      "Initial loss:  1959306.2893430686\n",
      "best loss: 1087.49\t\tLearning rate: 1.274e-01, Batch size: 12, Momentum: 1.577e-01\n",
      "Initial loss:  1462364.0995149359\n",
      "best loss: 214844.89\t\tLearning rate: 2.336e-06, Batch size: 37, Momentum: 1.052e-01\n",
      "Initial loss:  242370.17645368236\n",
      "best loss: 973.94\t\tLearning rate: 1.624e-03, Batch size: 4, Momentum: 7.361e-01\n",
      "Initial loss:  3292715.490534937\n",
      "best loss: 1076.66\t\tLearning rate: 4.281e-02, Batch size: 47, Momentum: 7.361e-01\n",
      "Initial loss:  1053797.4658212243\n",
      "best loss: 543.08\t\tLearning rate: 2.637e-07, Batch size: 24, Momentum: 2.629e-01\n",
      "Initial loss:  1121495.0545915542\n",
      "best loss: 1152.68\t\tLearning rate: 1.438e-02, Batch size: 7, Momentum: 9.464e-01\n",
      "Initial loss:  3808634.3894060273\n",
      "best loss: 497.74\t\tLearning rate: 2.336e-06, Batch size: 37, Momentum: 6.835e-01\n",
      "Initial loss:  1359881.2988458376\n",
      "best loss: 1416.53\t\tLearning rate: 1.000e+01, Batch size: 19, Momentum: 8.413e-01\n",
      "Initial loss:  989631.0792891651\n",
      "best loss: 500.27\t\tLearning rate: 6.952e-06, Batch size: 34, Momentum: 5.784e-01\n",
      "Initial loss:  1148542.7693272734\n",
      "best loss: 84348.41\t\tLearning rate: 2.336e-06, Batch size: 7, Momentum: 4.206e-01\n",
      "Initial loss:  2719754.7148975153\n",
      "best loss: 1304.08\t\tLearning rate: 3.360e+00, Batch size: 17, Momentum: 2.103e-01\n",
      "Initial loss:  683923.6273791977\n",
      "best loss: 534.41\t\tLearning rate: 7.848e-07, Batch size: 47, Momentum: 2.103e-01\n",
      "Initial loss:  1105811.5366362236\n",
      "best loss: 635.69\t\tLearning rate: 2.069e-05, Batch size: 22, Momentum: 5.258e-01\n",
      "Initial loss:  1110985.5156494307\n",
      "best loss: 1166.25\t\tLearning rate: 1.438e-02, Batch size: 7, Momentum: 9.990e-01\n",
      "Initial loss:  1603905.6873981834\n",
      "best loss: 1096.77\t\tLearning rate: 4.281e-02, Batch size: 29, Momentum: 1.577e-01\n",
      "Initial loss:  1339458.7347831614\n",
      "best loss: 1335.87\t\tLearning rate: 3.360e+00, Batch size: 22, Momentum: 4.206e-01\n",
      "Initial loss:  846502.1818690664\n",
      "best loss: 493.10\t\tLearning rate: 6.952e-06, Batch size: 47, Momentum: 5.258e-01\n",
      "Initial loss:  799691.4683239104\n",
      "best loss: 639.64\t\tLearning rate: 8.859e-08, Batch size: 9, Momentum: 0.000e+00\n",
      "Initial loss:  3134112.6989661246\n",
      "best loss: 898.54\t\tLearning rate: 1.624e-03, Batch size: 17, Momentum: 0.000e+00\n",
      "Initial loss:  2211473.852244312\n",
      "best loss: 737.51\t\tLearning rate: 2.069e-05, Batch size: 22, Momentum: 8.413e-01\n",
      "Initial loss:  492.1624694396988\n",
      "best loss: 488.03\t\tLearning rate: 1.438e-02, Batch size: 27, Momentum: 2.103e-01\n",
      "Initial loss:  2658984.917806796\n",
      "best loss: 1385.78\t\tLearning rate: 1.000e+01, Batch size: 22, Momentum: 2.629e-01\n",
      "Initial loss:  3384206.9805050045\n",
      "best loss: 1328.61\t\tLearning rate: 3.360e+00, Batch size: 37, Momentum: 5.784e-01\n",
      "Initial loss:  2581084.3877612306\n",
      "best loss: 619.70\t\tLearning rate: 2.069e-05, Batch size: 47, Momentum: 5.258e-01\n",
      "Initial loss:  3252875.40638109\n",
      "best loss: 613121.31\t\tLearning rate: 4.833e-03, Batch size: 42, Momentum: 5.258e-02\n",
      "Initial loss:  2541921.8256283645\n",
      "best loss: 1379220.97\t\tLearning rate: 1.000e-08, Batch size: 44, Momentum: 5.258e-01\n",
      "Initial loss:  966566.9527134628\n",
      "best loss: 550.95\t\tLearning rate: 2.637e-07, Batch size: 9, Momentum: 0.000e+00\n",
      "Initial loss:  1230502.191489699\n",
      "best loss: 3916.51\t\tLearning rate: 1.000e-08, Batch size: 2, Momentum: 3.681e-01\n",
      "Initial loss:  1624545.042197571\n",
      "best loss: 1040.04\t\tLearning rate: 1.624e-03, Batch size: 44, Momentum: 8.413e-01\n",
      "Initial loss:  4010371.2045635125\n",
      "best loss: 1264.69\t\tLearning rate: 3.793e-01, Batch size: 17, Momentum: 6.835e-01\n",
      "Initial loss:  2062279.4329881645\n",
      "best loss: 808.15\t\tLearning rate: 2.976e-08, Batch size: 14, Momentum: 3.681e-01\n",
      "Initial loss:  1109976.7168044706\n",
      "best loss: 965.30\t\tLearning rate: 4.833e-03, Batch size: 7, Momentum: 3.155e-01\n",
      "Initial loss:  5095044.294529637\n",
      "best loss: 675.66\t\tLearning rate: 6.158e-05, Batch size: 27, Momentum: 3.155e-01\n",
      "Initial loss:  729868.9673744978\n",
      "best loss: 1123.84\t\tLearning rate: 1.438e-02, Batch size: 39, Momentum: 8.413e-01\n",
      "Initial loss:  946063.3423807857\n",
      "best loss: 901.02\t\tLearning rate: 5.456e-04, Batch size: 37, Momentum: 4.732e-01\n",
      "Initial loss:  2381753.0716815465\n",
      "best loss: 1002.28\t\tLearning rate: 4.833e-03, Batch size: 7, Momentum: 6.835e-01\n",
      "Initial loss:  3999297.3194937245\n",
      "best loss: 540.91\t\tLearning rate: 6.952e-06, Batch size: 12, Momentum: 6.309e-01\n",
      "Initial loss:  1796968.251669622\n",
      "best loss: 489.99\t\tLearning rate: 1.000e-08, Batch size: 19, Momentum: 9.990e-01\n",
      "Initial loss:  542630.7780766488\n",
      "best loss: 1236.36\t\tLearning rate: 3.793e-01, Batch size: 32, Momentum: 5.784e-01\n",
      "Initial loss:  2482211.3164346665\n",
      "best loss: 546.16\t\tLearning rate: 8.859e-08, Batch size: 14, Momentum: 2.103e-01\n",
      "Initial loss:  1348971.2695146\n",
      "best loss: 976.83\t\tLearning rate: 4.833e-03, Batch size: 39, Momentum: 2.103e-01\n",
      "Initial loss:  2791118.7901550094\n",
      "best loss: 1214.75\t\tLearning rate: 3.793e-01, Batch size: 19, Momentum: 5.258e-02\n",
      "Initial loss:  1361827.7124267793\n",
      "best loss: 579.06\t\tLearning rate: 2.976e-08, Batch size: 22, Momentum: 6.309e-01\n",
      "Initial loss:  1494729.174841022\n",
      "best loss: 1240.78\t\tLearning rate: 1.129e+00, Batch size: 22, Momentum: 1.052e-01\n",
      "Initial loss:  1563071.1215364041\n",
      "best loss: 1191.05\t\tLearning rate: 3.793e-01, Batch size: 29, Momentum: 3.155e-01\n",
      "Initial loss:  1095816.098157032\n",
      "best loss: 498.46\t\tLearning rate: 6.952e-06, Batch size: 12, Momentum: 9.464e-01\n",
      "Initial loss:  1310473.7127019847\n",
      "best loss: 1071.64\t\tLearning rate: 4.281e-02, Batch size: 14, Momentum: 4.206e-01\n",
      "Initial loss:  4400442.493273646\n",
      "best loss: 1353.52\t\tLearning rate: 1.129e+00, Batch size: 7, Momentum: 9.464e-01\n",
      "Initial loss:  2454333.9189398414\n",
      "best loss: 1011.99\t\tLearning rate: 4.833e-03, Batch size: 37, Momentum: 8.413e-01\n",
      "Initial loss:  495.26878257773103\n",
      "best loss: 478.56\t\tLearning rate: 7.848e-07, Batch size: 4, Momentum: 6.309e-01\n",
      "Initial loss:  4659424.374033188\n",
      "best loss: 1145.55\t\tLearning rate: 1.274e-01, Batch size: 4, Momentum: 1.577e-01\n",
      "Initial loss:  1802793.2058665438\n",
      "best loss: 895.30\t\tLearning rate: 5.456e-04, Batch size: 42, Momentum: 4.206e-01\n",
      "Initial loss:  891801.7457691047\n",
      "best loss: 492.48\t\tLearning rate: 7.848e-07, Batch size: 7, Momentum: 5.258e-02\n",
      "Initial loss:  847344.5008855805\n",
      "best loss: 490.65\t\tLearning rate: 6.952e-06, Batch size: 42, Momentum: 4.206e-01\n",
      "Initial loss:  2009423.1546123656\n",
      "best loss: 995.33\t\tLearning rate: 1.624e-03, Batch size: 12, Momentum: 8.413e-01\n",
      "Initial loss:  3408828.8911615713\n",
      "best loss: 1317.36\t\tLearning rate: 3.360e+00, Batch size: 17, Momentum: 5.258e-01\n",
      "Initial loss:  1033691.7588434577\n",
      "best loss: 524.79\t\tLearning rate: 2.976e-08, Batch size: 34, Momentum: 6.309e-01\n",
      "Initial loss:  3526707.3607070222\n",
      "best loss: 9629.67\t\tLearning rate: 1.000e-08, Batch size: 44, Momentum: 2.103e-01\n",
      "Initial loss:  4852124.074789005\n",
      "best loss: 500.08\t\tLearning rate: 8.859e-08, Batch size: 29, Momentum: 9.464e-01\n",
      "Initial loss:  509.3359511427876\n",
      "best loss: 487.69\t\tLearning rate: 6.158e-05, Batch size: 7, Momentum: 4.206e-01\n",
      "Initial loss:  1180781.3883536677\n",
      "best loss: 995.29\t\tLearning rate: 4.833e-03, Batch size: 42, Momentum: 3.155e-01\n",
      "Initial loss:  4107131.1061081486\n",
      "best loss: 869.10\t\tLearning rate: 1.833e-04, Batch size: 27, Momentum: 8.938e-01\n",
      "Initial loss:  7304061.314937768\n",
      "best loss: 697397.96\t\tLearning rate: 1.000e-08, Batch size: 24, Momentum: 4.732e-01\n",
      "Initial loss:  1596663.652720088\n",
      "best loss: 5552.51\t\tLearning rate: 2.976e-08, Batch size: 32, Momentum: 3.681e-01\n",
      "Initial loss:  5789420.917045951\n",
      "best loss: 1182.66\t\tLearning rate: 3.793e-01, Batch size: 7, Momentum: 5.258e-02\n",
      "Initial loss:  2594126.3257735353\n",
      "best loss: 1227.24\t\tLearning rate: 1.274e-01, Batch size: 12, Momentum: 7.887e-01\n",
      "Initial loss:  643207.3709129064\n",
      "best loss: 1386.00\t\tLearning rate: 1.000e+01, Batch size: 44, Momentum: 2.629e-01\n",
      "Initial loss:  1614216.4833538653\n",
      "best loss: 1086.89\t\tLearning rate: 4.281e-02, Batch size: 34, Momentum: 2.629e-01\n",
      "Initial loss:  898699.4347308875\n",
      "best loss: 1440.94\t\tLearning rate: 1.000e+01, Batch size: 17, Momentum: 8.938e-01\n",
      "Initial loss:  1155731.3218883104\n",
      "best loss: 1040.93\t\tLearning rate: 4.833e-03, Batch size: 12, Momentum: 7.887e-01\n",
      "Initial loss:  1364259.4692938537\n",
      "best loss: 1445.80\t\tLearning rate: 3.360e+00, Batch size: 14, Momentum: 9.464e-01\n",
      "Initial loss:  3516172.286501533\n",
      "best loss: 822720.56\t\tLearning rate: 1.000e+01, Batch size: 44, Momentum: 0.000e+00\n",
      "Initial loss:  1154897.5159631027\n",
      "best loss: 1294.61\t\tLearning rate: 1.129e+00, Batch size: 19, Momentum: 5.258e-01\n",
      "Initial loss:  1510142.8535191352\n",
      "best loss: 1479.86\t\tLearning rate: 1.000e+01, Batch size: 32, Momentum: 7.887e-01\n",
      "Initial loss:  1411432.0374080334\n",
      "best loss: 114126.84\t\tLearning rate: 1.000e-08, Batch size: 32, Momentum: 4.732e-01\n",
      "Initial loss:  1989892.619310028\n",
      "best loss: 758.53\t\tLearning rate: 6.158e-05, Batch size: 7, Momentum: 9.464e-01\n",
      "Initial loss:  1723854.9102144702\n",
      "best loss: 491.07\t\tLearning rate: 2.336e-06, Batch size: 22, Momentum: 2.103e-01\n",
      "Initial loss:  1367802.9950828012\n",
      "best loss: 121450.48\t\tLearning rate: 2.976e-08, Batch size: 24, Momentum: 5.258e-02\n",
      "Initial loss:  2206222.922729681\n",
      "best loss: 1332.02\t\tLearning rate: 3.360e+00, Batch size: 50, Momentum: 2.629e-01\n",
      "Initial loss:  4215442.455836032\n",
      "best loss: 929.24\t\tLearning rate: 1.624e-03, Batch size: 2, Momentum: 1.052e-01\n",
      "Initial loss:  510.9559052859547\n",
      "best loss: 479.31\t\tLearning rate: 4.281e-02, Batch size: 4, Momentum: 8.938e-01\n",
      "Initial loss:  3009677.7629030785\n",
      "best loss: 1277.85\t\tLearning rate: 3.793e-01, Batch size: 4, Momentum: 4.206e-01\n",
      "Initial loss:  2908731.483184339\n",
      "best loss: 1303.93\t\tLearning rate: 1.129e+00, Batch size: 39, Momentum: 4.732e-01\n",
      "Initial loss:  869346.5511676503\n",
      "best loss: 881.98\t\tLearning rate: 1.624e-03, Batch size: 37, Momentum: 6.835e-01\n",
      "Initial loss:  2704766.4270765106\n",
      "best loss: 1477.21\t\tLearning rate: 1.000e+01, Batch size: 17, Momentum: 8.413e-01\n",
      "Initial loss:  885412.3177995196\n",
      "best loss: 896.79\t\tLearning rate: 1.000e-08, Batch size: 22, Momentum: 5.784e-01\n",
      "Initial loss:  1609845.209080489\n",
      "best loss: 1044.12\t\tLearning rate: 1.624e-03, Batch size: 42, Momentum: 9.464e-01\n",
      "Initial loss:  1112266.068137118\n",
      "best loss: 981.91\t\tLearning rate: 1.624e-03, Batch size: 12, Momentum: 6.309e-01\n",
      "Initial loss:  1367005.143009743\n",
      "best loss: 542.12\t\tLearning rate: 2.637e-07, Batch size: 44, Momentum: 5.784e-01\n",
      "Initial loss:  4394050.270942496\n",
      "best loss: 1030.96\t\tLearning rate: 1.624e-03, Batch size: 39, Momentum: 9.990e-01\n",
      "Initial loss:  5119566.966158741\n",
      "best loss: 1017.14\t\tLearning rate: 1.438e-02, Batch size: 4, Momentum: 2.103e-01\n",
      "Initial loss:  964728.8323770259\n",
      "best loss: 789.67\t\tLearning rate: 1.833e-04, Batch size: 22, Momentum: 7.887e-01\n",
      "Initial loss:  2784612.6195484404\n",
      "best loss: 119814.83\t\tLearning rate: 2.976e-08, Batch size: 42, Momentum: 4.732e-01\n",
      "Initial loss:  781183.4579475659\n",
      "best loss: 1424.75\t\tLearning rate: 3.360e+00, Batch size: 2, Momentum: 6.835e-01\n",
      "Initial loss:  478954.12423338904\n",
      "best loss: 500.45\t\tLearning rate: 6.952e-06, Batch size: 37, Momentum: 8.413e-01\n",
      "Initial loss:  1694365.9018632828\n",
      "best loss: 1158.81\t\tLearning rate: 1.274e-01, Batch size: 39, Momentum: 5.784e-01\n",
      "Initial loss:  1170207.315045823\n",
      "best loss: 270760.08\t\tLearning rate: 1.624e-03, Batch size: 34, Momentum: 0.000e+00\n",
      "Initial loss:  1613798.354692207\n",
      "best loss: 587.92\t\tLearning rate: 2.069e-05, Batch size: 50, Momentum: 0.000e+00\n",
      "Initial loss:  753865.1518286569\n",
      "best loss: 1156.63\t\tLearning rate: 3.793e-01, Batch size: 29, Momentum: 3.681e-01\n",
      "Initial loss:  1913863.0040469905\n",
      "best loss: 1348.84\t\tLearning rate: 1.129e+00, Batch size: 7, Momentum: 9.990e-01\n",
      "Initial loss:  465610.2319564981\n",
      "best loss: 491.00\t\tLearning rate: 2.637e-07, Batch size: 47, Momentum: 9.990e-01\n",
      "Initial loss:  3434285.769815856\n",
      "best loss: 690.79\t\tLearning rate: 6.158e-05, Batch size: 19, Momentum: 2.103e-01\n",
      "Initial loss:  2616465.4300776646\n",
      "best loss: 995.70\t\tLearning rate: 4.833e-03, Batch size: 7, Momentum: 4.732e-01\n",
      "Initial loss:  1872377.2561436533\n",
      "best loss: 910.53\t\tLearning rate: 5.456e-04, Batch size: 24, Momentum: 4.206e-01\n",
      "Initial loss:  713818.1146392348\n",
      "best loss: 530.04\t\tLearning rate: 8.859e-08, Batch size: 7, Momentum: 1.052e-01\n",
      "Initial loss:  1144491.7704638275\n",
      "best loss: 684.56\t\tLearning rate: 2.069e-05, Batch size: 37, Momentum: 2.629e-01\n",
      "Initial loss:  1171876.1220760304\n",
      "best loss: 352394.25\t\tLearning rate: 8.859e-08, Batch size: 32, Momentum: 3.681e-01\n",
      "Initial loss:  1911395.4254220845\n",
      "best loss: 641.76\t\tLearning rate: 2.069e-05, Batch size: 14, Momentum: 7.361e-01\n",
      "Initial loss:  902420.2890781839\n",
      "best loss: 584.34\t\tLearning rate: 2.336e-06, Batch size: 24, Momentum: 2.103e-01\n",
      "Initial loss:  5503208.884017063\n",
      "best loss: 779.16\t\tLearning rate: 1.833e-04, Batch size: 9, Momentum: 3.155e-01\n",
      "Initial loss:  3079770.4805459953\n",
      "best loss: 680.28\t\tLearning rate: 2.069e-05, Batch size: 9, Momentum: 5.258e-01\n",
      "Initial loss:  897559.3114153899\n",
      "best loss: 494.66\t\tLearning rate: 6.952e-06, Batch size: 24, Momentum: 5.784e-01\n",
      "Initial loss:  4352061.132102731\n",
      "best loss: 918.17\t\tLearning rate: 5.456e-04, Batch size: 42, Momentum: 7.887e-01\n",
      "Initial loss:  1541323.1789579643\n",
      "best loss: 327536.60\t\tLearning rate: 1.000e+01, Batch size: 32, Momentum: 0.000e+00\n",
      "Initial loss:  1248016.7245743785\n",
      "best loss: 1001.02\t\tLearning rate: 1.438e-02, Batch size: 14, Momentum: 5.258e-02\n",
      "Initial loss:  3127942.731736427\n",
      "best loss: 614319.68\t\tLearning rate: 8.859e-08, Batch size: 50, Momentum: 1.052e-01\n",
      "Initial loss:  2056853.7274879646\n",
      "best loss: 856.78\t\tLearning rate: 5.456e-04, Batch size: 42, Momentum: 1.577e-01\n",
      "Initial loss:  1569251.0582423962\n",
      "best loss: 488.75\t\tLearning rate: 6.952e-06, Batch size: 19, Momentum: 2.629e-01\n",
      "Initial loss:  1035845.7260204394\n",
      "best loss: 858.46\t\tLearning rate: 5.456e-04, Batch size: 29, Momentum: 6.309e-01\n",
      "Initial loss:  1075976.6803987965\n",
      "best loss: 148479.75\t\tLearning rate: 1.000e-08, Batch size: 44, Momentum: 4.732e-01\n",
      "Initial loss:  818143.4911198212\n",
      "best loss: 1457.69\t\tLearning rate: 1.000e+01, Batch size: 9, Momentum: 8.938e-01\n",
      "Initial loss:  576237.0734928397\n",
      "best loss: 1334.39\t\tLearning rate: 1.129e+00, Batch size: 27, Momentum: 5.258e-01\n",
      "Initial loss:  491.6085699411972\n",
      "best loss: 487.52\t\tLearning rate: 3.360e+00, Batch size: 37, Momentum: 3.155e-01\n",
      "Initial loss:  1426076.5701608832\n",
      "best loss: 1307.61\t\tLearning rate: 1.129e+00, Batch size: 19, Momentum: 6.835e-01\n",
      "Initial loss:  2040653.0330774623\n",
      "best loss: 369051.22\t\tLearning rate: 3.360e+00, Batch size: 37, Momentum: 5.258e-01\n",
      "Initial loss:  1547223.571800837\n",
      "best loss: 493.03\t\tLearning rate: 2.336e-06, Batch size: 39, Momentum: 8.413e-01\n",
      "Initial loss:  1920393.829195322\n",
      "best loss: 1242.38\t\tLearning rate: 1.129e+00, Batch size: 17, Momentum: 5.258e-02\n",
      "Initial loss:  258774.54856805335\n",
      "best loss: 1063.17\t\tLearning rate: 4.833e-03, Batch size: 42, Momentum: 7.361e-01\n",
      "Initial loss:  1025555.0822263634\n",
      "best loss: 961.21\t\tLearning rate: 1.624e-03, Batch size: 17, Momentum: 3.681e-01\n",
      "Initial loss:  901410.9288360383\n",
      "best loss: 1303.05\t\tLearning rate: 1.274e-01, Batch size: 14, Momentum: 9.990e-01\n",
      "Initial loss:  3838682.9635428623\n",
      "best loss: 1092.25\t\tLearning rate: 1.274e-01, Batch size: 22, Momentum: 0.000e+00\n",
      "Initial loss:  1859804.342412827\n",
      "best loss: 1352.92\t\tLearning rate: 1.000e+01, Batch size: 50, Momentum: 2.629e-01\n",
      "Initial loss:  987770.3185816184\n",
      "best loss: 911.23\t\tLearning rate: 5.456e-04, Batch size: 12, Momentum: 7.361e-01\n",
      "Initial loss:  1548290.2137324242\n",
      "best loss: 1493.68\t\tLearning rate: 1.000e+01, Batch size: 4, Momentum: 8.938e-01\n",
      "Initial loss:  1432259.01157585\n",
      "best loss: 1419.48\t\tLearning rate: 1.129e+00, Batch size: 4, Momentum: 7.887e-01\n",
      "Initial loss:  4322537.265856429\n",
      "best loss: 654955.97\t\tLearning rate: 2.976e-08, Batch size: 17, Momentum: 0.000e+00\n",
      "Initial loss:  3826699.566170346\n",
      "best loss: 1369.89\t\tLearning rate: 1.000e+01, Batch size: 2, Momentum: 5.258e-01\n",
      "Initial loss:  2667372.317174265\n",
      "best loss: 1307.52\t\tLearning rate: 3.360e+00, Batch size: 12, Momentum: 2.103e-01\n",
      "Initial loss:  1059112.264891213\n",
      "best loss: 119096.75\t\tLearning rate: 5.456e-04, Batch size: 19, Momentum: 5.258e-02\n",
      "Initial loss:  739196.855785874\n",
      "best loss: 492.08\t\tLearning rate: 2.637e-07, Batch size: 39, Momentum: 7.361e-01\n",
      "Initial loss:  2271335.9936028277\n",
      "best loss: 804.90\t\tLearning rate: 1.833e-04, Batch size: 4, Momentum: 0.000e+00\n",
      "Initial loss:  2685801.7280520285\n",
      "best loss: 693.84\t\tLearning rate: 2.069e-05, Batch size: 37, Momentum: 7.361e-01\n",
      "Initial loss:  4589280.935429676\n",
      "best loss: 959.02\t\tLearning rate: 4.833e-03, Batch size: 14, Momentum: 0.000e+00\n",
      "Initial loss:  1719163.7471231176\n",
      "best loss: 510.66\t\tLearning rate: 2.336e-06, Batch size: 12, Momentum: 8.938e-01\n",
      "Initial loss:  4069296.7472590236\n",
      "best loss: 610.93\t\tLearning rate: 2.069e-05, Batch size: 29, Momentum: 4.206e-01\n",
      "Initial loss:  1659464.2992816768\n",
      "best loss: 112604.83\t\tLearning rate: 2.976e-08, Batch size: 34, Momentum: 5.784e-01\n",
      "Initial loss:  4398936.642631617\n",
      "best loss: 1189.99\t\tLearning rate: 4.281e-02, Batch size: 4, Momentum: 7.361e-01\n",
      "Initial loss:  2589768.946368003\n",
      "best loss: 1078.57\t\tLearning rate: 4.281e-02, Batch size: 17, Momentum: 1.577e-01\n",
      "Initial loss:  1214846.0425683009\n",
      "best loss: 1374.59\t\tLearning rate: 1.129e+00, Batch size: 24, Momentum: 9.990e-01\n",
      "Initial loss:  2442757.883457005\n",
      "best loss: 682.55\t\tLearning rate: 2.069e-05, Batch size: 14, Momentum: 7.887e-01\n",
      "Initial loss:  2929271.6837217542\n",
      "best loss: 531579.52\t\tLearning rate: 2.637e-07, Batch size: 9, Momentum: 1.052e-01\n",
      "Initial loss:  1226692.8403267935\n",
      "best loss: 1421.47\t\tLearning rate: 3.360e+00, Batch size: 27, Momentum: 9.464e-01\n",
      "Initial loss:  2479350.6658925028\n",
      "best loss: 1024.90\t\tLearning rate: 1.438e-02, Batch size: 22, Momentum: 2.629e-01\n",
      "Initial loss:  468616.27955581073\n",
      "best loss: 770.45\t\tLearning rate: 6.158e-05, Batch size: 39, Momentum: 1.052e-01\n",
      "Initial loss:  2727062.16873654\n",
      "best loss: 506.84\t\tLearning rate: 1.000e-08, Batch size: 47, Momentum: 8.413e-01\n",
      "Initial loss:  1800284.6863581557\n",
      "best loss: 1271.88\t\tLearning rate: 3.360e+00, Batch size: 29, Momentum: 0.000e+00\n",
      "Initial loss:  530844.9148003856\n",
      "best loss: 609.94\t\tLearning rate: 2.069e-05, Batch size: 22, Momentum: 2.103e-01\n",
      "Initial loss:  1899631.6085108083\n",
      "best loss: 742.79\t\tLearning rate: 2.976e-08, Batch size: 24, Momentum: 5.258e-02\n",
      "Initial loss:  837311.7690545693\n",
      "best loss: 1226.06\t\tLearning rate: 1.274e-01, Batch size: 37, Momentum: 8.413e-01\n",
      "Initial loss:  2548188.0594855454\n",
      "best loss: 620.84\t\tLearning rate: 6.158e-05, Batch size: 2, Momentum: 0.000e+00\n",
      "Initial loss:  1669913.201667346\n",
      "best loss: 298482.97\t\tLearning rate: 1.000e-08, Batch size: 27, Momentum: 4.206e-01\n",
      "Initial loss:  483352.0686084429\n",
      "best loss: 494.39\t\tLearning rate: 2.336e-06, Batch size: 32, Momentum: 5.258e-02\n",
      "Initial loss:  1140019.1180224072\n",
      "best loss: 1319.32\t\tLearning rate: 3.360e+00, Batch size: 2, Momentum: 1.577e-01\n",
      "Initial loss:  1463965.4293339523\n",
      "best loss: 736.75\t\tLearning rate: 1.833e-04, Batch size: 2, Momentum: 1.577e-01\n",
      "Initial loss:  496863.4026752902\n",
      "best loss: 578.74\t\tLearning rate: 7.848e-07, Batch size: 37, Momentum: 1.577e-01\n",
      "Initial loss:  1643911.0620909599\n",
      "best loss: 488.31\t\tLearning rate: 2.336e-06, Batch size: 14, Momentum: 4.732e-01\n",
      "Initial loss:  2479976.5907253283\n",
      "best loss: 961.38\t\tLearning rate: 4.833e-03, Batch size: 50, Momentum: 0.000e+00\n",
      "Initial loss:  504.54719711269297\n",
      "best loss: 490.99\t\tLearning rate: 2.976e-08, Batch size: 32, Momentum: 0.000e+00\n",
      "Initial loss:  616163.9949635952\n",
      "best loss: 1159.23\t\tLearning rate: 1.438e-02, Batch size: 17, Momentum: 8.938e-01\n",
      "Initial loss:  2094564.8414153159\n",
      "best loss: 1026.50\t\tLearning rate: 4.833e-03, Batch size: 17, Momentum: 5.784e-01\n",
      "Initial loss:  1464063.6783695102\n",
      "best loss: 900.76\t\tLearning rate: 5.456e-04, Batch size: 19, Momentum: 4.732e-01\n",
      "Initial loss:  3093174.545658992\n",
      "best loss: 1278.01\t\tLearning rate: 3.793e-01, Batch size: 32, Momentum: 6.835e-01\n",
      "Initial loss:  1112842.5702134522\n",
      "best loss: 616.23\t\tLearning rate: 2.069e-05, Batch size: 19, Momentum: 5.784e-01\n",
      "Initial loss:  3194064.1165713593\n",
      "best loss: 664.37\t\tLearning rate: 6.158e-05, Batch size: 29, Momentum: 5.784e-01\n",
      "Initial loss:  1937949.6747524901\n",
      "best loss: 494.61\t\tLearning rate: 1.000e-08, Batch size: 7, Momentum: 8.413e-01\n",
      "Initial loss:  1487620.4738652776\n",
      "best loss: 119510.96\t\tLearning rate: 2.976e-08, Batch size: 39, Momentum: 7.887e-01\n",
      "Initial loss:  497.41501397272964\n",
      "best loss: 489.89\t\tLearning rate: 2.637e-07, Batch size: 24, Momentum: 0.000e+00\n",
      "Initial loss:  1983434.5089990597\n",
      "best loss: 1030.52\t\tLearning rate: 4.833e-03, Batch size: 32, Momentum: 9.464e-01\n",
      "Initial loss:  1308647.8210690562\n",
      "best loss: 1368.10\t\tLearning rate: 1.000e+01, Batch size: 2, Momentum: 4.732e-01\n",
      "Initial loss:  755630.9299486802\n",
      "best loss: 1031.25\t\tLearning rate: 1.438e-02, Batch size: 39, Momentum: 3.155e-01\n",
      "Initial loss:  2397308.614250492\n",
      "best loss: 1315.71\t\tLearning rate: 3.793e-01, Batch size: 44, Momentum: 9.464e-01\n",
      "Initial loss:  1568876.798416021\n",
      "best loss: 1025.93\t\tLearning rate: 4.281e-02, Batch size: 47, Momentum: 0.000e+00\n",
      "Initial loss:  826345.9318353648\n",
      "best loss: 517.37\t\tLearning rate: 2.976e-08, Batch size: 7, Momentum: 2.629e-01\n",
      "Initial loss:  1325758.3434441988\n",
      "best loss: 823.56\t\tLearning rate: 1.833e-04, Batch size: 12, Momentum: 8.938e-01\n",
      "Initial loss:  1134678.0849709914\n",
      "best loss: 692.95\t\tLearning rate: 2.976e-08, Batch size: 34, Momentum: 1.577e-01\n",
      "Initial loss:  1418821.3244833674\n",
      "best loss: 1349.45\t\tLearning rate: 3.360e+00, Batch size: 17, Momentum: 4.206e-01\n",
      "Initial loss:  2214244.783514065\n",
      "best loss: 1026.00\t\tLearning rate: 1.624e-03, Batch size: 14, Momentum: 7.361e-01\n",
      "Initial loss:  1469056.1992618965\n",
      "best loss: 115589.18\t\tLearning rate: 2.637e-07, Batch size: 39, Momentum: 3.681e-01\n",
      "Initial loss:  1250592.7085627874\n",
      "best loss: 515.30\t\tLearning rate: 2.637e-07, Batch size: 39, Momentum: 3.681e-01\n",
      "Initial loss:  1230902.8025123284\n",
      "best loss: 1138.49\t\tLearning rate: 4.281e-02, Batch size: 50, Momentum: 6.835e-01\n",
      "Initial loss:  1102841.2445511287\n",
      "best loss: 494.71\t\tLearning rate: 2.637e-07, Batch size: 32, Momentum: 6.309e-01\n",
      "Initial loss:  2005708.8559151283\n",
      "best loss: 960.30\t\tLearning rate: 5.456e-04, Batch size: 9, Momentum: 7.887e-01\n",
      "Initial loss:  1602879.7702340358\n",
      "best loss: 551.23\t\tLearning rate: 2.976e-08, Batch size: 4, Momentum: 0.000e+00\n",
      "Initial loss:  1452918.8928725831\n",
      "best loss: 1167.27\t\tLearning rate: 4.281e-02, Batch size: 47, Momentum: 7.361e-01\n",
      "Initial loss:  4564375.62006107\n",
      "best loss: 119694.03\t\tLearning rate: 8.859e-08, Batch size: 17, Momentum: 2.629e-01\n",
      "Initial loss:  872555.9215070733\n",
      "best loss: 902.97\t\tLearning rate: 1.833e-04, Batch size: 12, Momentum: 8.413e-01\n",
      "Initial loss:  1211198.1164940193\n",
      "best loss: 1204.87\t\tLearning rate: 3.793e-01, Batch size: 39, Momentum: 3.155e-01\n",
      "Initial loss:  556070.9722026965\n",
      "best loss: 1162.58\t\tLearning rate: 1.274e-01, Batch size: 2, Momentum: 1.577e-01\n",
      "Initial loss:  1085573.08546584\n",
      "best loss: 488.85\t\tLearning rate: 7.848e-07, Batch size: 29, Momentum: 9.464e-01\n",
      "Initial loss:  1071442.4639836727\n",
      "best loss: 699.09\t\tLearning rate: 2.976e-08, Batch size: 50, Momentum: 5.258e-01\n",
      "Initial loss:  1460802.7105210745\n",
      "best loss: 700.22\t\tLearning rate: 6.158e-05, Batch size: 50, Momentum: 1.577e-01\n",
      "Initial loss:  837359.6377520167\n",
      "best loss: 582.57\t\tLearning rate: 2.976e-08, Batch size: 14, Momentum: 0.000e+00\n",
      "Initial loss:  1827177.9230584851\n",
      "best loss: 653.16\t\tLearning rate: 6.952e-06, Batch size: 7, Momentum: 9.990e-01\n",
      "Initial loss:  3344841.812982367\n",
      "best loss: 494.44\t\tLearning rate: 2.336e-06, Batch size: 29, Momentum: 5.258e-01\n",
      "Initial loss:  2611320.8658872605\n",
      "best loss: 681.01\t\tLearning rate: 2.069e-05, Batch size: 22, Momentum: 4.732e-01\n",
      "Initial loss:  2097512.152865614\n",
      "best loss: 1043.02\t\tLearning rate: 1.624e-03, Batch size: 39, Momentum: 8.413e-01\n",
      "Initial loss:  1256203.8817609285\n",
      "best loss: 1205.08\t\tLearning rate: 1.438e-02, Batch size: 29, Momentum: 9.464e-01\n",
      "Initial loss:  1683715.6747984875\n",
      "best loss: 497.15\t\tLearning rate: 2.976e-08, Batch size: 7, Momentum: 8.413e-01\n",
      "Initial loss:  912661.1731603615\n",
      "best loss: 294195.99\t\tLearning rate: 1.000e-08, Batch size: 14, Momentum: 7.361e-01\n",
      "Initial loss:  497.8292800618964\n",
      "best loss: 487.85\t\tLearning rate: 4.833e-03, Batch size: 14, Momentum: 6.309e-01\n",
      "Initial loss:  1612555.6611660738\n",
      "best loss: 565.96\t\tLearning rate: 2.069e-05, Batch size: 12, Momentum: 3.155e-01\n",
      "Initial loss:  1505813.8493466233\n",
      "best loss: 494.43\t\tLearning rate: 7.848e-07, Batch size: 37, Momentum: 8.938e-01\n",
      "Initial loss:  2671091.7789845457\n",
      "best loss: 654.15\t\tLearning rate: 2.069e-05, Batch size: 47, Momentum: 4.732e-01\n",
      "Initial loss:  2779745.153940175\n",
      "best loss: 277021.29\t\tLearning rate: 7.848e-07, Batch size: 17, Momentum: 3.155e-01\n",
      "Initial loss:  1665228.1147993105\n",
      "best loss: 1132.30\t\tLearning rate: 4.833e-03, Batch size: 2, Momentum: 7.887e-01\n",
      "Initial loss:  3986264.799852153\n",
      "best loss: 1214.94\t\tLearning rate: 3.793e-01, Batch size: 2, Momentum: 9.464e-01\n",
      "Initial loss:  1646764.5522570987\n",
      "best loss: 411969.96\t\tLearning rate: 2.976e-08, Batch size: 34, Momentum: 5.784e-01\n",
      "Initial loss:  720389.495431766\n",
      "best loss: 1123.63\t\tLearning rate: 1.624e-03, Batch size: 4, Momentum: 9.464e-01\n",
      "Initial loss:  4158933.668585059\n",
      "best loss: 925.43\t\tLearning rate: 1.624e-03, Batch size: 29, Momentum: 5.258e-02\n",
      "Initial loss:  3592649.228368929\n",
      "best loss: 854.93\t\tLearning rate: 5.456e-04, Batch size: 47, Momentum: 1.052e-01\n",
      "Initial loss:  386561.2168482559\n",
      "best loss: 485.73\t\tLearning rate: 7.848e-07, Batch size: 9, Momentum: 2.629e-01\n",
      "Initial loss:  1076048.7687592828\n",
      "best loss: 557.07\t\tLearning rate: 6.952e-06, Batch size: 4, Momentum: 6.835e-01\n",
      "Initial loss:  262613.2165252003\n",
      "best loss: 1007.55\t\tLearning rate: 1.438e-02, Batch size: 17, Momentum: 0.000e+00\n",
      "Initial loss:  1012611.8242634814\n",
      "best loss: 898.49\t\tLearning rate: 1.624e-03, Batch size: 29, Momentum: 1.052e-01\n",
      "Initial loss:  3201008.5631260956\n",
      "best loss: 1239.68\t\tLearning rate: 3.793e-01, Batch size: 50, Momentum: 2.629e-01\n",
      "Initial loss:  2313725.3509925837\n",
      "best loss: 537.22\t\tLearning rate: 2.336e-06, Batch size: 34, Momentum: 3.155e-01\n",
      "Initial loss:  2364628.216592368\n",
      "best loss: 501.28\t\tLearning rate: 2.336e-06, Batch size: 29, Momentum: 2.629e-01\n",
      "Initial loss:  1034569.3501961861\n",
      "best loss: 863.28\t\tLearning rate: 1.833e-04, Batch size: 12, Momentum: 7.887e-01\n",
      "Initial loss:  2930418.148726451\n",
      "best loss: 1406.38\t\tLearning rate: 3.360e+00, Batch size: 12, Momentum: 7.361e-01\n",
      "Initial loss:  4094128.9671129594\n",
      "best loss: 797.23\t\tLearning rate: 1.833e-04, Batch size: 12, Momentum: 4.732e-01\n",
      "Initial loss:  945265.1531073053\n",
      "best loss: 946.01\t\tLearning rate: 5.456e-04, Batch size: 12, Momentum: 9.990e-01\n",
      "Initial loss:  2455775.6998296194\n",
      "best loss: 474.78\t\tLearning rate: 7.848e-07, Batch size: 2, Momentum: 7.361e-01\n",
      "Initial loss:  1033344.78353367\n",
      "best loss: 492.16\t\tLearning rate: 2.336e-06, Batch size: 44, Momentum: 3.155e-01\n",
      "Initial loss:  644180.7904547221\n",
      "best loss: 991.03\t\tLearning rate: 5.456e-04, Batch size: 22, Momentum: 9.990e-01\n",
      "Initial loss:  1150320.1075830376\n",
      "best loss: 112840.83\t\tLearning rate: 3.793e-01, Batch size: 34, Momentum: 1.052e-01\n",
      "Initial loss:  1855425.4694552072\n",
      "best loss: 1073.98\t\tLearning rate: 4.281e-02, Batch size: 17, Momentum: 1.052e-01\n",
      "Initial loss:  2150637.524606668\n",
      "best loss: 642.76\t\tLearning rate: 2.069e-05, Batch size: 7, Momentum: 7.887e-01\n",
      "Initial loss:  1273649.9419372159\n",
      "best loss: 1424.79\t\tLearning rate: 1.000e+01, Batch size: 47, Momentum: 6.309e-01\n",
      "Initial loss:  3811872.1335125044\n",
      "best loss: 695.92\t\tLearning rate: 6.158e-05, Batch size: 22, Momentum: 2.103e-01\n",
      "Initial loss:  1206393.818594583\n",
      "best loss: 1110.83\t\tLearning rate: 2.976e-08, Batch size: 34, Momentum: 2.103e-01\n",
      "Initial loss:  2144940.229709238\n",
      "best loss: 1381.25\t\tLearning rate: 3.360e+00, Batch size: 42, Momentum: 6.309e-01\n",
      "Initial loss:  1379589.2329155991\n",
      "best loss: 505.26\t\tLearning rate: 7.848e-07, Batch size: 22, Momentum: 3.155e-01\n",
      "Initial loss:  491666.3109072837\n",
      "best loss: 1069.70\t\tLearning rate: 4.833e-03, Batch size: 9, Momentum: 8.413e-01\n",
      "Initial loss:  2462999.173273338\n",
      "best loss: 895.88\t\tLearning rate: 5.456e-04, Batch size: 7, Momentum: 4.732e-01\n",
      "Initial loss:  2293220.599402021\n",
      "best loss: 644.94\t\tLearning rate: 6.952e-06, Batch size: 17, Momentum: 9.464e-01\n",
      "Initial loss:  1310593.146327356\n",
      "best loss: 726.24\t\tLearning rate: 2.976e-08, Batch size: 29, Momentum: 2.629e-01\n",
      "Initial loss:  5206709.761401121\n",
      "best loss: 1502122.70\t\tLearning rate: 2.637e-07, Batch size: 17, Momentum: 6.309e-01\n",
      "Initial loss:  608016.6412210385\n",
      "best loss: 1417.30\t\tLearning rate: 1.000e+01, Batch size: 7, Momentum: 7.887e-01\n",
      "Initial loss:  3135369.9317217483\n",
      "best loss: 1221.90\t\tLearning rate: 3.793e-01, Batch size: 44, Momentum: 4.732e-01\n",
      "Initial loss:  1542457.9071809277\n",
      "best loss: 1293.51\t\tLearning rate: 3.793e-01, Batch size: 19, Momentum: 7.361e-01\n",
      "Initial loss:  2926086.4629505444\n",
      "best loss: 505.27\t\tLearning rate: 2.976e-08, Batch size: 7, Momentum: 7.361e-01\n",
      "Initial loss:  609726.556026499\n",
      "best loss: 1020.24\t\tLearning rate: 4.833e-03, Batch size: 47, Momentum: 8.413e-01\n",
      "Initial loss:  156244.10411992142\n",
      "best loss: 1356.37\t\tLearning rate: 3.360e+00, Batch size: 7, Momentum: 4.732e-01\n",
      "Initial loss:  4071758.2817460815\n",
      "best loss: 1173.83\t\tLearning rate: 4.281e-02, Batch size: 37, Momentum: 6.835e-01\n",
      "Initial loss:  2934327.793804709\n",
      "best loss: 499.42\t\tLearning rate: 8.859e-08, Batch size: 14, Momentum: 5.784e-01\n",
      "Initial loss:  1364285.8893889464\n",
      "best loss: 753.10\t\tLearning rate: 6.158e-05, Batch size: 32, Momentum: 6.309e-01\n",
      "Initial loss:  2365271.3921452295\n",
      "best loss: 497901.51\t\tLearning rate: 1.833e-04, Batch size: 7, Momentum: 0.000e+00\n",
      "Initial loss:  1827213.6518468084\n",
      "best loss: 1499.70\t\tLearning rate: 1.000e+01, Batch size: 39, Momentum: 8.413e-01\n",
      "Initial loss:  2032038.4394392713\n",
      "best loss: 847.04\t\tLearning rate: 2.637e-07, Batch size: 22, Momentum: 2.629e-01\n",
      "Initial loss:  1532915.9456460432\n",
      "best loss: 488.32\t\tLearning rate: 7.848e-07, Batch size: 19, Momentum: 6.309e-01\n",
      "Initial loss:  2116789.738896036\n",
      "best loss: 1303.88\t\tLearning rate: 1.129e+00, Batch size: 50, Momentum: 5.784e-01\n",
      "Initial loss:  781931.2341686513\n",
      "best loss: 529.28\t\tLearning rate: 2.336e-06, Batch size: 14, Momentum: 2.629e-01\n",
      "Initial loss:  3031954.9927763185\n",
      "best loss: 623894.62\t\tLearning rate: 2.637e-07, Batch size: 27, Momentum: 5.258e-01\n",
      "Initial loss:  2259594.7289172504\n",
      "best loss: 686.02\t\tLearning rate: 6.158e-05, Batch size: 34, Momentum: 2.629e-01\n",
      "Initial loss:  1869463.7444742937\n",
      "best loss: 523320.41\t\tLearning rate: 8.859e-08, Batch size: 39, Momentum: 0.000e+00\n",
      "Initial loss:  1298024.1165070445\n",
      "best loss: 545.54\t\tLearning rate: 2.637e-07, Batch size: 17, Momentum: 0.000e+00\n",
      "Initial loss:  2551548.495800615\n",
      "best loss: 2076.97\t\tLearning rate: 2.976e-08, Batch size: 47, Momentum: 0.000e+00\n",
      "Initial loss:  945340.9141862422\n",
      "best loss: 1463.28\t\tLearning rate: 3.360e+00, Batch size: 12, Momentum: 9.990e-01\n",
      "Initial loss:  3090995.6237533027\n",
      "best loss: 858.21\t\tLearning rate: 5.456e-04, Batch size: 17, Momentum: 4.206e-01\n",
      "Initial loss:  2594066.2742654425\n",
      "best loss: 1420.58\t\tLearning rate: 1.000e+01, Batch size: 27, Momentum: 4.732e-01\n",
      "Initial loss:  821290.7491764532\n",
      "best loss: 662.15\t\tLearning rate: 2.069e-05, Batch size: 42, Momentum: 3.155e-01\n",
      "Initial loss:  4072164.816951884\n",
      "best loss: 1037.03\t\tLearning rate: 1.438e-02, Batch size: 4, Momentum: 3.155e-01\n",
      "Initial loss:  1947142.0290878506\n",
      "best loss: 802.77\t\tLearning rate: 1.833e-04, Batch size: 4, Momentum: 6.309e-01\n",
      "Initial loss:  1316248.4064728622\n",
      "best loss: 991.39\t\tLearning rate: 8.859e-08, Batch size: 44, Momentum: 2.103e-01\n",
      "Initial loss:  4042522.9055944234\n",
      "best loss: 1398.02\t\tLearning rate: 3.360e+00, Batch size: 12, Momentum: 7.887e-01\n",
      "Initial loss:  999331.1344627395\n",
      "best loss: 1291.54\t\tLearning rate: 3.793e-01, Batch size: 2, Momentum: 7.361e-01\n",
      "Initial loss:  656730.5408757939\n",
      "best loss: 495.92\t\tLearning rate: 7.848e-07, Batch size: 37, Momentum: 5.784e-01\n",
      "Initial loss:  932643.748443556\n",
      "best loss: 493.26\t\tLearning rate: 2.069e-05, Batch size: 19, Momentum: 1.577e-01\n",
      "Initial loss:  1609524.0440387186\n",
      "best loss: 835.55\t\tLearning rate: 1.833e-04, Batch size: 12, Momentum: 4.732e-01\n",
      "Initial loss:  635135.2422448754\n",
      "best loss: 531.53\t\tLearning rate: 8.859e-08, Batch size: 12, Momentum: 5.784e-01\n",
      "Initial loss:  3433550.9167025555\n",
      "best loss: 47838.60\t\tLearning rate: 7.848e-07, Batch size: 12, Momentum: 0.000e+00\n",
      "Initial loss:  1729243.4546790458\n",
      "best loss: 1524.97\t\tLearning rate: 1.438e-02, Batch size: 2, Momentum: 1.052e-01\n",
      "Initial loss:  4141121.8020619587\n",
      "best loss: 1242.25\t\tLearning rate: 1.129e+00, Batch size: 14, Momentum: 5.258e-02\n",
      "Initial loss:  1761849.3282363755\n",
      "best loss: 959.10\t\tLearning rate: 4.833e-03, Batch size: 29, Momentum: 5.258e-02\n",
      "Initial loss:  571.5195390878401\n",
      "best loss: 501.53\t\tLearning rate: 3.793e-01, Batch size: 29, Momentum: 2.103e-01\n",
      "Initial loss:  2255666.9873903454\n",
      "best loss: 1114.19\t\tLearning rate: 4.281e-02, Batch size: 39, Momentum: 2.629e-01\n",
      "Initial loss:  390496.7338090655\n",
      "best loss: 708.50\t\tLearning rate: 6.158e-05, Batch size: 50, Momentum: 8.938e-01\n",
      "Initial loss:  2249854.876490305\n",
      "best loss: 492.61\t\tLearning rate: 7.848e-07, Batch size: 29, Momentum: 6.309e-01\n",
      "Initial loss:  4037273.4935144656\n",
      "best loss: 500.89\t\tLearning rate: 7.848e-07, Batch size: 37, Momentum: 4.206e-01\n",
      "Initial loss:  1605129.7958753144\n",
      "best loss: 881.76\t\tLearning rate: 5.456e-04, Batch size: 44, Momentum: 3.681e-01\n",
      "Initial loss:  1367941.9886897283\n",
      "best loss: 494.41\t\tLearning rate: 2.637e-07, Batch size: 42, Momentum: 6.835e-01\n",
      "Initial loss:  495.77019689474514\n",
      "best loss: 489.50\t\tLearning rate: 2.637e-07, Batch size: 32, Momentum: 6.835e-01\n",
      "Initial loss:  1224595.336820534\n",
      "best loss: 1262.81\t\tLearning rate: 3.793e-01, Batch size: 42, Momentum: 6.835e-01\n",
      "Initial loss:  1053528.4212727519\n",
      "best loss: 770.95\t\tLearning rate: 6.158e-05, Batch size: 12, Momentum: 5.258e-01\n",
      "Initial loss:  640035.1973572979\n",
      "best loss: 888.06\t\tLearning rate: 5.456e-04, Batch size: 2, Momentum: 9.990e-01\n",
      "Initial loss:  723882.0077791896\n",
      "best loss: 490.41\t\tLearning rate: 7.848e-07, Batch size: 42, Momentum: 6.835e-01\n",
      "Initial loss:  1175139.4961809218\n",
      "best loss: 1021.93\t\tLearning rate: 1.438e-02, Batch size: 12, Momentum: 4.206e-01\n",
      "Initial loss:  1052496.093572604\n",
      "best loss: 902.42\t\tLearning rate: 1.624e-03, Batch size: 39, Momentum: 0.000e+00\n",
      "Initial loss:  506.54541670154157\n",
      "best loss: 500.48\t\tLearning rate: 7.848e-07, Batch size: 42, Momentum: 1.052e-01\n",
      "Initial loss:  2462676.44449235\n",
      "best loss: 493.48\t\tLearning rate: 2.637e-07, Batch size: 22, Momentum: 9.464e-01\n",
      "Initial loss:  1629796.4064729481\n",
      "best loss: 1384.00\t\tLearning rate: 1.000e+01, Batch size: 7, Momentum: 1.577e-01\n",
      "Initial loss:  1309763.6495396441\n",
      "best loss: 1257.35\t\tLearning rate: 3.793e-01, Batch size: 50, Momentum: 4.732e-01\n",
      "Initial loss:  4284910.512148235\n",
      "best loss: 807315.90\t\tLearning rate: 8.859e-08, Batch size: 24, Momentum: 7.887e-01\n",
      "Initial loss:  504.19229787395307\n",
      "best loss: 491.19\t\tLearning rate: 1.274e-01, Batch size: 32, Momentum: 1.577e-01\n",
      "Initial loss:  2320686.1982668666\n",
      "best loss: 723.12\t\tLearning rate: 2.069e-05, Batch size: 44, Momentum: 6.309e-01\n",
      "Initial loss:  6493441.765635269\n",
      "best loss: 149773.31\t\tLearning rate: 1.000e-08, Batch size: 14, Momentum: 4.206e-01\n",
      "Initial loss:  2946822.732544392\n",
      "best loss: 531.43\t\tLearning rate: 2.637e-07, Batch size: 44, Momentum: 8.413e-01\n",
      "Initial loss:  1374020.1321054937\n",
      "best loss: 493.47\t\tLearning rate: 2.336e-06, Batch size: 27, Momentum: 2.629e-01\n",
      "Initial loss:  1185594.1363153006\n",
      "best loss: 228469.64\t\tLearning rate: 3.360e+00, Batch size: 27, Momentum: 3.681e-01\n",
      "Initial loss:  1036652.2802553038\n",
      "best loss: 542.78\t\tLearning rate: 2.976e-08, Batch size: 47, Momentum: 6.835e-01\n",
      "Initial loss:  516.4743640843604\n",
      "best loss: 498.12\t\tLearning rate: 1.274e-01, Batch size: 27, Momentum: 5.258e-01\n",
      "Initial loss:  2074302.7726699566\n",
      "best loss: 1223.95\t\tLearning rate: 1.274e-01, Batch size: 17, Momentum: 6.309e-01\n",
      "Initial loss:  1155225.1657262512\n",
      "best loss: 1121.05\t\tLearning rate: 1.438e-02, Batch size: 29, Momentum: 8.938e-01\n",
      "Initial loss:  2791679.432473078\n",
      "best loss: 809.32\t\tLearning rate: 6.158e-05, Batch size: 22, Momentum: 9.464e-01\n",
      "Initial loss:  1136313.784461769\n",
      "best loss: 1402.65\t\tLearning rate: 1.000e+01, Batch size: 24, Momentum: 4.732e-01\n",
      "Initial loss:  1411271.6616882824\n",
      "best loss: 1153.60\t\tLearning rate: 1.274e-01, Batch size: 9, Momentum: 4.206e-01\n",
      "Initial loss:  1311768.8974976707\n",
      "best loss: 495.39\t\tLearning rate: 7.848e-07, Batch size: 50, Momentum: 4.206e-01\n",
      "Initial loss:  1599291.2277891696\n",
      "best loss: 785.89\t\tLearning rate: 1.833e-04, Batch size: 50, Momentum: 3.681e-01\n",
      "Initial loss:  1261706.5817561992\n",
      "best loss: 1155.39\t\tLearning rate: 4.281e-02, Batch size: 22, Momentum: 7.887e-01\n",
      "Initial loss:  1115565.4614940053\n",
      "best loss: 493.31\t\tLearning rate: 2.336e-06, Batch size: 14, Momentum: 0.000e+00\n",
      "Initial loss:  2845210.5471841167\n",
      "best loss: 492.63\t\tLearning rate: 7.848e-07, Batch size: 32, Momentum: 5.258e-01\n",
      "Initial loss:  1480840.160256973\n",
      "best loss: 1250.62\t\tLearning rate: 1.000e-08, Batch size: 7, Momentum: 3.155e-01\n",
      "Initial loss:  2225071.565162755\n",
      "best loss: 1456.50\t\tLearning rate: 3.360e+00, Batch size: 44, Momentum: 9.464e-01\n",
      "Initial loss:  1247632.5800698046\n",
      "best loss: 936.56\t\tLearning rate: 4.833e-03, Batch size: 42, Momentum: 3.155e-01\n",
      "Initial loss:  2404427.0213277037\n",
      "best loss: 1023280.70\t\tLearning rate: 5.456e-04, Batch size: 19, Momentum: 3.155e-01\n",
      "Initial loss:  625146.640099848\n",
      "best loss: 487.40\t\tLearning rate: 7.848e-07, Batch size: 27, Momentum: 5.784e-01\n",
      "Initial loss:  1304278.7050749327\n",
      "best loss: 943.04\t\tLearning rate: 5.456e-04, Batch size: 7, Momentum: 5.784e-01\n",
      "Initial loss:  1262478.0321985711\n",
      "best loss: 1319.82\t\tLearning rate: 3.793e-01, Batch size: 32, Momentum: 8.413e-01\n",
      "Initial loss:  1279140.1751011664\n",
      "best loss: 983.88\t\tLearning rate: 5.456e-04, Batch size: 37, Momentum: 8.938e-01\n",
      "Initial loss:  889421.414012844\n",
      "best loss: 500.79\t\tLearning rate: 6.952e-06, Batch size: 32, Momentum: 2.629e-01\n",
      "Initial loss:  1801287.9959753624\n",
      "best loss: 1132.29\t\tLearning rate: 4.281e-02, Batch size: 9, Momentum: 6.835e-01\n",
      "Initial loss:  528896.6624024458\n",
      "best loss: 805.06\t\tLearning rate: 1.833e-04, Batch size: 34, Momentum: 2.629e-01\n",
      "Initial loss:  1431750.175983726\n",
      "best loss: 1353.22\t\tLearning rate: 3.360e+00, Batch size: 42, Momentum: 6.309e-01\n",
      "Initial loss:  4654997.059421526\n",
      "best loss: 1225.38\t\tLearning rate: 1.274e-01, Batch size: 27, Momentum: 6.309e-01\n",
      "Initial loss:  2763692.394774405\n",
      "best loss: 839.02\t\tLearning rate: 5.456e-04, Batch size: 44, Momentum: 4.732e-01\n",
      "Initial loss:  3367695.2464042013\n",
      "best loss: 796774.93\t\tLearning rate: 8.859e-08, Batch size: 32, Momentum: 6.309e-01\n",
      "Initial loss:  1692335.971321304\n",
      "best loss: 1083.68\t\tLearning rate: 4.833e-03, Batch size: 34, Momentum: 7.887e-01\n",
      "Initial loss:  1032280.1074176301\n",
      "best loss: 531.75\t\tLearning rate: 8.859e-08, Batch size: 34, Momentum: 5.258e-01\n",
      "Initial loss:  1740854.4250422164\n",
      "best loss: 372103.57\t\tLearning rate: 2.637e-07, Batch size: 29, Momentum: 6.835e-01\n",
      "Initial loss:  3545590.021946353\n",
      "best loss: 547775.01\t\tLearning rate: 8.859e-08, Batch size: 44, Momentum: 2.103e-01\n",
      "Initial loss:  3570873.7112568854\n",
      "best loss: 795.40\t\tLearning rate: 5.456e-04, Batch size: 2, Momentum: 0.000e+00\n",
      "Initial loss:  2379441.4455363457\n",
      "best loss: 1411.50\t\tLearning rate: 1.000e+01, Batch size: 12, Momentum: 4.732e-01\n",
      "Initial loss:  1190124.2218597792\n",
      "best loss: 499.96\t\tLearning rate: 8.859e-08, Batch size: 42, Momentum: 9.990e-01\n",
      "Initial loss:  491.38684808496373\n",
      "best loss: 484.99\t\tLearning rate: 1.000e+01, Batch size: 22, Momentum: 3.681e-01\n",
      "Initial loss:  3545101.233957246\n",
      "best loss: 492.19\t\tLearning rate: 2.336e-06, Batch size: 9, Momentum: 6.309e-01\n",
      "Initial loss:  2478540.656193909\n",
      "best loss: 775.04\t\tLearning rate: 6.158e-05, Batch size: 17, Momentum: 5.258e-01\n",
      "Initial loss:  3217857.1389188166\n",
      "best loss: 1090.46\t\tLearning rate: 4.833e-03, Batch size: 50, Momentum: 9.464e-01\n",
      "Initial loss:  2029725.0927873817\n",
      "best loss: 1428.87\t\tLearning rate: 3.360e+00, Batch size: 44, Momentum: 9.464e-01\n",
      "Initial loss:  1091803.1872831406\n",
      "best loss: 1083.81\t\tLearning rate: 4.281e-02, Batch size: 4, Momentum: 5.258e-01\n",
      "Initial loss:  1236469.785080251\n",
      "best loss: 1003.74\t\tLearning rate: 1.624e-03, Batch size: 14, Momentum: 8.938e-01\n",
      "Initial loss:  702753.75265711\n",
      "best loss: 1134.37\t\tLearning rate: 4.281e-02, Batch size: 44, Momentum: 4.206e-01\n",
      "Initial loss:  3365535.097626547\n",
      "best loss: 495.53\t\tLearning rate: 2.637e-07, Batch size: 12, Momentum: 1.577e-01\n",
      "Initial loss:  2911220.361152138\n",
      "best loss: 597.92\t\tLearning rate: 2.637e-07, Batch size: 17, Momentum: 5.258e-02\n",
      "Initial loss:  1053441.1184180467\n",
      "best loss: 444781.44\t\tLearning rate: 2.637e-07, Batch size: 24, Momentum: 7.361e-01\n",
      "Initial loss:  1335285.042409987\n",
      "best loss: 1021.12\t\tLearning rate: 1.438e-02, Batch size: 34, Momentum: 2.103e-01\n",
      "Initial loss:  2639340.542816424\n",
      "best loss: 936.88\t\tLearning rate: 5.456e-04, Batch size: 17, Momentum: 6.835e-01\n",
      "Initial loss:  3016985.1512527196\n",
      "best loss: 1344.78\t\tLearning rate: 1.274e-01, Batch size: 37, Momentum: 9.464e-01\n",
      "Initial loss:  475046.1498595774\n",
      "best loss: 501.00\t\tLearning rate: 2.637e-07, Batch size: 37, Momentum: 6.835e-01\n",
      "Initial loss:  1747747.6689500986\n",
      "best loss: 1127.65\t\tLearning rate: 4.833e-03, Batch size: 29, Momentum: 9.990e-01\n",
      "Initial loss:  2577651.989205847\n",
      "best loss: 1211.01\t\tLearning rate: 1.000e-08, Batch size: 19, Momentum: 2.629e-01\n",
      "Initial loss:  2192755.454041238\n",
      "best loss: 736.13\t\tLearning rate: 8.859e-08, Batch size: 47, Momentum: 0.000e+00\n",
      "Initial loss:  998186.4001383176\n",
      "best loss: 490.08\t\tLearning rate: 2.976e-08, Batch size: 22, Momentum: 9.990e-01\n",
      "Initial loss:  1220418.2304820744\n",
      "best loss: 1341.84\t\tLearning rate: 3.360e+00, Batch size: 47, Momentum: 4.732e-01\n",
      "Initial loss:  1245781.9975942555\n",
      "best loss: 909.79\t\tLearning rate: 1.624e-03, Batch size: 4, Momentum: 3.155e-01\n",
      "Initial loss:  1943821.0467754086\n",
      "best loss: 1036.11\t\tLearning rate: 4.833e-03, Batch size: 7, Momentum: 3.155e-01\n",
      "Initial loss:  3080459.802899758\n",
      "best loss: 1293.66\t\tLearning rate: 1.274e-01, Batch size: 50, Momentum: 9.464e-01\n",
      "Initial loss:  858571.6046410166\n",
      "best loss: 481.86\t\tLearning rate: 2.336e-06, Batch size: 2, Momentum: 1.577e-01\n",
      "Initial loss:  2511862.6047696345\n",
      "best loss: 489.52\t\tLearning rate: 6.952e-06, Batch size: 14, Momentum: 4.732e-01\n",
      "Initial loss:  1401680.4854269875\n",
      "best loss: 930.24\t\tLearning rate: 1.624e-03, Batch size: 32, Momentum: 5.258e-01\n",
      "Initial loss:  3339778.6495436355\n",
      "best loss: 513.45\t\tLearning rate: 6.952e-06, Batch size: 29, Momentum: 7.887e-01\n",
      "Initial loss:  911395.5762438517\n",
      "best loss: 488.61\t\tLearning rate: 7.848e-07, Batch size: 22, Momentum: 5.784e-01\n",
      "Initial loss:  2251403.2958491957\n",
      "best loss: 491.19\t\tLearning rate: 6.952e-06, Batch size: 24, Momentum: 3.681e-01\n",
      "Initial loss:  3433645.907582822\n",
      "best loss: 802.37\t\tLearning rate: 1.833e-04, Batch size: 19, Momentum: 2.629e-01\n",
      "Initial loss:  1625074.4040440798\n",
      "best loss: 846.52\t\tLearning rate: 6.158e-05, Batch size: 14, Momentum: 9.464e-01\n",
      "Initial loss:  1397271.5034031523\n",
      "best loss: 495.02\t\tLearning rate: 6.952e-06, Batch size: 44, Momentum: 7.361e-01\n",
      "Initial loss:  908681.3122204591\n",
      "best loss: 1208.49\t\tLearning rate: 1.129e+00, Batch size: 7, Momentum: 1.052e-01\n",
      "Initial loss:  501.6509631647209\n",
      "best loss: 489.87\t\tLearning rate: 4.281e-02, Batch size: 19, Momentum: 7.887e-01\n",
      "Initial loss:  1583022.991928096\n",
      "best loss: 940.07\t\tLearning rate: 1.624e-03, Batch size: 4, Momentum: 4.732e-01\n",
      "Initial loss:  4583749.965423569\n",
      "best loss: 512.03\t\tLearning rate: 2.637e-07, Batch size: 39, Momentum: 7.361e-01\n",
      "Initial loss:  560307.0200630986\n",
      "best loss: 1051.92\t\tLearning rate: 1.624e-03, Batch size: 2, Momentum: 9.990e-01\n",
      "Initial loss:  3050070.932114352\n",
      "best loss: 465342.23\t\tLearning rate: 2.976e-08, Batch size: 19, Momentum: 7.887e-01\n",
      "Initial loss:  2188861.240774273\n",
      "best loss: 1348.28\t\tLearning rate: 3.360e+00, Batch size: 19, Momentum: 4.732e-01\n",
      "Initial loss:  2072381.2339075268\n",
      "best loss: 1346.55\t\tLearning rate: 1.129e+00, Batch size: 34, Momentum: 5.258e-01\n",
      "Initial loss:  1268764.093314154\n",
      "best loss: 493.61\t\tLearning rate: 2.976e-08, Batch size: 29, Momentum: 9.990e-01\n",
      "Initial loss:  3256581.3887802926\n",
      "best loss: 1378.01\t\tLearning rate: 1.129e+00, Batch size: 29, Momentum: 9.990e-01\n",
      "Initial loss:  1332538.2793241984\n",
      "best loss: 1331.87\t\tLearning rate: 1.000e+01, Batch size: 17, Momentum: 0.000e+00\n",
      "Initial loss:  3784390.3362942943\n",
      "best loss: 1189.57\t\tLearning rate: 1.274e-01, Batch size: 4, Momentum: 2.629e-01\n",
      "Initial loss:  604741.7112724991\n",
      "best loss: 223866.40\t\tLearning rate: 1.274e-01, Batch size: 29, Momentum: 0.000e+00\n",
      "Initial loss:  635247.3803393687\n",
      "best loss: 1342.21\t\tLearning rate: 1.000e+01, Batch size: 4, Momentum: 2.103e-01\n",
      "Initial loss:  1951767.49323662\n",
      "best loss: 1401.17\t\tLearning rate: 1.000e+01, Batch size: 27, Momentum: 6.309e-01\n",
      "Initial loss:  625818.3106709323\n",
      "best loss: 973.95\t\tLearning rate: 4.833e-03, Batch size: 7, Momentum: 3.681e-01\n",
      "Initial loss:  718528.3965125793\n",
      "best loss: 494.87\t\tLearning rate: 1.000e-08, Batch size: 2, Momentum: 6.835e-01\n",
      "Initial loss:  387070.50368110766\n",
      "best loss: 846.99\t\tLearning rate: 1.624e-03, Batch size: 7, Momentum: 3.681e-01\n",
      "Initial loss:  1520656.522197856\n",
      "best loss: 496.71\t\tLearning rate: 6.952e-06, Batch size: 12, Momentum: 5.784e-01\n",
      "Initial loss:  937572.989993219\n",
      "best loss: 476.98\t\tLearning rate: 2.336e-06, Batch size: 4, Momentum: 4.206e-01\n",
      "Initial loss:  1082302.2994244308\n",
      "best loss: 479.35\t\tLearning rate: 2.637e-07, Batch size: 4, Momentum: 4.206e-01\n",
      "Initial loss:  2296015.461225936\n",
      "best loss: 1383.60\t\tLearning rate: 1.000e+01, Batch size: 47, Momentum: 2.629e-01\n",
      "Initial loss:  2693093.206443178\n",
      "best loss: 1320.54\t\tLearning rate: 1.129e+00, Batch size: 14, Momentum: 5.784e-01\n",
      "Initial loss:  206857.92667283918\n",
      "best loss: 498.03\t\tLearning rate: 6.952e-06, Batch size: 44, Momentum: 5.258e-02\n",
      "Initial loss:  800593.1613491802\n",
      "best loss: 557.49\t\tLearning rate: 2.637e-07, Batch size: 29, Momentum: 2.629e-01\n",
      "Initial loss:  2684309.288461441\n",
      "best loss: 915.27\t\tLearning rate: 1.624e-03, Batch size: 22, Momentum: 1.577e-01\n",
      "Initial loss:  1154103.9070000628\n",
      "best loss: 980.30\t\tLearning rate: 4.833e-03, Batch size: 39, Momentum: 4.206e-01\n",
      "Initial loss:  2469537.148089597\n",
      "best loss: 574.11\t\tLearning rate: 2.069e-05, Batch size: 7, Momentum: 2.629e-01\n",
      "Initial loss:  3561174.4056970924\n",
      "best loss: 1068.90\t\tLearning rate: 1.624e-03, Batch size: 7, Momentum: 8.938e-01\n",
      "Initial loss:  3298671.5836789636\n",
      "best loss: 847.56\t\tLearning rate: 1.833e-04, Batch size: 34, Momentum: 5.784e-01\n",
      "Initial loss:  1664353.6183919555\n",
      "best loss: 1035.18\t\tLearning rate: 1.624e-03, Batch size: 17, Momentum: 7.361e-01\n",
      "Initial loss:  2865982.746347654\n",
      "best loss: 1345.06\t\tLearning rate: 1.129e+00, Batch size: 42, Momentum: 8.413e-01\n",
      "Initial loss:  4033671.4163894113\n",
      "best loss: 1288.25\t\tLearning rate: 3.360e+00, Batch size: 44, Momentum: 5.258e-02\n",
      "Initial loss:  2215807.249261943\n",
      "best loss: 1443.26\t\tLearning rate: 3.360e+00, Batch size: 14, Momentum: 9.464e-01\n",
      "Initial loss:  2713345.5569296884\n",
      "best loss: 515.82\t\tLearning rate: 2.976e-08, Batch size: 34, Momentum: 9.990e-01\n",
      "Initial loss:  2603690.620030189\n",
      "best loss: 1275.69\t\tLearning rate: 3.793e-01, Batch size: 27, Momentum: 5.258e-01\n",
      "Initial loss:  2264221.5834252024\n",
      "best loss: 1463.93\t\tLearning rate: 1.000e+01, Batch size: 50, Momentum: 8.413e-01\n",
      "Initial loss:  2780357.299884944\n",
      "best loss: 990.26\t\tLearning rate: 1.438e-02, Batch size: 27, Momentum: 5.258e-02\n",
      "Initial loss:  1405228.9367469815\n",
      "best loss: 417110.86\t\tLearning rate: 1.000e-08, Batch size: 29, Momentum: 5.258e-02\n",
      "Initial loss:  1492563.2648267266\n",
      "best loss: 496.31\t\tLearning rate: 2.336e-06, Batch size: 17, Momentum: 8.938e-01\n",
      "Initial loss:  3629446.110468284\n",
      "best loss: 1235.77\t\tLearning rate: 3.360e+00, Batch size: 34, Momentum: 5.258e-02\n",
      "Initial loss:  2390522.689603927\n",
      "best loss: 1224.69\t\tLearning rate: 1.129e+00, Batch size: 27, Momentum: 1.577e-01\n",
      "Initial loss:  1780505.7809495563\n",
      "best loss: 1342.39\t\tLearning rate: 3.360e+00, Batch size: 34, Momentum: 3.155e-01\n",
      "Initial loss:  1696173.7913449986\n",
      "best loss: 1360.90\t\tLearning rate: 3.360e+00, Batch size: 44, Momentum: 5.784e-01\n",
      "Initial loss:  4837483.853099796\n",
      "best loss: 957.01\t\tLearning rate: 4.833e-03, Batch size: 44, Momentum: 1.577e-01\n",
      "Initial loss:  1659260.372374529\n",
      "best loss: 517.64\t\tLearning rate: 2.336e-06, Batch size: 29, Momentum: 0.000e+00\n",
      "Initial loss:  1150703.4796312156\n",
      "best loss: 499.31\t\tLearning rate: 2.336e-06, Batch size: 7, Momentum: 5.258e-02\n",
      "Initial loss:  1230042.9562391911\n",
      "best loss: 932.32\t\tLearning rate: 5.456e-04, Batch size: 12, Momentum: 8.413e-01\n",
      "Initial loss:  1413856.825945481\n",
      "best loss: 1293.29\t\tLearning rate: 3.793e-01, Batch size: 4, Momentum: 9.990e-01\n",
      "Initial loss:  1474875.8252609216\n",
      "best loss: 1345.40\t\tLearning rate: 1.129e+00, Batch size: 37, Momentum: 7.361e-01\n",
      "Initial loss:  2456467.0947403447\n",
      "best loss: 498.36\t\tLearning rate: 2.336e-06, Batch size: 22, Momentum: 6.309e-01\n",
      "Initial loss:  1714723.7693287265\n",
      "best loss: 795.74\t\tLearning rate: 6.158e-05, Batch size: 2, Momentum: 8.938e-01\n",
      "Initial loss:  1236084.7236268471\n",
      "best loss: 1383.78\t\tLearning rate: 3.793e-01, Batch size: 47, Momentum: 9.990e-01\n",
      "Initial loss:  1840086.560618703\n",
      "best loss: 759.68\t\tLearning rate: 1.833e-04, Batch size: 39, Momentum: 3.155e-01\n",
      "Initial loss:  2210092.2643895503\n",
      "best loss: 492.84\t\tLearning rate: 7.848e-07, Batch size: 39, Momentum: 7.887e-01\n",
      "Initial loss:  1015899.921668065\n",
      "best loss: 1451.03\t\tLearning rate: 3.360e+00, Batch size: 37, Momentum: 9.464e-01\n",
      "Initial loss:  791907.7278767816\n",
      "best loss: 1302.38\t\tLearning rate: 3.793e-01, Batch size: 19, Momentum: 7.361e-01\n",
      "Initial loss:  1331052.5493295563\n",
      "best loss: 1039.60\t\tLearning rate: 4.833e-03, Batch size: 14, Momentum: 8.938e-01\n",
      "Initial loss:  3854031.0203047227\n",
      "best loss: 1277.45\t\tLearning rate: 3.360e+00, Batch size: 22, Momentum: 5.258e-02\n",
      "Initial loss:  2858838.1243205154\n",
      "best loss: 498.97\t\tLearning rate: 2.336e-06, Batch size: 24, Momentum: 3.681e-01\n",
      "Initial loss:  328805.4831013864\n",
      "best loss: 1159.17\t\tLearning rate: 4.281e-02, Batch size: 42, Momentum: 8.938e-01\n",
      "Initial loss:  653708.7231277102\n",
      "best loss: 1072.63\t\tLearning rate: 4.833e-03, Batch size: 19, Momentum: 7.361e-01\n",
      "Initial loss:  2033889.8864944146\n",
      "best loss: 1504.66\t\tLearning rate: 3.360e+00, Batch size: 17, Momentum: 9.464e-01\n",
      "Initial loss:  1282974.2546063873\n",
      "best loss: 545.13\t\tLearning rate: 2.976e-08, Batch size: 42, Momentum: 7.361e-01\n",
      "Initial loss:  2106240.0991691947\n",
      "best loss: 705.65\t\tLearning rate: 6.158e-05, Batch size: 4, Momentum: 6.835e-01\n",
      "Initial loss:  3267289.97910915\n",
      "best loss: 702.97\t\tLearning rate: 6.158e-05, Batch size: 12, Momentum: 4.732e-01\n",
      "Initial loss:  492.6540496582184\n",
      "best loss: 489.21\t\tLearning rate: 6.158e-05, Batch size: 19, Momentum: 9.464e-01\n",
      "Initial loss:  828056.6772008446\n",
      "best loss: 486.18\t\tLearning rate: 6.952e-06, Batch size: 12, Momentum: 4.732e-01\n",
      "Initial loss:  1365393.795748712\n",
      "best loss: 492.33\t\tLearning rate: 2.336e-06, Batch size: 39, Momentum: 1.577e-01\n",
      "Initial loss:  4866014.258933121\n",
      "best loss: 1095.08\t\tLearning rate: 1.274e-01, Batch size: 12, Momentum: 0.000e+00\n",
      "Initial loss:  2323097.0424405434\n",
      "best loss: 327993.86\t\tLearning rate: 8.859e-08, Batch size: 19, Momentum: 3.155e-01\n",
      "Initial loss:  1458602.4324666292\n",
      "best loss: 617.28\t\tLearning rate: 2.069e-05, Batch size: 27, Momentum: 5.784e-01\n",
      "Initial loss:  2931054.7425637515\n",
      "best loss: 1216.28\t\tLearning rate: 3.793e-01, Batch size: 50, Momentum: 5.258e-02\n",
      "Initial loss:  4208439.441002344\n",
      "best loss: 795.89\t\tLearning rate: 1.833e-04, Batch size: 19, Momentum: 5.258e-01\n",
      "Initial loss:  2879685.5187652335\n",
      "best loss: 496.66\t\tLearning rate: 7.848e-07, Batch size: 22, Momentum: 9.990e-01\n",
      "Initial loss:  1072858.4216149282\n",
      "best loss: 495.17\t\tLearning rate: 2.637e-07, Batch size: 47, Momentum: 7.361e-01\n",
      "Initial loss:  153917.63275051417\n",
      "best loss: 1129.34\t\tLearning rate: 1.274e-01, Batch size: 19, Momentum: 5.258e-01\n",
      "Initial loss:  1819185.431733609\n",
      "best loss: 1317.45\t\tLearning rate: 1.000e+01, Batch size: 22, Momentum: 4.206e-01\n",
      "Initial loss:  3921757.218552368\n",
      "best loss: 491.21\t\tLearning rate: 2.336e-06, Batch size: 7, Momentum: 9.464e-01\n",
      "Initial loss:  1693372.6142668377\n",
      "best loss: 22022.97\t\tLearning rate: 1.000e-08, Batch size: 7, Momentum: 5.258e-02\n",
      "Initial loss:  2802310.3772791447\n",
      "best loss: 552.30\t\tLearning rate: 2.976e-08, Batch size: 32, Momentum: 6.835e-01\n",
      "Initial loss:  1593417.83351584\n",
      "best loss: 495.18\t\tLearning rate: 7.848e-07, Batch size: 42, Momentum: 2.629e-01\n",
      "Initial loss:  1732904.3096448916\n",
      "best loss: 1098.23\t\tLearning rate: 4.833e-03, Batch size: 42, Momentum: 9.990e-01\n",
      "Initial loss:  1683164.7560311505\n",
      "best loss: 1047.55\t\tLearning rate: 4.281e-02, Batch size: 37, Momentum: 3.155e-01\n",
      "Initial loss:  2333941.6605597185\n",
      "best loss: 1190.08\t\tLearning rate: 1.274e-01, Batch size: 4, Momentum: 4.206e-01\n",
      "Initial loss:  2103677.910432652\n",
      "best loss: 735.72\t\tLearning rate: 1.833e-04, Batch size: 14, Momentum: 5.258e-02\n",
      "Initial loss:  1734163.1960291336\n",
      "best loss: 1449.81\t\tLearning rate: 1.000e+01, Batch size: 34, Momentum: 7.887e-01\n",
      "Initial loss:  3715707.976900916\n",
      "best loss: 1299.85\t\tLearning rate: 3.360e+00, Batch size: 39, Momentum: 2.103e-01\n",
      "Initial loss:  1343368.9344230823\n",
      "best loss: 962.52\t\tLearning rate: 4.833e-03, Batch size: 34, Momentum: 9.464e-01\n",
      "Initial loss:  211944.81679845956\n",
      "best loss: 936.06\t\tLearning rate: 1.624e-03, Batch size: 29, Momentum: 4.206e-01\n",
      "Initial loss:  1266656.696598901\n",
      "best loss: 150636.46\t\tLearning rate: 3.793e-01, Batch size: 44, Momentum: 5.258e-01\n",
      "Initial loss:  502.432045614245\n",
      "best loss: 491.32\t\tLearning rate: 1.000e-08, Batch size: 19, Momentum: 0.000e+00\n",
      "Initial loss:  2460249.7954627504\n",
      "best loss: 251304.36\t\tLearning rate: 2.976e-08, Batch size: 9, Momentum: 5.784e-01\n",
      "Initial loss:  2096614.446413166\n",
      "best loss: 614.59\t\tLearning rate: 2.069e-05, Batch size: 17, Momentum: 7.361e-01\n",
      "Initial loss:  2599792.9425668474\n",
      "best loss: 1312.09\t\tLearning rate: 3.360e+00, Batch size: 24, Momentum: 2.103e-01\n",
      "Initial loss:  1500430.4886369312\n",
      "best loss: 549.78\t\tLearning rate: 2.069e-05, Batch size: 42, Momentum: 5.258e-02\n",
      "Initial loss:  3829852.5376904677\n",
      "best loss: 1308.96\t\tLearning rate: 3.360e+00, Batch size: 29, Momentum: 2.103e-01\n",
      "Initial loss:  499.9252043663568\n",
      "best loss: 491.94\t\tLearning rate: 7.848e-07, Batch size: 50, Momentum: 4.732e-01\n",
      "Initial loss:  490463.1584458652\n",
      "best loss: 105576.26\t\tLearning rate: 3.793e-01, Batch size: 19, Momentum: 1.052e-01\n",
      "Initial loss:  1807856.2786134202\n",
      "best loss: 899.65\t\tLearning rate: 1.624e-03, Batch size: 47, Momentum: 0.000e+00\n",
      "Initial loss:  3044767.7448559124\n",
      "best loss: 721.39\t\tLearning rate: 6.158e-05, Batch size: 27, Momentum: 2.103e-01\n",
      "Initial loss:  1715846.5802530928\n",
      "best loss: 838.03\t\tLearning rate: 1.833e-04, Batch size: 7, Momentum: 5.784e-01\n",
      "Initial loss:  1564722.0479617687\n",
      "best loss: 1156.85\t\tLearning rate: 1.274e-01, Batch size: 24, Momentum: 4.206e-01\n",
      "Initial loss:  1923689.5758058624\n",
      "best loss: 1521.57\t\tLearning rate: 1.000e+01, Batch size: 12, Momentum: 9.990e-01\n",
      "Initial loss:  2840660.580174412\n",
      "best loss: 1246.89\t\tLearning rate: 4.281e-02, Batch size: 27, Momentum: 9.464e-01\n",
      "Initial loss:  3964548.182677824\n",
      "best loss: 973.10\t\tLearning rate: 5.456e-04, Batch size: 9, Momentum: 9.464e-01\n",
      "Initial loss:  2141910.1250413256\n",
      "best loss: 490.92\t\tLearning rate: 2.336e-06, Batch size: 19, Momentum: 5.784e-01\n",
      "Initial loss:  1520200.0586244478\n",
      "best loss: 479.99\t\tLearning rate: 2.069e-05, Batch size: 4, Momentum: 2.103e-01\n",
      "Initial loss:  1811229.474787367\n",
      "best loss: 986.78\t\tLearning rate: 1.624e-03, Batch size: 37, Momentum: 6.835e-01\n",
      "Initial loss:  516575.74805247167\n",
      "best loss: 958.27\t\tLearning rate: 4.833e-03, Batch size: 34, Momentum: 1.577e-01\n",
      "Initial loss:  1921184.4822396305\n",
      "best loss: 1451.12\t\tLearning rate: 3.360e+00, Batch size: 22, Momentum: 8.938e-01\n",
      "Initial loss:  506.2655209346117\n",
      "best loss: 490.03\t\tLearning rate: 4.833e-03, Batch size: 32, Momentum: 6.309e-01\n",
      "Initial loss:  494.7447098549419\n",
      "best loss: 485.47\t\tLearning rate: 3.360e+00, Batch size: 9, Momentum: 9.990e-01\n",
      "Initial loss:  1077131.479445607\n",
      "best loss: 960.55\t\tLearning rate: 1.624e-03, Batch size: 9, Momentum: 2.103e-01\n",
      "Initial loss:  3670334.194039095\n",
      "best loss: 1124066.20\t\tLearning rate: 8.859e-08, Batch size: 24, Momentum: 5.258e-02\n",
      "Initial loss:  1295336.5232666552\n",
      "best loss: 841.92\t\tLearning rate: 1.833e-04, Batch size: 29, Momentum: 1.577e-01\n",
      "Initial loss:  945163.1429149267\n",
      "best loss: 1150760.91\t\tLearning rate: 5.456e-04, Batch size: 47, Momentum: 5.258e-02\n",
      "Initial loss:  2146750.6366327377\n",
      "best loss: 648.63\t\tLearning rate: 6.952e-06, Batch size: 4, Momentum: 8.938e-01\n",
      "Initial loss:  944809.5283477249\n",
      "best loss: 499.86\t\tLearning rate: 8.859e-08, Batch size: 19, Momentum: 6.309e-01\n",
      "Initial loss:  1713856.504693207\n",
      "best loss: 1157.98\t\tLearning rate: 4.281e-02, Batch size: 32, Momentum: 7.361e-01\n",
      "Initial loss:  3669097.908987726\n",
      "best loss: 1312.72\t\tLearning rate: 1.129e+00, Batch size: 14, Momentum: 6.309e-01\n",
      "Initial loss:  3229311.0886911815\n",
      "best loss: 445019.06\t\tLearning rate: 8.859e-08, Batch size: 29, Momentum: 7.361e-01\n",
      "Initial loss:  4171874.433121859\n",
      "best loss: 1157.86\t\tLearning rate: 1.274e-01, Batch size: 32, Momentum: 5.784e-01\n",
      "Initial loss:  3599890.3323888634\n",
      "best loss: 963.27\t\tLearning rate: 1.624e-03, Batch size: 50, Momentum: 6.835e-01\n",
      "Initial loss:  233431.41299333452\n",
      "best loss: 1369.09\t\tLearning rate: 3.360e+00, Batch size: 42, Momentum: 4.732e-01\n",
      "Initial loss:  2794006.7197860023\n",
      "best loss: 587.93\t\tLearning rate: 1.000e-08, Batch size: 22, Momentum: 4.206e-01\n",
      "Initial loss:  3423433.767317358\n",
      "best loss: 1007.15\t\tLearning rate: 4.833e-03, Batch size: 2, Momentum: 4.206e-01\n",
      "Initial loss:  1021681.3111477245\n",
      "best loss: 636.21\t\tLearning rate: 8.859e-08, Batch size: 32, Momentum: 1.052e-01\n",
      "Initial loss:  1227486.821993257\n",
      "best loss: 492.34\t\tLearning rate: 7.848e-07, Batch size: 4, Momentum: 0.000e+00\n",
      "Initial loss:  416524.1532912387\n",
      "best loss: 1178.20\t\tLearning rate: 1.438e-02, Batch size: 42, Momentum: 8.938e-01\n",
      "Initial loss:  2467340.8502769303\n",
      "best loss: 658212.54\t\tLearning rate: 1.274e-01, Batch size: 12, Momentum: 0.000e+00\n",
      "Initial loss:  4096709.2286024746\n",
      "best loss: 1136.13\t\tLearning rate: 1.274e-01, Batch size: 44, Momentum: 2.629e-01\n",
      "Initial loss:  3066506.722865966\n",
      "best loss: 964.59\t\tLearning rate: 1.624e-03, Batch size: 14, Momentum: 4.206e-01\n",
      "Initial loss:  1251695.1454610424\n",
      "best loss: 797.16\t\tLearning rate: 1.833e-04, Batch size: 17, Momentum: 5.784e-01\n",
      "Initial loss:  1155686.716375553\n",
      "best loss: 1375.23\t\tLearning rate: 1.000e+01, Batch size: 24, Momentum: 4.732e-01\n",
      "Initial loss:  1087039.5835404661\n",
      "best loss: 650.63\t\tLearning rate: 6.158e-05, Batch size: 4, Momentum: 4.206e-01\n",
      "Initial loss:  735278.7496168737\n",
      "best loss: 918.42\t\tLearning rate: 1.624e-03, Batch size: 27, Momentum: 5.258e-01\n",
      "Initial loss:  2255034.6515952735\n",
      "best loss: 901.42\t\tLearning rate: 1.624e-03, Batch size: 2, Momentum: 4.206e-01\n",
      "Initial loss:  1840715.667200298\n",
      "best loss: 817.52\t\tLearning rate: 1.833e-04, Batch size: 9, Momentum: 5.784e-01\n",
      "Initial loss:  1164409.3569242596\n",
      "best loss: 1276.49\t\tLearning rate: 3.793e-01, Batch size: 44, Momentum: 5.258e-01\n",
      "Initial loss:  1343806.6811489959\n",
      "best loss: 502.66\t\tLearning rate: 2.637e-07, Batch size: 37, Momentum: 5.258e-01\n",
      "Initial loss:  2220998.6316847904\n",
      "best loss: 1217.33\t\tLearning rate: 3.793e-01, Batch size: 24, Momentum: 2.629e-01\n",
      "Initial loss:  2062552.0269764236\n",
      "best loss: 1260.21\t\tLearning rate: 1.129e+00, Batch size: 50, Momentum: 2.103e-01\n",
      "Initial loss:  1950697.0073280446\n",
      "best loss: 1242.56\t\tLearning rate: 3.793e-01, Batch size: 29, Momentum: 5.784e-01\n",
      "Initial loss:  1114353.727950361\n",
      "best loss: 1502.49\t\tLearning rate: 1.000e+01, Batch size: 32, Momentum: 9.464e-01\n",
      "Initial loss:  3961352.022169564\n",
      "best loss: 1236.57\t\tLearning rate: 1.129e+00, Batch size: 44, Momentum: 0.000e+00\n",
      "Initial loss:  3023026.5421546865\n",
      "best loss: 495.16\t\tLearning rate: 7.848e-07, Batch size: 50, Momentum: 9.464e-01\n",
      "Initial loss:  4198850.308547471\n",
      "best loss: 912.64\t\tLearning rate: 5.456e-04, Batch size: 32, Momentum: 6.835e-01\n",
      "Initial loss:  496.5487095872574\n",
      "best loss: 491.09\t\tLearning rate: 6.158e-05, Batch size: 27, Momentum: 4.206e-01\n",
      "Initial loss:  1007533.3430338835\n",
      "best loss: 508.50\t\tLearning rate: 8.859e-08, Batch size: 12, Momentum: 7.361e-01\n",
      "Initial loss:  2512631.95252277\n",
      "best loss: 1409.26\t\tLearning rate: 3.360e+00, Batch size: 47, Momentum: 8.938e-01\n",
      "Initial loss:  1118621.1503590923\n",
      "best loss: 499.39\t\tLearning rate: 7.848e-07, Batch size: 42, Momentum: 5.258e-01\n",
      "Initial loss:  1095593.7304991789\n",
      "best loss: 1905.81\t\tLearning rate: 1.000e-08, Batch size: 22, Momentum: 2.103e-01\n",
      "Initial loss:  3662879.5399523186\n",
      "best loss: 647.04\t\tLearning rate: 6.158e-05, Batch size: 27, Momentum: 1.577e-01\n",
      "Initial loss:  2430548.635666249\n",
      "best loss: 504.59\t\tLearning rate: 2.637e-07, Batch size: 39, Momentum: 4.732e-01\n",
      "Initial loss:  498.10785649319627\n",
      "best loss: 491.85\t\tLearning rate: 2.976e-08, Batch size: 37, Momentum: 1.052e-01\n",
      "Initial loss:  1763190.9315908875\n",
      "best loss: 498.63\t\tLearning rate: 6.952e-06, Batch size: 34, Momentum: 5.784e-01\n",
      "Initial loss:  827208.0101368391\n",
      "best loss: 84903.55\t\tLearning rate: 3.793e-01, Batch size: 14, Momentum: 1.052e-01\n",
      "Initial loss:  2020560.9743432472\n",
      "best loss: 1119.68\t\tLearning rate: 4.281e-02, Batch size: 9, Momentum: 5.784e-01\n",
      "Initial loss:  1890232.2938107532\n",
      "best loss: 534910.87\t\tLearning rate: 8.859e-08, Batch size: 32, Momentum: 3.681e-01\n",
      "Initial loss:  698188.8590037844\n",
      "best loss: 1229.31\t\tLearning rate: 3.793e-01, Batch size: 39, Momentum: 4.206e-01\n",
      "Initial loss:  2897310.84349728\n",
      "best loss: 859.31\t\tLearning rate: 5.456e-04, Batch size: 12, Momentum: 4.206e-01\n",
      "Initial loss:  3690729.187897588\n",
      "best loss: 1146.79\t\tLearning rate: 1.274e-01, Batch size: 29, Momentum: 2.103e-01\n",
      "Initial loss:  913439.4036853699\n",
      "best loss: 728.12\t\tLearning rate: 1.833e-04, Batch size: 14, Momentum: 1.052e-01\n",
      "Initial loss:  5932446.698221541\n",
      "best loss: 516.70\t\tLearning rate: 2.069e-05, Batch size: 4, Momentum: 2.629e-01\n",
      "Initial loss:  3002936.9549269215\n",
      "best loss: 662.00\t\tLearning rate: 2.069e-05, Batch size: 7, Momentum: 8.413e-01\n",
      "Initial loss:  1334524.8927702303\n",
      "best loss: 505.54\t\tLearning rate: 2.336e-06, Batch size: 39, Momentum: 1.052e-01\n",
      "Initial loss:  477635.5749359001\n",
      "best loss: 1094.53\t\tLearning rate: 4.281e-02, Batch size: 27, Momentum: 3.681e-01\n",
      "Initial loss:  1948890.6492513479\n",
      "best loss: 950.92\t\tLearning rate: 4.833e-03, Batch size: 50, Momentum: 4.732e-01\n",
      "Initial loss:  1356784.035520824\n",
      "best loss: 782.43\t\tLearning rate: 1.833e-04, Batch size: 47, Momentum: 4.206e-01\n",
      "Initial loss:  851897.4904929955\n",
      "best loss: 731.71\t\tLearning rate: 2.069e-05, Batch size: 39, Momentum: 5.258e-01\n",
      "Initial loss:  1153944.3998141112\n",
      "best loss: 1445.14\t\tLearning rate: 3.360e+00, Batch size: 24, Momentum: 9.464e-01\n",
      "Initial loss:  1629432.9330373001\n",
      "best loss: 255990.31\t\tLearning rate: 8.859e-08, Batch size: 4, Momentum: 3.155e-01\n",
      "Initial loss:  923939.8397532944\n",
      "best loss: 499.68\t\tLearning rate: 2.976e-08, Batch size: 12, Momentum: 8.938e-01\n",
      "Initial loss:  2487428.9252857445\n",
      "best loss: 395537.29\t\tLearning rate: 8.859e-08, Batch size: 24, Momentum: 7.361e-01\n",
      "Initial loss:  1947417.380412891\n",
      "best loss: 1244.60\t\tLearning rate: 1.129e+00, Batch size: 34, Momentum: 3.681e-01\n",
      "Initial loss:  1578919.4603190054\n",
      "best loss: 1146.96\t\tLearning rate: 1.274e-01, Batch size: 27, Momentum: 8.413e-01\n",
      "Initial loss:  3094743.5496381274\n",
      "best loss: 971.12\t\tLearning rate: 4.833e-03, Batch size: 2, Momentum: 2.103e-01\n",
      "Initial loss:  1893799.0644710385\n",
      "best loss: 1211.29\t\tLearning rate: 3.793e-01, Batch size: 32, Momentum: 5.784e-01\n",
      "Initial loss:  3915130.3073266856\n",
      "best loss: 718845.86\t\tLearning rate: 2.637e-07, Batch size: 27, Momentum: 2.629e-01\n",
      "Initial loss:  1875715.9249220963\n",
      "best loss: 799.05\t\tLearning rate: 6.158e-05, Batch size: 29, Momentum: 3.681e-01\n",
      "Initial loss:  1611697.123689734\n",
      "best loss: 663.62\t\tLearning rate: 2.976e-08, Batch size: 22, Momentum: 3.155e-01\n",
      "Initial loss:  2607257.268263119\n",
      "best loss: 791.44\t\tLearning rate: 1.833e-04, Batch size: 44, Momentum: 7.887e-01\n",
      "Initial loss:  2490909.605073619\n",
      "best loss: 515.29\t\tLearning rate: 8.859e-08, Batch size: 34, Momentum: 7.361e-01\n",
      "Initial loss:  1095956.1794528377\n",
      "best loss: 1289.76\t\tLearning rate: 1.129e+00, Batch size: 9, Momentum: 6.835e-01\n",
      "Initial loss:  3357347.6209024847\n",
      "best loss: 1298.21\t\tLearning rate: 1.129e+00, Batch size: 9, Momentum: 4.732e-01\n",
      "Initial loss:  2110504.5890953885\n",
      "best loss: 1019.35\t\tLearning rate: 1.624e-03, Batch size: 9, Momentum: 9.464e-01\n",
      "Initial loss:  454278.05177192175\n",
      "best loss: 533.76\t\tLearning rate: 2.976e-08, Batch size: 27, Momentum: 7.361e-01\n",
      "Initial loss:  1891053.6602792428\n",
      "best loss: 821.93\t\tLearning rate: 5.456e-04, Batch size: 19, Momentum: 0.000e+00\n",
      "Initial loss:  2694841.972687234\n",
      "best loss: 532.89\t\tLearning rate: 2.637e-07, Batch size: 42, Momentum: 3.155e-01\n",
      "Initial loss:  924820.2640039924\n",
      "best loss: 1102.92\t\tLearning rate: 4.281e-02, Batch size: 42, Momentum: 3.681e-01\n",
      "Initial loss:  2216271.7434591637\n",
      "best loss: 479.51\t\tLearning rate: 6.952e-06, Batch size: 2, Momentum: 5.258e-01\n",
      "Initial loss:  891424.675194655\n",
      "best loss: 1268.48\t\tLearning rate: 3.793e-01, Batch size: 22, Momentum: 8.413e-01\n",
      "Initial loss:  751283.768881575\n",
      "best loss: 545.94\t\tLearning rate: 1.000e-08, Batch size: 7, Momentum: 5.784e-01\n",
      "Initial loss:  1666418.6333803087\n",
      "best loss: 1069532.20\t\tLearning rate: 1.000e-08, Batch size: 39, Momentum: 6.309e-01\n",
      "Initial loss:  2301739.0433869464\n",
      "best loss: 510.35\t\tLearning rate: 6.952e-06, Batch size: 42, Momentum: 9.464e-01\n",
      "Initial loss:  511.6087268981868\n",
      "best loss: 492.92\t\tLearning rate: 1.274e-01, Batch size: 12, Momentum: 4.732e-01\n",
      "Initial loss:  510.7743700999954\n",
      "best loss: 489.26\t\tLearning rate: 7.848e-07, Batch size: 12, Momentum: 1.577e-01\n",
      "Initial loss:  1442282.0224986242\n",
      "best loss: 482.99\t\tLearning rate: 2.336e-06, Batch size: 7, Momentum: 7.361e-01\n",
      "Initial loss:  593109.9203158745\n",
      "best loss: 499.67\t\tLearning rate: 2.069e-05, Batch size: 9, Momentum: 8.938e-01\n",
      "Initial loss:  2037123.647956636\n",
      "best loss: 932.12\t\tLearning rate: 4.833e-03, Batch size: 17, Momentum: 2.629e-01\n",
      "Initial loss:  1312336.5312191164\n",
      "best loss: 955.67\t\tLearning rate: 5.456e-04, Batch size: 2, Momentum: 8.938e-01\n",
      "Initial loss:  476962.1499859548\n",
      "best loss: 526.48\t\tLearning rate: 1.000e-08, Batch size: 19, Momentum: 7.361e-01\n",
      "Initial loss:  1320734.3050192236\n",
      "best loss: 365888.54\t\tLearning rate: 8.859e-08, Batch size: 32, Momentum: 5.258e-01\n",
      "Initial loss:  3011397.512770146\n",
      "best loss: 1408.38\t\tLearning rate: 1.000e+01, Batch size: 19, Momentum: 4.206e-01\n",
      "Initial loss:  2456535.0846207226\n",
      "best loss: 1152.19\t\tLearning rate: 1.274e-01, Batch size: 24, Momentum: 2.103e-01\n",
      "Initial loss:  1723185.710737098\n",
      "best loss: 675.04\t\tLearning rate: 8.859e-08, Batch size: 19, Momentum: 5.784e-01\n",
      "Initial loss:  3700169.793026322\n",
      "best loss: 1831625.18\t\tLearning rate: 2.637e-07, Batch size: 34, Momentum: 3.155e-01\n",
      "Initial loss:  525363.6838755665\n",
      "best loss: 606.98\t\tLearning rate: 1.000e-08, Batch size: 14, Momentum: 4.732e-01\n",
      "Initial loss:  1857896.448299714\n",
      "best loss: 488.87\t\tLearning rate: 7.848e-07, Batch size: 12, Momentum: 9.464e-01\n",
      "Initial loss:  497.34780120904884\n",
      "best loss: 488.88\t\tLearning rate: 5.456e-04, Batch size: 42, Momentum: 3.155e-01\n",
      "Initial loss:  1280887.7815878289\n",
      "best loss: 1170.31\t\tLearning rate: 1.274e-01, Batch size: 22, Momentum: 3.681e-01\n",
      "Initial loss:  1337798.7945664548\n",
      "best loss: 1167.98\t\tLearning rate: 4.281e-02, Batch size: 39, Momentum: 7.887e-01\n",
      "Initial loss:  498.2254384660385\n",
      "best loss: 489.17\t\tLearning rate: 2.637e-07, Batch size: 24, Momentum: 9.464e-01\n",
      "Initial loss:  2270036.4337495756\n",
      "best loss: 1161.78\t\tLearning rate: 4.281e-02, Batch size: 44, Momentum: 5.784e-01\n",
      "Initial loss:  2680485.4616810502\n",
      "best loss: 1388.56\t\tLearning rate: 3.360e+00, Batch size: 19, Momentum: 3.155e-01\n",
      "Initial loss:  1146024.3092442984\n",
      "best loss: 601.98\t\tLearning rate: 6.952e-06, Batch size: 24, Momentum: 8.938e-01\n",
      "Initial loss:  662247.2795964781\n",
      "best loss: 484.13\t\tLearning rate: 8.859e-08, Batch size: 2, Momentum: 3.155e-01\n",
      "Initial loss:  2697587.8091647727\n",
      "best loss: 531.66\t\tLearning rate: 2.976e-08, Batch size: 44, Momentum: 3.155e-01\n",
      "Initial loss:  1986592.6914719006\n",
      "best loss: 553.37\t\tLearning rate: 1.000e-08, Batch size: 17, Momentum: 7.887e-01\n",
      "Initial loss:  2718624.4184923274\n",
      "best loss: 1046.72\t\tLearning rate: 1.438e-02, Batch size: 44, Momentum: 2.629e-01\n",
      "Initial loss:  1468411.5302721271\n",
      "best loss: 742.70\t\tLearning rate: 1.833e-04, Batch size: 22, Momentum: 0.000e+00\n",
      "Initial loss:  5452916.9497391945\n",
      "best loss: 873.62\t\tLearning rate: 5.456e-04, Batch size: 47, Momentum: 5.258e-01\n",
      "Initial loss:  3336969.104866773\n",
      "best loss: 1074.98\t\tLearning rate: 4.833e-03, Batch size: 27, Momentum: 9.990e-01\n",
      "Initial loss:  4537382.341550028\n",
      "best loss: 812.71\t\tLearning rate: 5.456e-04, Batch size: 29, Momentum: 5.258e-02\n",
      "Initial loss:  2006399.086841918\n",
      "best loss: 1435.78\t\tLearning rate: 3.360e+00, Batch size: 12, Momentum: 7.887e-01\n",
      "Initial loss:  1838751.5453528976\n",
      "best loss: 688.63\t\tLearning rate: 6.158e-05, Batch size: 47, Momentum: 3.681e-01\n",
      "Initial loss:  1334704.7386898287\n",
      "best loss: 1278.91\t\tLearning rate: 3.360e+00, Batch size: 32, Momentum: 0.000e+00\n",
      "Initial loss:  2893277.318853985\n",
      "best loss: 1144.65\t\tLearning rate: 1.274e-01, Batch size: 22, Momentum: 2.103e-01\n",
      "Initial loss:  1297925.3390208073\n",
      "best loss: 885.25\t\tLearning rate: 5.456e-04, Batch size: 27, Momentum: 7.887e-01\n",
      "Initial loss:  1219295.0302541896\n",
      "best loss: 485.23\t\tLearning rate: 2.336e-06, Batch size: 9, Momentum: 2.629e-01\n",
      "Initial loss:  1852554.0295419223\n",
      "best loss: 598.58\t\tLearning rate: 2.976e-08, Batch size: 24, Momentum: 7.361e-01\n",
      "Initial loss:  1121086.7695347206\n",
      "best loss: 1242.48\t\tLearning rate: 3.360e+00, Batch size: 32, Momentum: 5.258e-02\n",
      "Initial loss:  1434466.4055998917\n",
      "best loss: 1053.51\t\tLearning rate: 1.438e-02, Batch size: 37, Momentum: 5.784e-01\n",
      "Initial loss:  2000593.8477944923\n",
      "best loss: 1036.63\t\tLearning rate: 1.624e-03, Batch size: 42, Momentum: 7.361e-01\n",
      "Initial loss:  1142899.8328204558\n",
      "best loss: 1119.96\t\tLearning rate: 1.274e-01, Batch size: 29, Momentum: 9.990e-01\n",
      "Initial loss:  1487828.6859257375\n",
      "best loss: 821176.86\t\tLearning rate: 8.859e-08, Batch size: 17, Momentum: 5.784e-01\n",
      "Initial loss:  501.7616291804299\n",
      "best loss: 484.71\t\tLearning rate: 2.637e-07, Batch size: 9, Momentum: 8.938e-01\n",
      "Initial loss:  887924.4832312042\n",
      "best loss: 861.83\t\tLearning rate: 5.456e-04, Batch size: 4, Momentum: 2.103e-01\n",
      "Initial loss:  247910.1018874201\n",
      "best loss: 493.91\t\tLearning rate: 6.952e-06, Batch size: 4, Momentum: 8.938e-01\n",
      "Initial loss:  1148187.436990661\n",
      "best loss: 1219.96\t\tLearning rate: 3.793e-01, Batch size: 32, Momentum: 3.681e-01\n",
      "Initial loss:  489.7070861957491\n",
      "best loss: 486.91\t\tLearning rate: 1.129e+00, Batch size: 9, Momentum: 2.629e-01\n",
      "Initial loss:  3474399.124724716\n",
      "best loss: 950.80\t\tLearning rate: 5.456e-04, Batch size: 4, Momentum: 4.206e-01\n",
      "Initial loss:  1576313.8936238554\n",
      "best loss: 1218.35\t\tLearning rate: 4.281e-02, Batch size: 42, Momentum: 9.464e-01\n",
      "Initial loss:  1297343.2441541422\n",
      "best loss: 958.15\t\tLearning rate: 1.624e-03, Batch size: 37, Momentum: 5.258e-01\n",
      "Initial loss:  1534228.227845244\n",
      "best loss: 1190.25\t\tLearning rate: 1.274e-01, Batch size: 44, Momentum: 4.206e-01\n",
      "Initial loss:  2198781.554512148\n",
      "best loss: 608.22\t\tLearning rate: 7.848e-07, Batch size: 44, Momentum: 2.103e-01\n",
      "Initial loss:  618297.4477039204\n",
      "best loss: 497.36\t\tLearning rate: 2.637e-07, Batch size: 47, Momentum: 8.938e-01\n",
      "Initial loss:  1442529.6731549967\n",
      "best loss: 513.84\t\tLearning rate: 7.848e-07, Batch size: 39, Momentum: 2.629e-01\n",
      "Initial loss:  799560.1978058275\n",
      "best loss: 1094.52\t\tLearning rate: 1.274e-01, Batch size: 17, Momentum: 1.052e-01\n",
      "Initial loss:  732691.8734364422\n",
      "best loss: 1068.92\t\tLearning rate: 1.438e-02, Batch size: 50, Momentum: 6.835e-01\n",
      "Initial loss:  2209893.8201812836\n",
      "best loss: 583.01\t\tLearning rate: 6.952e-06, Batch size: 29, Momentum: 8.413e-01\n",
      "Initial loss:  3130519.8313945374\n",
      "best loss: 691.03\t\tLearning rate: 8.859e-08, Batch size: 24, Momentum: 3.155e-01\n",
      "Initial loss:  1226334.2594162931\n",
      "best loss: 491.82\t\tLearning rate: 1.000e-08, Batch size: 44, Momentum: 9.990e-01\n",
      "Initial loss:  2651640.1038230527\n",
      "best loss: 1153.16\t\tLearning rate: 3.793e-01, Batch size: 2, Momentum: 1.577e-01\n",
      "Initial loss:  393631.35995384306\n",
      "best loss: 1363.72\t\tLearning rate: 3.793e-01, Batch size: 34, Momentum: 9.990e-01\n",
      "Initial loss:  735074.278489702\n",
      "best loss: 737.72\t\tLearning rate: 6.158e-05, Batch size: 44, Momentum: 4.732e-01\n",
      "Initial loss:  1691536.2174186606\n",
      "best loss: 491.23\t\tLearning rate: 7.848e-07, Batch size: 19, Momentum: 5.258e-01\n",
      "Initial loss:  2407152.8260355424\n",
      "best loss: 663.93\t\tLearning rate: 6.158e-05, Batch size: 19, Momentum: 1.577e-01\n",
      "Initial loss:  623362.4319882089\n",
      "best loss: 894.59\t\tLearning rate: 1.624e-03, Batch size: 19, Momentum: 1.577e-01\n",
      "Initial loss:  1407261.8767396123\n",
      "best loss: 501.98\t\tLearning rate: 6.952e-06, Batch size: 14, Momentum: 5.784e-01\n",
      "Initial loss:  3601771.973383591\n",
      "best loss: 1483796.27\t\tLearning rate: 8.859e-08, Batch size: 29, Momentum: 6.835e-01\n",
      "Initial loss:  1160822.994425947\n",
      "best loss: 510.06\t\tLearning rate: 1.000e-08, Batch size: 24, Momentum: 9.464e-01\n",
      "Initial loss:  2197028.225802355\n",
      "best loss: 668.22\t\tLearning rate: 6.158e-05, Batch size: 37, Momentum: 4.206e-01\n",
      "Initial loss:  962705.3241501293\n",
      "best loss: 1204.21\t\tLearning rate: 3.793e-01, Batch size: 39, Momentum: 1.052e-01\n",
      "Initial loss:  1896352.8753539615\n",
      "best loss: 1193.10\t\tLearning rate: 1.274e-01, Batch size: 12, Momentum: 1.577e-01\n",
      "Initial loss:  1031873.0332093589\n",
      "best loss: 524.93\t\tLearning rate: 2.637e-07, Batch size: 37, Momentum: 6.835e-01\n",
      "Initial loss:  1155977.5415175378\n",
      "best loss: 493.72\t\tLearning rate: 6.952e-06, Batch size: 44, Momentum: 1.052e-01\n",
      "Initial loss:  996889.5624347301\n",
      "best loss: 122067.13\t\tLearning rate: 7.848e-07, Batch size: 50, Momentum: 6.835e-01\n",
      "Initial loss:  2093805.3279360349\n",
      "best loss: 492.06\t\tLearning rate: 2.336e-06, Batch size: 32, Momentum: 4.732e-01\n",
      "Initial loss:  3785120.530984503\n",
      "best loss: 1016.17\t\tLearning rate: 1.438e-02, Batch size: 50, Momentum: 2.629e-01\n",
      "Initial loss:  1034076.7485089672\n",
      "best loss: 84522.16\t\tLearning rate: 1.000e-08, Batch size: 12, Momentum: 6.309e-01\n",
      "Initial loss:  1791263.6108375133\n",
      "best loss: 186338.04\t\tLearning rate: 1.000e-08, Batch size: 29, Momentum: 6.835e-01\n",
      "Initial loss:  485473.1331342866\n",
      "best loss: 506.28\t\tLearning rate: 6.952e-06, Batch size: 34, Momentum: 0.000e+00\n",
      "Initial loss:  3413910.366504351\n",
      "best loss: 1132.98\t\tLearning rate: 4.281e-02, Batch size: 50, Momentum: 5.784e-01\n",
      "Initial loss:  3226798.7705181018\n",
      "best loss: 1416.20\t\tLearning rate: 1.000e+01, Batch size: 37, Momentum: 6.835e-01\n",
      "Initial loss:  1624432.8178413536\n",
      "best loss: 573.94\t\tLearning rate: 2.069e-05, Batch size: 17, Momentum: 5.258e-02\n",
      "Initial loss:  696694.3726329111\n",
      "best loss: 818.73\t\tLearning rate: 5.456e-04, Batch size: 14, Momentum: 0.000e+00\n",
      "Initial loss:  218567.74412645993\n",
      "best loss: 893.68\t\tLearning rate: 1.833e-04, Batch size: 24, Momentum: 9.990e-01\n",
      "Initial loss:  3907321.424172049\n",
      "best loss: 1391.48\t\tLearning rate: 3.360e+00, Batch size: 39, Momentum: 6.835e-01\n",
      "Initial loss:  1103084.8687616799\n",
      "best loss: 285677.46\t\tLearning rate: 1.000e-08, Batch size: 17, Momentum: 9.464e-01\n",
      "Initial loss:  4281941.831111929\n",
      "best loss: 1179.49\t\tLearning rate: 1.274e-01, Batch size: 39, Momentum: 4.206e-01\n",
      "Initial loss:  902228.4127320787\n",
      "best loss: 1170.50\t\tLearning rate: 1.274e-01, Batch size: 27, Momentum: 5.258e-01\n",
      "Initial loss:  1733936.2721693362\n",
      "best loss: 714.22\t\tLearning rate: 2.069e-05, Batch size: 4, Momentum: 7.887e-01\n",
      "Initial loss:  1353157.8182741054\n",
      "best loss: 1152.86\t\tLearning rate: 3.793e-01, Batch size: 42, Momentum: 2.103e-01\n",
      "Initial loss:  1780870.5037501783\n",
      "best loss: 1211.88\t\tLearning rate: 1.129e+00, Batch size: 7, Momentum: 5.258e-02\n",
      "Initial loss:  511.2906401703246\n",
      "best loss: 493.82\t\tLearning rate: 4.833e-03, Batch size: 19, Momentum: 1.052e-01\n",
      "Initial loss:  3116794.353122624\n",
      "best loss: 1366.18\t\tLearning rate: 1.129e+00, Batch size: 34, Momentum: 9.464e-01\n",
      "Initial loss:  3509148.1915976894\n",
      "best loss: 492.90\t\tLearning rate: 7.848e-07, Batch size: 12, Momentum: 2.629e-01\n",
      "Initial loss:  1074903.039161598\n",
      "best loss: 239135.01\t\tLearning rate: 2.976e-08, Batch size: 44, Momentum: 1.052e-01\n",
      "Initial loss:  1018770.2230723694\n",
      "best loss: 766.83\t\tLearning rate: 1.833e-04, Batch size: 7, Momentum: 2.103e-01\n",
      "Initial loss:  3266580.4329942614\n",
      "best loss: 1211.45\t\tLearning rate: 3.793e-01, Batch size: 4, Momentum: 5.258e-01\n",
      "Initial loss:  2954457.013012471\n",
      "best loss: 1312.35\t\tLearning rate: 3.360e+00, Batch size: 47, Momentum: 5.258e-02\n",
      "Initial loss:  2661087.1780021577\n",
      "best loss: 1046.14\t\tLearning rate: 4.281e-02, Batch size: 14, Momentum: 5.258e-02\n",
      "Initial loss:  2540773.9715923327\n",
      "best loss: 543.36\t\tLearning rate: 2.637e-07, Batch size: 17, Momentum: 5.258e-01\n",
      "Initial loss:  800725.2524471035\n",
      "best loss: 489.87\t\tLearning rate: 6.952e-06, Batch size: 27, Momentum: 0.000e+00\n",
      "Initial loss:  484683.2236012896\n",
      "best loss: 491.21\t\tLearning rate: 2.336e-06, Batch size: 44, Momentum: 7.361e-01\n",
      "Initial loss:  1413184.4465706244\n",
      "best loss: 1126.77\t\tLearning rate: 4.281e-02, Batch size: 27, Momentum: 7.887e-01\n",
      "Initial loss:  497.88836433877725\n",
      "best loss: 484.52\t\tLearning rate: 7.848e-07, Batch size: 12, Momentum: 2.629e-01\n",
      "Initial loss:  2253064.525945966\n",
      "best loss: 1388.51\t\tLearning rate: 1.129e+00, Batch size: 27, Momentum: 7.361e-01\n",
      "Initial loss:  2040807.3218531795\n",
      "best loss: 985.93\t\tLearning rate: 2.976e-08, Batch size: 32, Momentum: 2.103e-01\n",
      "Initial loss:  2666834.3718140586\n",
      "best loss: 1026.73\t\tLearning rate: 4.833e-03, Batch size: 44, Momentum: 8.938e-01\n",
      "Initial loss:  2641914.2120733117\n",
      "best loss: 1244.31\t\tLearning rate: 3.793e-01, Batch size: 27, Momentum: 2.103e-01\n",
      "Initial loss:  499.94668503210505\n",
      "best loss: 489.06\t\tLearning rate: 6.158e-05, Batch size: 27, Momentum: 2.629e-01\n",
      "Initial loss:  667454.3727867529\n",
      "best loss: 1159.31\t\tLearning rate: 3.793e-01, Batch size: 2, Momentum: 5.258e-02\n",
      "Initial loss:  2785981.810631329\n",
      "best loss: 1409.39\t\tLearning rate: 3.360e+00, Batch size: 42, Momentum: 6.835e-01\n",
      "Initial loss:  3718140.9465357745\n",
      "best loss: 1120.01\t\tLearning rate: 4.281e-02, Batch size: 44, Momentum: 1.577e-01\n",
      "Initial loss:  2711901.4146609497\n",
      "best loss: 1213.10\t\tLearning rate: 1.274e-01, Batch size: 22, Momentum: 6.309e-01\n",
      "Initial loss:  1888563.25307131\n",
      "best loss: 723.07\t\tLearning rate: 6.158e-05, Batch size: 12, Momentum: 6.835e-01\n",
      "Initial loss:  1557097.3683110008\n",
      "best loss: 497.04\t\tLearning rate: 2.976e-08, Batch size: 44, Momentum: 9.464e-01\n",
      "Initial loss:  1125851.3803112472\n",
      "best loss: 963.63\t\tLearning rate: 4.833e-03, Batch size: 19, Momentum: 2.103e-01\n",
      "Initial loss:  3024846.9742308916\n",
      "best loss: 499.02\t\tLearning rate: 6.952e-06, Batch size: 27, Momentum: 2.629e-01\n",
      "Initial loss:  318694.88780072436\n",
      "best loss: 1249.18\t\tLearning rate: 1.129e+00, Batch size: 22, Momentum: 2.629e-01\n",
      "Initial loss:  3231609.5534895295\n",
      "best loss: 1229.33\t\tLearning rate: 3.793e-01, Batch size: 37, Momentum: 1.577e-01\n",
      "Initial loss:  942909.327307927\n",
      "best loss: 1460.99\t\tLearning rate: 1.000e+01, Batch size: 7, Momentum: 6.835e-01\n",
      "Initial loss:  1267182.2825473733\n",
      "best loss: 807.55\t\tLearning rate: 1.833e-04, Batch size: 22, Momentum: 4.206e-01\n",
      "Initial loss:  2968376.7547204564\n",
      "best loss: 909.75\t\tLearning rate: 1.624e-03, Batch size: 47, Momentum: 1.577e-01\n",
      "Initial loss:  612999.9258094692\n",
      "best loss: 699.76\t\tLearning rate: 2.069e-05, Batch size: 2, Momentum: 9.464e-01\n",
      "Initial loss:  1301435.979947515\n",
      "best loss: 1290.25\t\tLearning rate: 1.274e-01, Batch size: 17, Momentum: 9.990e-01\n",
      "Initial loss:  2147367.200579802\n",
      "best loss: 489.53\t\tLearning rate: 6.952e-06, Batch size: 17, Momentum: 2.629e-01\n",
      "Initial loss:  869675.7292233928\n",
      "best loss: 522.34\t\tLearning rate: 2.637e-07, Batch size: 22, Momentum: 5.258e-02\n",
      "Initial loss:  497.0727086793271\n",
      "best loss: 489.07\t\tLearning rate: 5.456e-04, Batch size: 32, Momentum: 5.258e-02\n",
      "Initial loss:  388392.55314777466\n",
      "best loss: 1387.28\t\tLearning rate: 1.000e+01, Batch size: 39, Momentum: 5.258e-01\n",
      "Initial loss:  1105453.110352004\n",
      "best loss: 667.27\t\tLearning rate: 6.158e-05, Batch size: 37, Momentum: 1.577e-01\n",
      "Initial loss:  1995683.0284843238\n",
      "best loss: 662.51\t\tLearning rate: 2.069e-05, Batch size: 42, Momentum: 7.887e-01\n",
      "Initial loss:  873803.419590718\n",
      "best loss: 659.16\t\tLearning rate: 6.158e-05, Batch size: 37, Momentum: 1.052e-01\n",
      "Initial loss:  977042.911440999\n",
      "best loss: 533.81\t\tLearning rate: 2.637e-07, Batch size: 19, Momentum: 3.155e-01\n",
      "Initial loss:  464742.04040716885\n",
      "best loss: 995.87\t\tLearning rate: 1.624e-03, Batch size: 44, Momentum: 5.784e-01\n",
      "Initial loss:  2303718.1378511833\n",
      "best loss: 801.94\t\tLearning rate: 2.637e-07, Batch size: 32, Momentum: 5.258e-02\n",
      "Initial loss:  1416531.9813304604\n",
      "best loss: 494.23\t\tLearning rate: 2.637e-07, Batch size: 24, Momentum: 5.258e-01\n",
      "Initial loss:  344781.72573597037\n",
      "best loss: 816.31\t\tLearning rate: 5.456e-04, Batch size: 12, Momentum: 0.000e+00\n",
      "Initial loss:  1213922.8603462707\n",
      "best loss: 593.60\t\tLearning rate: 2.069e-05, Batch size: 4, Momentum: 2.103e-01\n",
      "Initial loss:  3644754.1948616323\n",
      "best loss: 499961.58\t\tLearning rate: 1.000e-08, Batch size: 29, Momentum: 9.990e-01\n",
      "Initial loss:  730528.347531668\n",
      "best loss: 937.10\t\tLearning rate: 5.456e-04, Batch size: 34, Momentum: 6.835e-01\n",
      "Initial loss:  1200606.9314883777\n",
      "best loss: 1166.72\t\tLearning rate: 1.438e-02, Batch size: 9, Momentum: 9.464e-01\n",
      "Initial loss:  3755934.3066096865\n",
      "best loss: 676440.94\t\tLearning rate: 2.637e-07, Batch size: 47, Momentum: 6.309e-01\n",
      "Initial loss:  1009628.14552065\n",
      "best loss: 895.26\t\tLearning rate: 1.624e-03, Batch size: 4, Momentum: 1.577e-01\n",
      "Initial loss:  989578.8815583277\n",
      "best loss: 587.87\t\tLearning rate: 1.000e-08, Batch size: 14, Momentum: 7.361e-01\n",
      "Initial loss:  2858432.8494065213\n",
      "best loss: 830.76\t\tLearning rate: 1.833e-04, Batch size: 14, Momentum: 4.732e-01\n",
      "Initial loss:  1497928.1694565834\n",
      "best loss: 513.02\t\tLearning rate: 2.637e-07, Batch size: 47, Momentum: 7.887e-01\n",
      "Initial loss:  688643.5835708971\n",
      "best loss: 650.19\t\tLearning rate: 2.069e-05, Batch size: 32, Momentum: 6.835e-01\n",
      "Initial loss:  932350.1565105952\n",
      "best loss: 114920.39\t\tLearning rate: 1.000e-08, Batch size: 22, Momentum: 6.835e-01\n",
      "Initial loss:  1272295.7528111993\n",
      "best loss: 785.77\t\tLearning rate: 1.833e-04, Batch size: 27, Momentum: 5.258e-02\n",
      "Initial loss:  3350164.7814591927\n",
      "best loss: 315036.97\t\tLearning rate: 2.976e-08, Batch size: 34, Momentum: 6.835e-01\n",
      "Initial loss:  503.44400908758064\n",
      "best loss: 485.94\t\tLearning rate: 6.158e-05, Batch size: 7, Momentum: 0.000e+00\n",
      "Initial loss:  981020.5094250939\n",
      "best loss: 611.58\t\tLearning rate: 2.069e-05, Batch size: 2, Momentum: 3.155e-01\n",
      "Initial loss:  2153578.896122778\n",
      "best loss: 1345.93\t\tLearning rate: 3.360e+00, Batch size: 47, Momentum: 4.732e-01\n",
      "Initial loss:  3364922.606610214\n",
      "best loss: 493.66\t\tLearning rate: 7.848e-07, Batch size: 34, Momentum: 7.361e-01\n",
      "Initial loss:  1721852.0691736778\n",
      "best loss: 940.93\t\tLearning rate: 4.833e-03, Batch size: 39, Momentum: 0.000e+00\n",
      "Initial loss:  1236848.744314833\n",
      "best loss: 1343.13\t\tLearning rate: 3.360e+00, Batch size: 17, Momentum: 3.681e-01\n",
      "Initial loss:  2359392.804186183\n",
      "best loss: 1028.56\t\tLearning rate: 4.833e-03, Batch size: 14, Momentum: 5.258e-01\n",
      "Initial loss:  2352065.1927373824\n",
      "best loss: 505.88\t\tLearning rate: 6.952e-06, Batch size: 24, Momentum: 5.258e-02\n",
      "Initial loss:  1166050.290125435\n",
      "best loss: 541.30\t\tLearning rate: 7.848e-07, Batch size: 34, Momentum: 0.000e+00\n",
      "Initial loss:  1361715.3045857002\n",
      "best loss: 1482.31\t\tLearning rate: 1.000e+01, Batch size: 44, Momentum: 8.413e-01\n",
      "Initial loss:  3419480.871524746\n",
      "best loss: 494.15\t\tLearning rate: 2.336e-06, Batch size: 27, Momentum: 4.732e-01\n",
      "Initial loss:  3447446.121425521\n",
      "best loss: 486.32\t\tLearning rate: 7.848e-07, Batch size: 12, Momentum: 6.835e-01\n",
      "Initial loss:  2551952.7052563173\n",
      "best loss: 1120.38\t\tLearning rate: 4.281e-02, Batch size: 19, Momentum: 5.784e-01\n",
      "Initial loss:  492.57574014492775\n",
      "best loss: 479.43\t\tLearning rate: 6.158e-05, Batch size: 2, Momentum: 3.155e-01\n",
      "Initial loss:  2291301.056175178\n",
      "best loss: 1256.00\t\tLearning rate: 1.274e-01, Batch size: 9, Momentum: 6.309e-01\n",
      "Initial loss:  1710835.732951604\n",
      "best loss: 506.85\t\tLearning rate: 7.848e-07, Batch size: 24, Momentum: 8.413e-01\n",
      "Initial loss:  1786277.66810046\n",
      "best loss: 1091.96\t\tLearning rate: 1.438e-02, Batch size: 44, Momentum: 6.835e-01\n",
      "Initial loss:  4025510.769807186\n",
      "best loss: 531.00\t\tLearning rate: 6.952e-06, Batch size: 17, Momentum: 5.784e-01\n",
      "Initial loss:  355990.28442540945\n",
      "best loss: 1299.79\t\tLearning rate: 3.793e-01, Batch size: 4, Momentum: 9.464e-01\n",
      "Initial loss:  4141930.686823492\n",
      "best loss: 771.22\t\tLearning rate: 1.833e-04, Batch size: 2, Momentum: 6.835e-01\n",
      "Initial loss:  501.81548080547356\n",
      "best loss: 490.21\t\tLearning rate: 1.000e-08, Batch size: 27, Momentum: 4.206e-01\n",
      "Initial loss:  861707.4643936895\n",
      "best loss: 1238.61\t\tLearning rate: 1.274e-01, Batch size: 4, Momentum: 6.309e-01\n",
      "Initial loss:  1802927.1162617013\n",
      "best loss: 961.86\t\tLearning rate: 4.833e-03, Batch size: 4, Momentum: 3.681e-01\n",
      "Initial loss:  3056492.9637689246\n",
      "best loss: 1395.96\t\tLearning rate: 1.000e+01, Batch size: 27, Momentum: 9.464e-01\n",
      "Initial loss:  450014.00063186395\n",
      "best loss: 677.48\t\tLearning rate: 2.069e-05, Batch size: 39, Momentum: 5.258e-01\n",
      "Initial loss:  1975198.5472505202\n",
      "best loss: 707.66\t\tLearning rate: 6.158e-05, Batch size: 22, Momentum: 4.206e-01\n",
      "Initial loss:  1229902.9384264378\n",
      "best loss: 825.57\t\tLearning rate: 5.456e-04, Batch size: 29, Momentum: 0.000e+00\n",
      "Initial loss:  1113389.0947306263\n",
      "best loss: 496.68\t\tLearning rate: 6.952e-06, Batch size: 37, Momentum: 9.464e-01\n",
      "Initial loss:  3858618.8012081683\n",
      "best loss: 1222.46\t\tLearning rate: 1.274e-01, Batch size: 7, Momentum: 8.413e-01\n",
      "Initial loss:  3064989.461857724\n",
      "best loss: 1267.31\t\tLearning rate: 3.360e+00, Batch size: 27, Momentum: 1.052e-01\n",
      "Initial loss:  2853916.7740070056\n",
      "best loss: 729.03\t\tLearning rate: 6.158e-05, Batch size: 39, Momentum: 4.732e-01\n",
      "Initial loss:  2730365.2762596984\n",
      "best loss: 548.83\t\tLearning rate: 6.952e-06, Batch size: 4, Momentum: 8.938e-01\n",
      "Initial loss:  1891757.0996177336\n",
      "best loss: 708.89\t\tLearning rate: 1.833e-04, Batch size: 2, Momentum: 3.155e-01\n",
      "Initial loss:  1384570.7917935706\n",
      "best loss: 1314.48\t\tLearning rate: 3.793e-01, Batch size: 39, Momentum: 6.835e-01\n",
      "Initial loss:  3126060.6206995263\n",
      "best loss: 495.93\t\tLearning rate: 2.336e-06, Batch size: 29, Momentum: 1.577e-01\n",
      "Initial loss:  6461462.79562166\n",
      "best loss: 495.31\t\tLearning rate: 2.976e-08, Batch size: 9, Momentum: 7.361e-01\n",
      "Initial loss:  1058609.6325568622\n",
      "best loss: 489.40\t\tLearning rate: 7.848e-07, Batch size: 22, Momentum: 7.887e-01\n",
      "Initial loss:  968166.7250256042\n",
      "best loss: 1195.18\t\tLearning rate: 3.793e-01, Batch size: 2, Momentum: 1.052e-01\n",
      "Initial loss:  1273627.6372251327\n",
      "best loss: 864.83\t\tLearning rate: 1.624e-03, Batch size: 14, Momentum: 0.000e+00\n",
      "Initial loss:  843715.2850681029\n",
      "best loss: 1412.44\t\tLearning rate: 1.000e+01, Batch size: 22, Momentum: 5.784e-01\n",
      "Initial loss:  1972036.4730250076\n",
      "best loss: 1041.37\t\tLearning rate: 1.624e-03, Batch size: 32, Momentum: 8.938e-01\n",
      "Initial loss:  809851.921736145\n",
      "best loss: 3804784.03\t\tLearning rate: 4.833e-03, Batch size: 24, Momentum: 3.155e-01\n",
      "Initial loss:  260968.7271796271\n",
      "best loss: 1353.23\t\tLearning rate: 1.129e+00, Batch size: 17, Momentum: 6.835e-01\n",
      "Initial loss:  1594064.0083705485\n",
      "best loss: 1165.97\t\tLearning rate: 1.274e-01, Batch size: 7, Momentum: 5.784e-01\n",
      "Initial loss:  1064608.6033777576\n",
      "best loss: 1277.83\t\tLearning rate: 3.793e-01, Batch size: 7, Momentum: 6.309e-01\n",
      "Initial loss:  2583461.3918702207\n",
      "best loss: 512.43\t\tLearning rate: 2.336e-06, Batch size: 34, Momentum: 9.990e-01\n",
      "Initial loss:  921568.1390684323\n",
      "best loss: 753.56\t\tLearning rate: 2.069e-05, Batch size: 7, Momentum: 7.361e-01\n",
      "Initial loss:  2216264.244971236\n",
      "best loss: 415397.47\t\tLearning rate: 7.848e-07, Batch size: 50, Momentum: 7.887e-01\n",
      "Initial loss:  507.0685778834504\n",
      "best loss: 481.66\t\tLearning rate: 2.637e-07, Batch size: 7, Momentum: 9.464e-01\n",
      "Initial loss:  1877516.7854327988\n",
      "best loss: 1275.06\t\tLearning rate: 3.793e-01, Batch size: 27, Momentum: 6.309e-01\n",
      "Initial loss:  2597766.048540754\n",
      "best loss: 1149.92\t\tLearning rate: 1.274e-01, Batch size: 12, Momentum: 2.629e-01\n",
      "Initial loss:  2624061.6308113676\n",
      "best loss: 1367.60\t\tLearning rate: 3.360e+00, Batch size: 9, Momentum: 5.784e-01\n",
      "Initial loss:  494.22390814297756\n",
      "best loss: 487.84\t\tLearning rate: 1.129e+00, Batch size: 29, Momentum: 9.464e-01\n",
      "Initial loss:  2231706.4709349563\n",
      "best loss: 494.01\t\tLearning rate: 6.952e-06, Batch size: 29, Momentum: 1.052e-01\n",
      "Initial loss:  977526.3592890066\n",
      "best loss: 475.45\t\tLearning rate: 7.848e-07, Batch size: 2, Momentum: 2.629e-01\n",
      "Initial loss:  1345385.547927955\n",
      "best loss: 784.06\t\tLearning rate: 1.833e-04, Batch size: 50, Momentum: 1.577e-01\n",
      "Initial loss:  764139.9375113724\n",
      "best loss: 1176.53\t\tLearning rate: 1.438e-02, Batch size: 2, Momentum: 9.990e-01\n",
      "Initial loss:  2984728.1001802846\n",
      "best loss: 1172.59\t\tLearning rate: 3.793e-01, Batch size: 7, Momentum: 2.103e-01\n",
      "Initial loss:  679601.1560360601\n",
      "best loss: 504.50\t\tLearning rate: 2.637e-07, Batch size: 37, Momentum: 3.681e-01\n",
      "Initial loss:  1594757.875673677\n",
      "best loss: 1112.02\t\tLearning rate: 1.274e-01, Batch size: 34, Momentum: 2.103e-01\n",
      "Initial loss:  467030.1798770009\n",
      "best loss: 837.30\t\tLearning rate: 1.833e-04, Batch size: 24, Momentum: 7.361e-01\n",
      "Initial loss:  1980884.9631756435\n",
      "best loss: 1367.97\t\tLearning rate: 1.000e+01, Batch size: 34, Momentum: 2.103e-01\n",
      "Initial loss:  2368383.2982958513\n",
      "best loss: 499.66\t\tLearning rate: 2.336e-06, Batch size: 37, Momentum: 5.258e-02\n",
      "Initial loss:  1634263.2517715762\n",
      "best loss: 726.68\t\tLearning rate: 6.158e-05, Batch size: 14, Momentum: 3.155e-01\n",
      "Initial loss:  927494.5930453852\n",
      "best loss: 1069.65\t\tLearning rate: 4.833e-03, Batch size: 34, Momentum: 7.887e-01\n",
      "Initial loss:  3681859.487478407\n",
      "best loss: 701.45\t\tLearning rate: 6.158e-05, Batch size: 42, Momentum: 2.103e-01\n",
      "Initial loss:  2338090.5382821336\n",
      "best loss: 932.15\t\tLearning rate: 1.833e-04, Batch size: 29, Momentum: 9.990e-01\n",
      "Initial loss:  2685145.3950353134\n",
      "best loss: 677.61\t\tLearning rate: 2.069e-05, Batch size: 29, Momentum: 5.784e-01\n",
      "Initial loss:  507576.9741805653\n",
      "best loss: 771.21\t\tLearning rate: 6.158e-05, Batch size: 17, Momentum: 8.938e-01\n",
      "Initial loss:  2811173.070028911\n",
      "best loss: 497.81\t\tLearning rate: 7.848e-07, Batch size: 50, Momentum: 8.413e-01\n",
      "Initial loss:  493.3983153342872\n",
      "best loss: 489.06\t\tLearning rate: 3.793e-01, Batch size: 14, Momentum: 2.629e-01\n",
      "Initial loss:  1113977.6196605912\n",
      "best loss: 704.80\t\tLearning rate: 2.069e-05, Batch size: 19, Momentum: 3.681e-01\n",
      "Initial loss:  2048552.5118992205\n",
      "best loss: 956.56\t\tLearning rate: 4.833e-03, Batch size: 37, Momentum: 3.155e-01\n",
      "Initial loss:  1537726.4221319682\n",
      "best loss: 757.48\t\tLearning rate: 1.833e-04, Batch size: 12, Momentum: 5.784e-01\n",
      "Initial loss:  3035785.0654979185\n",
      "best loss: 1403.37\t\tLearning rate: 1.000e+01, Batch size: 27, Momentum: 1.577e-01\n",
      "Initial loss:  2219219.320455252\n",
      "best loss: 500.20\t\tLearning rate: 2.637e-07, Batch size: 39, Momentum: 4.732e-01\n",
      "Initial loss:  1173814.112832463\n",
      "best loss: 608.62\t\tLearning rate: 2.637e-07, Batch size: 39, Momentum: 0.000e+00\n",
      "Initial loss:  1671771.005697657\n",
      "best loss: 1269.36\t\tLearning rate: 1.129e+00, Batch size: 47, Momentum: 2.629e-01\n",
      "Initial loss:  1139032.4099023563\n",
      "best loss: 492.17\t\tLearning rate: 2.637e-07, Batch size: 29, Momentum: 9.990e-01\n",
      "Initial loss:  1034931.8466199312\n",
      "best loss: 1251.00\t\tLearning rate: 1.274e-01, Batch size: 27, Momentum: 5.784e-01\n",
      "Initial loss:  3031694.9094955553\n",
      "best loss: 1086.51\t\tLearning rate: 1.438e-02, Batch size: 27, Momentum: 3.681e-01\n",
      "Initial loss:  490577.15830454184\n",
      "best loss: 901.95\t\tLearning rate: 1.624e-03, Batch size: 9, Momentum: 1.577e-01\n",
      "Initial loss:  175875.2262285237\n",
      "best loss: 489.56\t\tLearning rate: 6.158e-05, Batch size: 32, Momentum: 5.258e-01\n",
      "Initial loss:  1044303.631560837\n",
      "best loss: 494.40\t\tLearning rate: 2.336e-06, Batch size: 17, Momentum: 7.887e-01\n",
      "Initial loss:  5024233.020459288\n",
      "best loss: 104170.62\t\tLearning rate: 1.274e-01, Batch size: 7, Momentum: 0.000e+00\n",
      "Initial loss:  1091192.6876485758\n",
      "best loss: 1887.57\t\tLearning rate: 2.637e-07, Batch size: 47, Momentum: 0.000e+00\n",
      "Initial loss:  2916963.2277383306\n",
      "best loss: 1265.45\t\tLearning rate: 3.793e-01, Batch size: 22, Momentum: 7.361e-01\n",
      "Initial loss:  2804078.2203236716\n",
      "best loss: 1065.98\t\tLearning rate: 1.438e-02, Batch size: 39, Momentum: 3.155e-01\n",
      "Initial loss:  1792088.0069944686\n",
      "best loss: 482.61\t\tLearning rate: 2.637e-07, Batch size: 4, Momentum: 5.784e-01\n",
      "Initial loss:  2973018.060121008\n",
      "best loss: 1204.86\t\tLearning rate: 4.281e-02, Batch size: 7, Momentum: 8.938e-01\n",
      "Initial loss:  2567243.6416140213\n",
      "best loss: 1071.11\t\tLearning rate: 1.624e-03, Batch size: 34, Momentum: 9.464e-01\n",
      "Initial loss:  1116649.4560356545\n",
      "best loss: 938.79\t\tLearning rate: 1.624e-03, Batch size: 50, Momentum: 5.784e-01\n",
      "Initial loss:  1758755.0853662924\n",
      "best loss: 864.21\t\tLearning rate: 1.833e-04, Batch size: 44, Momentum: 6.309e-01\n",
      "Initial loss:  695968.1909060787\n",
      "best loss: 489.13\t\tLearning rate: 7.848e-07, Batch size: 17, Momentum: 7.887e-01\n",
      "Initial loss:  2139563.979432046\n",
      "best loss: 1425.34\t\tLearning rate: 3.360e+00, Batch size: 32, Momentum: 7.887e-01\n",
      "Initial loss:  1111822.5482791197\n",
      "best loss: 520.52\t\tLearning rate: 7.848e-07, Batch size: 9, Momentum: 3.155e-01\n",
      "Initial loss:  3773925.3745988896\n",
      "best loss: 1145.68\t\tLearning rate: 2.976e-08, Batch size: 42, Momentum: 5.258e-02\n",
      "Initial loss:  3569396.9324823385\n",
      "best loss: 1340.24\t\tLearning rate: 3.360e+00, Batch size: 32, Momentum: 3.681e-01\n",
      "Initial loss:  894183.659100712\n",
      "best loss: 1089.64\t\tLearning rate: 4.281e-02, Batch size: 17, Momentum: 2.629e-01\n",
      "Initial loss:  1111602.26047766\n",
      "best loss: 505.74\t\tLearning rate: 2.637e-07, Batch size: 22, Momentum: 6.309e-01\n",
      "Initial loss:  364144.8861734624\n",
      "best loss: 1068.82\t\tLearning rate: 4.281e-02, Batch size: 24, Momentum: 2.103e-01\n",
      "Initial loss:  4141571.9651703904\n",
      "best loss: 1028.45\t\tLearning rate: 1.624e-03, Batch size: 19, Momentum: 7.887e-01\n",
      "Initial loss:  1485832.0333985267\n",
      "best loss: 547103.09\t\tLearning rate: 1.624e-03, Batch size: 19, Momentum: 1.052e-01\n",
      "Initial loss:  1275549.2204987379\n",
      "best loss: 585.34\t\tLearning rate: 1.000e-08, Batch size: 12, Momentum: 6.835e-01\n",
      "Initial loss:  1084595.446292768\n",
      "best loss: 558.31\t\tLearning rate: 2.976e-08, Batch size: 47, Momentum: 5.784e-01\n",
      "Initial loss:  2808278.3020914122\n",
      "best loss: 1435.22\t\tLearning rate: 1.000e+01, Batch size: 27, Momentum: 7.361e-01\n",
      "Initial loss:  274976.53592398117\n",
      "best loss: 479.73\t\tLearning rate: 6.952e-06, Batch size: 2, Momentum: 5.258e-02\n",
      "Initial loss:  1078132.365919431\n",
      "best loss: 492.67\t\tLearning rate: 8.859e-08, Batch size: 2, Momentum: 6.309e-01\n",
      "Initial loss:  2363863.778694783\n",
      "best loss: 495.19\t\tLearning rate: 2.976e-08, Batch size: 27, Momentum: 8.938e-01\n",
      "Initial loss:  2092347.433390584\n",
      "best loss: 1049.18\t\tLearning rate: 1.438e-02, Batch size: 34, Momentum: 5.258e-01\n",
      "Initial loss:  5587489.669835196\n",
      "best loss: 617.07\t\tLearning rate: 2.069e-05, Batch size: 4, Momentum: 2.103e-01\n",
      "Initial loss:  1211683.5488824567\n",
      "best loss: 781.24\t\tLearning rate: 6.158e-05, Batch size: 44, Momentum: 7.887e-01\n",
      "Initial loss:  836268.6924310126\n",
      "best loss: 514.70\t\tLearning rate: 1.000e-08, Batch size: 12, Momentum: 8.413e-01\n",
      "Initial loss:  2335111.4361120835\n",
      "best loss: 832.63\t\tLearning rate: 1.833e-04, Batch size: 17, Momentum: 4.732e-01\n",
      "Initial loss:  4082520.9498314015\n",
      "best loss: 328744.06\t\tLearning rate: 1.000e-08, Batch size: 7, Momentum: 6.309e-01\n",
      "Initial loss:  1001252.9518007115\n",
      "best loss: 957.01\t\tLearning rate: 1.624e-03, Batch size: 14, Momentum: 4.732e-01\n",
      "Initial loss:  371811.5172220274\n",
      "best loss: 1169.31\t\tLearning rate: 1.129e+00, Batch size: 19, Momentum: 0.000e+00\n",
      "Initial loss:  1566245.3645259468\n",
      "best loss: 921.11\t\tLearning rate: 4.833e-03, Batch size: 44, Momentum: 3.681e-01\n",
      "Initial loss:  2179072.1228110287\n",
      "best loss: 501.09\t\tLearning rate: 6.952e-06, Batch size: 14, Momentum: 8.413e-01\n",
      "Initial loss:  877785.2160388017\n",
      "best loss: 1092.06\t\tLearning rate: 1.438e-02, Batch size: 2, Momentum: 6.309e-01\n",
      "Initial loss:  1262678.243855486\n",
      "best loss: 1192.17\t\tLearning rate: 4.281e-02, Batch size: 14, Momentum: 8.413e-01\n",
      "Initial loss:  1470815.4144338765\n",
      "best loss: 487.25\t\tLearning rate: 8.859e-08, Batch size: 14, Momentum: 9.990e-01\n",
      "Initial loss:  3203856.365777544\n",
      "best loss: 889.40\t\tLearning rate: 5.456e-04, Batch size: 42, Momentum: 2.103e-01\n",
      "Initial loss:  1401932.3664108315\n",
      "best loss: 489.56\t\tLearning rate: 2.336e-06, Batch size: 22, Momentum: 6.835e-01\n",
      "Initial loss:  1873249.8645235144\n",
      "best loss: 609.61\t\tLearning rate: 2.069e-05, Batch size: 37, Momentum: 5.258e-01\n",
      "Initial loss:  1848941.2497825283\n",
      "best loss: 1066.44\t\tLearning rate: 1.438e-02, Batch size: 9, Momentum: 5.258e-01\n",
      "Initial loss:  1652498.2726604787\n",
      "best loss: 364977.10\t\tLearning rate: 1.000e-08, Batch size: 50, Momentum: 1.577e-01\n",
      "Initial loss:  1870176.05723031\n",
      "best loss: 508.82\t\tLearning rate: 2.976e-08, Batch size: 24, Momentum: 8.413e-01\n",
      "Initial loss:  2527712.7175356257\n",
      "best loss: 1025.97\t\tLearning rate: 4.833e-03, Batch size: 50, Momentum: 8.938e-01\n",
      "Initial loss:  2387594.0968025946\n",
      "best loss: 1055.14\t\tLearning rate: 4.281e-02, Batch size: 14, Momentum: 0.000e+00\n",
      "Initial loss:  506617.9401853648\n",
      "best loss: 1488.90\t\tLearning rate: 1.000e+01, Batch size: 24, Momentum: 6.835e-01\n",
      "Initial loss:  1154338.1968330294\n",
      "best loss: 1321.05\t\tLearning rate: 1.000e+01, Batch size: 29, Momentum: 5.258e-02\n",
      "Initial loss:  2480789.2219281374\n",
      "best loss: 914.82\t\tLearning rate: 1.624e-03, Batch size: 34, Momentum: 3.155e-01\n",
      "Initial loss:  6060732.288517813\n",
      "best loss: 685.18\t\tLearning rate: 2.069e-05, Batch size: 19, Momentum: 6.309e-01\n",
      "Initial loss:  1186657.951810987\n",
      "best loss: 499.78\t\tLearning rate: 7.848e-07, Batch size: 19, Momentum: 3.155e-01\n",
      "Initial loss:  119253.46391242008\n",
      "best loss: 595.75\t\tLearning rate: 8.859e-08, Batch size: 9, Momentum: 1.577e-01\n",
      "Initial loss:  3748525.5214462774\n",
      "best loss: 1030.75\t\tLearning rate: 4.281e-02, Batch size: 42, Momentum: 0.000e+00\n",
      "Initial loss:  1828599.78878936\n",
      "best loss: 1447.82\t\tLearning rate: 3.360e+00, Batch size: 22, Momentum: 8.938e-01\n",
      "Initial loss:  495.7244620507822\n",
      "best loss: 493.09\t\tLearning rate: 5.456e-04, Batch size: 44, Momentum: 1.577e-01\n",
      "Initial loss:  3865483.426907146\n",
      "best loss: 1241.18\t\tLearning rate: 1.274e-01, Batch size: 7, Momentum: 4.732e-01\n",
      "Initial loss:  2154721.977679015\n",
      "best loss: 1009.38\t\tLearning rate: 1.438e-02, Batch size: 7, Momentum: 0.000e+00\n",
      "Initial loss:  2943245.8370377417\n",
      "best loss: 507.85\t\tLearning rate: 6.952e-06, Batch size: 50, Momentum: 0.000e+00\n",
      "Initial loss:  2108612.9178558923\n",
      "best loss: 967712.75\t\tLearning rate: 2.637e-07, Batch size: 47, Momentum: 7.361e-01\n",
      "Initial loss:  1147905.6418730007\n",
      "best loss: 850.41\t\tLearning rate: 5.456e-04, Batch size: 22, Momentum: 1.052e-01\n",
      "Initial loss:  1863263.273233723\n",
      "best loss: 220614.69\t\tLearning rate: 2.976e-08, Batch size: 32, Momentum: 0.000e+00\n",
      "Initial loss:  1260937.3447744877\n",
      "best loss: 765.15\t\tLearning rate: 2.069e-05, Batch size: 47, Momentum: 2.103e-01\n",
      "Initial loss:  1612975.3353956358\n",
      "best loss: 831.35\t\tLearning rate: 6.158e-05, Batch size: 32, Momentum: 9.464e-01\n",
      "Initial loss:  2865754.7537115617\n",
      "best loss: 515.52\t\tLearning rate: 6.952e-06, Batch size: 29, Momentum: 1.052e-01\n",
      "Initial loss:  181524.41085095686\n",
      "best loss: 777.62\t\tLearning rate: 1.833e-04, Batch size: 44, Momentum: 2.629e-01\n",
      "Initial loss:  1514307.37919912\n",
      "best loss: 880.44\t\tLearning rate: 1.833e-04, Batch size: 19, Momentum: 6.309e-01\n",
      "Initial loss:  1920174.4085771355\n",
      "best loss: 494.05\t\tLearning rate: 2.637e-07, Batch size: 29, Momentum: 6.309e-01\n",
      "Initial loss:  970986.0972421987\n",
      "best loss: 1111.62\t\tLearning rate: 1.274e-01, Batch size: 39, Momentum: 1.577e-01\n",
      "Initial loss:  778090.9967071862\n",
      "best loss: 1352.03\t\tLearning rate: 1.000e+01, Batch size: 29, Momentum: 2.629e-01\n",
      "Initial loss:  6279688.555715602\n",
      "best loss: 564.98\t\tLearning rate: 6.952e-06, Batch size: 17, Momentum: 7.887e-01\n",
      "Initial loss:  590489.1745005659\n",
      "best loss: 1408.45\t\tLearning rate: 1.000e+01, Batch size: 39, Momentum: 4.732e-01\n",
      "Initial loss:  730947.1950130688\n",
      "best loss: 474.07\t\tLearning rate: 2.336e-06, Batch size: 2, Momentum: 2.103e-01\n",
      "Initial loss:  3068796.5618420956\n",
      "best loss: 1080.21\t\tLearning rate: 4.281e-02, Batch size: 19, Momentum: 1.577e-01\n",
      "Initial loss:  1566874.6953262098\n",
      "best loss: 665.43\t\tLearning rate: 2.976e-08, Batch size: 42, Momentum: 5.784e-01\n",
      "Initial loss:  3315686.729661264\n",
      "best loss: 486.19\t\tLearning rate: 7.848e-07, Batch size: 7, Momentum: 6.835e-01\n",
      "Initial loss:  2327775.689998787\n",
      "best loss: 15024.86\t\tLearning rate: 2.976e-08, Batch size: 4, Momentum: 2.629e-01\n",
      "Initial loss:  2097387.722246514\n",
      "best loss: 1321.06\t\tLearning rate: 1.129e+00, Batch size: 9, Momentum: 6.835e-01\n",
      "Initial loss:  1107260.6582047078\n",
      "best loss: 705.98\t\tLearning rate: 6.158e-05, Batch size: 39, Momentum: 5.258e-01\n",
      "Initial loss:  1502869.8481705827\n",
      "best loss: 953.09\t\tLearning rate: 5.456e-04, Batch size: 22, Momentum: 8.413e-01\n",
      "Initial loss:  1929907.3502858542\n",
      "best loss: 756.61\t\tLearning rate: 2.069e-05, Batch size: 12, Momentum: 8.938e-01\n",
      "Initial loss:  2287393.159135065\n",
      "best loss: 498.45\t\tLearning rate: 2.336e-06, Batch size: 12, Momentum: 2.629e-01\n",
      "Initial loss:  4018561.6968924827\n",
      "best loss: 1470.91\t\tLearning rate: 1.000e+01, Batch size: 47, Momentum: 7.361e-01\n",
      "Initial loss:  671529.2297724473\n",
      "best loss: 1198.04\t\tLearning rate: 3.793e-01, Batch size: 29, Momentum: 4.732e-01\n",
      "Initial loss:  1265189.5778236885\n",
      "best loss: 661.69\t\tLearning rate: 2.637e-07, Batch size: 39, Momentum: 3.155e-01\n",
      "Initial loss:  2419615.0988374418\n",
      "best loss: 1526.13\t\tLearning rate: 1.000e+01, Batch size: 24, Momentum: 9.464e-01\n",
      "Initial loss:  589277.729345144\n",
      "best loss: 1063.10\t\tLearning rate: 4.833e-03, Batch size: 22, Momentum: 6.835e-01\n",
      "Initial loss:  1442073.9510349885\n",
      "best loss: 491.20\t\tLearning rate: 2.336e-06, Batch size: 24, Momentum: 7.361e-01\n",
      "Initial loss:  1773443.5525572351\n",
      "best loss: 750.98\t\tLearning rate: 2.069e-05, Batch size: 50, Momentum: 8.938e-01\n",
      "Initial loss:  2383131.681269226\n",
      "best loss: 695.36\t\tLearning rate: 6.158e-05, Batch size: 50, Momentum: 0.000e+00\n",
      "Initial loss:  1277058.2065869549\n",
      "best loss: 1094.84\t\tLearning rate: 1.438e-02, Batch size: 34, Momentum: 9.990e-01\n",
      "Initial loss:  1852147.1938025933\n",
      "best loss: 871.62\t\tLearning rate: 1.000e-08, Batch size: 7, Momentum: 4.732e-01\n",
      "Initial loss:  2277506.909997988\n",
      "best loss: 798.03\t\tLearning rate: 1.833e-04, Batch size: 14, Momentum: 3.155e-01\n",
      "Initial loss:  2058013.1776783005\n",
      "best loss: 748.16\t\tLearning rate: 6.158e-05, Batch size: 37, Momentum: 2.103e-01\n",
      "Initial loss:  592377.5930057424\n",
      "best loss: 1071.92\t\tLearning rate: 1.000e-08, Batch size: 19, Momentum: 7.361e-01\n",
      "Initial loss:  1514933.5361666023\n",
      "best loss: 1443.11\t\tLearning rate: 1.000e+01, Batch size: 17, Momentum: 6.835e-01\n",
      "Initial loss:  1251213.4259424303\n",
      "best loss: 1313.51\t\tLearning rate: 3.360e+00, Batch size: 50, Momentum: 4.206e-01\n",
      "Initial loss:  1183286.9094902605\n",
      "best loss: 492.74\t\tLearning rate: 2.336e-06, Batch size: 42, Momentum: 7.887e-01\n",
      "Initial loss:  2316041.952799543\n",
      "best loss: 842.97\t\tLearning rate: 5.456e-04, Batch size: 2, Momentum: 5.258e-02\n",
      "Initial loss:  1740274.6351475124\n",
      "best loss: 500.36\t\tLearning rate: 2.637e-07, Batch size: 9, Momentum: 7.361e-01\n",
      "Initial loss:  2631179.258356116\n",
      "best loss: 1212.11\t\tLearning rate: 1.129e+00, Batch size: 47, Momentum: 5.258e-02\n",
      "Initial loss:  1280940.7112517166\n",
      "best loss: 885.53\t\tLearning rate: 1.833e-04, Batch size: 34, Momentum: 2.103e-01\n",
      "Initial loss:  1682205.8612385048\n",
      "best loss: 1356.04\t\tLearning rate: 3.360e+00, Batch size: 29, Momentum: 5.784e-01\n",
      "Initial loss:  499.0965112990756\n",
      "best loss: 491.21\t\tLearning rate: 1.000e+01, Batch size: 47, Momentum: 9.464e-01\n",
      "Initial loss:  2386363.2004181696\n",
      "best loss: 497253.58\t\tLearning rate: 1.000e-08, Batch size: 42, Momentum: 6.835e-01\n",
      "Initial loss:  2622215.318310849\n",
      "best loss: 740132.15\t\tLearning rate: 1.000e-08, Batch size: 9, Momentum: 9.464e-01\n",
      "Initial loss:  2450100.925805814\n",
      "best loss: 1235.71\t\tLearning rate: 3.793e-01, Batch size: 17, Momentum: 4.206e-01\n",
      "Initial loss:  2096377.2583470398\n",
      "best loss: 1329.61\t\tLearning rate: 1.129e+00, Batch size: 19, Momentum: 7.887e-01\n",
      "Initial loss:  1957327.9915176888\n",
      "best loss: 535.75\t\tLearning rate: 8.859e-08, Batch size: 37, Momentum: 5.784e-01\n",
      "Initial loss:  3291674.571618639\n",
      "best loss: 1285.30\t\tLearning rate: 3.793e-01, Batch size: 42, Momentum: 7.361e-01\n",
      "Initial loss:  3264175.4509288375\n",
      "best loss: 1439.69\t\tLearning rate: 1.000e+01, Batch size: 9, Momentum: 7.887e-01\n",
      "Initial loss:  3730526.881145177\n",
      "best loss: 1254.32\t\tLearning rate: 1.274e-01, Batch size: 29, Momentum: 8.413e-01\n",
      "Initial loss:  1630019.7777125435\n",
      "best loss: 1421.98\t\tLearning rate: 3.360e+00, Batch size: 17, Momentum: 7.887e-01\n",
      "Initial loss:  1451940.2528767393\n",
      "best loss: 1006.65\t\tLearning rate: 4.833e-03, Batch size: 27, Momentum: 4.206e-01\n",
      "Initial loss:  1070970.5058622572\n",
      "best loss: 488.97\t\tLearning rate: 2.336e-06, Batch size: 22, Momentum: 3.681e-01\n",
      "Initial loss:  2271363.216393811\n",
      "best loss: 1463.84\t\tLearning rate: 1.000e+01, Batch size: 27, Momentum: 6.835e-01\n",
      "Initial loss:  770678.2755312255\n",
      "best loss: 540.12\t\tLearning rate: 2.976e-08, Batch size: 19, Momentum: 3.681e-01\n",
      "Initial loss:  380452.40802078875\n",
      "best loss: 1392.72\t\tLearning rate: 3.360e+00, Batch size: 29, Momentum: 6.835e-01\n",
      "Initial loss:  996540.085797396\n",
      "best loss: 1211.47\t\tLearning rate: 1.274e-01, Batch size: 27, Momentum: 8.413e-01\n",
      "Initial loss:  796662.2020996569\n",
      "best loss: 714.96\t\tLearning rate: 1.000e-08, Batch size: 39, Momentum: 2.629e-01\n",
      "Initial loss:  2360287.2060356718\n",
      "best loss: 1094.84\t\tLearning rate: 1.438e-02, Batch size: 32, Momentum: 6.309e-01\n",
      "Initial loss:  1803929.5915222655\n",
      "best loss: 1147.07\t\tLearning rate: 3.793e-01, Batch size: 34, Momentum: 0.000e+00\n",
      "Initial loss:  1173302.820413055\n",
      "best loss: 562.44\t\tLearning rate: 8.859e-08, Batch size: 9, Momentum: 4.206e-01\n",
      "Initial loss:  2095122.686005251\n",
      "best loss: 1007.77\t\tLearning rate: 4.833e-03, Batch size: 37, Momentum: 6.309e-01\n",
      "Initial loss:  607551.2198652903\n",
      "best loss: 479.83\t\tLearning rate: 2.336e-06, Batch size: 4, Momentum: 5.784e-01\n",
      "Initial loss:  1563218.0483286798\n",
      "best loss: 196847.55\t\tLearning rate: 2.976e-08, Batch size: 27, Momentum: 7.361e-01\n",
      "Initial loss:  746467.2023522567\n",
      "best loss: 808.51\t\tLearning rate: 6.158e-05, Batch size: 12, Momentum: 7.887e-01\n",
      "Initial loss:  2412080.361969273\n",
      "best loss: 892.24\t\tLearning rate: 5.456e-04, Batch size: 17, Momentum: 8.413e-01\n",
      "Initial loss:  2098134.0229813103\n",
      "best loss: 1086.79\t\tLearning rate: 1.438e-02, Batch size: 27, Momentum: 8.413e-01\n",
      "Initial loss:  800090.915853955\n",
      "best loss: 962.19\t\tLearning rate: 4.833e-03, Batch size: 17, Momentum: 5.258e-02\n",
      "Initial loss:  893441.4760194451\n",
      "best loss: 753.83\t\tLearning rate: 1.833e-04, Batch size: 12, Momentum: 3.155e-01\n",
      "Initial loss:  1321634.7546499087\n",
      "best loss: 1147.30\t\tLearning rate: 3.793e-01, Batch size: 37, Momentum: 0.000e+00\n",
      "Initial loss:  2258111.7849147217\n",
      "best loss: 576563.88\t\tLearning rate: 1.000e-08, Batch size: 32, Momentum: 3.681e-01\n",
      "Initial loss:  2239476.0235320167\n",
      "best loss: 330437.84\t\tLearning rate: 1.000e-08, Batch size: 39, Momentum: 5.258e-02\n",
      "Initial loss:  1328992.370582066\n",
      "best loss: 505.01\t\tLearning rate: 6.952e-06, Batch size: 47, Momentum: 8.413e-01\n",
      "Initial loss:  1912321.7126235974\n",
      "best loss: 477265.24\t\tLearning rate: 1.000e-08, Batch size: 19, Momentum: 4.206e-01\n",
      "Initial loss:  1207402.1896867591\n",
      "best loss: 1017.24\t\tLearning rate: 4.281e-02, Batch size: 50, Momentum: 1.577e-01\n",
      "Initial loss:  910786.5197418144\n",
      "best loss: 1169.09\t\tLearning rate: 3.793e-01, Batch size: 24, Momentum: 3.681e-01\n",
      "Initial loss:  554.0612840313352\n",
      "best loss: 490.99\t\tLearning rate: 2.976e-08, Batch size: 7, Momentum: 7.361e-01\n",
      "Initial loss:  1284801.8867572874\n",
      "best loss: 1162.12\t\tLearning rate: 4.281e-02, Batch size: 44, Momentum: 9.464e-01\n",
      "Initial loss:  2465786.892950735\n",
      "best loss: 636.45\t\tLearning rate: 2.069e-05, Batch size: 19, Momentum: 4.206e-01\n",
      "Initial loss:  2291342.998829798\n",
      "best loss: 762.40\t\tLearning rate: 6.158e-05, Batch size: 32, Momentum: 7.361e-01\n",
      "Initial loss:  1636391.9752514982\n",
      "best loss: 241753.16\t\tLearning rate: 2.336e-06, Batch size: 42, Momentum: 5.258e-02\n",
      "Initial loss:  1100964.2114134242\n",
      "best loss: 821.10\t\tLearning rate: 6.158e-05, Batch size: 17, Momentum: 5.784e-01\n",
      "Initial loss:  7090343.4901062725\n",
      "best loss: 1350.84\t\tLearning rate: 3.793e-01, Batch size: 2, Momentum: 9.464e-01\n",
      "Initial loss:  2197197.8905091593\n",
      "best loss: 998.94\t\tLearning rate: 4.833e-03, Batch size: 14, Momentum: 3.155e-01\n",
      "Initial loss:  1256558.0693171283\n",
      "best loss: 1188.30\t\tLearning rate: 3.793e-01, Batch size: 9, Momentum: 3.155e-01\n",
      "Initial loss:  363741.49391162145\n",
      "best loss: 1151.19\t\tLearning rate: 1.274e-01, Batch size: 42, Momentum: 5.258e-01\n",
      "Initial loss:  639075.1217700084\n",
      "best loss: 932.31\t\tLearning rate: 1.624e-03, Batch size: 50, Momentum: 4.206e-01\n",
      "Initial loss:  2023544.4358437716\n",
      "best loss: 748.69\t\tLearning rate: 6.158e-05, Batch size: 19, Momentum: 9.464e-01\n",
      "Initial loss:  4037678.504393838\n",
      "best loss: 628.55\t\tLearning rate: 6.952e-06, Batch size: 42, Momentum: 9.990e-01\n",
      "Initial loss:  518.7394100121379\n",
      "best loss: 503.88\t\tLearning rate: 1.000e-08, Batch size: 42, Momentum: 4.206e-01\n",
      "Initial loss:  1477617.6463792254\n",
      "best loss: 1079.86\t\tLearning rate: 4.833e-03, Batch size: 32, Momentum: 9.990e-01\n",
      "Initial loss:  2684790.2205558293\n",
      "best loss: 917.53\t\tLearning rate: 5.456e-04, Batch size: 37, Momentum: 9.990e-01\n",
      "Initial loss:  1377863.9776310758\n",
      "best loss: 586.49\t\tLearning rate: 2.069e-05, Batch size: 34, Momentum: 0.000e+00\n",
      "Initial loss:  1858633.6474751309\n",
      "best loss: 1105.98\t\tLearning rate: 4.281e-02, Batch size: 50, Momentum: 4.206e-01\n",
      "Initial loss:  1684575.4123446252\n",
      "best loss: 249823.55\t\tLearning rate: 2.976e-08, Batch size: 24, Momentum: 0.000e+00\n",
      "Initial loss:  499.08302498701215\n",
      "best loss: 491.82\t\tLearning rate: 1.274e-01, Batch size: 47, Momentum: 3.155e-01\n",
      "Initial loss:  1664228.579809524\n",
      "best loss: 1361.77\t\tLearning rate: 1.129e+00, Batch size: 22, Momentum: 8.938e-01\n",
      "Initial loss:  806129.1008993259\n",
      "best loss: 502.41\t\tLearning rate: 7.848e-07, Batch size: 39, Momentum: 5.258e-02\n",
      "Initial loss:  1753172.943071304\n",
      "best loss: 498.01\t\tLearning rate: 7.848e-07, Batch size: 34, Momentum: 8.938e-01\n",
      "Initial loss:  4170604.468809545\n",
      "best loss: 1281.66\t\tLearning rate: 1.129e+00, Batch size: 24, Momentum: 2.103e-01\n",
      "Initial loss:  2589463.3066885984\n",
      "best loss: 651.28\t\tLearning rate: 6.158e-05, Batch size: 9, Momentum: 0.000e+00\n",
      "Initial loss:  1059004.996360011\n",
      "best loss: 1035.64\t\tLearning rate: 4.281e-02, Batch size: 37, Momentum: 2.103e-01\n",
      "Initial loss:  2847384.9365483434\n",
      "best loss: 1194.75\t\tLearning rate: 1.129e+00, Batch size: 27, Momentum: 0.000e+00\n",
      "Initial loss:  3044297.162055763\n",
      "best loss: 752.75\t\tLearning rate: 6.158e-05, Batch size: 14, Momentum: 9.464e-01\n",
      "Initial loss:  636320.7843068191\n",
      "best loss: 1248.34\t\tLearning rate: 3.793e-01, Batch size: 32, Momentum: 6.835e-01\n",
      "Initial loss:  1415163.171407907\n",
      "best loss: 1091.92\t\tLearning rate: 4.281e-02, Batch size: 27, Momentum: 3.155e-01\n",
      "Initial loss:  1965895.8930860497\n",
      "best loss: 1024.91\t\tLearning rate: 1.624e-03, Batch size: 9, Momentum: 7.887e-01\n",
      "Initial loss:  1684051.0613890337\n",
      "best loss: 1222.05\t\tLearning rate: 1.274e-01, Batch size: 17, Momentum: 4.732e-01\n",
      "Initial loss:  1424872.217719441\n",
      "best loss: 725.00\t\tLearning rate: 6.158e-05, Batch size: 42, Momentum: 4.732e-01\n",
      "Initial loss:  1683581.734265834\n",
      "best loss: 498.02\t\tLearning rate: 6.952e-06, Batch size: 24, Momentum: 7.887e-01\n",
      "Initial loss:  494.187000533421\n",
      "best loss: 488.08\t\tLearning rate: 6.158e-05, Batch size: 34, Momentum: 2.629e-01\n",
      "Initial loss:  1185448.761344787\n",
      "best loss: 957.23\t\tLearning rate: 1.624e-03, Batch size: 9, Momentum: 2.629e-01\n",
      "Initial loss:  1411707.7157732518\n",
      "best loss: 503.89\t\tLearning rate: 2.336e-06, Batch size: 47, Momentum: 1.577e-01\n",
      "Initial loss:  1750420.4802735378\n",
      "best loss: 676.40\t\tLearning rate: 6.158e-05, Batch size: 17, Momentum: 3.155e-01\n",
      "Initial loss:  4466670.079775494\n",
      "best loss: 1445.56\t\tLearning rate: 1.000e+01, Batch size: 4, Momentum: 5.258e-01\n",
      "Initial loss:  1342540.461442076\n",
      "best loss: 494.96\t\tLearning rate: 6.952e-06, Batch size: 50, Momentum: 2.629e-01\n",
      "Initial loss:  1083154.6702961081\n",
      "best loss: 492.76\t\tLearning rate: 7.848e-07, Batch size: 34, Momentum: 5.258e-01\n",
      "Initial loss:  976912.6590086351\n",
      "best loss: 502.15\t\tLearning rate: 2.637e-07, Batch size: 17, Momentum: 9.464e-01\n",
      "Initial loss:  1448172.3806913912\n",
      "best loss: 980.72\t\tLearning rate: 1.624e-03, Batch size: 17, Momentum: 5.784e-01\n",
      "Initial loss:  2529210.1027588337\n",
      "best loss: 1094.67\t\tLearning rate: 4.833e-03, Batch size: 50, Momentum: 8.938e-01\n",
      "Initial loss:  2643957.624351838\n",
      "best loss: 1112.20\t\tLearning rate: 1.438e-02, Batch size: 47, Momentum: 6.835e-01\n",
      "Initial loss:  2830967.7038807655\n",
      "best loss: 496.67\t\tLearning rate: 2.637e-07, Batch size: 37, Momentum: 9.990e-01\n",
      "Initial loss:  1124508.2459490765\n",
      "best loss: 1227.13\t\tLearning rate: 1.274e-01, Batch size: 29, Momentum: 7.887e-01\n",
      "Initial loss:  1278853.298747954\n",
      "best loss: 922.15\t\tLearning rate: 1.624e-03, Batch size: 12, Momentum: 1.577e-01\n",
      "Initial loss:  3318805.150780175\n",
      "best loss: 493.72\t\tLearning rate: 7.848e-07, Batch size: 50, Momentum: 8.413e-01\n",
      "Initial loss:  3408772.1811561906\n",
      "best loss: 1238.03\t\tLearning rate: 3.793e-01, Batch size: 50, Momentum: 3.681e-01\n",
      "Initial loss:  691222.7680851781\n",
      "best loss: 1302.11\t\tLearning rate: 1.129e+00, Batch size: 39, Momentum: 6.309e-01\n",
      "Initial loss:  510.12669564620444\n",
      "best loss: 489.90\t\tLearning rate: 1.000e+01, Batch size: 34, Momentum: 8.413e-01\n",
      "Initial loss:  502.5386020855549\n",
      "best loss: 489.18\t\tLearning rate: 1.274e-01, Batch size: 12, Momentum: 0.000e+00\n",
      "Initial loss:  558027.6943059554\n",
      "best loss: 553.72\t\tLearning rate: 8.859e-08, Batch size: 22, Momentum: 2.629e-01\n",
      "Initial loss:  1590029.3943184\n",
      "best loss: 495.19\t\tLearning rate: 6.952e-06, Batch size: 42, Momentum: 2.629e-01\n",
      "Initial loss:  1758579.9573815498\n",
      "best loss: 1049.70\t\tLearning rate: 1.438e-02, Batch size: 12, Momentum: 3.681e-01\n",
      "Initial loss:  2157294.504993696\n",
      "best loss: 1060.28\t\tLearning rate: 4.281e-02, Batch size: 24, Momentum: 5.258e-02\n",
      "Initial loss:  851265.3266548506\n",
      "best loss: 865.44\t\tLearning rate: 2.637e-07, Batch size: 24, Momentum: 3.155e-01\n",
      "Initial loss:  533123.2209634349\n",
      "best loss: 1027.55\t\tLearning rate: 4.833e-03, Batch size: 42, Momentum: 5.258e-01\n",
      "Initial loss:  1422780.4384637168\n",
      "best loss: 516.23\t\tLearning rate: 6.952e-06, Batch size: 39, Momentum: 6.835e-01\n",
      "Initial loss:  1079696.2435204224\n",
      "best loss: 1014.71\t\tLearning rate: 1.624e-03, Batch size: 34, Momentum: 7.361e-01\n",
      "Initial loss:  1978363.1261907145\n",
      "best loss: 496.14\t\tLearning rate: 2.637e-07, Batch size: 42, Momentum: 6.835e-01\n",
      "Initial loss:  1824861.426744937\n",
      "best loss: 1131.34\t\tLearning rate: 2.637e-07, Batch size: 27, Momentum: 1.577e-01\n",
      "Initial loss:  2384091.624088776\n",
      "best loss: 1447.68\t\tLearning rate: 1.000e+01, Batch size: 12, Momentum: 6.835e-01\n",
      "Initial loss:  1170884.5082229197\n",
      "best loss: 1105.13\t\tLearning rate: 4.281e-02, Batch size: 37, Momentum: 3.681e-01\n",
      "Initial loss:  2546918.889352719\n",
      "best loss: 615.37\t\tLearning rate: 2.069e-05, Batch size: 22, Momentum: 0.000e+00\n",
      "Initial loss:  494.56997484639925\n",
      "best loss: 486.20\t\tLearning rate: 2.637e-07, Batch size: 27, Momentum: 5.258e-02\n",
      "Initial loss:  2462214.822109411\n",
      "best loss: 529.42\t\tLearning rate: 2.637e-07, Batch size: 39, Momentum: 3.155e-01\n",
      "Initial loss:  2763186.7276393394\n",
      "best loss: 988.93\t\tLearning rate: 4.833e-03, Batch size: 39, Momentum: 5.784e-01\n",
      "Initial loss:  3072269.2920094943\n",
      "best loss: 495.50\t\tLearning rate: 2.336e-06, Batch size: 39, Momentum: 3.681e-01\n",
      "Initial loss:  2017629.4041711837\n",
      "best loss: 352782.18\t\tLearning rate: 8.859e-08, Batch size: 44, Momentum: 4.732e-01\n",
      "Initial loss:  1187675.5466493287\n",
      "best loss: 1140.82\t\tLearning rate: 1.274e-01, Batch size: 44, Momentum: 3.155e-01\n",
      "Initial loss:  2462107.446626962\n",
      "best loss: 525.81\t\tLearning rate: 6.952e-06, Batch size: 19, Momentum: 6.309e-01\n",
      "Initial loss:  1608041.8073808155\n",
      "best loss: 912.99\t\tLearning rate: 5.456e-04, Batch size: 2, Momentum: 1.577e-01\n",
      "Initial loss:  1797122.5804852387\n",
      "best loss: 1210.26\t\tLearning rate: 3.793e-01, Batch size: 9, Momentum: 1.052e-01\n",
      "Initial loss:  666492.7263512496\n",
      "best loss: 142129.69\t\tLearning rate: 8.859e-08, Batch size: 50, Momentum: 8.938e-01\n",
      "Initial loss:  3816117.6734816856\n",
      "best loss: 493.61\t\tLearning rate: 2.336e-06, Batch size: 47, Momentum: 3.155e-01\n",
      "Initial loss:  1422363.2263370347\n",
      "best loss: 1149.45\t\tLearning rate: 3.793e-01, Batch size: 29, Momentum: 0.000e+00\n",
      "Initial loss:  1709369.6226062446\n",
      "best loss: 671.21\t\tLearning rate: 2.069e-05, Batch size: 19, Momentum: 5.258e-02\n",
      "Initial loss:  2172313.038106201\n",
      "best loss: 1351.70\t\tLearning rate: 3.360e+00, Batch size: 24, Momentum: 4.732e-01\n",
      "Initial loss:  495.21887595850166\n",
      "best loss: 487.49\t\tLearning rate: 3.360e+00, Batch size: 9, Momentum: 8.938e-01\n",
      "Initial loss:  2653452.997514815\n",
      "best loss: 1251.01\t\tLearning rate: 2.637e-07, Batch size: 32, Momentum: 7.361e-01\n",
      "Initial loss:  1588484.055197193\n",
      "best loss: 789.08\t\tLearning rate: 1.833e-04, Batch size: 9, Momentum: 7.361e-01\n",
      "Initial loss:  510.7678462404426\n",
      "best loss: 492.88\t\tLearning rate: 3.360e+00, Batch size: 24, Momentum: 8.413e-01\n",
      "Initial loss:  2566769.849246158\n",
      "best loss: 491.44\t\tLearning rate: 7.848e-07, Batch size: 12, Momentum: 6.835e-01\n",
      "Initial loss:  194803.5463584927\n",
      "best loss: 493.94\t\tLearning rate: 6.952e-06, Batch size: 22, Momentum: 3.681e-01\n",
      "Initial loss:  2889464.4457650995\n",
      "best loss: 1151.00\t\tLearning rate: 1.438e-02, Batch size: 39, Momentum: 9.464e-01\n",
      "Initial loss:  2538753.0398679036\n",
      "best loss: 707.15\t\tLearning rate: 2.069e-05, Batch size: 27, Momentum: 8.938e-01\n",
      "Initial loss:  3637432.972058273\n",
      "best loss: 1194.50\t\tLearning rate: 4.281e-02, Batch size: 17, Momentum: 8.938e-01\n",
      "Initial loss:  493.1512152584286\n",
      "best loss: 491.35\t\tLearning rate: 1.624e-03, Batch size: 27, Momentum: 8.413e-01\n",
      "Initial loss:  1052375.4961112665\n",
      "best loss: 1160.37\t\tLearning rate: 1.274e-01, Batch size: 42, Momentum: 2.103e-01\n",
      "Initial loss:  2131609.990151467\n",
      "best loss: 498.36\t\tLearning rate: 2.069e-05, Batch size: 24, Momentum: 9.464e-01\n",
      "Initial loss:  3337663.0703781755\n",
      "best loss: 1281.97\t\tLearning rate: 3.793e-01, Batch size: 37, Momentum: 6.835e-01\n",
      "Initial loss:  2718192.524174539\n",
      "best loss: 92372.38\t\tLearning rate: 2.976e-08, Batch size: 37, Momentum: 6.309e-01\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/hpinkard_waller/GitRepos/EncodingInformation/modeling_and_mi_estimation/optimizing_gaussian_fits DPC_Right.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bwaller-fuoco.eecs.berkeley.edu/home/hpinkard_waller/GitRepos/EncodingInformation/modeling_and_mi_estimation/optimizing_gaussian_fits%20DPC_Right.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, (learning_rate, batch_size, momentum) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(hyperparameter_tuples):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bwaller-fuoco.eecs.berkeley.edu/home/hpinkard_waller/GitRepos/EncodingInformation/modeling_and_mi_estimation/optimizing_gaussian_fits%20DPC_Right.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m     best_hp_loss \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39minf\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bwaller-fuoco.eecs.berkeley.edu/home/hpinkard_waller/GitRepos/EncodingInformation/modeling_and_mi_estimation/optimizing_gaussian_fits%20DPC_Right.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m     patches \u001b[39m=\u001b[39m extract_patches(images, patch_size, num_patches\u001b[39m=\u001b[39;49mnum_patches, seed\u001b[39m=\u001b[39;49mi)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bwaller-fuoco.eecs.berkeley.edu/home/hpinkard_waller/GitRepos/EncodingInformation/modeling_and_mi_estimation/optimizing_gaussian_fits%20DPC_Right.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m     best_cov_mat, cov_mat_initial, mean_vec, best_loss \u001b[39m=\u001b[39m run_optimization(patches, momentum, learning_rate, batch_size, eigenvalue_floor\u001b[39m=\u001b[39m\u001b[39m1e-3\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bwaller-fuoco.eecs.berkeley.edu/home/hpinkard_waller/GitRepos/EncodingInformation/modeling_and_mi_estimation/optimizing_gaussian_fits%20DPC_Right.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m     \u001b[39mif\u001b[39;00m best_loss \u001b[39m<\u001b[39m best_hp_loss:\n",
      "File \u001b[0;32m~/GitRepos/EncodingInformation/image_utils.py:68\u001b[0m, in \u001b[0;36mextract_patches\u001b[0;34m(stack, patch_size, num_patches, seed, verbose)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m iterator:\n\u001b[1;32m     67\u001b[0m     patches\u001b[39m.\u001b[39mappend(stack[image_indices[i], x_indices[i]:x_indices[i]\u001b[39m+\u001b[39mpatch_size, y_indices[i]:y_indices[i]\u001b[39m+\u001b[39mpatch_size])\n\u001b[0;32m---> 68\u001b[0m \u001b[39mreturn\u001b[39;00m jax\u001b[39m.\u001b[39;49mnumpy\u001b[39m.\u001b[39;49marray(patches)\n",
      "File \u001b[0;32m~/mambaforge/envs/phenotypes/lib/python3.10/site-packages/jax/_src/numpy/lax_numpy.py:1980\u001b[0m, in \u001b[0;36marray\u001b[0;34m(object, dtype, copy, order, ndmin)\u001b[0m\n\u001b[1;32m   1978\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mobject\u001b[39m, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)):\n\u001b[1;32m   1979\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mobject\u001b[39m:\n\u001b[0;32m-> 1980\u001b[0m     out \u001b[39m=\u001b[39m stack([asarray(elt, dtype\u001b[39m=\u001b[39;49mdtype) \u001b[39mfor\u001b[39;49;00m elt \u001b[39min\u001b[39;49;00m \u001b[39mobject\u001b[39;49m])\n\u001b[1;32m   1981\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1982\u001b[0m     out \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([], dtype\u001b[39m=\u001b[39mdtype)\n",
      "File \u001b[0;32m~/mambaforge/envs/phenotypes/lib/python3.10/site-packages/jax/_src/numpy/lax_numpy.py:1716\u001b[0m, in \u001b[0;36mstack\u001b[0;34m(arrays, axis, out, dtype)\u001b[0m\n\u001b[1;32m   1714\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mAll input arrays must have the same shape.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1715\u001b[0m   new_arrays\u001b[39m.\u001b[39mappend(expand_dims(a, axis))\n\u001b[0;32m-> 1716\u001b[0m \u001b[39mreturn\u001b[39;00m concatenate(new_arrays, axis\u001b[39m=\u001b[39;49maxis, dtype\u001b[39m=\u001b[39;49mdtype)\n",
      "File \u001b[0;32m~/mambaforge/envs/phenotypes/lib/python3.10/site-packages/jax/_src/numpy/lax_numpy.py:1755\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(arrays, axis, dtype)\u001b[0m\n\u001b[1;32m   1753\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(arrays, (np\u001b[39m.\u001b[39mndarray, Array)):\n\u001b[1;32m   1754\u001b[0m   \u001b[39mreturn\u001b[39;00m _concatenate_array(arrays, axis, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[0;32m-> 1755\u001b[0m util\u001b[39m.\u001b[39m_stackable(\u001b[39m*\u001b[39marrays) \u001b[39mor\u001b[39;00m util\u001b[39m.\u001b[39;49mcheck_arraylike(\u001b[39m\"\u001b[39;49m\u001b[39mconcatenate\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49marrays)\n\u001b[1;32m   1756\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mlen\u001b[39m(arrays):\n\u001b[1;32m   1757\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNeed at least one array to concatenate.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/mambaforge/envs/phenotypes/lib/python3.10/site-packages/jax/_src/numpy/util.py:339\u001b[0m, in \u001b[0;36mcheck_arraylike\u001b[0;34m(fun_name, *args)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[39m\"\"\"Check if all args fit JAX's definition of arraylike.\"\"\"\u001b[39;00m\n\u001b[1;32m    338\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(fun_name, \u001b[39mstr\u001b[39m), \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfun_name must be a string. Got \u001b[39m\u001b[39m{\u001b[39;00mfun_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 339\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39many\u001b[39;49m(\u001b[39mnot\u001b[39;49;00m _arraylike(arg) \u001b[39mfor\u001b[39;49;00m arg \u001b[39min\u001b[39;49;00m args):\n\u001b[1;32m    340\u001b[0m   pos, arg \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m((i, arg) \u001b[39mfor\u001b[39;00m i, arg \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(args)\n\u001b[1;32m    341\u001b[0m                   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _arraylike(arg))\n\u001b[1;32m    342\u001b[0m   msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m requires ndarray or scalar arguments, got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m at position \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/mambaforge/envs/phenotypes/lib/python3.10/site-packages/jax/_src/numpy/util.py:339\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[39m\"\"\"Check if all args fit JAX's definition of arraylike.\"\"\"\u001b[39;00m\n\u001b[1;32m    338\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(fun_name, \u001b[39mstr\u001b[39m), \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfun_name must be a string. Got \u001b[39m\u001b[39m{\u001b[39;00mfun_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 339\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39mnot\u001b[39;00m _arraylike(arg) \u001b[39mfor\u001b[39;00m arg \u001b[39min\u001b[39;00m args):\n\u001b[1;32m    340\u001b[0m   pos, arg \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m((i, arg) \u001b[39mfor\u001b[39;00m i, arg \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(args)\n\u001b[1;32m    341\u001b[0m                   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _arraylike(arg))\n\u001b[1;32m    342\u001b[0m   msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m requires ndarray or scalar arguments, got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m at position \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learning_rates = np.logspace(1, -8, 20)\n",
    "batch_sizes = np.linspace(2, 50, 20).astype(int)\n",
    "momentums = np.linspace(0, 0.999, 20)\n",
    "\n",
    "# generate tuples of random hyperparameters\n",
    "hyperparameter_tuples = []\n",
    "for i in range(10000):\n",
    "    lr = onp.random.choice(learning_rates)\n",
    "    bs = onp.random.choice(batch_sizes)\n",
    "    m = onp.random.choice(momentums)\n",
    "    hyperparameter_tuples.append((lr, bs, m))\n",
    "\n",
    "results = {}\n",
    "for i, (learning_rate, batch_size, momentum) in enumerate(hyperparameter_tuples):\n",
    "    best_hp_loss = np.inf\n",
    "\n",
    "    patches = extract_patches(images, patch_size, num_patches=num_patches, seed=i)\n",
    "    best_cov_mat, cov_mat_initial, mean_vec, best_loss = run_optimization(patches, momentum, learning_rate, batch_size, eigenvalue_floor=1e-3)\n",
    "\n",
    "    if best_loss < best_hp_loss:\n",
    "        best_hp_loss = best_loss\n",
    "        best_hp = (learning_rate, batch_size, momentum)\n",
    "        \n",
    "    # collect results\n",
    "    results[(learning_rate, batch_size, momentum)] = best_loss\n",
    "\n",
    "    # print hyperparameters and their best loss\n",
    "    print(f\"best loss: {best_loss:.2f}\\t\\tLearning rate: {learning_rate:.3e}, Batch size: {batch_size}, Momentum: {momentum:.3e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best loss: 469.85\t\tLearning rate: 8.859e-08, Batch size: 2, Momentum: 7.361e-01\n",
      "best loss: 474.07\t\tLearning rate: 2.336e-06, Batch size: 2, Momentum: 2.103e-01\n",
      "best loss: 474.78\t\tLearning rate: 7.848e-07, Batch size: 2, Momentum: 7.361e-01\n",
      "best loss: 475.45\t\tLearning rate: 7.848e-07, Batch size: 2, Momentum: 2.629e-01\n",
      "best loss: 476.66\t\tLearning rate: 2.637e-07, Batch size: 4, Momentum: 1.577e-01\n",
      "best loss: 476.98\t\tLearning rate: 2.336e-06, Batch size: 4, Momentum: 4.206e-01\n",
      "best loss: 478.56\t\tLearning rate: 7.848e-07, Batch size: 4, Momentum: 6.309e-01\n",
      "best loss: 479.31\t\tLearning rate: 4.281e-02, Batch size: 4, Momentum: 8.938e-01\n",
      "best loss: 479.35\t\tLearning rate: 2.637e-07, Batch size: 4, Momentum: 4.206e-01\n",
      "best loss: 479.43\t\tLearning rate: 6.158e-05, Batch size: 2, Momentum: 3.155e-01\n",
      "best loss: 479.46\t\tLearning rate: 7.848e-07, Batch size: 4, Momentum: 6.835e-01\n",
      "best loss: 479.51\t\tLearning rate: 6.952e-06, Batch size: 2, Momentum: 5.258e-01\n",
      "best loss: 479.73\t\tLearning rate: 6.952e-06, Batch size: 2, Momentum: 5.258e-02\n",
      "best loss: 479.83\t\tLearning rate: 2.336e-06, Batch size: 4, Momentum: 5.784e-01\n",
      "best loss: 480.32\t\tLearning rate: 2.976e-08, Batch size: 2, Momentum: 6.309e-01\n",
      "best loss: 481.66\t\tLearning rate: 2.637e-07, Batch size: 7, Momentum: 9.464e-01\n",
      "best loss: 481.86\t\tLearning rate: 2.336e-06, Batch size: 2, Momentum: 1.577e-01\n",
      "best loss: 482.61\t\tLearning rate: 2.637e-07, Batch size: 4, Momentum: 5.784e-01\n",
      "best loss: 482.99\t\tLearning rate: 2.336e-06, Batch size: 7, Momentum: 7.361e-01\n",
      "best loss: 484.13\t\tLearning rate: 8.859e-08, Batch size: 2, Momentum: 3.155e-01\n",
      "best loss: 484.51\t\tLearning rate: 2.637e-07, Batch size: 14, Momentum: 9.990e-01\n",
      "best loss: 484.52\t\tLearning rate: 7.848e-07, Batch size: 12, Momentum: 2.629e-01\n",
      "best loss: 484.71\t\tLearning rate: 2.637e-07, Batch size: 9, Momentum: 8.938e-01\n",
      "best loss: 484.99\t\tLearning rate: 2.336e-06, Batch size: 9, Momentum: 1.052e-01\n",
      "best loss: 484.99\t\tLearning rate: 1.000e+01, Batch size: 22, Momentum: 3.681e-01\n",
      "best loss: 485.23\t\tLearning rate: 2.336e-06, Batch size: 9, Momentum: 2.629e-01\n",
      "best loss: 485.47\t\tLearning rate: 3.360e+00, Batch size: 9, Momentum: 9.990e-01\n",
      "best loss: 485.73\t\tLearning rate: 7.848e-07, Batch size: 9, Momentum: 2.629e-01\n",
      "best loss: 485.94\t\tLearning rate: 6.158e-05, Batch size: 7, Momentum: 0.000e+00\n",
      "best loss: 486.18\t\tLearning rate: 6.952e-06, Batch size: 12, Momentum: 4.732e-01\n",
      "best loss: 486.19\t\tLearning rate: 7.848e-07, Batch size: 7, Momentum: 6.835e-01\n",
      "best loss: 486.20\t\tLearning rate: 2.637e-07, Batch size: 27, Momentum: 5.258e-02\n",
      "best loss: 486.66\t\tLearning rate: 3.793e-01, Batch size: 22, Momentum: 7.887e-01\n",
      "best loss: 486.91\t\tLearning rate: 1.129e+00, Batch size: 9, Momentum: 2.629e-01\n",
      "best loss: 486.94\t\tLearning rate: 7.848e-07, Batch size: 17, Momentum: 6.835e-01\n",
      "best loss: 487.06\t\tLearning rate: 7.848e-07, Batch size: 2, Momentum: 7.887e-01\n",
      "best loss: 487.25\t\tLearning rate: 8.859e-08, Batch size: 14, Momentum: 9.990e-01\n",
      "best loss: 487.29\t\tLearning rate: 6.952e-06, Batch size: 22, Momentum: 2.103e-01\n",
      "best loss: 487.40\t\tLearning rate: 7.848e-07, Batch size: 27, Momentum: 5.784e-01\n",
      "best loss: 487.49\t\tLearning rate: 3.360e+00, Batch size: 9, Momentum: 8.938e-01\n",
      "best loss: 487.52\t\tLearning rate: 3.360e+00, Batch size: 37, Momentum: 3.155e-01\n",
      "best loss: 487.69\t\tLearning rate: 6.158e-05, Batch size: 7, Momentum: 4.206e-01\n",
      "best loss: 487.84\t\tLearning rate: 1.129e+00, Batch size: 29, Momentum: 9.464e-01\n",
      "best loss: 487.85\t\tLearning rate: 4.833e-03, Batch size: 14, Momentum: 6.309e-01\n",
      "best loss: 488.03\t\tLearning rate: 1.438e-02, Batch size: 27, Momentum: 2.103e-01\n",
      "best loss: 488.08\t\tLearning rate: 6.158e-05, Batch size: 34, Momentum: 2.629e-01\n",
      "best loss: 488.31\t\tLearning rate: 2.336e-06, Batch size: 14, Momentum: 4.732e-01\n",
      "best loss: 488.32\t\tLearning rate: 7.848e-07, Batch size: 19, Momentum: 6.309e-01\n",
      "best loss: 488.59\t\tLearning rate: 2.336e-06, Batch size: 14, Momentum: 3.681e-01\n",
      "best loss: 488.61\t\tLearning rate: 7.848e-07, Batch size: 22, Momentum: 5.784e-01\n",
      "best loss: 488.71\t\tLearning rate: 2.336e-06, Batch size: 22, Momentum: 4.206e-01\n",
      "best loss: 488.75\t\tLearning rate: 6.952e-06, Batch size: 19, Momentum: 2.629e-01\n",
      "best loss: 488.77\t\tLearning rate: 2.336e-06, Batch size: 12, Momentum: 4.206e-01\n",
      "best loss: 488.85\t\tLearning rate: 7.848e-07, Batch size: 29, Momentum: 9.464e-01\n",
      "best loss: 488.87\t\tLearning rate: 7.848e-07, Batch size: 12, Momentum: 9.464e-01\n",
      "best loss: 488.88\t\tLearning rate: 5.456e-04, Batch size: 42, Momentum: 3.155e-01\n",
      "best loss: 488.97\t\tLearning rate: 2.336e-06, Batch size: 22, Momentum: 3.681e-01\n",
      "best loss: 489.06\t\tLearning rate: 3.793e-01, Batch size: 14, Momentum: 2.629e-01\n",
      "best loss: 489.06\t\tLearning rate: 6.158e-05, Batch size: 27, Momentum: 2.629e-01\n",
      "best loss: 489.07\t\tLearning rate: 5.456e-04, Batch size: 32, Momentum: 5.258e-02\n",
      "best loss: 489.13\t\tLearning rate: 7.848e-07, Batch size: 17, Momentum: 7.887e-01\n",
      "best loss: 489.17\t\tLearning rate: 2.637e-07, Batch size: 24, Momentum: 9.464e-01\n",
      "best loss: 489.18\t\tLearning rate: 1.274e-01, Batch size: 12, Momentum: 0.000e+00\n",
      "best loss: 489.23\t\tLearning rate: 2.336e-06, Batch size: 9, Momentum: 6.835e-01\n",
      "best loss: 489.26\t\tLearning rate: 7.848e-07, Batch size: 12, Momentum: 1.577e-01\n",
      "best loss: 489.40\t\tLearning rate: 7.848e-07, Batch size: 22, Momentum: 7.887e-01\n",
      "best loss: 489.43\t\tLearning rate: 7.848e-07, Batch size: 34, Momentum: 6.835e-01\n",
      "best loss: 489.50\t\tLearning rate: 2.637e-07, Batch size: 32, Momentum: 6.835e-01\n",
      "best loss: 489.52\t\tLearning rate: 6.952e-06, Batch size: 14, Momentum: 4.732e-01\n",
      "best loss: 489.53\t\tLearning rate: 6.952e-06, Batch size: 17, Momentum: 2.629e-01\n",
      "best loss: 489.56\t\tLearning rate: 6.158e-05, Batch size: 32, Momentum: 5.258e-01\n",
      "best loss: 489.56\t\tLearning rate: 2.336e-06, Batch size: 22, Momentum: 6.835e-01\n",
      "best loss: 489.72\t\tLearning rate: 7.848e-07, Batch size: 14, Momentum: 8.413e-01\n",
      "best loss: 489.73\t\tLearning rate: 5.456e-04, Batch size: 32, Momentum: 7.361e-01\n",
      "best loss: 489.87\t\tLearning rate: 6.952e-06, Batch size: 27, Momentum: 0.000e+00\n",
      "best loss: 489.87\t\tLearning rate: 4.281e-02, Batch size: 19, Momentum: 7.887e-01\n",
      "best loss: 489.89\t\tLearning rate: 2.637e-07, Batch size: 24, Momentum: 0.000e+00\n",
      "best loss: 489.90\t\tLearning rate: 1.000e+01, Batch size: 34, Momentum: 8.413e-01\n",
      "best loss: 489.90\t\tLearning rate: 4.833e-03, Batch size: 29, Momentum: 3.155e-01\n",
      "best loss: 489.99\t\tLearning rate: 1.000e-08, Batch size: 19, Momentum: 9.990e-01\n",
      "best loss: 490.03\t\tLearning rate: 4.833e-03, Batch size: 32, Momentum: 6.309e-01\n",
      "best loss: 490.08\t\tLearning rate: 2.976e-08, Batch size: 22, Momentum: 9.990e-01\n",
      "best loss: 490.21\t\tLearning rate: 1.000e-08, Batch size: 27, Momentum: 4.206e-01\n",
      "best loss: 490.41\t\tLearning rate: 7.848e-07, Batch size: 42, Momentum: 6.835e-01\n",
      "best loss: 490.61\t\tLearning rate: 6.158e-05, Batch size: 32, Momentum: 2.103e-01\n",
      "best loss: 490.65\t\tLearning rate: 6.952e-06, Batch size: 42, Momentum: 4.206e-01\n",
      "best loss: 490.92\t\tLearning rate: 2.336e-06, Batch size: 19, Momentum: 5.784e-01\n",
      "best loss: 490.99\t\tLearning rate: 2.976e-08, Batch size: 7, Momentum: 7.361e-01\n",
      "best loss: 491.00\t\tLearning rate: 2.637e-07, Batch size: 47, Momentum: 9.990e-01\n",
      "best loss: 491.07\t\tLearning rate: 2.336e-06, Batch size: 22, Momentum: 2.103e-01\n",
      "best loss: 491.09\t\tLearning rate: 6.158e-05, Batch size: 27, Momentum: 4.206e-01\n",
      "best loss: 491.19\t\tLearning rate: 1.274e-01, Batch size: 32, Momentum: 1.577e-01\n",
      "best loss: 491.19\t\tLearning rate: 6.952e-06, Batch size: 24, Momentum: 3.681e-01\n",
      "best loss: 491.20\t\tLearning rate: 2.336e-06, Batch size: 24, Momentum: 7.361e-01\n",
      "best loss: 491.21\t\tLearning rate: 1.000e+01, Batch size: 47, Momentum: 9.464e-01\n",
      "best loss: 491.21\t\tLearning rate: 2.336e-06, Batch size: 44, Momentum: 7.361e-01\n",
      "best loss: 491.21\t\tLearning rate: 2.336e-06, Batch size: 7, Momentum: 9.464e-01\n",
      "best loss: 491.23\t\tLearning rate: 7.848e-07, Batch size: 19, Momentum: 5.258e-01\n",
      "best loss: 491.32\t\tLearning rate: 1.000e-08, Batch size: 19, Momentum: 0.000e+00\n",
      "best loss: 491.35\t\tLearning rate: 1.624e-03, Batch size: 27, Momentum: 8.413e-01\n",
      "best loss: 491.36\t\tLearning rate: 2.336e-06, Batch size: 19, Momentum: 2.629e-01\n",
      "best loss: 491.44\t\tLearning rate: 7.848e-07, Batch size: 12, Momentum: 6.835e-01\n",
      "best loss: 491.44\t\tLearning rate: 5.456e-04, Batch size: 27, Momentum: 5.784e-01\n",
      "best loss: 491.45\t\tLearning rate: 8.859e-08, Batch size: 14, Momentum: 7.887e-01\n",
      "best loss: 491.61\t\tLearning rate: 2.336e-06, Batch size: 50, Momentum: 5.784e-01\n",
      "best loss: 491.79\t\tLearning rate: 7.848e-07, Batch size: 44, Momentum: 1.577e-01\n",
      "best loss: 491.82\t\tLearning rate: 1.274e-01, Batch size: 47, Momentum: 3.155e-01\n",
      "best loss: 491.82\t\tLearning rate: 1.000e-08, Batch size: 44, Momentum: 9.990e-01\n",
      "best loss: 491.85\t\tLearning rate: 2.976e-08, Batch size: 37, Momentum: 1.052e-01\n",
      "best loss: 491.94\t\tLearning rate: 7.848e-07, Batch size: 50, Momentum: 4.732e-01\n",
      "best loss: 492.03\t\tLearning rate: 2.336e-06, Batch size: 12, Momentum: 1.577e-01\n",
      "best loss: 492.06\t\tLearning rate: 2.336e-06, Batch size: 32, Momentum: 4.732e-01\n",
      "best loss: 492.15\t\tLearning rate: 7.848e-07, Batch size: 44, Momentum: 5.258e-02\n",
      "best loss: 492.16\t\tLearning rate: 2.336e-06, Batch size: 44, Momentum: 3.155e-01\n",
      "best loss: 492.17\t\tLearning rate: 2.637e-07, Batch size: 29, Momentum: 9.990e-01\n",
      "best loss: 492.19\t\tLearning rate: 2.336e-06, Batch size: 9, Momentum: 6.309e-01\n",
      "best loss: 492.19\t\tLearning rate: 2.336e-06, Batch size: 17, Momentum: 2.103e-01\n",
      "best loss: 492.32\t\tLearning rate: 5.456e-04, Batch size: 39, Momentum: 5.258e-02\n",
      "best loss: 492.33\t\tLearning rate: 2.336e-06, Batch size: 39, Momentum: 1.577e-01\n",
      "best loss: 492.34\t\tLearning rate: 7.848e-07, Batch size: 4, Momentum: 0.000e+00\n",
      "best loss: 492.48\t\tLearning rate: 7.848e-07, Batch size: 7, Momentum: 5.258e-02\n",
      "best loss: 492.61\t\tLearning rate: 7.848e-07, Batch size: 29, Momentum: 6.309e-01\n",
      "best loss: 492.63\t\tLearning rate: 7.848e-07, Batch size: 32, Momentum: 5.258e-01\n",
      "best loss: 492.67\t\tLearning rate: 8.859e-08, Batch size: 2, Momentum: 6.309e-01\n",
      "best loss: 492.71\t\tLearning rate: 7.848e-07, Batch size: 14, Momentum: 1.052e-01\n",
      "best loss: 492.74\t\tLearning rate: 2.336e-06, Batch size: 42, Momentum: 7.887e-01\n",
      "best loss: 492.76\t\tLearning rate: 7.848e-07, Batch size: 34, Momentum: 5.258e-01\n",
      "best loss: 492.84\t\tLearning rate: 7.848e-07, Batch size: 39, Momentum: 7.887e-01\n",
      "best loss: 492.88\t\tLearning rate: 3.360e+00, Batch size: 24, Momentum: 8.413e-01\n",
      "best loss: 492.89\t\tLearning rate: 7.848e-07, Batch size: 9, Momentum: 6.835e-01\n",
      "best loss: 492.92\t\tLearning rate: 2.637e-07, Batch size: 37, Momentum: 9.464e-01\n",
      "best loss: 492.92\t\tLearning rate: 1.274e-01, Batch size: 12, Momentum: 4.732e-01\n",
      "best loss: 493.03\t\tLearning rate: 2.336e-06, Batch size: 39, Momentum: 8.413e-01\n",
      "best loss: 493.09\t\tLearning rate: 5.456e-04, Batch size: 44, Momentum: 1.577e-01\n",
      "best loss: 493.10\t\tLearning rate: 6.952e-06, Batch size: 47, Momentum: 5.258e-01\n",
      "best loss: 493.26\t\tLearning rate: 2.069e-05, Batch size: 19, Momentum: 1.577e-01\n",
      "best loss: 493.27\t\tLearning rate: 2.637e-07, Batch size: 17, Momentum: 9.990e-01\n",
      "best loss: 493.31\t\tLearning rate: 2.336e-06, Batch size: 14, Momentum: 0.000e+00\n",
      "best loss: 493.47\t\tLearning rate: 1.000e-08, Batch size: 12, Momentum: 9.464e-01\n",
      "best loss: 493.47\t\tLearning rate: 2.336e-06, Batch size: 27, Momentum: 2.629e-01\n",
      "best loss: 493.48\t\tLearning rate: 2.637e-07, Batch size: 22, Momentum: 9.464e-01\n",
      "best loss: 493.61\t\tLearning rate: 2.336e-06, Batch size: 47, Momentum: 3.155e-01\n",
      "best loss: 493.61\t\tLearning rate: 2.976e-08, Batch size: 29, Momentum: 9.990e-01\n",
      "best loss: 493.66\t\tLearning rate: 7.848e-07, Batch size: 34, Momentum: 7.361e-01\n",
      "best loss: 493.72\t\tLearning rate: 6.952e-06, Batch size: 44, Momentum: 1.052e-01\n",
      "best loss: 493.72\t\tLearning rate: 7.848e-07, Batch size: 50, Momentum: 8.413e-01\n",
      "best loss: 493.82\t\tLearning rate: 4.833e-03, Batch size: 19, Momentum: 1.052e-01\n",
      "best loss: 493.87\t\tLearning rate: 7.848e-07, Batch size: 12, Momentum: 5.784e-01\n",
      "best loss: 493.94\t\tLearning rate: 6.952e-06, Batch size: 22, Momentum: 3.681e-01\n",
      "best loss: 494.05\t\tLearning rate: 2.637e-07, Batch size: 29, Momentum: 6.309e-01\n",
      "best loss: 494.15\t\tLearning rate: 2.336e-06, Batch size: 27, Momentum: 4.732e-01\n",
      "best loss: 494.23\t\tLearning rate: 2.637e-07, Batch size: 24, Momentum: 5.258e-01\n",
      "best loss: 494.39\t\tLearning rate: 2.336e-06, Batch size: 32, Momentum: 5.258e-02\n",
      "best loss: 494.40\t\tLearning rate: 2.336e-06, Batch size: 17, Momentum: 7.887e-01\n",
      "best loss: 494.43\t\tLearning rate: 7.848e-07, Batch size: 37, Momentum: 8.938e-01\n",
      "best loss: 494.44\t\tLearning rate: 2.336e-06, Batch size: 29, Momentum: 5.258e-01\n",
      "best loss: 494.45\t\tLearning rate: 2.336e-06, Batch size: 34, Momentum: 5.258e-01\n",
      "best loss: 494.61\t\tLearning rate: 1.000e-08, Batch size: 7, Momentum: 8.413e-01\n",
      "best loss: 494.66\t\tLearning rate: 6.952e-06, Batch size: 24, Momentum: 5.784e-01\n",
      "best loss: 494.71\t\tLearning rate: 2.637e-07, Batch size: 32, Momentum: 6.309e-01\n",
      "best loss: 494.87\t\tLearning rate: 1.000e-08, Batch size: 2, Momentum: 6.835e-01\n",
      "best loss: 494.96\t\tLearning rate: 6.952e-06, Batch size: 50, Momentum: 2.629e-01\n",
      "best loss: 495.02\t\tLearning rate: 6.952e-06, Batch size: 44, Momentum: 7.361e-01\n",
      "best loss: 495.16\t\tLearning rate: 7.848e-07, Batch size: 50, Momentum: 9.464e-01\n",
      "best loss: 495.18\t\tLearning rate: 7.848e-07, Batch size: 42, Momentum: 2.629e-01\n",
      "best loss: 495.19\t\tLearning rate: 6.952e-06, Batch size: 42, Momentum: 2.629e-01\n",
      "best loss: 495.19\t\tLearning rate: 2.976e-08, Batch size: 27, Momentum: 8.938e-01\n",
      "best loss: 495.31\t\tLearning rate: 2.976e-08, Batch size: 9, Momentum: 7.361e-01\n",
      "best loss: 495.39\t\tLearning rate: 7.848e-07, Batch size: 50, Momentum: 4.206e-01\n",
      "best loss: 495.50\t\tLearning rate: 2.336e-06, Batch size: 39, Momentum: 3.681e-01\n",
      "best loss: 495.53\t\tLearning rate: 2.637e-07, Batch size: 12, Momentum: 1.577e-01\n",
      "best loss: 495.78\t\tLearning rate: 2.637e-07, Batch size: 39, Momentum: 9.990e-01\n",
      "best loss: 495.92\t\tLearning rate: 7.848e-07, Batch size: 37, Momentum: 5.784e-01\n",
      "best loss: 495.93\t\tLearning rate: 2.336e-06, Batch size: 29, Momentum: 1.577e-01\n",
      "best loss: 496.06\t\tLearning rate: 2.637e-07, Batch size: 22, Momentum: 3.155e-01\n",
      "best loss: 496.14\t\tLearning rate: 2.637e-07, Batch size: 42, Momentum: 6.835e-01\n",
      "best loss: 496.31\t\tLearning rate: 2.336e-06, Batch size: 17, Momentum: 8.938e-01\n",
      "best loss: 496.66\t\tLearning rate: 7.848e-07, Batch size: 22, Momentum: 9.990e-01\n",
      "best loss: 496.67\t\tLearning rate: 2.637e-07, Batch size: 37, Momentum: 9.990e-01\n",
      "best loss: 496.68\t\tLearning rate: 6.952e-06, Batch size: 37, Momentum: 9.464e-01\n",
      "best loss: 496.71\t\tLearning rate: 6.952e-06, Batch size: 12, Momentum: 5.784e-01\n",
      "best loss: 497.04\t\tLearning rate: 2.976e-08, Batch size: 44, Momentum: 9.464e-01\n",
      "best loss: 497.15\t\tLearning rate: 2.976e-08, Batch size: 7, Momentum: 8.413e-01\n",
      "best loss: 497.36\t\tLearning rate: 2.637e-07, Batch size: 47, Momentum: 8.938e-01\n",
      "best loss: 497.74\t\tLearning rate: 2.336e-06, Batch size: 37, Momentum: 6.835e-01\n",
      "best loss: 498.01\t\tLearning rate: 7.848e-07, Batch size: 34, Momentum: 8.938e-01\n",
      "best loss: 498.02\t\tLearning rate: 6.952e-06, Batch size: 24, Momentum: 7.887e-01\n",
      "best loss: 498.03\t\tLearning rate: 6.952e-06, Batch size: 44, Momentum: 5.258e-02\n",
      "best loss: 498.36\t\tLearning rate: 2.336e-06, Batch size: 22, Momentum: 6.309e-01\n",
      "best loss: 498.36\t\tLearning rate: 2.069e-05, Batch size: 24, Momentum: 9.464e-01\n",
      "best loss: 498.45\t\tLearning rate: 2.336e-06, Batch size: 12, Momentum: 2.629e-01\n",
      "best loss: 498.46\t\tLearning rate: 6.952e-06, Batch size: 12, Momentum: 9.464e-01\n",
      "best loss: 498.51\t\tLearning rate: 6.952e-06, Batch size: 47, Momentum: 5.258e-02\n",
      "best loss: 498.63\t\tLearning rate: 6.952e-06, Batch size: 34, Momentum: 5.784e-01\n",
      "best loss: 498.84\t\tLearning rate: 8.859e-08, Batch size: 44, Momentum: 7.361e-01\n",
      "best loss: 498.86\t\tLearning rate: 8.859e-08, Batch size: 37, Momentum: 9.990e-01\n",
      "best loss: 498.97\t\tLearning rate: 2.336e-06, Batch size: 24, Momentum: 3.681e-01\n",
      "best loss: 499.02\t\tLearning rate: 6.952e-06, Batch size: 27, Momentum: 2.629e-01\n",
      "best loss: 499.04\t\tLearning rate: 7.848e-07, Batch size: 50, Momentum: 8.938e-01\n",
      "best loss: 499.17\t\tLearning rate: 2.336e-06, Batch size: 32, Momentum: 8.413e-01\n",
      "best loss: 499.31\t\tLearning rate: 2.336e-06, Batch size: 7, Momentum: 5.258e-02\n",
      "best loss: 499.39\t\tLearning rate: 7.848e-07, Batch size: 42, Momentum: 5.258e-01\n",
      "best loss: 499.42\t\tLearning rate: 8.859e-08, Batch size: 14, Momentum: 5.784e-01\n",
      "best loss: 499.66\t\tLearning rate: 2.336e-06, Batch size: 37, Momentum: 5.258e-02\n",
      "best loss: 499.67\t\tLearning rate: 2.069e-05, Batch size: 9, Momentum: 8.938e-01\n",
      "best loss: 499.68\t\tLearning rate: 2.976e-08, Batch size: 12, Momentum: 8.938e-01\n",
      "best loss: 499.78\t\tLearning rate: 7.848e-07, Batch size: 19, Momentum: 3.155e-01\n",
      "best loss: 499.86\t\tLearning rate: 8.859e-08, Batch size: 19, Momentum: 6.309e-01\n",
      "best loss: 499.96\t\tLearning rate: 8.859e-08, Batch size: 42, Momentum: 9.990e-01\n",
      "best loss: 500.08\t\tLearning rate: 8.859e-08, Batch size: 29, Momentum: 9.464e-01\n",
      "best loss: 500.20\t\tLearning rate: 2.637e-07, Batch size: 39, Momentum: 4.732e-01\n",
      "best loss: 500.36\t\tLearning rate: 2.637e-07, Batch size: 9, Momentum: 7.361e-01\n",
      "best loss: 500.36\t\tLearning rate: 2.637e-07, Batch size: 50, Momentum: 5.784e-01\n",
      "best loss: 500.45\t\tLearning rate: 6.952e-06, Batch size: 37, Momentum: 8.413e-01\n",
      "best loss: 500.48\t\tLearning rate: 7.848e-07, Batch size: 42, Momentum: 1.052e-01\n",
      "best loss: 500.79\t\tLearning rate: 6.952e-06, Batch size: 32, Momentum: 2.629e-01\n",
      "best loss: 500.89\t\tLearning rate: 7.848e-07, Batch size: 37, Momentum: 4.206e-01\n",
      "best loss: 501.09\t\tLearning rate: 6.952e-06, Batch size: 14, Momentum: 8.413e-01\n",
      "best loss: 501.28\t\tLearning rate: 2.336e-06, Batch size: 29, Momentum: 2.629e-01\n",
      "best loss: 501.53\t\tLearning rate: 3.793e-01, Batch size: 29, Momentum: 2.103e-01\n",
      "best loss: 501.98\t\tLearning rate: 6.952e-06, Batch size: 14, Momentum: 5.784e-01\n",
      "best loss: 502.15\t\tLearning rate: 2.637e-07, Batch size: 17, Momentum: 9.464e-01\n",
      "best loss: 502.41\t\tLearning rate: 7.848e-07, Batch size: 39, Momentum: 5.258e-02\n",
      "best loss: 502.47\t\tLearning rate: 7.848e-07, Batch size: 32, Momentum: 6.835e-01\n",
      "best loss: 502.62\t\tLearning rate: 2.336e-06, Batch size: 24, Momentum: 8.413e-01\n",
      "best loss: 502.66\t\tLearning rate: 2.637e-07, Batch size: 37, Momentum: 5.258e-01\n",
      "best loss: 503.67\t\tLearning rate: 2.336e-06, Batch size: 4, Momentum: 9.990e-01\n",
      "best loss: 503.73\t\tLearning rate: 7.848e-07, Batch size: 9, Momentum: 2.103e-01\n",
      "best loss: 503.84\t\tLearning rate: 6.952e-06, Batch size: 29, Momentum: 4.732e-01\n",
      "best loss: 503.88\t\tLearning rate: 1.000e-08, Batch size: 42, Momentum: 4.206e-01\n",
      "best loss: 503.89\t\tLearning rate: 2.336e-06, Batch size: 47, Momentum: 1.577e-01\n",
      "best loss: 504.23\t\tLearning rate: 2.336e-06, Batch size: 29, Momentum: 6.309e-01\n",
      "best loss: 504.50\t\tLearning rate: 2.637e-07, Batch size: 37, Momentum: 3.681e-01\n",
      "best loss: 504.50\t\tLearning rate: 8.859e-08, Batch size: 12, Momentum: 4.732e-01\n",
      "best loss: 505.01\t\tLearning rate: 6.952e-06, Batch size: 47, Momentum: 8.413e-01\n",
      "best loss: 505.26\t\tLearning rate: 7.848e-07, Batch size: 22, Momentum: 3.155e-01\n",
      "best loss: 505.54\t\tLearning rate: 2.336e-06, Batch size: 39, Momentum: 1.052e-01\n",
      "best loss: 505.74\t\tLearning rate: 7.848e-07, Batch size: 44, Momentum: 4.732e-01\n",
      "best loss: 505.74\t\tLearning rate: 2.637e-07, Batch size: 22, Momentum: 6.309e-01\n",
      "best loss: 505.88\t\tLearning rate: 6.952e-06, Batch size: 24, Momentum: 5.258e-02\n",
      "best loss: 506.28\t\tLearning rate: 6.952e-06, Batch size: 34, Momentum: 0.000e+00\n",
      "best loss: 506.84\t\tLearning rate: 1.000e-08, Batch size: 47, Momentum: 8.413e-01\n",
      "best loss: 506.85\t\tLearning rate: 7.848e-07, Batch size: 24, Momentum: 8.413e-01\n",
      "best loss: 507.28\t\tLearning rate: 7.848e-07, Batch size: 24, Momentum: 5.784e-01\n",
      "best loss: 507.39\t\tLearning rate: 8.859e-08, Batch size: 7, Momentum: 3.155e-01\n",
      "best loss: 507.85\t\tLearning rate: 6.952e-06, Batch size: 50, Momentum: 0.000e+00\n",
      "best loss: 508.04\t\tLearning rate: 7.848e-07, Batch size: 9, Momentum: 3.681e-01\n",
      "best loss: 508.50\t\tLearning rate: 8.859e-08, Batch size: 12, Momentum: 7.361e-01\n",
      "best loss: 508.75\t\tLearning rate: 2.336e-06, Batch size: 22, Momentum: 0.000e+00\n",
      "best loss: 508.82\t\tLearning rate: 2.976e-08, Batch size: 24, Momentum: 8.413e-01\n",
      "best loss: 510.06\t\tLearning rate: 1.000e-08, Batch size: 24, Momentum: 9.464e-01\n",
      "best loss: 510.34\t\tLearning rate: 2.637e-07, Batch size: 12, Momentum: 2.629e-01\n",
      "best loss: 510.35\t\tLearning rate: 6.952e-06, Batch size: 42, Momentum: 9.464e-01\n",
      "best loss: 510.66\t\tLearning rate: 2.336e-06, Batch size: 12, Momentum: 8.938e-01\n",
      "best loss: 510.68\t\tLearning rate: 6.952e-06, Batch size: 29, Momentum: 8.938e-01\n",
      "best loss: 512.03\t\tLearning rate: 2.637e-07, Batch size: 39, Momentum: 7.361e-01\n",
      "best loss: 512.43\t\tLearning rate: 2.336e-06, Batch size: 34, Momentum: 9.990e-01\n",
      "best loss: 513.02\t\tLearning rate: 2.637e-07, Batch size: 47, Momentum: 7.887e-01\n",
      "best loss: 513.45\t\tLearning rate: 6.952e-06, Batch size: 29, Momentum: 7.887e-01\n",
      "best loss: 513.84\t\tLearning rate: 7.848e-07, Batch size: 39, Momentum: 2.629e-01\n",
      "best loss: 514.09\t\tLearning rate: 8.859e-08, Batch size: 42, Momentum: 7.361e-01\n",
      "best loss: 514.37\t\tLearning rate: 7.848e-07, Batch size: 27, Momentum: 1.577e-01\n",
      "best loss: 514.45\t\tLearning rate: 8.859e-08, Batch size: 12, Momentum: 4.206e-01\n",
      "best loss: 514.70\t\tLearning rate: 1.000e-08, Batch size: 12, Momentum: 8.413e-01\n",
      "best loss: 514.94\t\tLearning rate: 1.000e-08, Batch size: 50, Momentum: 8.413e-01\n",
      "best loss: 515.29\t\tLearning rate: 8.859e-08, Batch size: 34, Momentum: 7.361e-01\n",
      "best loss: 515.30\t\tLearning rate: 2.637e-07, Batch size: 39, Momentum: 3.681e-01\n",
      "best loss: 515.51\t\tLearning rate: 7.848e-07, Batch size: 50, Momentum: 2.629e-01\n",
      "best loss: 515.52\t\tLearning rate: 6.952e-06, Batch size: 29, Momentum: 1.052e-01\n",
      "best loss: 515.82\t\tLearning rate: 2.976e-08, Batch size: 34, Momentum: 9.990e-01\n",
      "best loss: 516.23\t\tLearning rate: 6.952e-06, Batch size: 39, Momentum: 6.835e-01\n",
      "best loss: 516.70\t\tLearning rate: 2.069e-05, Batch size: 4, Momentum: 2.629e-01\n",
      "best loss: 517.37\t\tLearning rate: 2.976e-08, Batch size: 7, Momentum: 2.629e-01\n",
      "best loss: 517.64\t\tLearning rate: 2.336e-06, Batch size: 29, Momentum: 0.000e+00\n",
      "best loss: 520.52\t\tLearning rate: 7.848e-07, Batch size: 9, Momentum: 3.155e-01\n",
      "best loss: 522.34\t\tLearning rate: 2.637e-07, Batch size: 22, Momentum: 5.258e-02\n",
      "best loss: 523.15\t\tLearning rate: 8.859e-08, Batch size: 24, Momentum: 6.835e-01\n",
      "best loss: 523.22\t\tLearning rate: 6.952e-06, Batch size: 12, Momentum: 8.938e-01\n",
      "best loss: 524.79\t\tLearning rate: 2.976e-08, Batch size: 34, Momentum: 6.309e-01\n",
      "best loss: 524.93\t\tLearning rate: 2.637e-07, Batch size: 37, Momentum: 6.835e-01\n",
      "best loss: 525.81\t\tLearning rate: 6.952e-06, Batch size: 19, Momentum: 6.309e-01\n",
      "best loss: 528.67\t\tLearning rate: 7.848e-07, Batch size: 47, Momentum: 5.258e-02\n",
      "best loss: 529.28\t\tLearning rate: 2.336e-06, Batch size: 14, Momentum: 2.629e-01\n",
      "best loss: 529.42\t\tLearning rate: 2.637e-07, Batch size: 39, Momentum: 3.155e-01\n",
      "best loss: 530.04\t\tLearning rate: 8.859e-08, Batch size: 7, Momentum: 1.052e-01\n",
      "best loss: 531.00\t\tLearning rate: 6.952e-06, Batch size: 17, Momentum: 5.784e-01\n",
      "best loss: 531.43\t\tLearning rate: 2.637e-07, Batch size: 44, Momentum: 8.413e-01\n",
      "best loss: 531.53\t\tLearning rate: 8.859e-08, Batch size: 12, Momentum: 5.784e-01\n",
      "best loss: 531.66\t\tLearning rate: 2.976e-08, Batch size: 44, Momentum: 3.155e-01\n",
      "best loss: 531.75\t\tLearning rate: 8.859e-08, Batch size: 34, Momentum: 5.258e-01\n",
      "best loss: 532.89\t\tLearning rate: 2.637e-07, Batch size: 42, Momentum: 3.155e-01\n",
      "best loss: 533.81\t\tLearning rate: 2.637e-07, Batch size: 19, Momentum: 3.155e-01\n",
      "best loss: 534.41\t\tLearning rate: 7.848e-07, Batch size: 47, Momentum: 2.103e-01\n",
      "best loss: 535.75\t\tLearning rate: 8.859e-08, Batch size: 37, Momentum: 5.784e-01\n",
      "best loss: 536.98\t\tLearning rate: 2.336e-06, Batch size: 27, Momentum: 1.577e-01\n",
      "best loss: 537.22\t\tLearning rate: 2.336e-06, Batch size: 34, Momentum: 3.155e-01\n",
      "best loss: 539.07\t\tLearning rate: 2.976e-08, Batch size: 7, Momentum: 5.258e-01\n",
      "best loss: 540.12\t\tLearning rate: 2.976e-08, Batch size: 19, Momentum: 3.681e-01\n",
      "best loss: 540.91\t\tLearning rate: 6.952e-06, Batch size: 12, Momentum: 6.309e-01\n",
      "best loss: 541.30\t\tLearning rate: 7.848e-07, Batch size: 34, Momentum: 0.000e+00\n",
      "best loss: 542.12\t\tLearning rate: 2.637e-07, Batch size: 44, Momentum: 5.784e-01\n",
      "best loss: 542.78\t\tLearning rate: 2.976e-08, Batch size: 47, Momentum: 6.835e-01\n",
      "best loss: 543.08\t\tLearning rate: 2.637e-07, Batch size: 24, Momentum: 2.629e-01\n",
      "best loss: 543.19\t\tLearning rate: 2.069e-05, Batch size: 14, Momentum: 5.258e-02\n",
      "best loss: 543.36\t\tLearning rate: 2.637e-07, Batch size: 17, Momentum: 5.258e-01\n",
      "best loss: 545.13\t\tLearning rate: 2.976e-08, Batch size: 42, Momentum: 7.361e-01\n",
      "best loss: 545.54\t\tLearning rate: 2.637e-07, Batch size: 17, Momentum: 0.000e+00\n",
      "best loss: 545.94\t\tLearning rate: 1.000e-08, Batch size: 7, Momentum: 5.784e-01\n",
      "best loss: 546.16\t\tLearning rate: 8.859e-08, Batch size: 14, Momentum: 2.103e-01\n",
      "best loss: 546.80\t\tLearning rate: 8.859e-08, Batch size: 47, Momentum: 3.681e-01\n",
      "best loss: 547.74\t\tLearning rate: 8.859e-08, Batch size: 19, Momentum: 5.258e-02\n",
      "best loss: 548.83\t\tLearning rate: 6.952e-06, Batch size: 4, Momentum: 8.938e-01\n",
      "best loss: 549.67\t\tLearning rate: 2.336e-06, Batch size: 19, Momentum: 9.990e-01\n",
      "best loss: 549.78\t\tLearning rate: 2.069e-05, Batch size: 42, Momentum: 5.258e-02\n",
      "best loss: 550.95\t\tLearning rate: 2.637e-07, Batch size: 9, Momentum: 0.000e+00\n",
      "best loss: 551.23\t\tLearning rate: 2.976e-08, Batch size: 4, Momentum: 0.000e+00\n",
      "best loss: 552.30\t\tLearning rate: 2.976e-08, Batch size: 32, Momentum: 6.835e-01\n",
      "best loss: 553.37\t\tLearning rate: 1.000e-08, Batch size: 17, Momentum: 7.887e-01\n",
      "best loss: 553.72\t\tLearning rate: 8.859e-08, Batch size: 22, Momentum: 2.629e-01\n",
      "best loss: 557.07\t\tLearning rate: 6.952e-06, Batch size: 4, Momentum: 6.835e-01\n",
      "best loss: 557.49\t\tLearning rate: 2.637e-07, Batch size: 29, Momentum: 2.629e-01\n",
      "best loss: 558.31\t\tLearning rate: 2.976e-08, Batch size: 47, Momentum: 5.784e-01\n",
      "best loss: 562.44\t\tLearning rate: 8.859e-08, Batch size: 9, Momentum: 4.206e-01\n",
      "best loss: 564.98\t\tLearning rate: 6.952e-06, Batch size: 17, Momentum: 7.887e-01\n",
      "best loss: 565.96\t\tLearning rate: 2.069e-05, Batch size: 12, Momentum: 3.155e-01\n",
      "best loss: 567.87\t\tLearning rate: 2.976e-08, Batch size: 9, Momentum: 5.258e-01\n",
      "best loss: 570.64\t\tLearning rate: 8.859e-08, Batch size: 39, Momentum: 1.577e-01\n",
      "best loss: 573.94\t\tLearning rate: 2.069e-05, Batch size: 17, Momentum: 5.258e-02\n",
      "best loss: 574.11\t\tLearning rate: 2.069e-05, Batch size: 7, Momentum: 2.629e-01\n",
      "best loss: 578.74\t\tLearning rate: 7.848e-07, Batch size: 37, Momentum: 1.577e-01\n",
      "best loss: 579.06\t\tLearning rate: 2.976e-08, Batch size: 22, Momentum: 6.309e-01\n",
      "best loss: 582.57\t\tLearning rate: 2.976e-08, Batch size: 14, Momentum: 0.000e+00\n",
      "best loss: 583.01\t\tLearning rate: 6.952e-06, Batch size: 29, Momentum: 8.413e-01\n",
      "best loss: 584.34\t\tLearning rate: 2.336e-06, Batch size: 24, Momentum: 2.103e-01\n",
      "best loss: 584.61\t\tLearning rate: 6.952e-06, Batch size: 17, Momentum: 8.413e-01\n",
      "best loss: 585.34\t\tLearning rate: 1.000e-08, Batch size: 12, Momentum: 6.835e-01\n",
      "best loss: 586.49\t\tLearning rate: 2.069e-05, Batch size: 34, Momentum: 0.000e+00\n",
      "best loss: 587.87\t\tLearning rate: 1.000e-08, Batch size: 14, Momentum: 7.361e-01\n",
      "best loss: 587.92\t\tLearning rate: 2.069e-05, Batch size: 50, Momentum: 0.000e+00\n",
      "best loss: 587.93\t\tLearning rate: 1.000e-08, Batch size: 22, Momentum: 4.206e-01\n",
      "best loss: 593.64\t\tLearning rate: 2.069e-05, Batch size: 32, Momentum: 5.784e-01\n",
      "best loss: 594.98\t\tLearning rate: 1.000e-08, Batch size: 12, Momentum: 4.206e-01\n",
      "best loss: 595.75\t\tLearning rate: 8.859e-08, Batch size: 9, Momentum: 1.577e-01\n",
      "best loss: 597.60\t\tLearning rate: 2.069e-05, Batch size: 9, Momentum: 7.361e-01\n",
      "best loss: 597.92\t\tLearning rate: 2.637e-07, Batch size: 17, Momentum: 5.258e-02\n",
      "best loss: 598.02\t\tLearning rate: 1.000e-08, Batch size: 50, Momentum: 6.835e-01\n",
      "best loss: 598.58\t\tLearning rate: 2.976e-08, Batch size: 24, Momentum: 7.361e-01\n",
      "best loss: 601.98\t\tLearning rate: 6.952e-06, Batch size: 24, Momentum: 8.938e-01\n",
      "best loss: 606.98\t\tLearning rate: 1.000e-08, Batch size: 14, Momentum: 4.732e-01\n",
      "best loss: 608.22\t\tLearning rate: 7.848e-07, Batch size: 44, Momentum: 2.103e-01\n",
      "best loss: 608.62\t\tLearning rate: 2.637e-07, Batch size: 39, Momentum: 0.000e+00\n",
      "best loss: 609.61\t\tLearning rate: 2.069e-05, Batch size: 37, Momentum: 5.258e-01\n",
      "best loss: 609.64\t\tLearning rate: 2.637e-07, Batch size: 37, Momentum: 2.103e-01\n",
      "best loss: 609.94\t\tLearning rate: 2.069e-05, Batch size: 22, Momentum: 2.103e-01\n",
      "best loss: 610.93\t\tLearning rate: 2.069e-05, Batch size: 29, Momentum: 4.206e-01\n",
      "best loss: 611.58\t\tLearning rate: 2.069e-05, Batch size: 2, Momentum: 3.155e-01\n",
      "best loss: 614.59\t\tLearning rate: 2.069e-05, Batch size: 17, Momentum: 7.361e-01\n",
      "best loss: 615.37\t\tLearning rate: 2.069e-05, Batch size: 22, Momentum: 0.000e+00\n",
      "best loss: 615.80\t\tLearning rate: 2.976e-08, Batch size: 32, Momentum: 5.784e-01\n",
      "best loss: 616.23\t\tLearning rate: 2.069e-05, Batch size: 19, Momentum: 5.784e-01\n",
      "best loss: 617.07\t\tLearning rate: 2.069e-05, Batch size: 4, Momentum: 2.103e-01\n",
      "best loss: 617.28\t\tLearning rate: 2.069e-05, Batch size: 27, Momentum: 5.784e-01\n",
      "best loss: 618.19\t\tLearning rate: 2.069e-05, Batch size: 24, Momentum: 5.784e-01\n",
      "best loss: 619.70\t\tLearning rate: 2.069e-05, Batch size: 47, Momentum: 5.258e-01\n",
      "best loss: 620.84\t\tLearning rate: 6.158e-05, Batch size: 2, Momentum: 0.000e+00\n",
      "best loss: 624.73\t\tLearning rate: 6.952e-06, Batch size: 42, Momentum: 7.887e-01\n",
      "best loss: 628.55\t\tLearning rate: 6.952e-06, Batch size: 42, Momentum: 9.990e-01\n",
      "best loss: 635.07\t\tLearning rate: 6.158e-05, Batch size: 19, Momentum: 4.732e-01\n",
      "best loss: 635.69\t\tLearning rate: 2.069e-05, Batch size: 22, Momentum: 5.258e-01\n",
      "best loss: 636.21\t\tLearning rate: 8.859e-08, Batch size: 32, Momentum: 1.052e-01\n",
      "best loss: 636.45\t\tLearning rate: 2.069e-05, Batch size: 19, Momentum: 4.206e-01\n",
      "best loss: 639.64\t\tLearning rate: 8.859e-08, Batch size: 9, Momentum: 0.000e+00\n",
      "best loss: 641.76\t\tLearning rate: 2.069e-05, Batch size: 14, Momentum: 7.361e-01\n",
      "best loss: 642.21\t\tLearning rate: 1.000e-08, Batch size: 22, Momentum: 6.309e-01\n",
      "best loss: 642.76\t\tLearning rate: 2.069e-05, Batch size: 7, Momentum: 7.887e-01\n",
      "best loss: 642.97\t\tLearning rate: 2.069e-05, Batch size: 44, Momentum: 5.784e-01\n",
      "best loss: 644.94\t\tLearning rate: 6.952e-06, Batch size: 17, Momentum: 9.464e-01\n",
      "best loss: 647.04\t\tLearning rate: 6.158e-05, Batch size: 27, Momentum: 1.577e-01\n",
      "best loss: 647.95\t\tLearning rate: 2.069e-05, Batch size: 7, Momentum: 5.258e-01\n",
      "best loss: 650.19\t\tLearning rate: 2.069e-05, Batch size: 32, Momentum: 6.835e-01\n",
      "best loss: 650.63\t\tLearning rate: 6.158e-05, Batch size: 4, Momentum: 4.206e-01\n",
      "best loss: 651.28\t\tLearning rate: 6.158e-05, Batch size: 9, Momentum: 0.000e+00\n",
      "best loss: 653.16\t\tLearning rate: 6.952e-06, Batch size: 7, Momentum: 9.990e-01\n",
      "best loss: 654.15\t\tLearning rate: 2.069e-05, Batch size: 47, Momentum: 4.732e-01\n",
      "best loss: 659.16\t\tLearning rate: 6.158e-05, Batch size: 37, Momentum: 1.052e-01\n",
      "best loss: 659.83\t\tLearning rate: 1.000e-08, Batch size: 9, Momentum: 4.206e-01\n",
      "best loss: 661.33\t\tLearning rate: 6.158e-05, Batch size: 29, Momentum: 1.577e-01\n",
      "best loss: 661.83\t\tLearning rate: 2.069e-05, Batch size: 37, Momentum: 7.887e-01\n",
      "best loss: 662.00\t\tLearning rate: 2.069e-05, Batch size: 7, Momentum: 8.413e-01\n",
      "best loss: 662.15\t\tLearning rate: 2.069e-05, Batch size: 42, Momentum: 3.155e-01\n",
      "best loss: 662.51\t\tLearning rate: 2.069e-05, Batch size: 42, Momentum: 7.887e-01\n",
      "best loss: 662.76\t\tLearning rate: 2.069e-05, Batch size: 14, Momentum: 2.629e-01\n",
      "best loss: 663.62\t\tLearning rate: 2.976e-08, Batch size: 22, Momentum: 3.155e-01\n",
      "best loss: 663.93\t\tLearning rate: 6.158e-05, Batch size: 19, Momentum: 1.577e-01\n",
      "best loss: 664.37\t\tLearning rate: 6.158e-05, Batch size: 29, Momentum: 5.784e-01\n",
      "best loss: 665.43\t\tLearning rate: 2.976e-08, Batch size: 42, Momentum: 5.784e-01\n",
      "best loss: 665.66\t\tLearning rate: 6.158e-05, Batch size: 17, Momentum: 1.052e-01\n",
      "best loss: 667.27\t\tLearning rate: 6.158e-05, Batch size: 37, Momentum: 1.577e-01\n",
      "best loss: 668.22\t\tLearning rate: 6.158e-05, Batch size: 37, Momentum: 4.206e-01\n",
      "best loss: 671.21\t\tLearning rate: 2.069e-05, Batch size: 19, Momentum: 5.258e-02\n",
      "best loss: 671.25\t\tLearning rate: 2.069e-05, Batch size: 47, Momentum: 8.413e-01\n",
      "best loss: 675.04\t\tLearning rate: 8.859e-08, Batch size: 19, Momentum: 5.784e-01\n",
      "best loss: 675.66\t\tLearning rate: 6.158e-05, Batch size: 27, Momentum: 3.155e-01\n",
      "best loss: 676.40\t\tLearning rate: 6.158e-05, Batch size: 17, Momentum: 3.155e-01\n",
      "best loss: 677.48\t\tLearning rate: 2.069e-05, Batch size: 39, Momentum: 5.258e-01\n",
      "best loss: 677.61\t\tLearning rate: 2.069e-05, Batch size: 29, Momentum: 5.784e-01\n",
      "best loss: 679.21\t\tLearning rate: 2.069e-05, Batch size: 24, Momentum: 4.732e-01\n",
      "best loss: 680.28\t\tLearning rate: 2.069e-05, Batch size: 9, Momentum: 5.258e-01\n",
      "best loss: 681.01\t\tLearning rate: 2.069e-05, Batch size: 22, Momentum: 4.732e-01\n",
      "best loss: 681.28\t\tLearning rate: 6.158e-05, Batch size: 27, Momentum: 3.681e-01\n",
      "best loss: 681.61\t\tLearning rate: 6.158e-05, Batch size: 19, Momentum: 5.258e-01\n",
      "best loss: 682.25\t\tLearning rate: 1.000e-08, Batch size: 42, Momentum: 5.258e-02\n",
      "best loss: 682.55\t\tLearning rate: 2.069e-05, Batch size: 14, Momentum: 7.887e-01\n",
      "best loss: 684.56\t\tLearning rate: 2.069e-05, Batch size: 37, Momentum: 2.629e-01\n",
      "best loss: 685.18\t\tLearning rate: 2.069e-05, Batch size: 19, Momentum: 6.309e-01\n",
      "best loss: 688.63\t\tLearning rate: 6.158e-05, Batch size: 47, Momentum: 3.681e-01\n",
      "best loss: 690.79\t\tLearning rate: 6.158e-05, Batch size: 19, Momentum: 2.103e-01\n",
      "best loss: 691.03\t\tLearning rate: 8.859e-08, Batch size: 24, Momentum: 3.155e-01\n",
      "best loss: 692.95\t\tLearning rate: 2.976e-08, Batch size: 34, Momentum: 1.577e-01\n",
      "best loss: 693.84\t\tLearning rate: 2.069e-05, Batch size: 37, Momentum: 7.361e-01\n",
      "best loss: 695.18\t\tLearning rate: 2.976e-08, Batch size: 22, Momentum: 5.258e-02\n",
      "best loss: 695.36\t\tLearning rate: 6.158e-05, Batch size: 50, Momentum: 0.000e+00\n",
      "best loss: 695.92\t\tLearning rate: 6.158e-05, Batch size: 22, Momentum: 2.103e-01\n",
      "best loss: 697.84\t\tLearning rate: 2.069e-05, Batch size: 32, Momentum: 5.258e-01\n",
      "best loss: 699.09\t\tLearning rate: 2.976e-08, Batch size: 50, Momentum: 5.258e-01\n",
      "best loss: 699.76\t\tLearning rate: 2.069e-05, Batch size: 2, Momentum: 9.464e-01\n",
      "best loss: 700.22\t\tLearning rate: 6.158e-05, Batch size: 50, Momentum: 1.577e-01\n",
      "best loss: 701.45\t\tLearning rate: 6.158e-05, Batch size: 42, Momentum: 2.103e-01\n",
      "best loss: 702.97\t\tLearning rate: 6.158e-05, Batch size: 12, Momentum: 4.732e-01\n",
      "best loss: 704.80\t\tLearning rate: 2.069e-05, Batch size: 19, Momentum: 3.681e-01\n",
      "best loss: 705.15\t\tLearning rate: 6.158e-05, Batch size: 2, Momentum: 1.577e-01\n",
      "best loss: 705.65\t\tLearning rate: 6.158e-05, Batch size: 4, Momentum: 6.835e-01\n",
      "best loss: 705.73\t\tLearning rate: 2.069e-05, Batch size: 2, Momentum: 7.887e-01\n",
      "best loss: 705.81\t\tLearning rate: 6.158e-05, Batch size: 7, Momentum: 8.938e-01\n",
      "best loss: 705.98\t\tLearning rate: 6.158e-05, Batch size: 39, Momentum: 5.258e-01\n",
      "best loss: 707.15\t\tLearning rate: 2.069e-05, Batch size: 27, Momentum: 8.938e-01\n",
      "best loss: 707.66\t\tLearning rate: 6.158e-05, Batch size: 22, Momentum: 4.206e-01\n",
      "best loss: 708.50\t\tLearning rate: 6.158e-05, Batch size: 50, Momentum: 8.938e-01\n",
      "best loss: 708.89\t\tLearning rate: 1.833e-04, Batch size: 2, Momentum: 3.155e-01\n",
      "best loss: 714.22\t\tLearning rate: 2.069e-05, Batch size: 4, Momentum: 7.887e-01\n",
      "best loss: 714.96\t\tLearning rate: 1.000e-08, Batch size: 39, Momentum: 2.629e-01\n",
      "best loss: 721.39\t\tLearning rate: 6.158e-05, Batch size: 27, Momentum: 2.103e-01\n",
      "best loss: 723.07\t\tLearning rate: 6.158e-05, Batch size: 12, Momentum: 6.835e-01\n",
      "best loss: 723.12\t\tLearning rate: 2.069e-05, Batch size: 44, Momentum: 6.309e-01\n",
      "best loss: 724.59\t\tLearning rate: 6.158e-05, Batch size: 4, Momentum: 5.784e-01\n",
      "best loss: 725.00\t\tLearning rate: 6.158e-05, Batch size: 42, Momentum: 4.732e-01\n",
      "best loss: 726.24\t\tLearning rate: 2.976e-08, Batch size: 29, Momentum: 2.629e-01\n",
      "best loss: 726.68\t\tLearning rate: 6.158e-05, Batch size: 14, Momentum: 3.155e-01\n",
      "best loss: 728.12\t\tLearning rate: 1.833e-04, Batch size: 14, Momentum: 1.052e-01\n",
      "best loss: 729.03\t\tLearning rate: 6.158e-05, Batch size: 39, Momentum: 4.732e-01\n",
      "best loss: 730.23\t\tLearning rate: 6.158e-05, Batch size: 37, Momentum: 6.309e-01\n",
      "best loss: 731.99\t\tLearning rate: 1.833e-04, Batch size: 29, Momentum: 5.258e-02\n",
      "best loss: 735.72\t\tLearning rate: 1.833e-04, Batch size: 14, Momentum: 5.258e-02\n",
      "best loss: 736.13\t\tLearning rate: 8.859e-08, Batch size: 47, Momentum: 0.000e+00\n",
      "best loss: 736.75\t\tLearning rate: 1.833e-04, Batch size: 2, Momentum: 1.577e-01\n",
      "best loss: 737.51\t\tLearning rate: 2.069e-05, Batch size: 22, Momentum: 8.413e-01\n",
      "best loss: 737.72\t\tLearning rate: 6.158e-05, Batch size: 44, Momentum: 4.732e-01\n",
      "best loss: 742.70\t\tLearning rate: 1.833e-04, Batch size: 22, Momentum: 0.000e+00\n",
      "best loss: 742.79\t\tLearning rate: 2.976e-08, Batch size: 24, Momentum: 5.258e-02\n",
      "best loss: 744.63\t\tLearning rate: 6.158e-05, Batch size: 29, Momentum: 7.887e-01\n",
      "best loss: 748.16\t\tLearning rate: 6.158e-05, Batch size: 37, Momentum: 2.103e-01\n",
      "best loss: 748.69\t\tLearning rate: 6.158e-05, Batch size: 19, Momentum: 9.464e-01\n",
      "best loss: 750.98\t\tLearning rate: 2.069e-05, Batch size: 50, Momentum: 8.938e-01\n",
      "best loss: 752.75\t\tLearning rate: 6.158e-05, Batch size: 14, Momentum: 9.464e-01\n",
      "best loss: 753.10\t\tLearning rate: 6.158e-05, Batch size: 32, Momentum: 6.309e-01\n",
      "best loss: 753.56\t\tLearning rate: 2.069e-05, Batch size: 7, Momentum: 7.361e-01\n",
      "best loss: 753.78\t\tLearning rate: 6.158e-05, Batch size: 2, Momentum: 9.464e-01\n",
      "best loss: 753.83\t\tLearning rate: 1.833e-04, Batch size: 12, Momentum: 3.155e-01\n",
      "best loss: 756.61\t\tLearning rate: 2.069e-05, Batch size: 12, Momentum: 8.938e-01\n",
      "best loss: 757.48\t\tLearning rate: 1.833e-04, Batch size: 12, Momentum: 5.784e-01\n",
      "best loss: 758.53\t\tLearning rate: 6.158e-05, Batch size: 7, Momentum: 9.464e-01\n",
      "best loss: 759.68\t\tLearning rate: 1.833e-04, Batch size: 39, Momentum: 3.155e-01\n",
      "best loss: 761.35\t\tLearning rate: 1.833e-04, Batch size: 12, Momentum: 1.052e-01\n",
      "best loss: 762.40\t\tLearning rate: 6.158e-05, Batch size: 32, Momentum: 7.361e-01\n",
      "best loss: 762.82\t\tLearning rate: 7.848e-07, Batch size: 9, Momentum: 5.258e-02\n",
      "best loss: 765.15\t\tLearning rate: 2.069e-05, Batch size: 47, Momentum: 2.103e-01\n",
      "best loss: 766.83\t\tLearning rate: 1.833e-04, Batch size: 7, Momentum: 2.103e-01\n",
      "best loss: 770.45\t\tLearning rate: 6.158e-05, Batch size: 39, Momentum: 1.052e-01\n",
      "best loss: 770.95\t\tLearning rate: 6.158e-05, Batch size: 12, Momentum: 5.258e-01\n",
      "best loss: 771.21\t\tLearning rate: 6.158e-05, Batch size: 17, Momentum: 8.938e-01\n",
      "best loss: 771.22\t\tLearning rate: 1.833e-04, Batch size: 2, Momentum: 6.835e-01\n",
      "best loss: 775.04\t\tLearning rate: 6.158e-05, Batch size: 17, Momentum: 5.258e-01\n",
      "best loss: 777.56\t\tLearning rate: 1.833e-04, Batch size: 4, Momentum: 4.732e-01\n",
      "best loss: 777.62\t\tLearning rate: 1.833e-04, Batch size: 44, Momentum: 2.629e-01\n",
      "best loss: 779.16\t\tLearning rate: 1.833e-04, Batch size: 9, Momentum: 3.155e-01\n",
      "best loss: 781.24\t\tLearning rate: 6.158e-05, Batch size: 44, Momentum: 7.887e-01\n",
      "best loss: 782.43\t\tLearning rate: 1.833e-04, Batch size: 47, Momentum: 4.206e-01\n",
      "best loss: 784.06\t\tLearning rate: 1.833e-04, Batch size: 50, Momentum: 1.577e-01\n",
      "best loss: 785.77\t\tLearning rate: 1.833e-04, Batch size: 27, Momentum: 5.258e-02\n",
      "best loss: 785.89\t\tLearning rate: 1.833e-04, Batch size: 50, Momentum: 3.681e-01\n",
      "best loss: 789.08\t\tLearning rate: 1.833e-04, Batch size: 9, Momentum: 7.361e-01\n",
      "best loss: 789.67\t\tLearning rate: 1.833e-04, Batch size: 22, Momentum: 7.887e-01\n",
      "best loss: 791.44\t\tLearning rate: 1.833e-04, Batch size: 44, Momentum: 7.887e-01\n",
      "best loss: 795.40\t\tLearning rate: 5.456e-04, Batch size: 2, Momentum: 0.000e+00\n",
      "best loss: 795.74\t\tLearning rate: 6.158e-05, Batch size: 2, Momentum: 8.938e-01\n",
      "best loss: 795.89\t\tLearning rate: 1.833e-04, Batch size: 19, Momentum: 5.258e-01\n",
      "best loss: 797.16\t\tLearning rate: 1.833e-04, Batch size: 17, Momentum: 5.784e-01\n",
      "best loss: 798.03\t\tLearning rate: 1.833e-04, Batch size: 14, Momentum: 3.155e-01\n",
      "best loss: 799.05\t\tLearning rate: 6.158e-05, Batch size: 29, Momentum: 3.681e-01\n",
      "best loss: 801.28\t\tLearning rate: 6.158e-05, Batch size: 37, Momentum: 4.732e-01\n",
      "best loss: 801.94\t\tLearning rate: 2.637e-07, Batch size: 32, Momentum: 5.258e-02\n",
      "best loss: 802.37\t\tLearning rate: 1.833e-04, Batch size: 19, Momentum: 2.629e-01\n",
      "best loss: 802.77\t\tLearning rate: 1.833e-04, Batch size: 4, Momentum: 6.309e-01\n",
      "best loss: 803.70\t\tLearning rate: 1.833e-04, Batch size: 50, Momentum: 4.206e-01\n",
      "best loss: 804.90\t\tLearning rate: 1.833e-04, Batch size: 4, Momentum: 0.000e+00\n",
      "best loss: 805.06\t\tLearning rate: 1.833e-04, Batch size: 34, Momentum: 2.629e-01\n",
      "best loss: 805.56\t\tLearning rate: 1.833e-04, Batch size: 47, Momentum: 5.258e-01\n",
      "best loss: 807.55\t\tLearning rate: 1.833e-04, Batch size: 22, Momentum: 4.206e-01\n",
      "best loss: 808.15\t\tLearning rate: 2.976e-08, Batch size: 14, Momentum: 3.681e-01\n",
      "best loss: 808.51\t\tLearning rate: 6.158e-05, Batch size: 12, Momentum: 7.887e-01\n",
      "best loss: 809.32\t\tLearning rate: 6.158e-05, Batch size: 22, Momentum: 9.464e-01\n",
      "best loss: 811.70\t\tLearning rate: 5.456e-04, Batch size: 50, Momentum: 1.052e-01\n",
      "best loss: 812.71\t\tLearning rate: 5.456e-04, Batch size: 29, Momentum: 5.258e-02\n",
      "best loss: 816.31\t\tLearning rate: 5.456e-04, Batch size: 12, Momentum: 0.000e+00\n",
      "best loss: 817.52\t\tLearning rate: 1.833e-04, Batch size: 9, Momentum: 5.784e-01\n",
      "best loss: 818.73\t\tLearning rate: 5.456e-04, Batch size: 14, Momentum: 0.000e+00\n",
      "best loss: 821.10\t\tLearning rate: 6.158e-05, Batch size: 17, Momentum: 5.784e-01\n",
      "best loss: 821.93\t\tLearning rate: 5.456e-04, Batch size: 19, Momentum: 0.000e+00\n",
      "best loss: 823.30\t\tLearning rate: 6.158e-05, Batch size: 12, Momentum: 8.938e-01\n",
      "best loss: 823.56\t\tLearning rate: 1.833e-04, Batch size: 12, Momentum: 8.938e-01\n",
      "best loss: 825.57\t\tLearning rate: 5.456e-04, Batch size: 29, Momentum: 0.000e+00\n",
      "best loss: 827.68\t\tLearning rate: 6.158e-05, Batch size: 12, Momentum: 9.990e-01\n",
      "best loss: 830.76\t\tLearning rate: 1.833e-04, Batch size: 14, Momentum: 4.732e-01\n",
      "best loss: 831.35\t\tLearning rate: 6.158e-05, Batch size: 32, Momentum: 9.464e-01\n",
      "best loss: 832.63\t\tLearning rate: 1.833e-04, Batch size: 17, Momentum: 4.732e-01\n",
      "best loss: 835.42\t\tLearning rate: 5.456e-04, Batch size: 44, Momentum: 2.629e-01\n",
      "best loss: 835.55\t\tLearning rate: 1.833e-04, Batch size: 12, Momentum: 4.732e-01\n",
      "best loss: 837.30\t\tLearning rate: 1.833e-04, Batch size: 24, Momentum: 7.361e-01\n",
      "best loss: 838.03\t\tLearning rate: 1.833e-04, Batch size: 7, Momentum: 5.784e-01\n",
      "best loss: 839.02\t\tLearning rate: 5.456e-04, Batch size: 44, Momentum: 4.732e-01\n",
      "best loss: 841.92\t\tLearning rate: 1.833e-04, Batch size: 29, Momentum: 1.577e-01\n",
      "best loss: 842.97\t\tLearning rate: 5.456e-04, Batch size: 2, Momentum: 5.258e-02\n",
      "best loss: 844.73\t\tLearning rate: 2.976e-08, Batch size: 29, Momentum: 2.103e-01\n",
      "best loss: 846.28\t\tLearning rate: 5.456e-04, Batch size: 4, Momentum: 7.361e-01\n",
      "best loss: 846.64\t\tLearning rate: 5.456e-04, Batch size: 24, Momentum: 3.155e-01\n",
      "best loss: 846.99\t\tLearning rate: 1.624e-03, Batch size: 7, Momentum: 3.681e-01\n",
      "best loss: 847.04\t\tLearning rate: 2.637e-07, Batch size: 22, Momentum: 2.629e-01\n",
      "best loss: 847.56\t\tLearning rate: 1.833e-04, Batch size: 34, Momentum: 5.784e-01\n",
      "best loss: 850.41\t\tLearning rate: 5.456e-04, Batch size: 22, Momentum: 1.052e-01\n",
      "best loss: 854.39\t\tLearning rate: 1.624e-03, Batch size: 22, Momentum: 5.258e-02\n",
      "best loss: 854.93\t\tLearning rate: 5.456e-04, Batch size: 47, Momentum: 1.052e-01\n",
      "best loss: 856.78\t\tLearning rate: 5.456e-04, Batch size: 42, Momentum: 1.577e-01\n",
      "best loss: 858.21\t\tLearning rate: 5.456e-04, Batch size: 17, Momentum: 4.206e-01\n",
      "best loss: 858.46\t\tLearning rate: 5.456e-04, Batch size: 29, Momentum: 6.309e-01\n",
      "best loss: 859.31\t\tLearning rate: 5.456e-04, Batch size: 12, Momentum: 4.206e-01\n",
      "best loss: 861.32\t\tLearning rate: 5.456e-04, Batch size: 27, Momentum: 3.155e-01\n",
      "best loss: 861.83\t\tLearning rate: 5.456e-04, Batch size: 4, Momentum: 2.103e-01\n",
      "best loss: 863.28\t\tLearning rate: 1.833e-04, Batch size: 12, Momentum: 7.887e-01\n",
      "best loss: 864.21\t\tLearning rate: 1.833e-04, Batch size: 44, Momentum: 6.309e-01\n",
      "best loss: 864.83\t\tLearning rate: 1.624e-03, Batch size: 14, Momentum: 0.000e+00\n",
      "best loss: 865.44\t\tLearning rate: 2.637e-07, Batch size: 24, Momentum: 3.155e-01\n",
      "best loss: 869.10\t\tLearning rate: 1.833e-04, Batch size: 27, Momentum: 8.938e-01\n",
      "best loss: 871.62\t\tLearning rate: 1.000e-08, Batch size: 7, Momentum: 4.732e-01\n",
      "best loss: 873.62\t\tLearning rate: 5.456e-04, Batch size: 47, Momentum: 5.258e-01\n",
      "best loss: 880.44\t\tLearning rate: 1.833e-04, Batch size: 19, Momentum: 6.309e-01\n",
      "best loss: 880.83\t\tLearning rate: 5.456e-04, Batch size: 34, Momentum: 5.784e-01\n",
      "best loss: 881.76\t\tLearning rate: 5.456e-04, Batch size: 44, Momentum: 3.681e-01\n",
      "best loss: 885.25\t\tLearning rate: 5.456e-04, Batch size: 27, Momentum: 7.887e-01\n",
      "best loss: 885.53\t\tLearning rate: 1.833e-04, Batch size: 34, Momentum: 2.103e-01\n",
      "best loss: 886.53\t\tLearning rate: 8.859e-08, Batch size: 32, Momentum: 0.000e+00\n",
      "best loss: 888.06\t\tLearning rate: 5.456e-04, Batch size: 2, Momentum: 9.990e-01\n",
      "best loss: 889.12\t\tLearning rate: 5.456e-04, Batch size: 32, Momentum: 8.938e-01\n",
      "best loss: 889.40\t\tLearning rate: 5.456e-04, Batch size: 42, Momentum: 2.103e-01\n",
      "best loss: 892.04\t\tLearning rate: 5.456e-04, Batch size: 42, Momentum: 8.938e-01\n",
      "best loss: 892.24\t\tLearning rate: 5.456e-04, Batch size: 17, Momentum: 8.413e-01\n",
      "best loss: 893.68\t\tLearning rate: 1.833e-04, Batch size: 24, Momentum: 9.990e-01\n",
      "best loss: 894.59\t\tLearning rate: 1.624e-03, Batch size: 19, Momentum: 1.577e-01\n",
      "best loss: 894.95\t\tLearning rate: 5.456e-04, Batch size: 27, Momentum: 5.258e-01\n",
      "best loss: 895.26\t\tLearning rate: 1.624e-03, Batch size: 4, Momentum: 1.577e-01\n",
      "best loss: 895.30\t\tLearning rate: 5.456e-04, Batch size: 42, Momentum: 4.206e-01\n",
      "best loss: 895.88\t\tLearning rate: 5.456e-04, Batch size: 7, Momentum: 4.732e-01\n",
      "best loss: 896.53\t\tLearning rate: 6.158e-05, Batch size: 47, Momentum: 8.938e-01\n",
      "best loss: 896.79\t\tLearning rate: 1.000e-08, Batch size: 22, Momentum: 5.784e-01\n",
      "best loss: 898.49\t\tLearning rate: 1.624e-03, Batch size: 29, Momentum: 1.052e-01\n",
      "best loss: 898.54\t\tLearning rate: 1.624e-03, Batch size: 17, Momentum: 0.000e+00\n",
      "best loss: 899.65\t\tLearning rate: 1.624e-03, Batch size: 47, Momentum: 0.000e+00\n",
      "best loss: 900.28\t\tLearning rate: 5.456e-04, Batch size: 42, Momentum: 6.835e-01\n",
      "best loss: 900.76\t\tLearning rate: 5.456e-04, Batch size: 19, Momentum: 4.732e-01\n",
      "best loss: 901.02\t\tLearning rate: 5.456e-04, Batch size: 37, Momentum: 4.732e-01\n",
      "best loss: 901.42\t\tLearning rate: 1.624e-03, Batch size: 2, Momentum: 4.206e-01\n",
      "best loss: 901.95\t\tLearning rate: 1.624e-03, Batch size: 9, Momentum: 1.577e-01\n",
      "best loss: 902.42\t\tLearning rate: 1.624e-03, Batch size: 39, Momentum: 0.000e+00\n",
      "best loss: 902.97\t\tLearning rate: 1.833e-04, Batch size: 12, Momentum: 8.413e-01\n",
      "best loss: 909.33\t\tLearning rate: 5.456e-04, Batch size: 47, Momentum: 6.835e-01\n",
      "best loss: 909.75\t\tLearning rate: 1.624e-03, Batch size: 47, Momentum: 1.577e-01\n",
      "best loss: 909.79\t\tLearning rate: 1.624e-03, Batch size: 4, Momentum: 3.155e-01\n",
      "best loss: 910.16\t\tLearning rate: 1.624e-03, Batch size: 39, Momentum: 2.103e-01\n",
      "best loss: 910.53\t\tLearning rate: 5.456e-04, Batch size: 24, Momentum: 4.206e-01\n",
      "best loss: 911.23\t\tLearning rate: 5.456e-04, Batch size: 12, Momentum: 7.361e-01\n",
      "best loss: 912.64\t\tLearning rate: 5.456e-04, Batch size: 32, Momentum: 6.835e-01\n",
      "best loss: 912.99\t\tLearning rate: 5.456e-04, Batch size: 2, Momentum: 1.577e-01\n",
      "best loss: 914.82\t\tLearning rate: 1.624e-03, Batch size: 34, Momentum: 3.155e-01\n",
      "best loss: 915.27\t\tLearning rate: 1.624e-03, Batch size: 22, Momentum: 1.577e-01\n",
      "best loss: 917.41\t\tLearning rate: 5.456e-04, Batch size: 37, Momentum: 5.258e-01\n",
      "best loss: 917.53\t\tLearning rate: 5.456e-04, Batch size: 37, Momentum: 9.990e-01\n",
      "best loss: 918.17\t\tLearning rate: 5.456e-04, Batch size: 42, Momentum: 7.887e-01\n",
      "best loss: 918.42\t\tLearning rate: 1.624e-03, Batch size: 27, Momentum: 5.258e-01\n",
      "best loss: 921.11\t\tLearning rate: 4.833e-03, Batch size: 44, Momentum: 3.681e-01\n",
      "best loss: 922.15\t\tLearning rate: 1.624e-03, Batch size: 12, Momentum: 1.577e-01\n",
      "best loss: 924.39\t\tLearning rate: 5.456e-04, Batch size: 2, Momentum: 6.835e-01\n",
      "best loss: 925.43\t\tLearning rate: 1.624e-03, Batch size: 29, Momentum: 5.258e-02\n",
      "best loss: 929.24\t\tLearning rate: 1.624e-03, Batch size: 2, Momentum: 1.052e-01\n",
      "best loss: 930.24\t\tLearning rate: 1.624e-03, Batch size: 32, Momentum: 5.258e-01\n",
      "best loss: 932.12\t\tLearning rate: 4.833e-03, Batch size: 17, Momentum: 2.629e-01\n",
      "best loss: 932.15\t\tLearning rate: 1.833e-04, Batch size: 29, Momentum: 9.990e-01\n",
      "best loss: 932.31\t\tLearning rate: 1.624e-03, Batch size: 50, Momentum: 4.206e-01\n",
      "best loss: 932.32\t\tLearning rate: 5.456e-04, Batch size: 12, Momentum: 8.413e-01\n",
      "best loss: 934.68\t\tLearning rate: 1.624e-03, Batch size: 14, Momentum: 6.835e-01\n",
      "best loss: 936.06\t\tLearning rate: 1.624e-03, Batch size: 29, Momentum: 4.206e-01\n",
      "best loss: 936.56\t\tLearning rate: 4.833e-03, Batch size: 42, Momentum: 3.155e-01\n",
      "best loss: 936.88\t\tLearning rate: 5.456e-04, Batch size: 17, Momentum: 6.835e-01\n",
      "best loss: 937.10\t\tLearning rate: 5.456e-04, Batch size: 34, Momentum: 6.835e-01\n",
      "best loss: 938.58\t\tLearning rate: 2.637e-07, Batch size: 39, Momentum: 5.258e-02\n",
      "best loss: 938.79\t\tLearning rate: 1.624e-03, Batch size: 50, Momentum: 5.784e-01\n",
      "best loss: 940.07\t\tLearning rate: 1.624e-03, Batch size: 4, Momentum: 4.732e-01\n",
      "best loss: 940.93\t\tLearning rate: 4.833e-03, Batch size: 39, Momentum: 0.000e+00\n",
      "best loss: 943.04\t\tLearning rate: 5.456e-04, Batch size: 7, Momentum: 5.784e-01\n",
      "best loss: 946.01\t\tLearning rate: 5.456e-04, Batch size: 12, Momentum: 9.990e-01\n",
      "best loss: 946.87\t\tLearning rate: 1.624e-03, Batch size: 50, Momentum: 5.258e-01\n",
      "best loss: 949.11\t\tLearning rate: 1.624e-03, Batch size: 2, Momentum: 1.577e-01\n",
      "best loss: 950.80\t\tLearning rate: 5.456e-04, Batch size: 4, Momentum: 4.206e-01\n",
      "best loss: 950.92\t\tLearning rate: 4.833e-03, Batch size: 50, Momentum: 4.732e-01\n",
      "best loss: 953.09\t\tLearning rate: 5.456e-04, Batch size: 22, Momentum: 8.413e-01\n",
      "best loss: 955.67\t\tLearning rate: 5.456e-04, Batch size: 2, Momentum: 8.938e-01\n",
      "best loss: 956.56\t\tLearning rate: 4.833e-03, Batch size: 37, Momentum: 3.155e-01\n",
      "best loss: 957.01\t\tLearning rate: 4.833e-03, Batch size: 44, Momentum: 1.577e-01\n",
      "best loss: 957.01\t\tLearning rate: 1.624e-03, Batch size: 14, Momentum: 4.732e-01\n",
      "best loss: 957.23\t\tLearning rate: 1.624e-03, Batch size: 9, Momentum: 2.629e-01\n",
      "best loss: 957.45\t\tLearning rate: 4.833e-03, Batch size: 34, Momentum: 6.835e-01\n",
      "best loss: 958.15\t\tLearning rate: 1.624e-03, Batch size: 37, Momentum: 5.258e-01\n",
      "best loss: 958.27\t\tLearning rate: 4.833e-03, Batch size: 34, Momentum: 1.577e-01\n",
      "best loss: 959.02\t\tLearning rate: 4.833e-03, Batch size: 14, Momentum: 0.000e+00\n",
      "best loss: 959.10\t\tLearning rate: 4.833e-03, Batch size: 29, Momentum: 5.258e-02\n",
      "best loss: 959.97\t\tLearning rate: 5.456e-04, Batch size: 12, Momentum: 9.464e-01\n",
      "best loss: 960.30\t\tLearning rate: 5.456e-04, Batch size: 9, Momentum: 7.887e-01\n",
      "best loss: 960.55\t\tLearning rate: 1.624e-03, Batch size: 9, Momentum: 2.103e-01\n",
      "best loss: 961.21\t\tLearning rate: 1.624e-03, Batch size: 17, Momentum: 3.681e-01\n",
      "best loss: 961.38\t\tLearning rate: 4.833e-03, Batch size: 50, Momentum: 0.000e+00\n",
      "best loss: 961.86\t\tLearning rate: 4.833e-03, Batch size: 4, Momentum: 3.681e-01\n",
      "best loss: 961.89\t\tLearning rate: 4.833e-03, Batch size: 27, Momentum: 1.052e-01\n",
      "best loss: 962.19\t\tLearning rate: 4.833e-03, Batch size: 17, Momentum: 5.258e-02\n",
      "best loss: 962.52\t\tLearning rate: 4.833e-03, Batch size: 34, Momentum: 9.464e-01\n",
      "best loss: 963.27\t\tLearning rate: 1.624e-03, Batch size: 50, Momentum: 6.835e-01\n",
      "best loss: 963.63\t\tLearning rate: 4.833e-03, Batch size: 19, Momentum: 2.103e-01\n",
      "best loss: 964.17\t\tLearning rate: 5.456e-04, Batch size: 14, Momentum: 8.938e-01\n",
      "best loss: 964.59\t\tLearning rate: 1.624e-03, Batch size: 14, Momentum: 4.206e-01\n",
      "best loss: 971.12\t\tLearning rate: 4.833e-03, Batch size: 2, Momentum: 2.103e-01\n",
      "best loss: 973.10\t\tLearning rate: 5.456e-04, Batch size: 9, Momentum: 9.464e-01\n",
      "best loss: 973.94\t\tLearning rate: 1.624e-03, Batch size: 4, Momentum: 7.361e-01\n",
      "best loss: 973.95\t\tLearning rate: 4.833e-03, Batch size: 7, Momentum: 3.681e-01\n",
      "best loss: 976.83\t\tLearning rate: 4.833e-03, Batch size: 39, Momentum: 2.103e-01\n",
      "best loss: 978.12\t\tLearning rate: 4.833e-03, Batch size: 19, Momentum: 6.309e-01\n",
      "best loss: 979.13\t\tLearning rate: 4.833e-03, Batch size: 14, Momentum: 2.103e-01\n",
      "best loss: 980.30\t\tLearning rate: 4.833e-03, Batch size: 39, Momentum: 4.206e-01\n",
      "best loss: 980.72\t\tLearning rate: 1.624e-03, Batch size: 17, Momentum: 5.784e-01\n",
      "best loss: 981.91\t\tLearning rate: 1.624e-03, Batch size: 12, Momentum: 6.309e-01\n",
      "best loss: 983.88\t\tLearning rate: 5.456e-04, Batch size: 37, Momentum: 8.938e-01\n",
      "best loss: 985.93\t\tLearning rate: 2.976e-08, Batch size: 32, Momentum: 2.103e-01\n",
      "best loss: 986.78\t\tLearning rate: 1.624e-03, Batch size: 37, Momentum: 6.835e-01\n",
      "best loss: 986.99\t\tLearning rate: 1.438e-02, Batch size: 2, Momentum: 2.103e-01\n",
      "best loss: 988.93\t\tLearning rate: 4.833e-03, Batch size: 39, Momentum: 5.784e-01\n",
      "best loss: 989.80\t\tLearning rate: 4.833e-03, Batch size: 12, Momentum: 6.309e-01\n",
      "best loss: 990.26\t\tLearning rate: 1.438e-02, Batch size: 27, Momentum: 5.258e-02\n",
      "best loss: 991.01\t\tLearning rate: 1.438e-02, Batch size: 32, Momentum: 1.052e-01\n",
      "best loss: 991.03\t\tLearning rate: 5.456e-04, Batch size: 22, Momentum: 9.990e-01\n",
      "best loss: 992.40\t\tLearning rate: 4.833e-03, Batch size: 14, Momentum: 2.629e-01\n",
      "best loss: 995.33\t\tLearning rate: 1.624e-03, Batch size: 12, Momentum: 8.413e-01\n",
      "best loss: 995.70\t\tLearning rate: 4.833e-03, Batch size: 7, Momentum: 4.732e-01\n",
      "best loss: 995.87\t\tLearning rate: 1.624e-03, Batch size: 44, Momentum: 5.784e-01\n",
      "best loss: 998.94\t\tLearning rate: 4.833e-03, Batch size: 14, Momentum: 3.155e-01\n",
      "best loss: 999.00\t\tLearning rate: 1.624e-03, Batch size: 29, Momentum: 5.784e-01\n",
      "best loss: 1001.02\t\tLearning rate: 1.438e-02, Batch size: 14, Momentum: 5.258e-02\n",
      "best loss: 1002.28\t\tLearning rate: 4.833e-03, Batch size: 7, Momentum: 6.835e-01\n",
      "best loss: 1003.50\t\tLearning rate: 4.281e-02, Batch size: 9, Momentum: 0.000e+00\n",
      "best loss: 1003.74\t\tLearning rate: 1.624e-03, Batch size: 14, Momentum: 8.938e-01\n",
      "best loss: 1004.25\t\tLearning rate: 4.833e-03, Batch size: 39, Momentum: 4.732e-01\n",
      "best loss: 1006.65\t\tLearning rate: 4.833e-03, Batch size: 27, Momentum: 4.206e-01\n",
      "best loss: 1006.73\t\tLearning rate: 1.438e-02, Batch size: 19, Momentum: 4.732e-01\n",
      "best loss: 1007.15\t\tLearning rate: 4.833e-03, Batch size: 2, Momentum: 4.206e-01\n",
      "best loss: 1007.55\t\tLearning rate: 1.438e-02, Batch size: 17, Momentum: 0.000e+00\n",
      "best loss: 1007.77\t\tLearning rate: 4.833e-03, Batch size: 37, Momentum: 6.309e-01\n",
      "best loss: 1009.38\t\tLearning rate: 1.438e-02, Batch size: 7, Momentum: 0.000e+00\n",
      "best loss: 1009.51\t\tLearning rate: 1.624e-03, Batch size: 19, Momentum: 9.990e-01\n",
      "best loss: 1011.99\t\tLearning rate: 4.833e-03, Batch size: 37, Momentum: 8.413e-01\n",
      "best loss: 1014.71\t\tLearning rate: 1.624e-03, Batch size: 34, Momentum: 7.361e-01\n",
      "best loss: 1016.17\t\tLearning rate: 1.438e-02, Batch size: 50, Momentum: 2.629e-01\n",
      "best loss: 1017.14\t\tLearning rate: 1.438e-02, Batch size: 4, Momentum: 2.103e-01\n",
      "best loss: 1017.24\t\tLearning rate: 4.281e-02, Batch size: 50, Momentum: 1.577e-01\n",
      "best loss: 1019.35\t\tLearning rate: 1.624e-03, Batch size: 9, Momentum: 9.464e-01\n",
      "best loss: 1020.24\t\tLearning rate: 4.833e-03, Batch size: 47, Momentum: 8.413e-01\n",
      "best loss: 1021.12\t\tLearning rate: 1.438e-02, Batch size: 34, Momentum: 2.103e-01\n",
      "best loss: 1021.26\t\tLearning rate: 5.456e-04, Batch size: 27, Momentum: 9.990e-01\n",
      "best loss: 1021.93\t\tLearning rate: 1.438e-02, Batch size: 12, Momentum: 4.206e-01\n",
      "best loss: 1022.74\t\tLearning rate: 1.438e-02, Batch size: 19, Momentum: 2.103e-01\n",
      "best loss: 1024.90\t\tLearning rate: 1.438e-02, Batch size: 22, Momentum: 2.629e-01\n",
      "best loss: 1024.91\t\tLearning rate: 1.624e-03, Batch size: 9, Momentum: 7.887e-01\n",
      "best loss: 1025.93\t\tLearning rate: 4.281e-02, Batch size: 47, Momentum: 0.000e+00\n",
      "best loss: 1026.00\t\tLearning rate: 1.624e-03, Batch size: 14, Momentum: 7.361e-01\n",
      "best loss: 1026.50\t\tLearning rate: 4.833e-03, Batch size: 17, Momentum: 5.784e-01\n",
      "best loss: 1026.73\t\tLearning rate: 4.833e-03, Batch size: 44, Momentum: 8.938e-01\n",
      "best loss: 1027.12\t\tLearning rate: 4.833e-03, Batch size: 27, Momentum: 4.732e-01\n",
      "best loss: 1027.55\t\tLearning rate: 4.833e-03, Batch size: 42, Momentum: 5.258e-01\n",
      "best loss: 1028.45\t\tLearning rate: 1.624e-03, Batch size: 19, Momentum: 7.887e-01\n",
      "best loss: 1028.56\t\tLearning rate: 4.833e-03, Batch size: 14, Momentum: 5.258e-01\n",
      "best loss: 1030.20\t\tLearning rate: 4.833e-03, Batch size: 42, Momentum: 7.887e-01\n",
      "best loss: 1030.52\t\tLearning rate: 4.833e-03, Batch size: 32, Momentum: 9.464e-01\n",
      "best loss: 1030.54\t\tLearning rate: 1.438e-02, Batch size: 27, Momentum: 4.206e-01\n",
      "best loss: 1030.75\t\tLearning rate: 4.281e-02, Batch size: 42, Momentum: 0.000e+00\n",
      "best loss: 1030.96\t\tLearning rate: 1.624e-03, Batch size: 39, Momentum: 9.990e-01\n",
      "best loss: 1031.58\t\tLearning rate: 4.281e-02, Batch size: 19, Momentum: 5.258e-02\n",
      "best loss: 1034.98\t\tLearning rate: 1.438e-02, Batch size: 2, Momentum: 3.155e-01\n",
      "best loss: 1035.05\t\tLearning rate: 4.833e-03, Batch size: 22, Momentum: 5.784e-01\n",
      "best loss: 1035.18\t\tLearning rate: 1.624e-03, Batch size: 17, Momentum: 7.361e-01\n",
      "best loss: 1035.64\t\tLearning rate: 4.281e-02, Batch size: 37, Momentum: 2.103e-01\n",
      "best loss: 1036.11\t\tLearning rate: 4.833e-03, Batch size: 7, Momentum: 3.155e-01\n",
      "best loss: 1036.63\t\tLearning rate: 1.624e-03, Batch size: 42, Momentum: 7.361e-01\n",
      "best loss: 1037.03\t\tLearning rate: 1.438e-02, Batch size: 4, Momentum: 3.155e-01\n",
      "best loss: 1037.18\t\tLearning rate: 1.624e-03, Batch size: 4, Momentum: 8.413e-01\n",
      "best loss: 1037.91\t\tLearning rate: 4.281e-02, Batch size: 2, Momentum: 2.103e-01\n",
      "best loss: 1039.60\t\tLearning rate: 4.833e-03, Batch size: 14, Momentum: 8.938e-01\n",
      "best loss: 1040.04\t\tLearning rate: 1.624e-03, Batch size: 44, Momentum: 8.413e-01\n",
      "best loss: 1040.93\t\tLearning rate: 4.833e-03, Batch size: 12, Momentum: 7.887e-01\n",
      "best loss: 1041.37\t\tLearning rate: 1.624e-03, Batch size: 32, Momentum: 8.938e-01\n",
      "best loss: 1043.02\t\tLearning rate: 1.624e-03, Batch size: 39, Momentum: 8.413e-01\n",
      "best loss: 1044.12\t\tLearning rate: 1.624e-03, Batch size: 42, Momentum: 9.464e-01\n",
      "best loss: 1046.14\t\tLearning rate: 4.281e-02, Batch size: 14, Momentum: 5.258e-02\n",
      "best loss: 1046.72\t\tLearning rate: 1.438e-02, Batch size: 44, Momentum: 2.629e-01\n",
      "best loss: 1047.55\t\tLearning rate: 4.281e-02, Batch size: 37, Momentum: 3.155e-01\n",
      "best loss: 1049.18\t\tLearning rate: 1.438e-02, Batch size: 34, Momentum: 5.258e-01\n",
      "best loss: 1049.70\t\tLearning rate: 1.438e-02, Batch size: 12, Momentum: 3.681e-01\n",
      "best loss: 1050.66\t\tLearning rate: 4.833e-03, Batch size: 47, Momentum: 7.361e-01\n",
      "best loss: 1051.50\t\tLearning rate: 4.833e-03, Batch size: 2, Momentum: 8.413e-01\n",
      "best loss: 1051.92\t\tLearning rate: 1.624e-03, Batch size: 2, Momentum: 9.990e-01\n",
      "best loss: 1053.51\t\tLearning rate: 1.438e-02, Batch size: 37, Momentum: 5.784e-01\n",
      "best loss: 1053.65\t\tLearning rate: 4.833e-03, Batch size: 24, Momentum: 7.361e-01\n",
      "best loss: 1055.14\t\tLearning rate: 4.281e-02, Batch size: 14, Momentum: 0.000e+00\n",
      "best loss: 1059.30\t\tLearning rate: 4.833e-03, Batch size: 7, Momentum: 9.464e-01\n",
      "best loss: 1060.28\t\tLearning rate: 4.281e-02, Batch size: 24, Momentum: 5.258e-02\n",
      "best loss: 1063.10\t\tLearning rate: 4.833e-03, Batch size: 22, Momentum: 6.835e-01\n",
      "best loss: 1063.17\t\tLearning rate: 4.833e-03, Batch size: 42, Momentum: 7.361e-01\n",
      "best loss: 1063.29\t\tLearning rate: 4.833e-03, Batch size: 14, Momentum: 7.361e-01\n",
      "best loss: 1065.98\t\tLearning rate: 1.438e-02, Batch size: 39, Momentum: 3.155e-01\n",
      "best loss: 1066.44\t\tLearning rate: 1.438e-02, Batch size: 9, Momentum: 5.258e-01\n",
      "best loss: 1066.88\t\tLearning rate: 4.833e-03, Batch size: 19, Momentum: 8.938e-01\n",
      "best loss: 1068.82\t\tLearning rate: 4.281e-02, Batch size: 24, Momentum: 2.103e-01\n",
      "best loss: 1068.90\t\tLearning rate: 1.624e-03, Batch size: 7, Momentum: 8.938e-01\n",
      "best loss: 1068.92\t\tLearning rate: 1.438e-02, Batch size: 50, Momentum: 6.835e-01\n",
      "best loss: 1069.65\t\tLearning rate: 4.833e-03, Batch size: 34, Momentum: 7.887e-01\n",
      "best loss: 1069.70\t\tLearning rate: 4.833e-03, Batch size: 9, Momentum: 8.413e-01\n",
      "best loss: 1071.11\t\tLearning rate: 1.624e-03, Batch size: 34, Momentum: 9.464e-01\n",
      "best loss: 1071.64\t\tLearning rate: 4.281e-02, Batch size: 14, Momentum: 4.206e-01\n",
      "best loss: 1071.92\t\tLearning rate: 1.000e-08, Batch size: 19, Momentum: 7.361e-01\n",
      "best loss: 1072.22\t\tLearning rate: 1.624e-03, Batch size: 39, Momentum: 8.938e-01\n",
      "best loss: 1072.63\t\tLearning rate: 4.833e-03, Batch size: 19, Momentum: 7.361e-01\n",
      "best loss: 1073.98\t\tLearning rate: 4.281e-02, Batch size: 17, Momentum: 1.052e-01\n",
      "best loss: 1074.98\t\tLearning rate: 4.833e-03, Batch size: 27, Momentum: 9.990e-01\n",
      "best loss: 1078.57\t\tLearning rate: 4.281e-02, Batch size: 17, Momentum: 1.577e-01\n",
      "best loss: 1079.86\t\tLearning rate: 4.833e-03, Batch size: 32, Momentum: 9.990e-01\n",
      "best loss: 1080.21\t\tLearning rate: 4.281e-02, Batch size: 19, Momentum: 1.577e-01\n",
      "best loss: 1083.81\t\tLearning rate: 4.281e-02, Batch size: 4, Momentum: 5.258e-01\n",
      "best loss: 1086.51\t\tLearning rate: 1.438e-02, Batch size: 27, Momentum: 3.681e-01\n",
      "best loss: 1086.79\t\tLearning rate: 1.438e-02, Batch size: 27, Momentum: 8.413e-01\n",
      "best loss: 1086.89\t\tLearning rate: 4.281e-02, Batch size: 34, Momentum: 2.629e-01\n",
      "best loss: 1089.64\t\tLearning rate: 4.281e-02, Batch size: 17, Momentum: 2.629e-01\n",
      "best loss: 1090.46\t\tLearning rate: 4.833e-03, Batch size: 50, Momentum: 9.464e-01\n",
      "best loss: 1091.21\t\tLearning rate: 4.281e-02, Batch size: 2, Momentum: 5.258e-01\n",
      "best loss: 1091.92\t\tLearning rate: 4.281e-02, Batch size: 27, Momentum: 3.155e-01\n",
      "best loss: 1091.96\t\tLearning rate: 1.438e-02, Batch size: 44, Momentum: 6.835e-01\n",
      "best loss: 1092.06\t\tLearning rate: 1.438e-02, Batch size: 2, Momentum: 6.309e-01\n",
      "best loss: 1092.25\t\tLearning rate: 1.274e-01, Batch size: 22, Momentum: 0.000e+00\n",
      "best loss: 1094.52\t\tLearning rate: 1.274e-01, Batch size: 17, Momentum: 1.052e-01\n",
      "best loss: 1094.53\t\tLearning rate: 4.281e-02, Batch size: 27, Momentum: 3.681e-01\n",
      "best loss: 1094.67\t\tLearning rate: 4.833e-03, Batch size: 50, Momentum: 8.938e-01\n",
      "best loss: 1094.84\t\tLearning rate: 1.438e-02, Batch size: 34, Momentum: 9.990e-01\n",
      "best loss: 1094.84\t\tLearning rate: 1.438e-02, Batch size: 32, Momentum: 6.309e-01\n",
      "best loss: 1095.60\t\tLearning rate: 1.438e-02, Batch size: 9, Momentum: 6.309e-01\n",
      "best loss: 1095.87\t\tLearning rate: 1.438e-02, Batch size: 22, Momentum: 6.309e-01\n",
      "best loss: 1096.77\t\tLearning rate: 4.281e-02, Batch size: 29, Momentum: 1.577e-01\n",
      "best loss: 1098.23\t\tLearning rate: 4.833e-03, Batch size: 42, Momentum: 9.990e-01\n",
      "best loss: 1098.72\t\tLearning rate: 1.438e-02, Batch size: 29, Momentum: 6.309e-01\n",
      "best loss: 1102.64\t\tLearning rate: 4.281e-02, Batch size: 32, Momentum: 2.103e-01\n",
      "best loss: 1102.92\t\tLearning rate: 4.281e-02, Batch size: 42, Momentum: 3.681e-01\n",
      "best loss: 1104.11\t\tLearning rate: 1.274e-01, Batch size: 9, Momentum: 2.103e-01\n",
      "best loss: 1104.78\t\tLearning rate: 1.274e-01, Batch size: 47, Momentum: 1.052e-01\n",
      "best loss: 1105.13\t\tLearning rate: 4.281e-02, Batch size: 37, Momentum: 3.681e-01\n",
      "best loss: 1105.85\t\tLearning rate: 1.624e-03, Batch size: 47, Momentum: 9.464e-01\n",
      "best loss: 1105.98\t\tLearning rate: 4.281e-02, Batch size: 50, Momentum: 4.206e-01\n",
      "best loss: 1107.88\t\tLearning rate: 1.438e-02, Batch size: 17, Momentum: 7.361e-01\n",
      "best loss: 1110.83\t\tLearning rate: 2.976e-08, Batch size: 34, Momentum: 2.103e-01\n",
      "best loss: 1111.62\t\tLearning rate: 1.274e-01, Batch size: 39, Momentum: 1.577e-01\n",
      "best loss: 1112.02\t\tLearning rate: 1.274e-01, Batch size: 34, Momentum: 2.103e-01\n",
      "best loss: 1112.20\t\tLearning rate: 1.438e-02, Batch size: 47, Momentum: 6.835e-01\n",
      "best loss: 1114.19\t\tLearning rate: 4.281e-02, Batch size: 39, Momentum: 2.629e-01\n",
      "best loss: 1116.55\t\tLearning rate: 4.833e-03, Batch size: 19, Momentum: 9.990e-01\n",
      "best loss: 1118.85\t\tLearning rate: 1.274e-01, Batch size: 24, Momentum: 5.258e-02\n",
      "best loss: 1119.68\t\tLearning rate: 4.281e-02, Batch size: 9, Momentum: 5.784e-01\n",
      "best loss: 1119.96\t\tLearning rate: 1.274e-01, Batch size: 29, Momentum: 9.990e-01\n",
      "best loss: 1120.01\t\tLearning rate: 4.281e-02, Batch size: 44, Momentum: 1.577e-01\n",
      "best loss: 1120.38\t\tLearning rate: 4.281e-02, Batch size: 19, Momentum: 5.784e-01\n",
      "best loss: 1121.05\t\tLearning rate: 1.438e-02, Batch size: 29, Momentum: 8.938e-01\n",
      "best loss: 1123.63\t\tLearning rate: 1.624e-03, Batch size: 4, Momentum: 9.464e-01\n",
      "best loss: 1123.84\t\tLearning rate: 1.438e-02, Batch size: 39, Momentum: 8.413e-01\n",
      "best loss: 1124.90\t\tLearning rate: 4.281e-02, Batch size: 42, Momentum: 3.155e-01\n",
      "best loss: 1126.77\t\tLearning rate: 4.281e-02, Batch size: 27, Momentum: 7.887e-01\n",
      "best loss: 1127.53\t\tLearning rate: 1.438e-02, Batch size: 44, Momentum: 8.413e-01\n",
      "best loss: 1127.65\t\tLearning rate: 4.833e-03, Batch size: 29, Momentum: 9.990e-01\n",
      "best loss: 1129.34\t\tLearning rate: 1.274e-01, Batch size: 19, Momentum: 5.258e-01\n",
      "best loss: 1130.63\t\tLearning rate: 4.281e-02, Batch size: 7, Momentum: 4.732e-01\n",
      "best loss: 1130.73\t\tLearning rate: 4.281e-02, Batch size: 2, Momentum: 5.784e-01\n",
      "best loss: 1131.34\t\tLearning rate: 2.637e-07, Batch size: 27, Momentum: 1.577e-01\n",
      "best loss: 1131.83\t\tLearning rate: 1.438e-02, Batch size: 34, Momentum: 6.309e-01\n",
      "best loss: 1132.29\t\tLearning rate: 4.281e-02, Batch size: 9, Momentum: 6.835e-01\n",
      "best loss: 1132.30\t\tLearning rate: 4.833e-03, Batch size: 2, Momentum: 7.887e-01\n",
      "best loss: 1132.98\t\tLearning rate: 4.281e-02, Batch size: 50, Momentum: 5.784e-01\n",
      "best loss: 1134.37\t\tLearning rate: 4.281e-02, Batch size: 44, Momentum: 4.206e-01\n",
      "best loss: 1134.49\t\tLearning rate: 1.438e-02, Batch size: 47, Momentum: 9.464e-01\n",
      "best loss: 1136.13\t\tLearning rate: 1.274e-01, Batch size: 44, Momentum: 2.629e-01\n",
      "best loss: 1136.84\t\tLearning rate: 1.274e-01, Batch size: 44, Momentum: 1.052e-01\n",
      "best loss: 1138.49\t\tLearning rate: 4.281e-02, Batch size: 50, Momentum: 6.835e-01\n",
      "best loss: 1140.82\t\tLearning rate: 1.274e-01, Batch size: 44, Momentum: 3.155e-01\n",
      "best loss: 1142.03\t\tLearning rate: 3.793e-01, Batch size: 22, Momentum: 5.258e-02\n",
      "best loss: 1142.43\t\tLearning rate: 1.274e-01, Batch size: 42, Momentum: 1.052e-01\n",
      "best loss: 1142.87\t\tLearning rate: 1.274e-01, Batch size: 2, Momentum: 2.629e-01\n",
      "best loss: 1144.59\t\tLearning rate: 4.281e-02, Batch size: 27, Momentum: 8.413e-01\n",
      "best loss: 1144.65\t\tLearning rate: 1.274e-01, Batch size: 22, Momentum: 2.103e-01\n",
      "best loss: 1145.55\t\tLearning rate: 1.274e-01, Batch size: 4, Momentum: 1.577e-01\n",
      "best loss: 1145.68\t\tLearning rate: 2.976e-08, Batch size: 42, Momentum: 5.258e-02\n",
      "best loss: 1146.79\t\tLearning rate: 1.274e-01, Batch size: 29, Momentum: 2.103e-01\n",
      "best loss: 1147.07\t\tLearning rate: 3.793e-01, Batch size: 34, Momentum: 0.000e+00\n",
      "best loss: 1147.30\t\tLearning rate: 3.793e-01, Batch size: 37, Momentum: 0.000e+00\n",
      "best loss: 1148.28\t\tLearning rate: 3.793e-01, Batch size: 4, Momentum: 0.000e+00\n",
      "best loss: 1149.45\t\tLearning rate: 3.793e-01, Batch size: 29, Momentum: 0.000e+00\n",
      "best loss: 1149.92\t\tLearning rate: 1.274e-01, Batch size: 12, Momentum: 2.629e-01\n",
      "best loss: 1150.16\t\tLearning rate: 1.438e-02, Batch size: 9, Momentum: 9.990e-01\n",
      "best loss: 1151.00\t\tLearning rate: 1.438e-02, Batch size: 39, Momentum: 9.464e-01\n",
      "best loss: 1151.19\t\tLearning rate: 1.274e-01, Batch size: 42, Momentum: 5.258e-01\n",
      "best loss: 1152.10\t\tLearning rate: 4.281e-02, Batch size: 12, Momentum: 9.990e-01\n",
      "best loss: 1152.19\t\tLearning rate: 1.274e-01, Batch size: 24, Momentum: 2.103e-01\n",
      "best loss: 1152.49\t\tLearning rate: 1.274e-01, Batch size: 17, Momentum: 3.155e-01\n",
      "best loss: 1152.68\t\tLearning rate: 1.438e-02, Batch size: 7, Momentum: 9.464e-01\n",
      "best loss: 1152.86\t\tLearning rate: 3.793e-01, Batch size: 42, Momentum: 2.103e-01\n",
      "best loss: 1153.13\t\tLearning rate: 1.274e-01, Batch size: 17, Momentum: 3.681e-01\n",
      "best loss: 1153.16\t\tLearning rate: 3.793e-01, Batch size: 2, Momentum: 1.577e-01\n",
      "best loss: 1153.60\t\tLearning rate: 1.274e-01, Batch size: 9, Momentum: 4.206e-01\n",
      "best loss: 1155.39\t\tLearning rate: 4.281e-02, Batch size: 22, Momentum: 7.887e-01\n",
      "best loss: 1156.63\t\tLearning rate: 3.793e-01, Batch size: 29, Momentum: 3.681e-01\n",
      "best loss: 1156.85\t\tLearning rate: 1.274e-01, Batch size: 24, Momentum: 4.206e-01\n",
      "best loss: 1157.27\t\tLearning rate: 4.281e-02, Batch size: 47, Momentum: 6.309e-01\n",
      "best loss: 1157.86\t\tLearning rate: 1.274e-01, Batch size: 32, Momentum: 5.784e-01\n",
      "best loss: 1157.98\t\tLearning rate: 4.281e-02, Batch size: 32, Momentum: 7.361e-01\n",
      "best loss: 1158.81\t\tLearning rate: 1.274e-01, Batch size: 39, Momentum: 5.784e-01\n",
      "best loss: 1159.17\t\tLearning rate: 4.281e-02, Batch size: 42, Momentum: 8.938e-01\n",
      "best loss: 1159.23\t\tLearning rate: 1.438e-02, Batch size: 17, Momentum: 8.938e-01\n",
      "best loss: 1159.31\t\tLearning rate: 3.793e-01, Batch size: 2, Momentum: 5.258e-02\n",
      "best loss: 1160.37\t\tLearning rate: 1.274e-01, Batch size: 42, Momentum: 2.103e-01\n",
      "best loss: 1160.88\t\tLearning rate: 3.793e-01, Batch size: 22, Momentum: 1.577e-01\n",
      "best loss: 1161.78\t\tLearning rate: 4.281e-02, Batch size: 44, Momentum: 5.784e-01\n",
      "best loss: 1162.12\t\tLearning rate: 4.281e-02, Batch size: 44, Momentum: 9.464e-01\n",
      "best loss: 1162.58\t\tLearning rate: 1.274e-01, Batch size: 2, Momentum: 1.577e-01\n",
      "best loss: 1165.97\t\tLearning rate: 1.274e-01, Batch size: 7, Momentum: 5.784e-01\n",
      "best loss: 1166.25\t\tLearning rate: 1.438e-02, Batch size: 7, Momentum: 9.990e-01\n",
      "best loss: 1166.46\t\tLearning rate: 1.438e-02, Batch size: 14, Momentum: 9.990e-01\n",
      "best loss: 1166.72\t\tLearning rate: 1.438e-02, Batch size: 9, Momentum: 9.464e-01\n",
      "best loss: 1167.27\t\tLearning rate: 4.281e-02, Batch size: 47, Momentum: 7.361e-01\n",
      "best loss: 1167.98\t\tLearning rate: 4.281e-02, Batch size: 39, Momentum: 7.887e-01\n",
      "best loss: 1169.09\t\tLearning rate: 3.793e-01, Batch size: 24, Momentum: 3.681e-01\n",
      "best loss: 1169.31\t\tLearning rate: 1.129e+00, Batch size: 19, Momentum: 0.000e+00\n",
      "best loss: 1170.31\t\tLearning rate: 1.274e-01, Batch size: 22, Momentum: 3.681e-01\n",
      "best loss: 1170.50\t\tLearning rate: 1.274e-01, Batch size: 27, Momentum: 5.258e-01\n",
      "best loss: 1172.59\t\tLearning rate: 3.793e-01, Batch size: 7, Momentum: 2.103e-01\n",
      "best loss: 1173.83\t\tLearning rate: 4.281e-02, Batch size: 37, Momentum: 6.835e-01\n",
      "best loss: 1175.06\t\tLearning rate: 1.274e-01, Batch size: 42, Momentum: 2.629e-01\n",
      "best loss: 1176.10\t\tLearning rate: 4.833e-03, Batch size: 7, Momentum: 9.990e-01\n",
      "best loss: 1176.53\t\tLearning rate: 1.438e-02, Batch size: 2, Momentum: 9.990e-01\n",
      "best loss: 1178.20\t\tLearning rate: 1.438e-02, Batch size: 42, Momentum: 8.938e-01\n",
      "best loss: 1179.49\t\tLearning rate: 1.274e-01, Batch size: 39, Momentum: 4.206e-01\n",
      "best loss: 1182.66\t\tLearning rate: 3.793e-01, Batch size: 7, Momentum: 5.258e-02\n",
      "best loss: 1183.58\t\tLearning rate: 3.793e-01, Batch size: 12, Momentum: 1.577e-01\n",
      "best loss: 1186.97\t\tLearning rate: 1.274e-01, Batch size: 37, Momentum: 7.361e-01\n",
      "best loss: 1188.30\t\tLearning rate: 3.793e-01, Batch size: 9, Momentum: 3.155e-01\n",
      "best loss: 1189.57\t\tLearning rate: 1.274e-01, Batch size: 4, Momentum: 2.629e-01\n",
      "best loss: 1189.99\t\tLearning rate: 4.281e-02, Batch size: 4, Momentum: 7.361e-01\n",
      "best loss: 1190.08\t\tLearning rate: 1.274e-01, Batch size: 4, Momentum: 4.206e-01\n",
      "best loss: 1190.25\t\tLearning rate: 1.274e-01, Batch size: 44, Momentum: 4.206e-01\n",
      "best loss: 1191.05\t\tLearning rate: 3.793e-01, Batch size: 29, Momentum: 3.155e-01\n",
      "best loss: 1192.17\t\tLearning rate: 4.281e-02, Batch size: 14, Momentum: 8.413e-01\n",
      "best loss: 1193.10\t\tLearning rate: 1.274e-01, Batch size: 12, Momentum: 1.577e-01\n",
      "best loss: 1193.26\t\tLearning rate: 1.274e-01, Batch size: 37, Momentum: 2.629e-01\n",
      "best loss: 1194.50\t\tLearning rate: 4.281e-02, Batch size: 17, Momentum: 8.938e-01\n",
      "best loss: 1194.75\t\tLearning rate: 1.129e+00, Batch size: 27, Momentum: 0.000e+00\n",
      "best loss: 1195.18\t\tLearning rate: 3.793e-01, Batch size: 2, Momentum: 1.052e-01\n",
      "best loss: 1198.04\t\tLearning rate: 3.793e-01, Batch size: 29, Momentum: 4.732e-01\n",
      "best loss: 1203.09\t\tLearning rate: 3.793e-01, Batch size: 7, Momentum: 1.052e-01\n",
      "best loss: 1204.21\t\tLearning rate: 3.793e-01, Batch size: 39, Momentum: 1.052e-01\n",
      "best loss: 1204.86\t\tLearning rate: 4.281e-02, Batch size: 7, Momentum: 8.938e-01\n",
      "best loss: 1204.87\t\tLearning rate: 3.793e-01, Batch size: 39, Momentum: 3.155e-01\n",
      "best loss: 1205.08\t\tLearning rate: 1.438e-02, Batch size: 29, Momentum: 9.464e-01\n",
      "best loss: 1208.49\t\tLearning rate: 1.129e+00, Batch size: 7, Momentum: 1.052e-01\n",
      "best loss: 1210.26\t\tLearning rate: 3.793e-01, Batch size: 9, Momentum: 1.052e-01\n",
      "best loss: 1211.01\t\tLearning rate: 1.000e-08, Batch size: 19, Momentum: 2.629e-01\n",
      "best loss: 1211.29\t\tLearning rate: 3.793e-01, Batch size: 32, Momentum: 5.784e-01\n",
      "best loss: 1211.45\t\tLearning rate: 3.793e-01, Batch size: 4, Momentum: 5.258e-01\n",
      "best loss: 1211.47\t\tLearning rate: 1.274e-01, Batch size: 27, Momentum: 8.413e-01\n",
      "best loss: 1211.88\t\tLearning rate: 1.129e+00, Batch size: 7, Momentum: 5.258e-02\n",
      "best loss: 1212.11\t\tLearning rate: 1.129e+00, Batch size: 47, Momentum: 5.258e-02\n",
      "best loss: 1213.10\t\tLearning rate: 1.274e-01, Batch size: 22, Momentum: 6.309e-01\n",
      "best loss: 1214.75\t\tLearning rate: 3.793e-01, Batch size: 19, Momentum: 5.258e-02\n",
      "best loss: 1216.28\t\tLearning rate: 3.793e-01, Batch size: 50, Momentum: 5.258e-02\n",
      "best loss: 1217.33\t\tLearning rate: 3.793e-01, Batch size: 24, Momentum: 2.629e-01\n",
      "best loss: 1218.35\t\tLearning rate: 4.281e-02, Batch size: 42, Momentum: 9.464e-01\n",
      "best loss: 1219.17\t\tLearning rate: 3.793e-01, Batch size: 2, Momentum: 6.309e-01\n",
      "best loss: 1219.96\t\tLearning rate: 3.793e-01, Batch size: 32, Momentum: 3.681e-01\n",
      "best loss: 1221.90\t\tLearning rate: 3.793e-01, Batch size: 44, Momentum: 4.732e-01\n",
      "best loss: 1222.05\t\tLearning rate: 1.274e-01, Batch size: 17, Momentum: 4.732e-01\n",
      "best loss: 1222.46\t\tLearning rate: 1.274e-01, Batch size: 7, Momentum: 8.413e-01\n",
      "best loss: 1223.95\t\tLearning rate: 1.274e-01, Batch size: 17, Momentum: 6.309e-01\n",
      "best loss: 1224.05\t\tLearning rate: 1.274e-01, Batch size: 39, Momentum: 6.309e-01\n",
      "best loss: 1224.69\t\tLearning rate: 1.129e+00, Batch size: 27, Momentum: 1.577e-01\n",
      "best loss: 1225.11\t\tLearning rate: 1.274e-01, Batch size: 32, Momentum: 7.361e-01\n",
      "best loss: 1225.38\t\tLearning rate: 1.274e-01, Batch size: 27, Momentum: 6.309e-01\n",
      "best loss: 1226.06\t\tLearning rate: 1.274e-01, Batch size: 37, Momentum: 8.413e-01\n",
      "best loss: 1227.13\t\tLearning rate: 1.274e-01, Batch size: 29, Momentum: 7.887e-01\n",
      "best loss: 1227.24\t\tLearning rate: 1.274e-01, Batch size: 12, Momentum: 7.887e-01\n",
      "best loss: 1229.31\t\tLearning rate: 3.793e-01, Batch size: 39, Momentum: 4.206e-01\n",
      "best loss: 1229.33\t\tLearning rate: 3.793e-01, Batch size: 37, Momentum: 1.577e-01\n",
      "best loss: 1230.12\t\tLearning rate: 3.793e-01, Batch size: 12, Momentum: 4.732e-01\n",
      "best loss: 1231.35\t\tLearning rate: 1.274e-01, Batch size: 42, Momentum: 8.938e-01\n",
      "best loss: 1232.34\t\tLearning rate: 1.129e+00, Batch size: 4, Momentum: 2.629e-01\n",
      "best loss: 1233.94\t\tLearning rate: 1.129e+00, Batch size: 22, Momentum: 5.258e-02\n",
      "best loss: 1235.71\t\tLearning rate: 3.793e-01, Batch size: 17, Momentum: 4.206e-01\n",
      "best loss: 1235.77\t\tLearning rate: 3.360e+00, Batch size: 34, Momentum: 5.258e-02\n",
      "best loss: 1236.35\t\tLearning rate: 1.274e-01, Batch size: 50, Momentum: 8.938e-01\n",
      "best loss: 1236.57\t\tLearning rate: 1.129e+00, Batch size: 44, Momentum: 0.000e+00\n",
      "best loss: 1238.03\t\tLearning rate: 3.793e-01, Batch size: 50, Momentum: 3.681e-01\n",
      "best loss: 1238.61\t\tLearning rate: 1.274e-01, Batch size: 4, Momentum: 6.309e-01\n",
      "best loss: 1239.68\t\tLearning rate: 3.793e-01, Batch size: 50, Momentum: 2.629e-01\n",
      "best loss: 1240.76\t\tLearning rate: 3.793e-01, Batch size: 22, Momentum: 3.155e-01\n",
      "best loss: 1240.78\t\tLearning rate: 1.129e+00, Batch size: 22, Momentum: 1.052e-01\n",
      "best loss: 1241.18\t\tLearning rate: 1.274e-01, Batch size: 7, Momentum: 4.732e-01\n",
      "best loss: 1241.31\t\tLearning rate: 1.274e-01, Batch size: 4, Momentum: 6.835e-01\n",
      "best loss: 1242.25\t\tLearning rate: 1.129e+00, Batch size: 14, Momentum: 5.258e-02\n",
      "best loss: 1242.38\t\tLearning rate: 1.129e+00, Batch size: 17, Momentum: 5.258e-02\n",
      "best loss: 1242.48\t\tLearning rate: 3.360e+00, Batch size: 32, Momentum: 5.258e-02\n",
      "best loss: 1242.56\t\tLearning rate: 3.793e-01, Batch size: 29, Momentum: 5.784e-01\n",
      "best loss: 1242.63\t\tLearning rate: 3.793e-01, Batch size: 12, Momentum: 4.206e-01\n",
      "best loss: 1244.31\t\tLearning rate: 3.793e-01, Batch size: 27, Momentum: 2.103e-01\n",
      "best loss: 1244.60\t\tLearning rate: 1.129e+00, Batch size: 34, Momentum: 3.681e-01\n",
      "best loss: 1246.29\t\tLearning rate: 1.129e+00, Batch size: 4, Momentum: 1.577e-01\n",
      "best loss: 1246.89\t\tLearning rate: 4.281e-02, Batch size: 27, Momentum: 9.464e-01\n",
      "best loss: 1247.16\t\tLearning rate: 3.793e-01, Batch size: 2, Momentum: 5.784e-01\n",
      "best loss: 1248.34\t\tLearning rate: 3.793e-01, Batch size: 32, Momentum: 6.835e-01\n",
      "best loss: 1249.18\t\tLearning rate: 1.129e+00, Batch size: 22, Momentum: 2.629e-01\n",
      "best loss: 1249.78\t\tLearning rate: 1.129e+00, Batch size: 24, Momentum: 1.052e-01\n",
      "best loss: 1250.62\t\tLearning rate: 1.000e-08, Batch size: 7, Momentum: 3.155e-01\n",
      "best loss: 1251.00\t\tLearning rate: 1.274e-01, Batch size: 27, Momentum: 5.784e-01\n",
      "best loss: 1251.01\t\tLearning rate: 2.637e-07, Batch size: 32, Momentum: 7.361e-01\n",
      "best loss: 1254.32\t\tLearning rate: 1.274e-01, Batch size: 29, Momentum: 8.413e-01\n",
      "best loss: 1256.00\t\tLearning rate: 1.274e-01, Batch size: 9, Momentum: 6.309e-01\n",
      "best loss: 1257.35\t\tLearning rate: 3.793e-01, Batch size: 50, Momentum: 4.732e-01\n",
      "best loss: 1258.47\t\tLearning rate: 4.281e-02, Batch size: 2, Momentum: 7.887e-01\n",
      "best loss: 1260.21\t\tLearning rate: 1.129e+00, Batch size: 50, Momentum: 2.103e-01\n",
      "best loss: 1262.81\t\tLearning rate: 3.793e-01, Batch size: 42, Momentum: 6.835e-01\n",
      "best loss: 1264.20\t\tLearning rate: 3.793e-01, Batch size: 24, Momentum: 5.784e-01\n",
      "best loss: 1264.69\t\tLearning rate: 3.793e-01, Batch size: 17, Momentum: 6.835e-01\n",
      "best loss: 1265.45\t\tLearning rate: 3.793e-01, Batch size: 22, Momentum: 7.361e-01\n",
      "best loss: 1267.31\t\tLearning rate: 3.360e+00, Batch size: 27, Momentum: 1.052e-01\n",
      "best loss: 1267.50\t\tLearning rate: 1.274e-01, Batch size: 4, Momentum: 9.990e-01\n",
      "best loss: 1268.48\t\tLearning rate: 3.793e-01, Batch size: 22, Momentum: 8.413e-01\n",
      "best loss: 1269.36\t\tLearning rate: 1.129e+00, Batch size: 47, Momentum: 2.629e-01\n",
      "best loss: 1271.88\t\tLearning rate: 3.360e+00, Batch size: 29, Momentum: 0.000e+00\n",
      "best loss: 1275.06\t\tLearning rate: 3.793e-01, Batch size: 27, Momentum: 6.309e-01\n",
      "best loss: 1275.69\t\tLearning rate: 3.793e-01, Batch size: 27, Momentum: 5.258e-01\n",
      "best loss: 1276.49\t\tLearning rate: 3.793e-01, Batch size: 44, Momentum: 5.258e-01\n",
      "best loss: 1277.45\t\tLearning rate: 3.360e+00, Batch size: 22, Momentum: 5.258e-02\n",
      "best loss: 1277.83\t\tLearning rate: 3.793e-01, Batch size: 7, Momentum: 6.309e-01\n",
      "best loss: 1277.85\t\tLearning rate: 3.793e-01, Batch size: 4, Momentum: 4.206e-01\n",
      "best loss: 1278.91\t\tLearning rate: 3.360e+00, Batch size: 32, Momentum: 0.000e+00\n",
      "best loss: 1279.28\t\tLearning rate: 3.793e-01, Batch size: 12, Momentum: 8.413e-01\n",
      "best loss: 1281.66\t\tLearning rate: 1.129e+00, Batch size: 24, Momentum: 2.103e-01\n",
      "best loss: 1281.97\t\tLearning rate: 3.793e-01, Batch size: 37, Momentum: 6.835e-01\n",
      "best loss: 1284.40\t\tLearning rate: 1.129e+00, Batch size: 32, Momentum: 5.258e-01\n",
      "best loss: 1284.77\t\tLearning rate: 3.793e-01, Batch size: 7, Momentum: 5.258e-01\n",
      "best loss: 1285.30\t\tLearning rate: 3.793e-01, Batch size: 42, Momentum: 7.361e-01\n",
      "best loss: 1285.48\t\tLearning rate: 3.793e-01, Batch size: 42, Momentum: 5.784e-01\n",
      "best loss: 1288.25\t\tLearning rate: 3.360e+00, Batch size: 44, Momentum: 5.258e-02\n",
      "best loss: 1290.25\t\tLearning rate: 1.274e-01, Batch size: 17, Momentum: 9.990e-01\n",
      "best loss: 1290.48\t\tLearning rate: 1.129e+00, Batch size: 14, Momentum: 3.681e-01\n",
      "best loss: 1291.54\t\tLearning rate: 3.793e-01, Batch size: 2, Momentum: 7.361e-01\n",
      "best loss: 1292.43\t\tLearning rate: 1.129e+00, Batch size: 32, Momentum: 3.155e-01\n",
      "best loss: 1293.29\t\tLearning rate: 3.793e-01, Batch size: 4, Momentum: 9.990e-01\n",
      "best loss: 1293.66\t\tLearning rate: 1.274e-01, Batch size: 50, Momentum: 9.464e-01\n",
      "best loss: 1294.61\t\tLearning rate: 1.129e+00, Batch size: 19, Momentum: 5.258e-01\n",
      "best loss: 1295.50\t\tLearning rate: 1.129e+00, Batch size: 32, Momentum: 2.629e-01\n",
      "best loss: 1296.15\t\tLearning rate: 1.129e+00, Batch size: 29, Momentum: 6.309e-01\n",
      "best loss: 1296.88\t\tLearning rate: 3.793e-01, Batch size: 9, Momentum: 8.413e-01\n",
      "best loss: 1298.21\t\tLearning rate: 1.129e+00, Batch size: 9, Momentum: 4.732e-01\n",
      "best loss: 1298.97\t\tLearning rate: 3.360e+00, Batch size: 50, Momentum: 3.155e-01\n",
      "best loss: 1299.79\t\tLearning rate: 3.793e-01, Batch size: 4, Momentum: 9.464e-01\n",
      "best loss: 1299.85\t\tLearning rate: 3.360e+00, Batch size: 39, Momentum: 2.103e-01\n",
      "best loss: 1301.02\t\tLearning rate: 1.000e+01, Batch size: 9, Momentum: 0.000e+00\n",
      "best loss: 1302.11\t\tLearning rate: 1.129e+00, Batch size: 39, Momentum: 6.309e-01\n",
      "best loss: 1302.38\t\tLearning rate: 3.793e-01, Batch size: 19, Momentum: 7.361e-01\n",
      "best loss: 1303.05\t\tLearning rate: 1.274e-01, Batch size: 14, Momentum: 9.990e-01\n",
      "best loss: 1303.88\t\tLearning rate: 1.129e+00, Batch size: 50, Momentum: 5.784e-01\n",
      "best loss: 1303.93\t\tLearning rate: 1.129e+00, Batch size: 39, Momentum: 4.732e-01\n",
      "best loss: 1304.08\t\tLearning rate: 3.360e+00, Batch size: 17, Momentum: 2.103e-01\n",
      "best loss: 1307.52\t\tLearning rate: 3.360e+00, Batch size: 12, Momentum: 2.103e-01\n",
      "best loss: 1307.61\t\tLearning rate: 1.129e+00, Batch size: 19, Momentum: 6.835e-01\n",
      "best loss: 1308.96\t\tLearning rate: 3.360e+00, Batch size: 29, Momentum: 2.103e-01\n",
      "best loss: 1309.10\t\tLearning rate: 1.129e+00, Batch size: 24, Momentum: 4.732e-01\n",
      "best loss: 1312.09\t\tLearning rate: 3.360e+00, Batch size: 24, Momentum: 2.103e-01\n",
      "best loss: 1312.35\t\tLearning rate: 3.360e+00, Batch size: 47, Momentum: 5.258e-02\n",
      "best loss: 1312.72\t\tLearning rate: 1.129e+00, Batch size: 14, Momentum: 6.309e-01\n",
      "best loss: 1313.34\t\tLearning rate: 1.129e+00, Batch size: 27, Momentum: 6.309e-01\n",
      "best loss: 1313.51\t\tLearning rate: 3.360e+00, Batch size: 50, Momentum: 4.206e-01\n",
      "best loss: 1314.48\t\tLearning rate: 3.793e-01, Batch size: 39, Momentum: 6.835e-01\n",
      "best loss: 1315.71\t\tLearning rate: 3.793e-01, Batch size: 44, Momentum: 9.464e-01\n",
      "best loss: 1316.06\t\tLearning rate: 3.360e+00, Batch size: 24, Momentum: 2.629e-01\n",
      "best loss: 1317.36\t\tLearning rate: 3.360e+00, Batch size: 17, Momentum: 5.258e-01\n",
      "best loss: 1317.45\t\tLearning rate: 1.000e+01, Batch size: 22, Momentum: 4.206e-01\n",
      "best loss: 1319.32\t\tLearning rate: 3.360e+00, Batch size: 2, Momentum: 1.577e-01\n",
      "best loss: 1319.82\t\tLearning rate: 3.793e-01, Batch size: 32, Momentum: 8.413e-01\n",
      "best loss: 1320.54\t\tLearning rate: 1.129e+00, Batch size: 14, Momentum: 5.784e-01\n",
      "best loss: 1321.05\t\tLearning rate: 1.000e+01, Batch size: 29, Momentum: 5.258e-02\n",
      "best loss: 1321.06\t\tLearning rate: 1.129e+00, Batch size: 9, Momentum: 6.835e-01\n",
      "best loss: 1323.50\t\tLearning rate: 3.360e+00, Batch size: 4, Momentum: 3.681e-01\n",
      "best loss: 1328.61\t\tLearning rate: 3.360e+00, Batch size: 37, Momentum: 5.784e-01\n",
      "best loss: 1329.61\t\tLearning rate: 1.129e+00, Batch size: 19, Momentum: 7.887e-01\n",
      "best loss: 1331.87\t\tLearning rate: 1.000e+01, Batch size: 17, Momentum: 0.000e+00\n",
      "best loss: 1332.02\t\tLearning rate: 3.360e+00, Batch size: 50, Momentum: 2.629e-01\n",
      "best loss: 1334.39\t\tLearning rate: 1.129e+00, Batch size: 27, Momentum: 5.258e-01\n",
      "best loss: 1335.87\t\tLearning rate: 3.360e+00, Batch size: 22, Momentum: 4.206e-01\n",
      "best loss: 1337.11\t\tLearning rate: 1.129e+00, Batch size: 4, Momentum: 9.990e-01\n",
      "best loss: 1337.77\t\tLearning rate: 1.129e+00, Batch size: 50, Momentum: 7.361e-01\n",
      "best loss: 1340.04\t\tLearning rate: 3.793e-01, Batch size: 37, Momentum: 7.887e-01\n",
      "best loss: 1340.24\t\tLearning rate: 3.360e+00, Batch size: 32, Momentum: 3.681e-01\n",
      "best loss: 1340.95\t\tLearning rate: 1.129e+00, Batch size: 44, Momentum: 6.835e-01\n",
      "best loss: 1342.21\t\tLearning rate: 1.000e+01, Batch size: 4, Momentum: 2.103e-01\n",
      "best loss: 1342.39\t\tLearning rate: 3.360e+00, Batch size: 34, Momentum: 3.155e-01\n",
      "best loss: 1343.13\t\tLearning rate: 3.360e+00, Batch size: 17, Momentum: 3.681e-01\n",
      "best loss: 1343.64\t\tLearning rate: 1.129e+00, Batch size: 32, Momentum: 6.835e-01\n",
      "best loss: 1344.78\t\tLearning rate: 1.274e-01, Batch size: 37, Momentum: 9.464e-01\n",
      "best loss: 1345.06\t\tLearning rate: 1.129e+00, Batch size: 42, Momentum: 8.413e-01\n",
      "best loss: 1345.40\t\tLearning rate: 1.129e+00, Batch size: 37, Momentum: 7.361e-01\n",
      "best loss: 1345.93\t\tLearning rate: 3.360e+00, Batch size: 47, Momentum: 4.732e-01\n",
      "best loss: 1346.55\t\tLearning rate: 1.129e+00, Batch size: 34, Momentum: 5.258e-01\n",
      "best loss: 1348.28\t\tLearning rate: 3.360e+00, Batch size: 19, Momentum: 4.732e-01\n",
      "best loss: 1348.84\t\tLearning rate: 1.129e+00, Batch size: 7, Momentum: 9.990e-01\n",
      "best loss: 1349.45\t\tLearning rate: 3.360e+00, Batch size: 17, Momentum: 4.206e-01\n",
      "best loss: 1350.84\t\tLearning rate: 3.793e-01, Batch size: 2, Momentum: 9.464e-01\n",
      "best loss: 1351.70\t\tLearning rate: 3.360e+00, Batch size: 24, Momentum: 4.732e-01\n",
      "best loss: 1352.03\t\tLearning rate: 1.000e+01, Batch size: 29, Momentum: 2.629e-01\n",
      "best loss: 1352.92\t\tLearning rate: 1.000e+01, Batch size: 50, Momentum: 2.629e-01\n",
      "best loss: 1353.22\t\tLearning rate: 3.360e+00, Batch size: 42, Momentum: 6.309e-01\n",
      "best loss: 1353.23\t\tLearning rate: 1.129e+00, Batch size: 17, Momentum: 6.835e-01\n",
      "best loss: 1353.52\t\tLearning rate: 1.129e+00, Batch size: 7, Momentum: 9.464e-01\n",
      "best loss: 1355.15\t\tLearning rate: 3.793e-01, Batch size: 7, Momentum: 8.413e-01\n",
      "best loss: 1356.04\t\tLearning rate: 3.360e+00, Batch size: 29, Momentum: 5.784e-01\n",
      "best loss: 1356.37\t\tLearning rate: 3.360e+00, Batch size: 7, Momentum: 4.732e-01\n",
      "best loss: 1360.90\t\tLearning rate: 3.360e+00, Batch size: 44, Momentum: 5.784e-01\n",
      "best loss: 1361.77\t\tLearning rate: 1.129e+00, Batch size: 22, Momentum: 8.938e-01\n",
      "best loss: 1361.78\t\tLearning rate: 1.000e+01, Batch size: 7, Momentum: 5.258e-01\n",
      "best loss: 1363.72\t\tLearning rate: 3.793e-01, Batch size: 34, Momentum: 9.990e-01\n",
      "best loss: 1366.18\t\tLearning rate: 1.129e+00, Batch size: 34, Momentum: 9.464e-01\n",
      "best loss: 1367.60\t\tLearning rate: 3.360e+00, Batch size: 9, Momentum: 5.784e-01\n",
      "best loss: 1367.97\t\tLearning rate: 1.000e+01, Batch size: 34, Momentum: 2.103e-01\n",
      "best loss: 1368.09\t\tLearning rate: 1.129e+00, Batch size: 44, Momentum: 9.464e-01\n",
      "best loss: 1368.10\t\tLearning rate: 1.000e+01, Batch size: 2, Momentum: 4.732e-01\n",
      "best loss: 1369.09\t\tLearning rate: 3.360e+00, Batch size: 42, Momentum: 4.732e-01\n",
      "best loss: 1369.89\t\tLearning rate: 1.000e+01, Batch size: 2, Momentum: 5.258e-01\n",
      "best loss: 1370.81\t\tLearning rate: 1.000e+01, Batch size: 9, Momentum: 3.681e-01\n",
      "best loss: 1374.59\t\tLearning rate: 1.129e+00, Batch size: 24, Momentum: 9.990e-01\n",
      "best loss: 1375.23\t\tLearning rate: 1.000e+01, Batch size: 24, Momentum: 4.732e-01\n",
      "best loss: 1378.01\t\tLearning rate: 1.129e+00, Batch size: 29, Momentum: 9.990e-01\n",
      "best loss: 1382.93\t\tLearning rate: 1.000e+01, Batch size: 34, Momentum: 3.681e-01\n",
      "best loss: 1383.60\t\tLearning rate: 1.000e+01, Batch size: 47, Momentum: 2.629e-01\n",
      "best loss: 1383.78\t\tLearning rate: 3.793e-01, Batch size: 47, Momentum: 9.990e-01\n",
      "best loss: 1384.00\t\tLearning rate: 1.000e+01, Batch size: 7, Momentum: 1.577e-01\n",
      "best loss: 1385.78\t\tLearning rate: 1.000e+01, Batch size: 22, Momentum: 2.629e-01\n",
      "best loss: 1386.00\t\tLearning rate: 1.000e+01, Batch size: 44, Momentum: 2.629e-01\n",
      "best loss: 1387.28\t\tLearning rate: 1.000e+01, Batch size: 39, Momentum: 5.258e-01\n",
      "best loss: 1388.51\t\tLearning rate: 1.129e+00, Batch size: 27, Momentum: 7.361e-01\n",
      "best loss: 1388.56\t\tLearning rate: 3.360e+00, Batch size: 19, Momentum: 3.155e-01\n",
      "best loss: 1391.31\t\tLearning rate: 1.000e+01, Batch size: 24, Momentum: 5.258e-01\n",
      "best loss: 1391.48\t\tLearning rate: 3.360e+00, Batch size: 39, Momentum: 6.835e-01\n",
      "best loss: 1392.57\t\tLearning rate: 1.000e+01, Batch size: 17, Momentum: 3.155e-01\n",
      "best loss: 1392.72\t\tLearning rate: 3.360e+00, Batch size: 29, Momentum: 6.835e-01\n",
      "best loss: 1393.42\t\tLearning rate: 1.000e+01, Batch size: 44, Momentum: 4.206e-01\n",
      "best loss: 1395.96\t\tLearning rate: 1.000e+01, Batch size: 27, Momentum: 9.464e-01\n",
      "best loss: 1401.17\t\tLearning rate: 1.000e+01, Batch size: 27, Momentum: 6.309e-01\n",
      "best loss: 1403.02\t\tLearning rate: 1.000e+01, Batch size: 24, Momentum: 7.887e-01\n",
      "best loss: 1403.37\t\tLearning rate: 1.000e+01, Batch size: 27, Momentum: 1.577e-01\n",
      "best loss: 1406.38\t\tLearning rate: 3.360e+00, Batch size: 12, Momentum: 7.361e-01\n",
      "best loss: 1408.12\t\tLearning rate: 3.360e+00, Batch size: 29, Momentum: 8.413e-01\n",
      "best loss: 1408.38\t\tLearning rate: 1.000e+01, Batch size: 19, Momentum: 4.206e-01\n",
      "best loss: 1408.45\t\tLearning rate: 1.000e+01, Batch size: 39, Momentum: 4.732e-01\n",
      "best loss: 1409.26\t\tLearning rate: 3.360e+00, Batch size: 47, Momentum: 8.938e-01\n",
      "best loss: 1409.39\t\tLearning rate: 3.360e+00, Batch size: 42, Momentum: 6.835e-01\n",
      "best loss: 1411.45\t\tLearning rate: 1.129e+00, Batch size: 19, Momentum: 9.990e-01\n",
      "best loss: 1411.50\t\tLearning rate: 1.000e+01, Batch size: 12, Momentum: 4.732e-01\n",
      "best loss: 1412.44\t\tLearning rate: 1.000e+01, Batch size: 22, Momentum: 5.784e-01\n",
      "best loss: 1414.61\t\tLearning rate: 1.000e+01, Batch size: 39, Momentum: 7.361e-01\n",
      "best loss: 1415.37\t\tLearning rate: 3.360e+00, Batch size: 12, Momentum: 6.835e-01\n",
      "best loss: 1416.20\t\tLearning rate: 1.000e+01, Batch size: 37, Momentum: 6.835e-01\n",
      "best loss: 1416.53\t\tLearning rate: 1.000e+01, Batch size: 19, Momentum: 8.413e-01\n",
      "best loss: 1417.30\t\tLearning rate: 1.000e+01, Batch size: 7, Momentum: 7.887e-01\n",
      "best loss: 1419.18\t\tLearning rate: 1.000e+01, Batch size: 34, Momentum: 5.784e-01\n",
      "best loss: 1419.48\t\tLearning rate: 1.129e+00, Batch size: 4, Momentum: 7.887e-01\n",
      "best loss: 1420.58\t\tLearning rate: 1.000e+01, Batch size: 27, Momentum: 4.732e-01\n",
      "best loss: 1421.47\t\tLearning rate: 3.360e+00, Batch size: 27, Momentum: 9.464e-01\n",
      "best loss: 1421.98\t\tLearning rate: 3.360e+00, Batch size: 17, Momentum: 7.887e-01\n",
      "best loss: 1424.75\t\tLearning rate: 3.360e+00, Batch size: 2, Momentum: 6.835e-01\n",
      "best loss: 1424.79\t\tLearning rate: 1.000e+01, Batch size: 47, Momentum: 6.309e-01\n",
      "best loss: 1425.34\t\tLearning rate: 3.360e+00, Batch size: 32, Momentum: 7.887e-01\n",
      "best loss: 1428.87\t\tLearning rate: 3.360e+00, Batch size: 44, Momentum: 9.464e-01\n",
      "best loss: 1435.22\t\tLearning rate: 1.000e+01, Batch size: 27, Momentum: 7.361e-01\n",
      "best loss: 1435.78\t\tLearning rate: 3.360e+00, Batch size: 12, Momentum: 7.887e-01\n",
      "best loss: 1439.69\t\tLearning rate: 1.000e+01, Batch size: 9, Momentum: 7.887e-01\n",
      "best loss: 1440.94\t\tLearning rate: 1.000e+01, Batch size: 17, Momentum: 8.938e-01\n",
      "best loss: 1443.11\t\tLearning rate: 1.000e+01, Batch size: 17, Momentum: 6.835e-01\n",
      "best loss: 1443.26\t\tLearning rate: 3.360e+00, Batch size: 14, Momentum: 9.464e-01\n",
      "best loss: 1445.14\t\tLearning rate: 3.360e+00, Batch size: 24, Momentum: 9.464e-01\n",
      "best loss: 1445.56\t\tLearning rate: 1.000e+01, Batch size: 4, Momentum: 5.258e-01\n",
      "best loss: 1447.68\t\tLearning rate: 1.000e+01, Batch size: 12, Momentum: 6.835e-01\n",
      "best loss: 1447.82\t\tLearning rate: 3.360e+00, Batch size: 22, Momentum: 8.938e-01\n",
      "best loss: 1449.81\t\tLearning rate: 1.000e+01, Batch size: 34, Momentum: 7.887e-01\n",
      "best loss: 1451.03\t\tLearning rate: 3.360e+00, Batch size: 37, Momentum: 9.464e-01\n",
      "best loss: 1452.47\t\tLearning rate: 1.000e+01, Batch size: 12, Momentum: 8.413e-01\n",
      "best loss: 1457.69\t\tLearning rate: 1.000e+01, Batch size: 9, Momentum: 8.938e-01\n",
      "best loss: 1460.99\t\tLearning rate: 1.000e+01, Batch size: 7, Momentum: 6.835e-01\n",
      "best loss: 1463.28\t\tLearning rate: 3.360e+00, Batch size: 12, Momentum: 9.990e-01\n",
      "best loss: 1463.84\t\tLearning rate: 1.000e+01, Batch size: 27, Momentum: 6.835e-01\n",
      "best loss: 1463.93\t\tLearning rate: 1.000e+01, Batch size: 50, Momentum: 8.413e-01\n",
      "best loss: 1470.91\t\tLearning rate: 1.000e+01, Batch size: 47, Momentum: 7.361e-01\n",
      "best loss: 1477.21\t\tLearning rate: 1.000e+01, Batch size: 17, Momentum: 8.413e-01\n",
      "best loss: 1479.86\t\tLearning rate: 1.000e+01, Batch size: 32, Momentum: 7.887e-01\n",
      "best loss: 1482.31\t\tLearning rate: 1.000e+01, Batch size: 44, Momentum: 8.413e-01\n",
      "best loss: 1488.90\t\tLearning rate: 1.000e+01, Batch size: 24, Momentum: 6.835e-01\n",
      "best loss: 1493.68\t\tLearning rate: 1.000e+01, Batch size: 4, Momentum: 8.938e-01\n",
      "best loss: 1499.70\t\tLearning rate: 1.000e+01, Batch size: 39, Momentum: 8.413e-01\n",
      "best loss: 1502.49\t\tLearning rate: 1.000e+01, Batch size: 32, Momentum: 9.464e-01\n",
      "best loss: 1504.66\t\tLearning rate: 3.360e+00, Batch size: 17, Momentum: 9.464e-01\n",
      "best loss: 1521.57\t\tLearning rate: 1.000e+01, Batch size: 12, Momentum: 9.990e-01\n",
      "best loss: 1524.97\t\tLearning rate: 1.438e-02, Batch size: 2, Momentum: 1.052e-01\n",
      "best loss: 1526.13\t\tLearning rate: 1.000e+01, Batch size: 24, Momentum: 9.464e-01\n",
      "best loss: 1887.57\t\tLearning rate: 2.637e-07, Batch size: 47, Momentum: 0.000e+00\n",
      "best loss: 1905.81\t\tLearning rate: 1.000e-08, Batch size: 22, Momentum: 2.103e-01\n",
      "best loss: 2048.37\t\tLearning rate: 2.637e-07, Batch size: 32, Momentum: 1.052e-01\n",
      "best loss: 2076.97\t\tLearning rate: 2.976e-08, Batch size: 47, Momentum: 0.000e+00\n",
      "best loss: 3193.98\t\tLearning rate: 1.000e-08, Batch size: 19, Momentum: 3.681e-01\n",
      "best loss: 3846.40\t\tLearning rate: 1.000e-08, Batch size: 42, Momentum: 1.577e-01\n",
      "best loss: 3916.51\t\tLearning rate: 1.000e-08, Batch size: 2, Momentum: 3.681e-01\n",
      "best loss: 4230.14\t\tLearning rate: 2.976e-08, Batch size: 4, Momentum: 5.784e-01\n",
      "best loss: 5552.51\t\tLearning rate: 2.976e-08, Batch size: 32, Momentum: 3.681e-01\n",
      "best loss: 9629.67\t\tLearning rate: 1.000e-08, Batch size: 44, Momentum: 2.103e-01\n",
      "best loss: 15024.86\t\tLearning rate: 2.976e-08, Batch size: 4, Momentum: 2.629e-01\n",
      "best loss: 22022.97\t\tLearning rate: 1.000e-08, Batch size: 7, Momentum: 5.258e-02\n",
      "best loss: 33532.86\t\tLearning rate: 3.793e-01, Batch size: 2, Momentum: 0.000e+00\n",
      "best loss: 47838.60\t\tLearning rate: 7.848e-07, Batch size: 12, Momentum: 0.000e+00\n",
      "best loss: 67436.21\t\tLearning rate: 8.859e-08, Batch size: 14, Momentum: 1.052e-01\n",
      "best loss: 79805.54\t\tLearning rate: 2.976e-08, Batch size: 4, Momentum: 9.464e-01\n",
      "best loss: 84348.41\t\tLearning rate: 2.336e-06, Batch size: 7, Momentum: 4.206e-01\n",
      "best loss: 84522.16\t\tLearning rate: 1.000e-08, Batch size: 12, Momentum: 6.309e-01\n",
      "best loss: 84903.55\t\tLearning rate: 3.793e-01, Batch size: 14, Momentum: 1.052e-01\n",
      "best loss: 92372.38\t\tLearning rate: 2.976e-08, Batch size: 37, Momentum: 6.309e-01\n",
      "best loss: 93153.52\t\tLearning rate: 1.000e-08, Batch size: 42, Momentum: 5.258e-01\n",
      "best loss: 93389.21\t\tLearning rate: 3.360e+00, Batch size: 7, Momentum: 3.681e-01\n",
      "best loss: 96717.11\t\tLearning rate: 1.000e+01, Batch size: 14, Momentum: 3.681e-01\n",
      "best loss: 104170.62\t\tLearning rate: 1.274e-01, Batch size: 7, Momentum: 0.000e+00\n",
      "best loss: 105576.26\t\tLearning rate: 3.793e-01, Batch size: 19, Momentum: 1.052e-01\n",
      "best loss: 112840.83\t\tLearning rate: 3.793e-01, Batch size: 34, Momentum: 1.052e-01\n",
      "best loss: 114126.84\t\tLearning rate: 1.000e-08, Batch size: 32, Momentum: 4.732e-01\n",
      "best loss: 114920.39\t\tLearning rate: 1.000e-08, Batch size: 22, Momentum: 6.835e-01\n",
      "best loss: 116603.56\t\tLearning rate: 8.859e-08, Batch size: 19, Momentum: 2.629e-01\n",
      "best loss: 119096.75\t\tLearning rate: 5.456e-04, Batch size: 19, Momentum: 5.258e-02\n",
      "best loss: 119510.96\t\tLearning rate: 2.976e-08, Batch size: 39, Momentum: 7.887e-01\n",
      "best loss: 119694.03\t\tLearning rate: 8.859e-08, Batch size: 17, Momentum: 2.629e-01\n",
      "best loss: 119814.83\t\tLearning rate: 2.976e-08, Batch size: 42, Momentum: 4.732e-01\n",
      "best loss: 122067.13\t\tLearning rate: 7.848e-07, Batch size: 50, Momentum: 6.835e-01\n",
      "best loss: 142129.69\t\tLearning rate: 8.859e-08, Batch size: 50, Momentum: 8.938e-01\n",
      "best loss: 147862.80\t\tLearning rate: 1.000e-08, Batch size: 50, Momentum: 1.052e-01\n",
      "best loss: 148479.75\t\tLearning rate: 1.000e-08, Batch size: 44, Momentum: 4.732e-01\n",
      "best loss: 149773.31\t\tLearning rate: 1.000e-08, Batch size: 14, Momentum: 4.206e-01\n",
      "best loss: 184048.34\t\tLearning rate: 1.000e-08, Batch size: 14, Momentum: 5.258e-02\n",
      "best loss: 186338.04\t\tLearning rate: 1.000e-08, Batch size: 29, Momentum: 6.835e-01\n",
      "best loss: 196847.55\t\tLearning rate: 2.976e-08, Batch size: 27, Momentum: 7.361e-01\n",
      "best loss: 212466.66\t\tLearning rate: 2.976e-08, Batch size: 19, Momentum: 5.258e-01\n",
      "best loss: 214844.89\t\tLearning rate: 2.336e-06, Batch size: 37, Momentum: 1.052e-01\n",
      "best loss: 220614.69\t\tLearning rate: 2.976e-08, Batch size: 32, Momentum: 0.000e+00\n",
      "best loss: 223866.40\t\tLearning rate: 1.274e-01, Batch size: 29, Momentum: 0.000e+00\n",
      "best loss: 228469.64\t\tLearning rate: 3.360e+00, Batch size: 27, Momentum: 3.681e-01\n",
      "best loss: 239135.01\t\tLearning rate: 2.976e-08, Batch size: 44, Momentum: 1.052e-01\n",
      "best loss: 241753.16\t\tLearning rate: 2.336e-06, Batch size: 42, Momentum: 5.258e-02\n",
      "best loss: 249823.55\t\tLearning rate: 2.976e-08, Batch size: 24, Momentum: 0.000e+00\n",
      "best loss: 251304.36\t\tLearning rate: 2.976e-08, Batch size: 9, Momentum: 5.784e-01\n",
      "best loss: 255990.31\t\tLearning rate: 8.859e-08, Batch size: 4, Momentum: 3.155e-01\n",
      "best loss: 270760.08\t\tLearning rate: 1.624e-03, Batch size: 34, Momentum: 0.000e+00\n",
      "best loss: 277021.29\t\tLearning rate: 7.848e-07, Batch size: 17, Momentum: 3.155e-01\n",
      "best loss: 285677.46\t\tLearning rate: 1.000e-08, Batch size: 17, Momentum: 9.464e-01\n",
      "best loss: 315036.97\t\tLearning rate: 2.976e-08, Batch size: 34, Momentum: 6.835e-01\n",
      "best loss: 327536.60\t\tLearning rate: 1.000e+01, Batch size: 32, Momentum: 0.000e+00\n",
      "best loss: 327993.86\t\tLearning rate: 8.859e-08, Batch size: 19, Momentum: 3.155e-01\n",
      "best loss: 328744.06\t\tLearning rate: 1.000e-08, Batch size: 7, Momentum: 6.309e-01\n",
      "best loss: 330437.84\t\tLearning rate: 1.000e-08, Batch size: 39, Momentum: 5.258e-02\n",
      "best loss: 352782.18\t\tLearning rate: 8.859e-08, Batch size: 44, Momentum: 4.732e-01\n",
      "best loss: 364977.10\t\tLearning rate: 1.000e-08, Batch size: 50, Momentum: 1.577e-01\n",
      "best loss: 365888.54\t\tLearning rate: 8.859e-08, Batch size: 32, Momentum: 5.258e-01\n",
      "best loss: 369051.22\t\tLearning rate: 3.360e+00, Batch size: 37, Momentum: 5.258e-01\n",
      "best loss: 372103.57\t\tLearning rate: 2.637e-07, Batch size: 29, Momentum: 6.835e-01\n",
      "best loss: 375362.24\t\tLearning rate: 1.000e-08, Batch size: 17, Momentum: 6.835e-01\n",
      "best loss: 395537.29\t\tLearning rate: 8.859e-08, Batch size: 24, Momentum: 7.361e-01\n",
      "best loss: 411969.96\t\tLearning rate: 2.976e-08, Batch size: 34, Momentum: 5.784e-01\n",
      "best loss: 415397.47\t\tLearning rate: 7.848e-07, Batch size: 50, Momentum: 7.887e-01\n",
      "best loss: 417110.86\t\tLearning rate: 1.000e-08, Batch size: 29, Momentum: 5.258e-02\n",
      "best loss: 425393.95\t\tLearning rate: 8.859e-08, Batch size: 42, Momentum: 6.835e-01\n",
      "best loss: 431740.90\t\tLearning rate: 8.859e-08, Batch size: 39, Momentum: 5.258e-01\n",
      "best loss: 442468.73\t\tLearning rate: 8.859e-08, Batch size: 22, Momentum: 3.681e-01\n",
      "best loss: 444781.44\t\tLearning rate: 2.637e-07, Batch size: 24, Momentum: 7.361e-01\n",
      "best loss: 445019.06\t\tLearning rate: 8.859e-08, Batch size: 29, Momentum: 7.361e-01\n",
      "best loss: 465342.23\t\tLearning rate: 2.976e-08, Batch size: 19, Momentum: 7.887e-01\n",
      "best loss: 476158.23\t\tLearning rate: 8.859e-08, Batch size: 7, Momentum: 6.835e-01\n",
      "best loss: 477265.24\t\tLearning rate: 1.000e-08, Batch size: 19, Momentum: 4.206e-01\n",
      "best loss: 497253.58\t\tLearning rate: 1.000e-08, Batch size: 42, Momentum: 6.835e-01\n",
      "best loss: 497901.51\t\tLearning rate: 1.833e-04, Batch size: 7, Momentum: 0.000e+00\n",
      "best loss: 499961.58\t\tLearning rate: 1.000e-08, Batch size: 29, Momentum: 9.990e-01\n",
      "best loss: 523320.41\t\tLearning rate: 8.859e-08, Batch size: 39, Momentum: 0.000e+00\n",
      "best loss: 531579.52\t\tLearning rate: 2.637e-07, Batch size: 9, Momentum: 1.052e-01\n",
      "best loss: 534910.87\t\tLearning rate: 8.859e-08, Batch size: 32, Momentum: 3.681e-01\n",
      "best loss: 547103.09\t\tLearning rate: 1.624e-03, Batch size: 19, Momentum: 1.052e-01\n",
      "best loss: 547775.01\t\tLearning rate: 8.859e-08, Batch size: 44, Momentum: 2.103e-01\n",
      "best loss: 576563.88\t\tLearning rate: 1.000e-08, Batch size: 32, Momentum: 3.681e-01\n",
      "best loss: 613121.31\t\tLearning rate: 4.833e-03, Batch size: 42, Momentum: 5.258e-02\n",
      "best loss: 614319.68\t\tLearning rate: 8.859e-08, Batch size: 50, Momentum: 1.052e-01\n",
      "best loss: 623894.62\t\tLearning rate: 2.637e-07, Batch size: 27, Momentum: 5.258e-01\n",
      "best loss: 654955.97\t\tLearning rate: 2.976e-08, Batch size: 17, Momentum: 0.000e+00\n",
      "best loss: 676440.94\t\tLearning rate: 2.637e-07, Batch size: 47, Momentum: 6.309e-01\n",
      "best loss: 697397.96\t\tLearning rate: 1.000e-08, Batch size: 24, Momentum: 4.732e-01\n",
      "best loss: 718845.86\t\tLearning rate: 2.637e-07, Batch size: 27, Momentum: 2.629e-01\n",
      "best loss: 729140.94\t\tLearning rate: 2.637e-07, Batch size: 42, Momentum: 0.000e+00\n",
      "best loss: 740132.15\t\tLearning rate: 1.000e-08, Batch size: 9, Momentum: 9.464e-01\n",
      "best loss: 755796.44\t\tLearning rate: 2.976e-08, Batch size: 27, Momentum: 2.629e-01\n",
      "best loss: 796774.93\t\tLearning rate: 8.859e-08, Batch size: 32, Momentum: 6.309e-01\n",
      "best loss: 807315.90\t\tLearning rate: 8.859e-08, Batch size: 24, Momentum: 7.887e-01\n",
      "best loss: 821176.86\t\tLearning rate: 8.859e-08, Batch size: 17, Momentum: 5.784e-01\n",
      "best loss: 822720.56\t\tLearning rate: 1.000e+01, Batch size: 44, Momentum: 0.000e+00\n",
      "best loss: 879262.24\t\tLearning rate: 1.624e-03, Batch size: 9, Momentum: 0.000e+00\n",
      "best loss: 901979.74\t\tLearning rate: 1.000e-08, Batch size: 34, Momentum: 4.206e-01\n",
      "best loss: 967712.75\t\tLearning rate: 2.637e-07, Batch size: 47, Momentum: 7.361e-01\n",
      "best loss: 1023280.70\t\tLearning rate: 5.456e-04, Batch size: 19, Momentum: 3.155e-01\n",
      "best loss: 1069532.20\t\tLearning rate: 1.000e-08, Batch size: 39, Momentum: 6.309e-01\n",
      "best loss: 1087282.05\t\tLearning rate: 8.859e-08, Batch size: 7, Momentum: 3.681e-01\n",
      "best loss: 1124066.20\t\tLearning rate: 8.859e-08, Batch size: 24, Momentum: 5.258e-02\n",
      "best loss: 1150760.91\t\tLearning rate: 5.456e-04, Batch size: 47, Momentum: 5.258e-02\n",
      "best loss: 1379220.97\t\tLearning rate: 1.000e-08, Batch size: 44, Momentum: 5.258e-01\n",
      "best loss: 1450481.25\t\tLearning rate: 2.976e-08, Batch size: 50, Momentum: 2.103e-01\n",
      "best loss: 1483796.27\t\tLearning rate: 8.859e-08, Batch size: 29, Momentum: 6.835e-01\n",
      "best loss: 1496492.74\t\tLearning rate: 1.274e-01, Batch size: 7, Momentum: 2.103e-01\n",
      "best loss: 1502122.70\t\tLearning rate: 2.637e-07, Batch size: 17, Momentum: 6.309e-01\n",
      "best loss: 1610686.54\t\tLearning rate: 8.859e-08, Batch size: 24, Momentum: 4.732e-01\n",
      "best loss: 1831625.18\t\tLearning rate: 2.637e-07, Batch size: 34, Momentum: 3.155e-01\n",
      "best loss: 3804784.03\t\tLearning rate: 4.833e-03, Batch size: 24, Momentum: 3.155e-01\n"
     ]
    }
   ],
   "source": [
    "# print the hyperparameters ranked from best to worst\n",
    "sorted_results = sorted(results.items(), key=lambda x: x[1])\n",
    "for hp, loss in sorted_results:\n",
    "    print(f\"best loss: {loss:.2f}\\t\\tLearning rate: {hp[0]:.3e}, Batch size: {hp[1]}, Momentum: {hp[2]:.3e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phenotypes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
