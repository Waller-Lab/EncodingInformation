{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solve for Gaussian approximations using optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening BSCCM\n",
      "Opened BSCCM\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# this only works on startup!\n",
    "from jax import config\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'\n",
    "from gpu_utils import limit_gpu_memory_growth\n",
    "limit_gpu_memory_growth()\n",
    "\n",
    "from cleanplots import *\n",
    "from tqdm import tqdm\n",
    "from information_estimation import *\n",
    "from image_utils import *\n",
    "from gaussian_process_utils import *\n",
    "\n",
    "from led_array.bsccm_utils import *\n",
    "from bsccm import BSCCM\n",
    "from jax import jit\n",
    "import numpy as onp\n",
    "import jax.numpy as np\n",
    "\n",
    "bsccm = BSCCM('/home/hpinkard_waller/data/BSCCM/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images, extract patches, and compute cov mats\n",
    "edge_crop = 32\n",
    "patch_size = 10\n",
    "num_images = 20000\n",
    "num_patches = 1000\n",
    "channel = 'LED119'\n",
    "eigenvalue_floor = 1e0\n",
    "\n",
    "images = load_bsccm_images(bsccm, channel=channel, num_images=num_images, edge_crop=edge_crop, median_filter=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search through hyperparameter combos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = np.logspace(1, -8, 20)\n",
    "batch_sizes = np.linspace(2, 50, 20).astype(int)\n",
    "momentums = np.linspace(0, 0.999, 20)\n",
    "\n",
    "# generate tuples of random hyperparameters\n",
    "hyperparameter_tuples = []\n",
    "for i in range(10000):\n",
    "    lr = onp.random.choice(learning_rates)\n",
    "    bs = onp.random.choice(batch_sizes)\n",
    "    m = onp.random.choice(momentums)\n",
    "    hyperparameter_tuples.append((lr, bs, m))\n",
    "\n",
    "results = {}\n",
    "for i, (learning_rate, batch_size, momentum) in enumerate(hyperparameter_tuples):\n",
    "    best_hp_loss = np.inf\n",
    "\n",
    "    patches = extract_patches(images, patch_size, num_patches=num_patches, seed=i)\n",
    "    best_cov_mat, cov_mat_initial, mean_vec, best_loss = run_optimization(patches, momentum, learning_rate, batch_size, eigenvalue_floor=1e-3)\n",
    "\n",
    "    if best_loss < best_hp_loss:\n",
    "        best_hp_loss = best_loss\n",
    "        best_hp = (learning_rate, batch_size, momentum)\n",
    "        \n",
    "    # collect results\n",
    "    results[(learning_rate, batch_size, momentum)] = best_loss\n",
    "\n",
    "    # print hyperparameters and their best loss\n",
    "    print(f\"best loss: {best_loss:.2f}\\t\\tLearning rate: {learning_rate:.3e}, Batch size: {batch_size}, Momentum: {momentum:.3e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best loss: 422.89\t\tLearning rate: 2.976e-08, Batch size: 2, Momentum: 9.990e-01\n",
      "best loss: 425.53\t\tLearning rate: 4.281e-02, Batch size: 2, Momentum: 1.052e-01\n",
      "best loss: 427.50\t\tLearning rate: 1.000e-08, Batch size: 2, Momentum: 8.413e-01\n",
      "best loss: 428.09\t\tLearning rate: 6.952e-06, Batch size: 2, Momentum: 3.681e-01\n",
      "best loss: 429.96\t\tLearning rate: 1.129e+00, Batch size: 2, Momentum: 4.732e-01\n",
      "best loss: 430.36\t\tLearning rate: 2.069e-05, Batch size: 2, Momentum: 7.887e-01\n",
      "best loss: 430.54\t\tLearning rate: 2.637e-07, Batch size: 2, Momentum: 8.938e-01\n",
      "best loss: 430.77\t\tLearning rate: 6.952e-06, Batch size: 2, Momentum: 0.000e+00\n",
      "best loss: 431.62\t\tLearning rate: 2.637e-07, Batch size: 2, Momentum: 1.577e-01\n",
      "best loss: 431.76\t\tLearning rate: 7.848e-07, Batch size: 2, Momentum: 7.361e-01\n",
      "best loss: 432.17\t\tLearning rate: 4.833e-03, Batch size: 4, Momentum: 0.000e+00\n",
      "best loss: 432.28\t\tLearning rate: 1.438e-02, Batch size: 4, Momentum: 4.206e-01\n",
      "best loss: 432.48\t\tLearning rate: 2.069e-05, Batch size: 4, Momentum: 2.629e-01\n",
      "best loss: 432.59\t\tLearning rate: 8.859e-08, Batch size: 2, Momentum: 8.413e-01\n",
      "best loss: 433.00\t\tLearning rate: 6.952e-06, Batch size: 2, Momentum: 4.732e-01\n",
      "best loss: 433.21\t\tLearning rate: 2.637e-07, Batch size: 2, Momentum: 8.413e-01\n",
      "best loss: 433.60\t\tLearning rate: 1.000e-08, Batch size: 4, Momentum: 9.990e-01\n",
      "best loss: 433.89\t\tLearning rate: 2.336e-06, Batch size: 2, Momentum: 7.361e-01\n",
      "best loss: 434.28\t\tLearning rate: 1.129e+00, Batch size: 2, Momentum: 9.464e-01\n",
      "best loss: 434.39\t\tLearning rate: 1.624e-03, Batch size: 2, Momentum: 1.052e-01\n",
      "best loss: 434.46\t\tLearning rate: 1.000e-08, Batch size: 7, Momentum: 9.990e-01\n",
      "best loss: 434.57\t\tLearning rate: 8.859e-08, Batch size: 2, Momentum: 4.732e-01\n",
      "best loss: 434.68\t\tLearning rate: 5.456e-04, Batch size: 2, Momentum: 1.052e-01\n",
      "best loss: 434.91\t\tLearning rate: 1.000e+01, Batch size: 4, Momentum: 4.206e-01\n",
      "best loss: 435.13\t\tLearning rate: 4.833e-03, Batch size: 4, Momentum: 2.103e-01\n",
      "best loss: 435.24\t\tLearning rate: 6.952e-06, Batch size: 2, Momentum: 4.206e-01\n",
      "best loss: 435.26\t\tLearning rate: 2.336e-06, Batch size: 2, Momentum: 3.155e-01\n",
      "best loss: 435.59\t\tLearning rate: 1.000e-08, Batch size: 2, Momentum: 9.464e-01\n",
      "best loss: 435.66\t\tLearning rate: 2.976e-08, Batch size: 4, Momentum: 7.887e-01\n",
      "best loss: 437.03\t\tLearning rate: 4.833e-03, Batch size: 7, Momentum: 9.990e-01\n",
      "best loss: 437.41\t\tLearning rate: 2.336e-06, Batch size: 7, Momentum: 7.887e-01\n",
      "best loss: 437.46\t\tLearning rate: 1.129e+00, Batch size: 4, Momentum: 8.413e-01\n",
      "best loss: 437.61\t\tLearning rate: 8.859e-08, Batch size: 7, Momentum: 8.413e-01\n",
      "best loss: 437.68\t\tLearning rate: 2.069e-05, Batch size: 4, Momentum: 4.732e-01\n",
      "best loss: 437.87\t\tLearning rate: 2.069e-05, Batch size: 4, Momentum: 1.052e-01\n",
      "best loss: 438.40\t\tLearning rate: 7.848e-07, Batch size: 4, Momentum: 4.732e-01\n",
      "best loss: 438.60\t\tLearning rate: 1.833e-04, Batch size: 7, Momentum: 3.681e-01\n",
      "best loss: 438.98\t\tLearning rate: 2.336e-06, Batch size: 4, Momentum: 3.155e-01\n",
      "best loss: 439.40\t\tLearning rate: 3.360e+00, Batch size: 9, Momentum: 9.464e-01\n",
      "best loss: 439.43\t\tLearning rate: 1.833e-04, Batch size: 9, Momentum: 3.681e-01\n",
      "best loss: 439.75\t\tLearning rate: 2.976e-08, Batch size: 7, Momentum: 3.155e-01\n",
      "best loss: 439.80\t\tLearning rate: 5.456e-04, Batch size: 9, Momentum: 6.309e-01\n",
      "best loss: 439.88\t\tLearning rate: 1.833e-04, Batch size: 4, Momentum: 8.413e-01\n",
      "best loss: 439.92\t\tLearning rate: 7.848e-07, Batch size: 9, Momentum: 7.887e-01\n",
      "best loss: 440.22\t\tLearning rate: 7.848e-07, Batch size: 9, Momentum: 4.732e-01\n",
      "best loss: 440.57\t\tLearning rate: 4.281e-02, Batch size: 9, Momentum: 3.155e-01\n",
      "best loss: 440.60\t\tLearning rate: 1.624e-03, Batch size: 12, Momentum: 3.681e-01\n",
      "best loss: 440.61\t\tLearning rate: 2.336e-06, Batch size: 7, Momentum: 3.681e-01\n",
      "best loss: 440.66\t\tLearning rate: 2.637e-07, Batch size: 9, Momentum: 7.361e-01\n",
      "best loss: 440.71\t\tLearning rate: 2.637e-07, Batch size: 9, Momentum: 5.784e-01\n",
      "best loss: 440.74\t\tLearning rate: 1.833e-04, Batch size: 9, Momentum: 2.629e-01\n",
      "best loss: 440.80\t\tLearning rate: 1.833e-04, Batch size: 9, Momentum: 8.938e-01\n",
      "best loss: 440.87\t\tLearning rate: 2.976e-08, Batch size: 9, Momentum: 2.629e-01\n",
      "best loss: 440.91\t\tLearning rate: 2.637e-07, Batch size: 12, Momentum: 3.681e-01\n",
      "best loss: 441.47\t\tLearning rate: 8.859e-08, Batch size: 4, Momentum: 3.681e-01\n",
      "best loss: 441.48\t\tLearning rate: 5.456e-04, Batch size: 14, Momentum: 4.206e-01\n",
      "best loss: 441.51\t\tLearning rate: 1.000e+01, Batch size: 14, Momentum: 5.784e-01\n",
      "best loss: 441.53\t\tLearning rate: 3.360e+00, Batch size: 9, Momentum: 5.784e-01\n",
      "best loss: 441.63\t\tLearning rate: 2.336e-06, Batch size: 7, Momentum: 6.309e-01\n",
      "best loss: 441.74\t\tLearning rate: 2.637e-07, Batch size: 9, Momentum: 8.938e-01\n",
      "best loss: 441.75\t\tLearning rate: 2.336e-06, Batch size: 9, Momentum: 7.361e-01\n",
      "best loss: 441.86\t\tLearning rate: 1.624e-03, Batch size: 7, Momentum: 8.938e-01\n",
      "best loss: 441.98\t\tLearning rate: 3.360e+00, Batch size: 9, Momentum: 9.990e-01\n",
      "best loss: 442.42\t\tLearning rate: 7.848e-07, Batch size: 9, Momentum: 2.629e-01\n",
      "best loss: 442.46\t\tLearning rate: 8.859e-08, Batch size: 9, Momentum: 9.464e-01\n",
      "best loss: 442.54\t\tLearning rate: 8.859e-08, Batch size: 12, Momentum: 9.464e-01\n",
      "best loss: 442.57\t\tLearning rate: 8.859e-08, Batch size: 9, Momentum: 8.413e-01\n",
      "best loss: 442.68\t\tLearning rate: 8.859e-08, Batch size: 7, Momentum: 6.309e-01\n",
      "best loss: 442.93\t\tLearning rate: 1.129e+00, Batch size: 14, Momentum: 8.413e-01\n",
      "best loss: 443.04\t\tLearning rate: 5.456e-04, Batch size: 9, Momentum: 4.732e-01\n",
      "best loss: 443.04\t\tLearning rate: 1.833e-04, Batch size: 12, Momentum: 8.413e-01\n",
      "best loss: 443.14\t\tLearning rate: 1.438e-02, Batch size: 19, Momentum: 3.155e-01\n",
      "best loss: 443.27\t\tLearning rate: 2.336e-06, Batch size: 12, Momentum: 1.052e-01\n",
      "best loss: 443.39\t\tLearning rate: 6.952e-06, Batch size: 7, Momentum: 5.784e-01\n",
      "best loss: 443.44\t\tLearning rate: 4.281e-02, Batch size: 12, Momentum: 8.413e-01\n",
      "best loss: 443.51\t\tLearning rate: 6.952e-06, Batch size: 7, Momentum: 4.206e-01\n",
      "best loss: 443.52\t\tLearning rate: 3.793e-01, Batch size: 17, Momentum: 0.000e+00\n",
      "best loss: 443.67\t\tLearning rate: 2.976e-08, Batch size: 4, Momentum: 8.413e-01\n",
      "best loss: 443.71\t\tLearning rate: 5.456e-04, Batch size: 14, Momentum: 3.681e-01\n",
      "best loss: 443.98\t\tLearning rate: 1.274e-01, Batch size: 14, Momentum: 8.938e-01\n",
      "best loss: 444.18\t\tLearning rate: 1.274e-01, Batch size: 14, Momentum: 3.681e-01\n",
      "best loss: 444.25\t\tLearning rate: 1.000e-08, Batch size: 27, Momentum: 9.990e-01\n",
      "best loss: 444.26\t\tLearning rate: 2.976e-08, Batch size: 9, Momentum: 9.464e-01\n",
      "best loss: 444.34\t\tLearning rate: 1.833e-04, Batch size: 22, Momentum: 5.258e-01\n",
      "best loss: 444.35\t\tLearning rate: 2.336e-06, Batch size: 14, Momentum: 2.629e-01\n",
      "best loss: 444.39\t\tLearning rate: 2.637e-07, Batch size: 17, Momentum: 9.464e-01\n",
      "best loss: 444.51\t\tLearning rate: 1.129e+00, Batch size: 19, Momentum: 9.990e-01\n",
      "best loss: 444.56\t\tLearning rate: 1.000e+01, Batch size: 22, Momentum: 9.990e-01\n",
      "best loss: 444.58\t\tLearning rate: 7.848e-07, Batch size: 7, Momentum: 9.464e-01\n",
      "best loss: 444.60\t\tLearning rate: 1.000e+01, Batch size: 27, Momentum: 9.464e-01\n",
      "best loss: 444.61\t\tLearning rate: 2.637e-07, Batch size: 2, Momentum: 0.000e+00\n",
      "best loss: 444.68\t\tLearning rate: 1.000e-08, Batch size: 14, Momentum: 4.206e-01\n",
      "best loss: 444.73\t\tLearning rate: 2.069e-05, Batch size: 9, Momentum: 2.103e-01\n",
      "best loss: 444.77\t\tLearning rate: 7.848e-07, Batch size: 19, Momentum: 9.464e-01\n",
      "best loss: 444.91\t\tLearning rate: 4.833e-03, Batch size: 9, Momentum: 6.835e-01\n",
      "best loss: 444.93\t\tLearning rate: 2.637e-07, Batch size: 17, Momentum: 7.361e-01\n",
      "best loss: 445.03\t\tLearning rate: 1.129e+00, Batch size: 7, Momentum: 1.577e-01\n",
      "best loss: 445.04\t\tLearning rate: 4.833e-03, Batch size: 27, Momentum: 5.784e-01\n",
      "best loss: 445.14\t\tLearning rate: 2.336e-06, Batch size: 12, Momentum: 8.938e-01\n",
      "best loss: 445.14\t\tLearning rate: 2.976e-08, Batch size: 14, Momentum: 7.887e-01\n",
      "best loss: 445.28\t\tLearning rate: 3.360e+00, Batch size: 19, Momentum: 9.464e-01\n",
      "best loss: 445.28\t\tLearning rate: 6.952e-06, Batch size: 42, Momentum: 2.103e-01\n",
      "best loss: 445.30\t\tLearning rate: 1.000e-08, Batch size: 19, Momentum: 6.835e-01\n",
      "best loss: 445.40\t\tLearning rate: 2.637e-07, Batch size: 27, Momentum: 7.887e-01\n",
      "best loss: 445.41\t\tLearning rate: 1.129e+00, Batch size: 22, Momentum: 9.990e-01\n",
      "best loss: 445.47\t\tLearning rate: 1.000e-08, Batch size: 22, Momentum: 9.464e-01\n",
      "best loss: 445.56\t\tLearning rate: 3.793e-01, Batch size: 24, Momentum: 0.000e+00\n",
      "best loss: 445.61\t\tLearning rate: 8.859e-08, Batch size: 29, Momentum: 7.361e-01\n",
      "best loss: 445.62\t\tLearning rate: 6.158e-05, Batch size: 19, Momentum: 8.938e-01\n",
      "best loss: 445.63\t\tLearning rate: 7.848e-07, Batch size: 14, Momentum: 9.464e-01\n",
      "best loss: 445.68\t\tLearning rate: 1.833e-04, Batch size: 22, Momentum: 9.990e-01\n",
      "best loss: 445.70\t\tLearning rate: 1.129e+00, Batch size: 17, Momentum: 1.052e-01\n",
      "best loss: 445.76\t\tLearning rate: 1.000e+01, Batch size: 27, Momentum: 3.681e-01\n",
      "best loss: 445.87\t\tLearning rate: 2.976e-08, Batch size: 14, Momentum: 3.155e-01\n",
      "best loss: 445.87\t\tLearning rate: 7.848e-07, Batch size: 37, Momentum: 8.938e-01\n",
      "best loss: 445.87\t\tLearning rate: 1.833e-04, Batch size: 27, Momentum: 0.000e+00\n",
      "best loss: 445.89\t\tLearning rate: 1.624e-03, Batch size: 17, Momentum: 3.155e-01\n",
      "best loss: 445.90\t\tLearning rate: 1.624e-03, Batch size: 17, Momentum: 1.052e-01\n",
      "best loss: 445.98\t\tLearning rate: 2.637e-07, Batch size: 24, Momentum: 9.464e-01\n",
      "best loss: 446.03\t\tLearning rate: 1.129e+00, Batch size: 27, Momentum: 8.938e-01\n",
      "best loss: 446.06\t\tLearning rate: 1.833e-04, Batch size: 14, Momentum: 7.361e-01\n",
      "best loss: 446.07\t\tLearning rate: 2.637e-07, Batch size: 12, Momentum: 7.887e-01\n",
      "best loss: 446.14\t\tLearning rate: 3.360e+00, Batch size: 14, Momentum: 6.309e-01\n",
      "best loss: 446.16\t\tLearning rate: 2.637e-07, Batch size: 27, Momentum: 8.413e-01\n",
      "best loss: 446.17\t\tLearning rate: 4.281e-02, Batch size: 14, Momentum: 2.629e-01\n",
      "best loss: 446.19\t\tLearning rate: 2.336e-06, Batch size: 24, Momentum: 7.361e-01\n",
      "best loss: 446.19\t\tLearning rate: 8.859e-08, Batch size: 22, Momentum: 8.938e-01\n",
      "best loss: 446.20\t\tLearning rate: 2.637e-07, Batch size: 14, Momentum: 9.990e-01\n",
      "best loss: 446.21\t\tLearning rate: 7.848e-07, Batch size: 22, Momentum: 3.681e-01\n",
      "best loss: 446.27\t\tLearning rate: 2.976e-08, Batch size: 4, Momentum: 5.784e-01\n",
      "best loss: 446.27\t\tLearning rate: 7.848e-07, Batch size: 27, Momentum: 2.103e-01\n",
      "best loss: 446.27\t\tLearning rate: 6.952e-06, Batch size: 12, Momentum: 3.681e-01\n",
      "best loss: 446.30\t\tLearning rate: 2.336e-06, Batch size: 12, Momentum: 3.155e-01\n",
      "best loss: 446.34\t\tLearning rate: 7.848e-07, Batch size: 19, Momentum: 3.155e-01\n",
      "best loss: 446.43\t\tLearning rate: 8.859e-08, Batch size: 19, Momentum: 7.361e-01\n",
      "best loss: 446.49\t\tLearning rate: 1.000e-08, Batch size: 19, Momentum: 1.577e-01\n",
      "best loss: 446.50\t\tLearning rate: 6.952e-06, Batch size: 29, Momentum: 1.577e-01\n",
      "best loss: 446.55\t\tLearning rate: 2.336e-06, Batch size: 34, Momentum: 9.990e-01\n",
      "best loss: 446.63\t\tLearning rate: 3.793e-01, Batch size: 27, Momentum: 9.464e-01\n",
      "best loss: 446.64\t\tLearning rate: 6.952e-06, Batch size: 44, Momentum: 3.155e-01\n",
      "best loss: 446.68\t\tLearning rate: 2.069e-05, Batch size: 17, Momentum: 5.258e-02\n",
      "best loss: 446.76\t\tLearning rate: 1.438e-02, Batch size: 17, Momentum: 9.464e-01\n",
      "best loss: 446.80\t\tLearning rate: 2.336e-06, Batch size: 47, Momentum: 8.938e-01\n",
      "best loss: 446.82\t\tLearning rate: 1.438e-02, Batch size: 32, Momentum: 4.206e-01\n",
      "best loss: 446.82\t\tLearning rate: 2.069e-05, Batch size: 37, Momentum: 0.000e+00\n",
      "best loss: 446.83\t\tLearning rate: 2.637e-07, Batch size: 9, Momentum: 6.835e-01\n",
      "best loss: 446.86\t\tLearning rate: 3.360e+00, Batch size: 42, Momentum: 9.990e-01\n",
      "best loss: 446.91\t\tLearning rate: 4.833e-03, Batch size: 37, Momentum: 1.577e-01\n",
      "best loss: 446.91\t\tLearning rate: 2.069e-05, Batch size: 14, Momentum: 6.309e-01\n",
      "best loss: 446.95\t\tLearning rate: 2.637e-07, Batch size: 4, Momentum: 3.155e-01\n",
      "best loss: 447.04\t\tLearning rate: 2.336e-06, Batch size: 39, Momentum: 7.887e-01\n",
      "best loss: 447.05\t\tLearning rate: 6.158e-05, Batch size: 47, Momentum: 8.413e-01\n",
      "best loss: 447.10\t\tLearning rate: 7.848e-07, Batch size: 9, Momentum: 5.258e-02\n",
      "best loss: 447.13\t\tLearning rate: 6.158e-05, Batch size: 44, Momentum: 4.732e-01\n",
      "best loss: 447.14\t\tLearning rate: 2.336e-06, Batch size: 19, Momentum: 1.052e-01\n",
      "best loss: 447.18\t\tLearning rate: 1.624e-03, Batch size: 24, Momentum: 3.681e-01\n",
      "best loss: 447.24\t\tLearning rate: 6.952e-06, Batch size: 34, Momentum: 2.103e-01\n",
      "best loss: 447.25\t\tLearning rate: 7.848e-07, Batch size: 22, Momentum: 8.413e-01\n",
      "best loss: 447.28\t\tLearning rate: 1.274e-01, Batch size: 39, Momentum: 7.887e-01\n",
      "best loss: 447.28\t\tLearning rate: 2.976e-08, Batch size: 34, Momentum: 3.155e-01\n",
      "best loss: 447.30\t\tLearning rate: 1.438e-02, Batch size: 39, Momentum: 1.577e-01\n",
      "best loss: 447.47\t\tLearning rate: 1.624e-03, Batch size: 47, Momentum: 8.413e-01\n",
      "best loss: 447.50\t\tLearning rate: 2.637e-07, Batch size: 19, Momentum: 7.887e-01\n",
      "best loss: 447.51\t\tLearning rate: 6.952e-06, Batch size: 32, Momentum: 1.577e-01\n",
      "best loss: 447.53\t\tLearning rate: 1.000e+01, Batch size: 37, Momentum: 8.413e-01\n",
      "best loss: 447.57\t\tLearning rate: 1.624e-03, Batch size: 12, Momentum: 6.309e-01\n",
      "best loss: 447.70\t\tLearning rate: 8.859e-08, Batch size: 14, Momentum: 7.887e-01\n",
      "best loss: 447.70\t\tLearning rate: 3.793e-01, Batch size: 39, Momentum: 9.990e-01\n",
      "best loss: 447.74\t\tLearning rate: 7.848e-07, Batch size: 27, Momentum: 7.361e-01\n",
      "best loss: 447.75\t\tLearning rate: 1.129e+00, Batch size: 37, Momentum: 1.577e-01\n",
      "best loss: 447.78\t\tLearning rate: 6.158e-05, Batch size: 34, Momentum: 9.464e-01\n",
      "best loss: 447.83\t\tLearning rate: 2.637e-07, Batch size: 39, Momentum: 8.413e-01\n",
      "best loss: 447.87\t\tLearning rate: 1.833e-04, Batch size: 42, Momentum: 5.258e-01\n",
      "best loss: 447.90\t\tLearning rate: 2.336e-06, Batch size: 17, Momentum: 3.155e-01\n",
      "best loss: 447.91\t\tLearning rate: 2.069e-05, Batch size: 7, Momentum: 5.784e-01\n",
      "best loss: 447.93\t\tLearning rate: 6.158e-05, Batch size: 27, Momentum: 8.938e-01\n",
      "best loss: 447.93\t\tLearning rate: 2.976e-08, Batch size: 27, Momentum: 9.464e-01\n",
      "best loss: 447.94\t\tLearning rate: 6.952e-06, Batch size: 29, Momentum: 5.258e-01\n",
      "best loss: 447.98\t\tLearning rate: 5.456e-04, Batch size: 44, Momentum: 5.258e-01\n",
      "best loss: 448.02\t\tLearning rate: 7.848e-07, Batch size: 34, Momentum: 7.887e-01\n",
      "best loss: 448.03\t\tLearning rate: 1.438e-02, Batch size: 34, Momentum: 2.629e-01\n",
      "best loss: 448.04\t\tLearning rate: 2.976e-08, Batch size: 47, Momentum: 8.413e-01\n",
      "best loss: 448.06\t\tLearning rate: 6.158e-05, Batch size: 37, Momentum: 2.103e-01\n",
      "best loss: 448.14\t\tLearning rate: 2.336e-06, Batch size: 9, Momentum: 1.052e-01\n",
      "best loss: 448.18\t\tLearning rate: 6.952e-06, Batch size: 29, Momentum: 0.000e+00\n",
      "best loss: 448.19\t\tLearning rate: 3.360e+00, Batch size: 34, Momentum: 7.887e-01\n",
      "best loss: 448.19\t\tLearning rate: 4.281e-02, Batch size: 17, Momentum: 9.990e-01\n",
      "best loss: 448.20\t\tLearning rate: 1.833e-04, Batch size: 34, Momentum: 7.361e-01\n",
      "best loss: 448.24\t\tLearning rate: 1.000e-08, Batch size: 27, Momentum: 4.732e-01\n",
      "best loss: 448.25\t\tLearning rate: 7.848e-07, Batch size: 34, Momentum: 8.938e-01\n",
      "best loss: 448.27\t\tLearning rate: 4.281e-02, Batch size: 24, Momentum: 9.990e-01\n",
      "best loss: 448.32\t\tLearning rate: 1.274e-01, Batch size: 22, Momentum: 8.938e-01\n",
      "best loss: 448.32\t\tLearning rate: 3.360e+00, Batch size: 37, Momentum: 3.155e-01\n",
      "best loss: 448.37\t\tLearning rate: 1.624e-03, Batch size: 37, Momentum: 8.938e-01\n",
      "best loss: 448.37\t\tLearning rate: 1.438e-02, Batch size: 27, Momentum: 4.206e-01\n",
      "best loss: 448.37\t\tLearning rate: 2.336e-06, Batch size: 44, Momentum: 0.000e+00\n",
      "best loss: 448.43\t\tLearning rate: 7.848e-07, Batch size: 22, Momentum: 7.887e-01\n",
      "best loss: 448.44\t\tLearning rate: 1.000e+01, Batch size: 29, Momentum: 1.577e-01\n",
      "best loss: 448.47\t\tLearning rate: 8.859e-08, Batch size: 39, Momentum: 5.784e-01\n",
      "best loss: 448.51\t\tLearning rate: 1.000e-08, Batch size: 4, Momentum: 8.938e-01\n",
      "best loss: 448.52\t\tLearning rate: 1.000e-08, Batch size: 37, Momentum: 7.887e-01\n",
      "best loss: 448.59\t\tLearning rate: 2.976e-08, Batch size: 50, Momentum: 1.577e-01\n",
      "best loss: 448.59\t\tLearning rate: 1.438e-02, Batch size: 29, Momentum: 4.732e-01\n",
      "best loss: 448.62\t\tLearning rate: 1.624e-03, Batch size: 17, Momentum: 3.681e-01\n",
      "best loss: 448.63\t\tLearning rate: 6.952e-06, Batch size: 39, Momentum: 6.835e-01\n",
      "best loss: 448.64\t\tLearning rate: 1.438e-02, Batch size: 39, Momentum: 6.309e-01\n",
      "best loss: 448.65\t\tLearning rate: 8.859e-08, Batch size: 19, Momentum: 1.052e-01\n",
      "best loss: 448.70\t\tLearning rate: 7.848e-07, Batch size: 34, Momentum: 2.629e-01\n",
      "best loss: 448.74\t\tLearning rate: 1.624e-03, Batch size: 39, Momentum: 4.206e-01\n",
      "best loss: 448.74\t\tLearning rate: 4.281e-02, Batch size: 42, Momentum: 4.206e-01\n",
      "best loss: 448.81\t\tLearning rate: 2.637e-07, Batch size: 39, Momentum: 7.887e-01\n",
      "best loss: 448.82\t\tLearning rate: 8.859e-08, Batch size: 34, Momentum: 9.990e-01\n",
      "best loss: 448.83\t\tLearning rate: 3.793e-01, Batch size: 42, Momentum: 9.990e-01\n",
      "best loss: 448.83\t\tLearning rate: 4.833e-03, Batch size: 39, Momentum: 3.681e-01\n",
      "best loss: 448.87\t\tLearning rate: 7.848e-07, Batch size: 39, Momentum: 2.103e-01\n",
      "best loss: 448.91\t\tLearning rate: 3.360e+00, Batch size: 29, Momentum: 0.000e+00\n",
      "best loss: 448.95\t\tLearning rate: 6.952e-06, Batch size: 9, Momentum: 6.835e-01\n",
      "best loss: 448.96\t\tLearning rate: 7.848e-07, Batch size: 17, Momentum: 9.464e-01\n",
      "best loss: 449.00\t\tLearning rate: 6.158e-05, Batch size: 34, Momentum: 5.258e-02\n",
      "best loss: 449.01\t\tLearning rate: 4.833e-03, Batch size: 17, Momentum: 7.887e-01\n",
      "best loss: 449.23\t\tLearning rate: 4.281e-02, Batch size: 42, Momentum: 4.732e-01\n",
      "best loss: 449.25\t\tLearning rate: 4.281e-02, Batch size: 34, Momentum: 0.000e+00\n",
      "best loss: 449.26\t\tLearning rate: 2.637e-07, Batch size: 27, Momentum: 5.784e-01\n",
      "best loss: 449.29\t\tLearning rate: 4.833e-03, Batch size: 47, Momentum: 3.681e-01\n",
      "best loss: 449.32\t\tLearning rate: 1.000e+01, Batch size: 44, Momentum: 7.887e-01\n",
      "best loss: 449.32\t\tLearning rate: 7.848e-07, Batch size: 50, Momentum: 4.206e-01\n",
      "best loss: 449.33\t\tLearning rate: 7.848e-07, Batch size: 12, Momentum: 5.784e-01\n",
      "best loss: 449.35\t\tLearning rate: 8.859e-08, Batch size: 47, Momentum: 9.464e-01\n",
      "best loss: 449.38\t\tLearning rate: 6.952e-06, Batch size: 24, Momentum: 8.938e-01\n",
      "best loss: 449.38\t\tLearning rate: 6.952e-06, Batch size: 4, Momentum: 9.990e-01\n",
      "best loss: 449.40\t\tLearning rate: 6.158e-05, Batch size: 50, Momentum: 7.361e-01\n",
      "best loss: 449.45\t\tLearning rate: 2.336e-06, Batch size: 29, Momentum: 6.835e-01\n",
      "best loss: 449.46\t\tLearning rate: 2.336e-06, Batch size: 24, Momentum: 8.413e-01\n",
      "best loss: 449.47\t\tLearning rate: 1.000e+01, Batch size: 42, Momentum: 9.990e-01\n",
      "best loss: 449.50\t\tLearning rate: 2.069e-05, Batch size: 50, Momentum: 2.629e-01\n",
      "best loss: 449.52\t\tLearning rate: 2.976e-08, Batch size: 44, Momentum: 3.155e-01\n",
      "best loss: 449.53\t\tLearning rate: 2.336e-06, Batch size: 50, Momentum: 4.732e-01\n",
      "best loss: 449.56\t\tLearning rate: 1.000e-08, Batch size: 47, Momentum: 7.361e-01\n",
      "best loss: 449.58\t\tLearning rate: 6.952e-06, Batch size: 22, Momentum: 1.052e-01\n",
      "best loss: 449.58\t\tLearning rate: 2.976e-08, Batch size: 27, Momentum: 2.629e-01\n",
      "best loss: 449.59\t\tLearning rate: 2.336e-06, Batch size: 50, Momentum: 5.258e-01\n",
      "best loss: 449.59\t\tLearning rate: 1.274e-01, Batch size: 37, Momentum: 0.000e+00\n",
      "best loss: 449.62\t\tLearning rate: 2.336e-06, Batch size: 34, Momentum: 1.577e-01\n",
      "best loss: 449.68\t\tLearning rate: 7.848e-07, Batch size: 50, Momentum: 9.990e-01\n",
      "best loss: 449.68\t\tLearning rate: 6.952e-06, Batch size: 50, Momentum: 5.784e-01\n",
      "best loss: 449.82\t\tLearning rate: 7.848e-07, Batch size: 37, Momentum: 8.413e-01\n",
      "best loss: 449.89\t\tLearning rate: 2.336e-06, Batch size: 29, Momentum: 1.052e-01\n",
      "best loss: 449.92\t\tLearning rate: 2.336e-06, Batch size: 17, Momentum: 4.732e-01\n",
      "best loss: 449.93\t\tLearning rate: 4.833e-03, Batch size: 37, Momentum: 9.464e-01\n",
      "best loss: 449.95\t\tLearning rate: 1.624e-03, Batch size: 50, Momentum: 7.361e-01\n",
      "best loss: 449.95\t\tLearning rate: 1.624e-03, Batch size: 39, Momentum: 9.990e-01\n",
      "best loss: 449.99\t\tLearning rate: 6.952e-06, Batch size: 17, Momentum: 1.577e-01\n",
      "best loss: 450.12\t\tLearning rate: 1.000e-08, Batch size: 34, Momentum: 9.464e-01\n",
      "best loss: 450.16\t\tLearning rate: 8.859e-08, Batch size: 34, Momentum: 8.413e-01\n",
      "best loss: 450.17\t\tLearning rate: 2.069e-05, Batch size: 44, Momentum: 5.784e-01\n",
      "best loss: 450.17\t\tLearning rate: 1.000e+01, Batch size: 50, Momentum: 8.938e-01\n",
      "best loss: 450.22\t\tLearning rate: 1.000e+01, Batch size: 39, Momentum: 3.155e-01\n",
      "best loss: 450.30\t\tLearning rate: 1.438e-02, Batch size: 19, Momentum: 2.103e-01\n",
      "best loss: 450.36\t\tLearning rate: 5.456e-04, Batch size: 37, Momentum: 0.000e+00\n",
      "best loss: 450.45\t\tLearning rate: 7.848e-07, Batch size: 47, Momentum: 7.887e-01\n",
      "best loss: 450.51\t\tLearning rate: 1.438e-02, Batch size: 50, Momentum: 6.309e-01\n",
      "best loss: 450.54\t\tLearning rate: 2.069e-05, Batch size: 32, Momentum: 4.206e-01\n",
      "best loss: 450.54\t\tLearning rate: 7.848e-07, Batch size: 47, Momentum: 8.938e-01\n",
      "best loss: 450.57\t\tLearning rate: 2.637e-07, Batch size: 32, Momentum: 9.464e-01\n",
      "best loss: 450.59\t\tLearning rate: 8.859e-08, Batch size: 27, Momentum: 7.887e-01\n",
      "best loss: 450.60\t\tLearning rate: 2.336e-06, Batch size: 44, Momentum: 7.361e-01\n",
      "best loss: 450.63\t\tLearning rate: 2.069e-05, Batch size: 29, Momentum: 1.052e-01\n",
      "best loss: 450.66\t\tLearning rate: 6.158e-05, Batch size: 29, Momentum: 1.052e-01\n",
      "best loss: 450.67\t\tLearning rate: 8.859e-08, Batch size: 42, Momentum: 4.206e-01\n",
      "best loss: 450.72\t\tLearning rate: 5.456e-04, Batch size: 42, Momentum: 9.990e-01\n",
      "best loss: 450.82\t\tLearning rate: 2.637e-07, Batch size: 32, Momentum: 8.413e-01\n",
      "best loss: 450.85\t\tLearning rate: 6.952e-06, Batch size: 50, Momentum: 5.258e-01\n",
      "best loss: 450.88\t\tLearning rate: 6.952e-06, Batch size: 42, Momentum: 7.887e-01\n",
      "best loss: 450.91\t\tLearning rate: 1.438e-02, Batch size: 37, Momentum: 9.990e-01\n",
      "best loss: 450.99\t\tLearning rate: 1.274e-01, Batch size: 44, Momentum: 8.413e-01\n",
      "best loss: 451.02\t\tLearning rate: 2.336e-06, Batch size: 29, Momentum: 0.000e+00\n",
      "best loss: 451.05\t\tLearning rate: 2.336e-06, Batch size: 47, Momentum: 4.732e-01\n",
      "best loss: 451.06\t\tLearning rate: 1.833e-04, Batch size: 47, Momentum: 5.784e-01\n",
      "best loss: 451.16\t\tLearning rate: 1.000e-08, Batch size: 17, Momentum: 4.206e-01\n",
      "best loss: 451.17\t\tLearning rate: 7.848e-07, Batch size: 9, Momentum: 1.052e-01\n",
      "best loss: 451.19\t\tLearning rate: 2.336e-06, Batch size: 24, Momentum: 5.258e-01\n",
      "best loss: 451.31\t\tLearning rate: 5.456e-04, Batch size: 34, Momentum: 4.732e-01\n",
      "best loss: 451.31\t\tLearning rate: 7.848e-07, Batch size: 19, Momentum: 8.413e-01\n",
      "best loss: 451.31\t\tLearning rate: 8.859e-08, Batch size: 50, Momentum: 7.361e-01\n",
      "best loss: 451.32\t\tLearning rate: 6.952e-06, Batch size: 9, Momentum: 1.052e-01\n",
      "best loss: 451.39\t\tLearning rate: 1.624e-03, Batch size: 44, Momentum: 2.629e-01\n",
      "best loss: 451.49\t\tLearning rate: 2.336e-06, Batch size: 27, Momentum: 2.629e-01\n",
      "best loss: 451.53\t\tLearning rate: 2.336e-06, Batch size: 22, Momentum: 8.413e-01\n",
      "best loss: 451.55\t\tLearning rate: 2.336e-06, Batch size: 29, Momentum: 9.464e-01\n",
      "best loss: 451.58\t\tLearning rate: 4.281e-02, Batch size: 50, Momentum: 5.258e-02\n",
      "best loss: 451.59\t\tLearning rate: 7.848e-07, Batch size: 12, Momentum: 0.000e+00\n",
      "best loss: 451.59\t\tLearning rate: 2.336e-06, Batch size: 50, Momentum: 7.887e-01\n",
      "best loss: 451.60\t\tLearning rate: 8.859e-08, Batch size: 42, Momentum: 8.938e-01\n",
      "best loss: 451.61\t\tLearning rate: 2.336e-06, Batch size: 44, Momentum: 2.103e-01\n",
      "best loss: 451.79\t\tLearning rate: 1.624e-03, Batch size: 19, Momentum: 1.577e-01\n",
      "best loss: 451.93\t\tLearning rate: 1.438e-02, Batch size: 37, Momentum: 9.464e-01\n",
      "best loss: 452.01\t\tLearning rate: 2.336e-06, Batch size: 44, Momentum: 9.990e-01\n",
      "best loss: 452.27\t\tLearning rate: 2.336e-06, Batch size: 27, Momentum: 6.309e-01\n",
      "best loss: 452.34\t\tLearning rate: 3.360e+00, Batch size: 50, Momentum: 1.577e-01\n",
      "best loss: 452.52\t\tLearning rate: 2.976e-08, Batch size: 47, Momentum: 9.990e-01\n",
      "best loss: 452.55\t\tLearning rate: 3.793e-01, Batch size: 37, Momentum: 2.629e-01\n",
      "best loss: 452.55\t\tLearning rate: 2.336e-06, Batch size: 47, Momentum: 9.464e-01\n",
      "best loss: 452.58\t\tLearning rate: 3.793e-01, Batch size: 32, Momentum: 4.732e-01\n",
      "best loss: 452.61\t\tLearning rate: 2.637e-07, Batch size: 37, Momentum: 9.990e-01\n",
      "best loss: 452.73\t\tLearning rate: 2.336e-06, Batch size: 47, Momentum: 7.887e-01\n",
      "best loss: 452.79\t\tLearning rate: 2.336e-06, Batch size: 17, Momentum: 3.681e-01\n",
      "best loss: 452.85\t\tLearning rate: 3.793e-01, Batch size: 44, Momentum: 1.577e-01\n",
      "best loss: 452.90\t\tLearning rate: 1.000e-08, Batch size: 12, Momentum: 8.938e-01\n",
      "best loss: 453.05\t\tLearning rate: 6.952e-06, Batch size: 19, Momentum: 9.990e-01\n",
      "best loss: 453.09\t\tLearning rate: 7.848e-07, Batch size: 27, Momentum: 5.258e-02\n",
      "best loss: 453.14\t\tLearning rate: 1.129e+00, Batch size: 50, Momentum: 8.413e-01\n",
      "best loss: 453.30\t\tLearning rate: 5.456e-04, Batch size: 27, Momentum: 9.464e-01\n",
      "best loss: 453.32\t\tLearning rate: 8.859e-08, Batch size: 29, Momentum: 6.835e-01\n",
      "best loss: 453.36\t\tLearning rate: 6.952e-06, Batch size: 50, Momentum: 4.206e-01\n",
      "best loss: 453.49\t\tLearning rate: 2.336e-06, Batch size: 44, Momentum: 6.835e-01\n",
      "best loss: 453.70\t\tLearning rate: 2.637e-07, Batch size: 42, Momentum: 6.309e-01\n",
      "best loss: 453.81\t\tLearning rate: 2.069e-05, Batch size: 39, Momentum: 4.732e-01\n",
      "best loss: 453.92\t\tLearning rate: 7.848e-07, Batch size: 22, Momentum: 4.732e-01\n",
      "best loss: 454.01\t\tLearning rate: 7.848e-07, Batch size: 50, Momentum: 5.784e-01\n",
      "best loss: 454.04\t\tLearning rate: 2.336e-06, Batch size: 22, Momentum: 9.464e-01\n",
      "best loss: 454.32\t\tLearning rate: 2.336e-06, Batch size: 24, Momentum: 0.000e+00\n",
      "best loss: 454.47\t\tLearning rate: 7.848e-07, Batch size: 12, Momentum: 1.577e-01\n",
      "best loss: 454.54\t\tLearning rate: 6.952e-06, Batch size: 47, Momentum: 9.990e-01\n",
      "best loss: 454.62\t\tLearning rate: 1.274e-01, Batch size: 47, Momentum: 6.835e-01\n",
      "best loss: 454.67\t\tLearning rate: 2.336e-06, Batch size: 39, Momentum: 9.464e-01\n",
      "best loss: 454.72\t\tLearning rate: 2.976e-08, Batch size: 47, Momentum: 8.938e-01\n",
      "best loss: 454.81\t\tLearning rate: 2.637e-07, Batch size: 7, Momentum: 4.206e-01\n",
      "best loss: 454.86\t\tLearning rate: 6.952e-06, Batch size: 29, Momentum: 9.464e-01\n",
      "best loss: 455.03\t\tLearning rate: 1.000e-08, Batch size: 14, Momentum: 9.464e-01\n",
      "best loss: 455.11\t\tLearning rate: 2.336e-06, Batch size: 37, Momentum: 6.835e-01\n",
      "best loss: 455.62\t\tLearning rate: 8.859e-08, Batch size: 37, Momentum: 7.887e-01\n",
      "best loss: 455.87\t\tLearning rate: 7.848e-07, Batch size: 50, Momentum: 5.258e-01\n",
      "best loss: 455.90\t\tLearning rate: 2.637e-07, Batch size: 27, Momentum: 4.206e-01\n",
      "best loss: 455.99\t\tLearning rate: 6.952e-06, Batch size: 34, Momentum: 8.413e-01\n",
      "best loss: 456.15\t\tLearning rate: 2.069e-05, Batch size: 39, Momentum: 5.258e-02\n",
      "best loss: 456.41\t\tLearning rate: 6.952e-06, Batch size: 27, Momentum: 6.309e-01\n",
      "best loss: 456.42\t\tLearning rate: 8.859e-08, Batch size: 44, Momentum: 7.361e-01\n",
      "best loss: 456.45\t\tLearning rate: 6.952e-06, Batch size: 42, Momentum: 2.629e-01\n",
      "best loss: 456.48\t\tLearning rate: 2.336e-06, Batch size: 32, Momentum: 3.155e-01\n",
      "best loss: 456.64\t\tLearning rate: 8.859e-08, Batch size: 12, Momentum: 5.258e-01\n",
      "best loss: 456.67\t\tLearning rate: 2.976e-08, Batch size: 42, Momentum: 8.938e-01\n",
      "best loss: 456.73\t\tLearning rate: 2.976e-08, Batch size: 37, Momentum: 2.629e-01\n",
      "best loss: 457.12\t\tLearning rate: 7.848e-07, Batch size: 29, Momentum: 8.938e-01\n",
      "best loss: 457.24\t\tLearning rate: 1.000e-08, Batch size: 9, Momentum: 9.464e-01\n",
      "best loss: 457.26\t\tLearning rate: 8.859e-08, Batch size: 14, Momentum: 7.361e-01\n",
      "best loss: 457.55\t\tLearning rate: 2.336e-06, Batch size: 50, Momentum: 9.990e-01\n",
      "best loss: 457.63\t\tLearning rate: 6.952e-06, Batch size: 9, Momentum: 7.887e-01\n",
      "best loss: 457.75\t\tLearning rate: 2.637e-07, Batch size: 12, Momentum: 3.155e-01\n",
      "best loss: 458.01\t\tLearning rate: 7.848e-07, Batch size: 19, Momentum: 2.103e-01\n",
      "best loss: 458.02\t\tLearning rate: 1.000e-08, Batch size: 4, Momentum: 7.887e-01\n",
      "best loss: 458.33\t\tLearning rate: 2.637e-07, Batch size: 7, Momentum: 1.577e-01\n",
      "best loss: 458.37\t\tLearning rate: 2.069e-05, Batch size: 12, Momentum: 2.103e-01\n",
      "best loss: 458.43\t\tLearning rate: 2.336e-06, Batch size: 39, Momentum: 8.413e-01\n",
      "best loss: 458.76\t\tLearning rate: 7.848e-07, Batch size: 19, Momentum: 3.681e-01\n",
      "best loss: 458.79\t\tLearning rate: 6.952e-06, Batch size: 2, Momentum: 9.990e-01\n",
      "best loss: 458.91\t\tLearning rate: 2.069e-05, Batch size: 34, Momentum: 1.052e-01\n",
      "best loss: 458.95\t\tLearning rate: 2.637e-07, Batch size: 37, Momentum: 1.052e-01\n",
      "best loss: 458.97\t\tLearning rate: 7.848e-07, Batch size: 37, Momentum: 4.206e-01\n",
      "best loss: 459.12\t\tLearning rate: 1.833e-04, Batch size: 42, Momentum: 6.309e-01\n",
      "best loss: 459.43\t\tLearning rate: 1.833e-04, Batch size: 29, Momentum: 3.155e-01\n",
      "best loss: 459.49\t\tLearning rate: 2.336e-06, Batch size: 27, Momentum: 5.258e-02\n",
      "best loss: 459.64\t\tLearning rate: 2.336e-06, Batch size: 27, Momentum: 0.000e+00\n",
      "best loss: 459.75\t\tLearning rate: 2.637e-07, Batch size: 42, Momentum: 3.155e-01\n",
      "best loss: 460.10\t\tLearning rate: 6.952e-06, Batch size: 19, Momentum: 7.361e-01\n",
      "best loss: 460.29\t\tLearning rate: 7.848e-07, Batch size: 14, Momentum: 5.258e-02\n",
      "best loss: 460.68\t\tLearning rate: 2.976e-08, Batch size: 50, Momentum: 8.938e-01\n",
      "best loss: 460.78\t\tLearning rate: 6.952e-06, Batch size: 29, Momentum: 9.990e-01\n",
      "best loss: 460.82\t\tLearning rate: 2.637e-07, Batch size: 4, Momentum: 4.206e-01\n",
      "best loss: 461.07\t\tLearning rate: 2.976e-08, Batch size: 42, Momentum: 9.990e-01\n",
      "best loss: 461.08\t\tLearning rate: 2.069e-05, Batch size: 27, Momentum: 5.784e-01\n",
      "best loss: 461.32\t\tLearning rate: 8.859e-08, Batch size: 22, Momentum: 2.629e-01\n",
      "best loss: 461.66\t\tLearning rate: 8.859e-08, Batch size: 47, Momentum: 7.887e-01\n",
      "best loss: 461.74\t\tLearning rate: 8.859e-08, Batch size: 42, Momentum: 6.309e-01\n",
      "best loss: 462.25\t\tLearning rate: 2.637e-07, Batch size: 14, Momentum: 4.732e-01\n",
      "best loss: 462.45\t\tLearning rate: 2.637e-07, Batch size: 22, Momentum: 3.681e-01\n",
      "best loss: 462.50\t\tLearning rate: 6.952e-06, Batch size: 14, Momentum: 9.464e-01\n",
      "best loss: 462.56\t\tLearning rate: 6.952e-06, Batch size: 32, Momentum: 6.835e-01\n",
      "best loss: 462.76\t\tLearning rate: 7.848e-07, Batch size: 47, Momentum: 3.681e-01\n",
      "best loss: 462.80\t\tLearning rate: 2.637e-07, Batch size: 34, Momentum: 5.784e-01\n",
      "best loss: 462.88\t\tLearning rate: 6.952e-06, Batch size: 22, Momentum: 6.835e-01\n",
      "best loss: 463.46\t\tLearning rate: 2.336e-06, Batch size: 37, Momentum: 2.629e-01\n",
      "best loss: 464.03\t\tLearning rate: 6.952e-06, Batch size: 50, Momentum: 1.577e-01\n",
      "best loss: 464.18\t\tLearning rate: 6.952e-06, Batch size: 4, Momentum: 2.103e-01\n",
      "best loss: 464.60\t\tLearning rate: 7.848e-07, Batch size: 47, Momentum: 4.206e-01\n",
      "best loss: 464.97\t\tLearning rate: 6.952e-06, Batch size: 12, Momentum: 7.887e-01\n",
      "best loss: 465.58\t\tLearning rate: 6.952e-06, Batch size: 9, Momentum: 3.681e-01\n",
      "best loss: 465.73\t\tLearning rate: 7.848e-07, Batch size: 50, Momentum: 2.629e-01\n",
      "best loss: 466.09\t\tLearning rate: 2.069e-05, Batch size: 12, Momentum: 8.938e-01\n",
      "best loss: 466.39\t\tLearning rate: 1.000e-08, Batch size: 27, Momentum: 9.464e-01\n",
      "best loss: 466.90\t\tLearning rate: 2.637e-07, Batch size: 37, Momentum: 7.361e-01\n",
      "best loss: 467.03\t\tLearning rate: 2.637e-07, Batch size: 22, Momentum: 3.155e-01\n",
      "best loss: 468.41\t\tLearning rate: 2.637e-07, Batch size: 29, Momentum: 5.784e-01\n",
      "best loss: 468.83\t\tLearning rate: 6.158e-05, Batch size: 47, Momentum: 3.681e-01\n",
      "best loss: 469.31\t\tLearning rate: 6.158e-05, Batch size: 2, Momentum: 6.309e-01\n",
      "best loss: 469.70\t\tLearning rate: 1.000e-08, Batch size: 37, Momentum: 8.938e-01\n",
      "best loss: 470.96\t\tLearning rate: 2.069e-05, Batch size: 19, Momentum: 2.629e-01\n",
      "best loss: 471.41\t\tLearning rate: 6.952e-06, Batch size: 47, Momentum: 0.000e+00\n",
      "best loss: 471.63\t\tLearning rate: 8.859e-08, Batch size: 12, Momentum: 1.052e-01\n",
      "best loss: 472.18\t\tLearning rate: 2.976e-08, Batch size: 2, Momentum: 7.887e-01\n",
      "best loss: 472.48\t\tLearning rate: 2.637e-07, Batch size: 42, Momentum: 2.103e-01\n",
      "best loss: 472.71\t\tLearning rate: 2.069e-05, Batch size: 32, Momentum: 5.258e-02\n",
      "best loss: 473.82\t\tLearning rate: 7.848e-07, Batch size: 32, Momentum: 1.577e-01\n",
      "best loss: 474.37\t\tLearning rate: 6.952e-06, Batch size: 47, Momentum: 1.577e-01\n",
      "best loss: 474.90\t\tLearning rate: 6.952e-06, Batch size: 17, Momentum: 7.361e-01\n",
      "best loss: 476.71\t\tLearning rate: 2.069e-05, Batch size: 27, Momentum: 5.258e-02\n",
      "best loss: 477.67\t\tLearning rate: 1.000e-08, Batch size: 12, Momentum: 5.258e-01\n",
      "best loss: 477.80\t\tLearning rate: 2.637e-07, Batch size: 27, Momentum: 1.577e-01\n",
      "best loss: 479.56\t\tLearning rate: 1.000e-08, Batch size: 17, Momentum: 8.938e-01\n",
      "best loss: 481.95\t\tLearning rate: 8.859e-08, Batch size: 19, Momentum: 4.206e-01\n",
      "best loss: 482.78\t\tLearning rate: 8.859e-08, Batch size: 44, Momentum: 4.206e-01\n",
      "best loss: 483.51\t\tLearning rate: 8.859e-08, Batch size: 14, Momentum: 8.413e-01\n",
      "best loss: 484.49\t\tLearning rate: 5.456e-04, Batch size: 50, Momentum: 3.681e-01\n",
      "best loss: 484.91\t\tLearning rate: 2.069e-05, Batch size: 42, Momentum: 5.258e-02\n",
      "best loss: 485.32\t\tLearning rate: 2.069e-05, Batch size: 2, Momentum: 3.681e-01\n",
      "best loss: 485.46\t\tLearning rate: 8.859e-08, Batch size: 17, Momentum: 6.835e-01\n",
      "best loss: 486.06\t\tLearning rate: 2.069e-05, Batch size: 47, Momentum: 3.681e-01\n",
      "best loss: 486.18\t\tLearning rate: 2.637e-07, Batch size: 37, Momentum: 4.206e-01\n",
      "best loss: 487.38\t\tLearning rate: 2.976e-08, Batch size: 9, Momentum: 3.155e-01\n",
      "best loss: 488.63\t\tLearning rate: 2.637e-07, Batch size: 17, Momentum: 4.206e-01\n",
      "best loss: 489.11\t\tLearning rate: 8.859e-08, Batch size: 50, Momentum: 5.258e-01\n",
      "best loss: 489.13\t\tLearning rate: 2.637e-07, Batch size: 22, Momentum: 2.629e-01\n",
      "best loss: 491.23\t\tLearning rate: 8.859e-08, Batch size: 47, Momentum: 5.258e-02\n",
      "best loss: 492.83\t\tLearning rate: 2.069e-05, Batch size: 17, Momentum: 0.000e+00\n",
      "best loss: 493.11\t\tLearning rate: 1.000e-08, Batch size: 32, Momentum: 5.258e-01\n",
      "best loss: 496.33\t\tLearning rate: 8.859e-08, Batch size: 50, Momentum: 1.577e-01\n",
      "best loss: 497.64\t\tLearning rate: 2.336e-06, Batch size: 9, Momentum: 2.103e-01\n",
      "best loss: 497.83\t\tLearning rate: 1.000e-08, Batch size: 19, Momentum: 6.309e-01\n",
      "best loss: 499.29\t\tLearning rate: 1.000e-08, Batch size: 12, Momentum: 7.887e-01\n",
      "best loss: 502.18\t\tLearning rate: 2.976e-08, Batch size: 7, Momentum: 5.258e-01\n",
      "best loss: 502.74\t\tLearning rate: 2.637e-07, Batch size: 50, Momentum: 6.309e-01\n",
      "best loss: 504.68\t\tLearning rate: 2.069e-05, Batch size: 39, Momentum: 3.155e-01\n",
      "best loss: 504.77\t\tLearning rate: 2.637e-07, Batch size: 29, Momentum: 5.258e-01\n",
      "best loss: 506.94\t\tLearning rate: 1.000e-08, Batch size: 9, Momentum: 5.784e-01\n",
      "best loss: 508.42\t\tLearning rate: 1.000e-08, Batch size: 50, Momentum: 6.835e-01\n",
      "best loss: 509.37\t\tLearning rate: 1.000e-08, Batch size: 2, Momentum: 3.681e-01\n",
      "best loss: 511.70\t\tLearning rate: 2.976e-08, Batch size: 29, Momentum: 5.258e-01\n",
      "best loss: 511.96\t\tLearning rate: 1.000e-08, Batch size: 12, Momentum: 7.361e-01\n",
      "best loss: 512.07\t\tLearning rate: 2.069e-05, Batch size: 9, Momentum: 4.206e-01\n",
      "best loss: 512.75\t\tLearning rate: 2.069e-05, Batch size: 29, Momentum: 3.155e-01\n",
      "best loss: 513.45\t\tLearning rate: 2.069e-05, Batch size: 17, Momentum: 1.577e-01\n",
      "best loss: 515.98\t\tLearning rate: 6.952e-06, Batch size: 39, Momentum: 5.258e-02\n",
      "best loss: 520.13\t\tLearning rate: 2.976e-08, Batch size: 22, Momentum: 5.784e-01\n",
      "best loss: 526.15\t\tLearning rate: 1.000e-08, Batch size: 44, Momentum: 8.938e-01\n",
      "best loss: 526.17\t\tLearning rate: 2.069e-05, Batch size: 42, Momentum: 2.629e-01\n",
      "best loss: 528.78\t\tLearning rate: 2.976e-08, Batch size: 29, Momentum: 2.103e-01\n",
      "best loss: 529.50\t\tLearning rate: 8.859e-08, Batch size: 4, Momentum: 1.052e-01\n",
      "best loss: 531.25\t\tLearning rate: 8.859e-08, Batch size: 39, Momentum: 6.835e-01\n",
      "best loss: 535.63\t\tLearning rate: 1.000e-08, Batch size: 37, Momentum: 4.206e-01\n",
      "best loss: 536.28\t\tLearning rate: 2.976e-08, Batch size: 9, Momentum: 3.681e-01\n",
      "best loss: 537.55\t\tLearning rate: 6.952e-06, Batch size: 17, Momentum: 9.464e-01\n",
      "best loss: 553.39\t\tLearning rate: 2.637e-07, Batch size: 29, Momentum: 1.577e-01\n",
      "best loss: 556.59\t\tLearning rate: 2.976e-08, Batch size: 12, Momentum: 2.103e-01\n",
      "best loss: 557.74\t\tLearning rate: 2.069e-05, Batch size: 9, Momentum: 4.732e-01\n",
      "best loss: 559.32\t\tLearning rate: 7.848e-07, Batch size: 22, Momentum: 1.577e-01\n",
      "best loss: 566.07\t\tLearning rate: 1.000e-08, Batch size: 32, Momentum: 2.629e-01\n",
      "best loss: 573.43\t\tLearning rate: 2.069e-05, Batch size: 44, Momentum: 3.155e-01\n",
      "best loss: 578.26\t\tLearning rate: 2.976e-08, Batch size: 29, Momentum: 7.361e-01\n",
      "best loss: 591.32\t\tLearning rate: 6.158e-05, Batch size: 19, Momentum: 5.258e-02\n",
      "best loss: 594.19\t\tLearning rate: 2.637e-07, Batch size: 19, Momentum: 1.577e-01\n",
      "best loss: 608.16\t\tLearning rate: 2.069e-05, Batch size: 4, Momentum: 7.361e-01\n",
      "best loss: 613.51\t\tLearning rate: 6.158e-05, Batch size: 4, Momentum: 1.577e-01\n",
      "best loss: 625.45\t\tLearning rate: 1.000e-08, Batch size: 47, Momentum: 6.835e-01\n",
      "best loss: 630.47\t\tLearning rate: 8.859e-08, Batch size: 29, Momentum: 6.309e-01\n",
      "best loss: 637.78\t\tLearning rate: 2.637e-07, Batch size: 27, Momentum: 0.000e+00\n",
      "best loss: 652.97\t\tLearning rate: 6.158e-05, Batch size: 29, Momentum: 4.206e-01\n",
      "best loss: 656.26\t\tLearning rate: 2.976e-08, Batch size: 42, Momentum: 2.629e-01\n",
      "best loss: 656.82\t\tLearning rate: 2.976e-08, Batch size: 39, Momentum: 0.000e+00\n",
      "best loss: 658.48\t\tLearning rate: 8.859e-08, Batch size: 17, Momentum: 5.258e-01\n",
      "best loss: 664.70\t\tLearning rate: 2.069e-05, Batch size: 9, Momentum: 5.258e-01\n",
      "best loss: 666.40\t\tLearning rate: 2.069e-05, Batch size: 42, Momentum: 1.052e-01\n",
      "best loss: 667.17\t\tLearning rate: 6.158e-05, Batch size: 14, Momentum: 4.206e-01\n",
      "best loss: 667.50\t\tLearning rate: 8.859e-08, Batch size: 14, Momentum: 3.681e-01\n",
      "best loss: 669.52\t\tLearning rate: 2.976e-08, Batch size: 14, Momentum: 4.206e-01\n",
      "best loss: 673.73\t\tLearning rate: 2.069e-05, Batch size: 24, Momentum: 9.464e-01\n",
      "best loss: 675.87\t\tLearning rate: 6.158e-05, Batch size: 27, Momentum: 5.258e-02\n",
      "best loss: 677.15\t\tLearning rate: 2.069e-05, Batch size: 12, Momentum: 4.732e-01\n",
      "best loss: 679.37\t\tLearning rate: 6.158e-05, Batch size: 4, Momentum: 5.784e-01\n",
      "best loss: 688.08\t\tLearning rate: 6.158e-05, Batch size: 24, Momentum: 6.309e-01\n",
      "best loss: 694.21\t\tLearning rate: 6.158e-05, Batch size: 7, Momentum: 0.000e+00\n",
      "best loss: 696.78\t\tLearning rate: 6.158e-05, Batch size: 12, Momentum: 5.258e-02\n",
      "best loss: 701.48\t\tLearning rate: 2.069e-05, Batch size: 44, Momentum: 5.258e-01\n",
      "best loss: 703.19\t\tLearning rate: 6.158e-05, Batch size: 32, Momentum: 1.577e-01\n",
      "best loss: 710.82\t\tLearning rate: 6.158e-05, Batch size: 32, Momentum: 9.990e-01\n",
      "best loss: 712.73\t\tLearning rate: 2.069e-05, Batch size: 39, Momentum: 3.681e-01\n",
      "best loss: 713.15\t\tLearning rate: 1.833e-04, Batch size: 27, Momentum: 5.258e-02\n",
      "best loss: 717.35\t\tLearning rate: 6.158e-05, Batch size: 29, Momentum: 9.990e-01\n",
      "best loss: 722.85\t\tLearning rate: 1.833e-04, Batch size: 9, Momentum: 0.000e+00\n",
      "best loss: 723.34\t\tLearning rate: 2.069e-05, Batch size: 14, Momentum: 8.413e-01\n",
      "best loss: 724.42\t\tLearning rate: 2.069e-05, Batch size: 17, Momentum: 6.835e-01\n",
      "best loss: 725.97\t\tLearning rate: 2.069e-05, Batch size: 9, Momentum: 8.413e-01\n",
      "best loss: 731.88\t\tLearning rate: 1.833e-04, Batch size: 22, Momentum: 7.887e-01\n",
      "best loss: 732.36\t\tLearning rate: 6.158e-05, Batch size: 2, Momentum: 5.784e-01\n",
      "best loss: 732.92\t\tLearning rate: 1.833e-04, Batch size: 50, Momentum: 1.577e-01\n",
      "best loss: 733.32\t\tLearning rate: 2.069e-05, Batch size: 4, Momentum: 7.887e-01\n",
      "best loss: 735.07\t\tLearning rate: 2.069e-05, Batch size: 19, Momentum: 8.413e-01\n",
      "best loss: 737.54\t\tLearning rate: 6.158e-05, Batch size: 29, Momentum: 4.732e-01\n",
      "best loss: 740.62\t\tLearning rate: 6.158e-05, Batch size: 32, Momentum: 4.732e-01\n",
      "best loss: 744.31\t\tLearning rate: 2.976e-08, Batch size: 24, Momentum: 1.577e-01\n",
      "best loss: 744.90\t\tLearning rate: 6.158e-05, Batch size: 32, Momentum: 4.206e-01\n",
      "best loss: 745.67\t\tLearning rate: 1.833e-04, Batch size: 47, Momentum: 1.577e-01\n",
      "best loss: 747.85\t\tLearning rate: 2.976e-08, Batch size: 27, Momentum: 5.258e-01\n",
      "best loss: 751.22\t\tLearning rate: 6.158e-05, Batch size: 29, Momentum: 3.681e-01\n",
      "best loss: 752.09\t\tLearning rate: 1.833e-04, Batch size: 24, Momentum: 1.577e-01\n",
      "best loss: 753.11\t\tLearning rate: 1.833e-04, Batch size: 32, Momentum: 1.577e-01\n",
      "best loss: 754.21\t\tLearning rate: 2.069e-05, Batch size: 17, Momentum: 5.784e-01\n",
      "best loss: 759.78\t\tLearning rate: 6.158e-05, Batch size: 22, Momentum: 3.681e-01\n",
      "best loss: 762.38\t\tLearning rate: 1.833e-04, Batch size: 17, Momentum: 3.681e-01\n",
      "best loss: 762.42\t\tLearning rate: 6.158e-05, Batch size: 27, Momentum: 2.103e-01\n",
      "best loss: 763.57\t\tLearning rate: 6.158e-05, Batch size: 4, Momentum: 4.206e-01\n",
      "best loss: 765.57\t\tLearning rate: 2.069e-05, Batch size: 50, Momentum: 9.990e-01\n",
      "best loss: 766.29\t\tLearning rate: 1.833e-04, Batch size: 39, Momentum: 6.835e-01\n",
      "best loss: 770.22\t\tLearning rate: 1.833e-04, Batch size: 14, Momentum: 8.413e-01\n",
      "best loss: 771.35\t\tLearning rate: 6.158e-05, Batch size: 19, Momentum: 5.784e-01\n",
      "best loss: 775.69\t\tLearning rate: 6.158e-05, Batch size: 39, Momentum: 5.258e-01\n",
      "best loss: 780.64\t\tLearning rate: 1.000e-08, Batch size: 47, Momentum: 3.155e-01\n",
      "best loss: 784.04\t\tLearning rate: 1.833e-04, Batch size: 42, Momentum: 7.361e-01\n",
      "best loss: 785.77\t\tLearning rate: 8.859e-08, Batch size: 22, Momentum: 0.000e+00\n",
      "best loss: 787.10\t\tLearning rate: 6.158e-05, Batch size: 17, Momentum: 5.784e-01\n",
      "best loss: 790.21\t\tLearning rate: 1.833e-04, Batch size: 39, Momentum: 9.990e-01\n",
      "best loss: 791.37\t\tLearning rate: 1.833e-04, Batch size: 17, Momentum: 8.413e-01\n",
      "best loss: 791.85\t\tLearning rate: 6.158e-05, Batch size: 19, Momentum: 7.361e-01\n",
      "best loss: 795.23\t\tLearning rate: 1.833e-04, Batch size: 4, Momentum: 3.681e-01\n",
      "best loss: 795.97\t\tLearning rate: 1.833e-04, Batch size: 39, Momentum: 4.732e-01\n",
      "best loss: 796.51\t\tLearning rate: 2.069e-05, Batch size: 47, Momentum: 7.361e-01\n",
      "best loss: 798.14\t\tLearning rate: 6.158e-05, Batch size: 37, Momentum: 7.361e-01\n",
      "best loss: 798.49\t\tLearning rate: 1.833e-04, Batch size: 4, Momentum: 3.155e-01\n",
      "best loss: 799.12\t\tLearning rate: 1.833e-04, Batch size: 14, Momentum: 3.681e-01\n",
      "best loss: 800.04\t\tLearning rate: 5.456e-04, Batch size: 4, Momentum: 3.681e-01\n",
      "best loss: 805.03\t\tLearning rate: 1.833e-04, Batch size: 37, Momentum: 2.629e-01\n",
      "best loss: 807.49\t\tLearning rate: 6.158e-05, Batch size: 32, Momentum: 8.938e-01\n",
      "best loss: 808.27\t\tLearning rate: 6.158e-05, Batch size: 29, Momentum: 6.835e-01\n",
      "best loss: 811.74\t\tLearning rate: 5.456e-04, Batch size: 42, Momentum: 2.103e-01\n",
      "best loss: 812.35\t\tLearning rate: 1.833e-04, Batch size: 42, Momentum: 3.681e-01\n",
      "best loss: 812.88\t\tLearning rate: 1.833e-04, Batch size: 37, Momentum: 6.835e-01\n",
      "best loss: 813.69\t\tLearning rate: 1.833e-04, Batch size: 17, Momentum: 5.784e-01\n",
      "best loss: 816.35\t\tLearning rate: 5.456e-04, Batch size: 39, Momentum: 5.258e-02\n",
      "best loss: 816.48\t\tLearning rate: 6.158e-05, Batch size: 19, Momentum: 6.835e-01\n",
      "best loss: 816.70\t\tLearning rate: 5.456e-04, Batch size: 17, Momentum: 4.206e-01\n",
      "best loss: 819.09\t\tLearning rate: 1.833e-04, Batch size: 27, Momentum: 9.464e-01\n",
      "best loss: 821.94\t\tLearning rate: 1.833e-04, Batch size: 7, Momentum: 4.732e-01\n",
      "best loss: 822.24\t\tLearning rate: 1.833e-04, Batch size: 50, Momentum: 5.258e-01\n",
      "best loss: 822.42\t\tLearning rate: 1.833e-04, Batch size: 19, Momentum: 5.258e-01\n",
      "best loss: 822.72\t\tLearning rate: 1.624e-03, Batch size: 17, Momentum: 0.000e+00\n",
      "best loss: 822.84\t\tLearning rate: 1.833e-04, Batch size: 4, Momentum: 5.258e-01\n",
      "best loss: 824.29\t\tLearning rate: 1.833e-04, Batch size: 24, Momentum: 5.258e-01\n",
      "best loss: 824.89\t\tLearning rate: 6.158e-05, Batch size: 50, Momentum: 8.938e-01\n",
      "best loss: 826.02\t\tLearning rate: 1.833e-04, Batch size: 27, Momentum: 5.784e-01\n",
      "best loss: 828.97\t\tLearning rate: 2.976e-08, Batch size: 14, Momentum: 4.732e-01\n",
      "best loss: 829.08\t\tLearning rate: 5.456e-04, Batch size: 17, Momentum: 6.309e-01\n",
      "best loss: 831.90\t\tLearning rate: 1.833e-04, Batch size: 12, Momentum: 4.732e-01\n",
      "best loss: 835.77\t\tLearning rate: 1.833e-04, Batch size: 22, Momentum: 9.464e-01\n",
      "best loss: 836.91\t\tLearning rate: 1.833e-04, Batch size: 12, Momentum: 5.258e-01\n",
      "best loss: 840.95\t\tLearning rate: 6.158e-05, Batch size: 39, Momentum: 7.887e-01\n",
      "best loss: 841.14\t\tLearning rate: 1.624e-03, Batch size: 32, Momentum: 0.000e+00\n",
      "best loss: 842.40\t\tLearning rate: 5.456e-04, Batch size: 4, Momentum: 2.103e-01\n",
      "best loss: 845.99\t\tLearning rate: 5.456e-04, Batch size: 19, Momentum: 2.103e-01\n",
      "best loss: 848.66\t\tLearning rate: 6.158e-05, Batch size: 24, Momentum: 9.990e-01\n",
      "best loss: 850.74\t\tLearning rate: 1.833e-04, Batch size: 4, Momentum: 7.361e-01\n",
      "best loss: 851.92\t\tLearning rate: 1.624e-03, Batch size: 32, Momentum: 2.103e-01\n",
      "best loss: 852.88\t\tLearning rate: 5.456e-04, Batch size: 47, Momentum: 2.103e-01\n",
      "best loss: 853.06\t\tLearning rate: 5.456e-04, Batch size: 34, Momentum: 5.784e-01\n",
      "best loss: 853.10\t\tLearning rate: 5.456e-04, Batch size: 42, Momentum: 4.206e-01\n",
      "best loss: 853.50\t\tLearning rate: 5.456e-04, Batch size: 14, Momentum: 7.361e-01\n",
      "best loss: 855.06\t\tLearning rate: 1.624e-03, Batch size: 14, Momentum: 7.361e-01\n",
      "best loss: 855.62\t\tLearning rate: 1.833e-04, Batch size: 34, Momentum: 9.990e-01\n",
      "best loss: 856.29\t\tLearning rate: 5.456e-04, Batch size: 27, Momentum: 7.361e-01\n",
      "best loss: 857.65\t\tLearning rate: 1.624e-03, Batch size: 12, Momentum: 1.577e-01\n",
      "best loss: 858.98\t\tLearning rate: 5.456e-04, Batch size: 44, Momentum: 7.361e-01\n",
      "best loss: 862.34\t\tLearning rate: 5.456e-04, Batch size: 34, Momentum: 2.629e-01\n",
      "best loss: 863.35\t\tLearning rate: 1.833e-04, Batch size: 4, Momentum: 8.938e-01\n",
      "best loss: 865.66\t\tLearning rate: 1.624e-03, Batch size: 9, Momentum: 2.629e-01\n",
      "best loss: 866.43\t\tLearning rate: 1.624e-03, Batch size: 27, Momentum: 5.258e-02\n",
      "best loss: 868.08\t\tLearning rate: 5.456e-04, Batch size: 29, Momentum: 5.784e-01\n",
      "best loss: 868.15\t\tLearning rate: 1.624e-03, Batch size: 50, Momentum: 1.577e-01\n",
      "best loss: 869.27\t\tLearning rate: 5.456e-04, Batch size: 34, Momentum: 5.258e-01\n",
      "best loss: 870.60\t\tLearning rate: 1.833e-04, Batch size: 42, Momentum: 9.990e-01\n",
      "best loss: 872.61\t\tLearning rate: 1.624e-03, Batch size: 27, Momentum: 1.577e-01\n",
      "best loss: 874.65\t\tLearning rate: 1.624e-03, Batch size: 27, Momentum: 2.103e-01\n",
      "best loss: 875.51\t\tLearning rate: 5.456e-04, Batch size: 14, Momentum: 6.835e-01\n",
      "best loss: 876.27\t\tLearning rate: 5.456e-04, Batch size: 39, Momentum: 5.258e-01\n",
      "best loss: 876.67\t\tLearning rate: 5.456e-04, Batch size: 29, Momentum: 8.938e-01\n",
      "best loss: 876.71\t\tLearning rate: 1.000e-08, Batch size: 47, Momentum: 6.309e-01\n",
      "best loss: 877.56\t\tLearning rate: 5.456e-04, Batch size: 4, Momentum: 3.155e-01\n",
      "best loss: 880.04\t\tLearning rate: 1.624e-03, Batch size: 37, Momentum: 2.103e-01\n",
      "best loss: 881.41\t\tLearning rate: 5.456e-04, Batch size: 42, Momentum: 8.413e-01\n",
      "best loss: 881.67\t\tLearning rate: 1.833e-04, Batch size: 32, Momentum: 8.413e-01\n",
      "best loss: 882.06\t\tLearning rate: 5.456e-04, Batch size: 12, Momentum: 4.732e-01\n",
      "best loss: 883.43\t\tLearning rate: 1.833e-04, Batch size: 14, Momentum: 9.464e-01\n",
      "best loss: 883.49\t\tLearning rate: 5.456e-04, Batch size: 29, Momentum: 8.413e-01\n",
      "best loss: 885.10\t\tLearning rate: 5.456e-04, Batch size: 17, Momentum: 5.258e-01\n",
      "best loss: 889.47\t\tLearning rate: 1.624e-03, Batch size: 14, Momentum: 8.938e-01\n",
      "best loss: 889.83\t\tLearning rate: 1.833e-04, Batch size: 37, Momentum: 7.887e-01\n",
      "best loss: 891.19\t\tLearning rate: 1.833e-04, Batch size: 19, Momentum: 8.413e-01\n",
      "best loss: 892.61\t\tLearning rate: 5.456e-04, Batch size: 29, Momentum: 4.732e-01\n",
      "best loss: 894.29\t\tLearning rate: 4.833e-03, Batch size: 19, Momentum: 0.000e+00\n",
      "best loss: 895.53\t\tLearning rate: 1.624e-03, Batch size: 42, Momentum: 2.103e-01\n",
      "best loss: 900.23\t\tLearning rate: 1.624e-03, Batch size: 9, Momentum: 6.309e-01\n",
      "best loss: 900.33\t\tLearning rate: 5.456e-04, Batch size: 37, Momentum: 7.887e-01\n",
      "best loss: 902.28\t\tLearning rate: 5.456e-04, Batch size: 22, Momentum: 6.835e-01\n",
      "best loss: 903.78\t\tLearning rate: 5.456e-04, Batch size: 12, Momentum: 5.784e-01\n",
      "best loss: 905.87\t\tLearning rate: 1.624e-03, Batch size: 17, Momentum: 5.784e-01\n",
      "best loss: 906.34\t\tLearning rate: 1.833e-04, Batch size: 50, Momentum: 9.990e-01\n",
      "best loss: 912.17\t\tLearning rate: 1.624e-03, Batch size: 32, Momentum: 6.309e-01\n",
      "best loss: 913.38\t\tLearning rate: 5.456e-04, Batch size: 12, Momentum: 9.464e-01\n",
      "best loss: 914.11\t\tLearning rate: 1.624e-03, Batch size: 4, Momentum: 4.732e-01\n",
      "best loss: 914.13\t\tLearning rate: 5.456e-04, Batch size: 50, Momentum: 8.413e-01\n",
      "best loss: 914.93\t\tLearning rate: 4.833e-03, Batch size: 24, Momentum: 0.000e+00\n",
      "best loss: 915.51\t\tLearning rate: 1.624e-03, Batch size: 37, Momentum: 5.784e-01\n",
      "best loss: 916.01\t\tLearning rate: 1.624e-03, Batch size: 17, Momentum: 5.258e-01\n",
      "best loss: 918.80\t\tLearning rate: 5.456e-04, Batch size: 19, Momentum: 9.990e-01\n",
      "best loss: 921.51\t\tLearning rate: 1.624e-03, Batch size: 24, Momentum: 6.309e-01\n",
      "best loss: 922.63\t\tLearning rate: 1.624e-03, Batch size: 32, Momentum: 7.361e-01\n",
      "best loss: 924.14\t\tLearning rate: 4.833e-03, Batch size: 44, Momentum: 1.577e-01\n",
      "best loss: 925.09\t\tLearning rate: 1.624e-03, Batch size: 2, Momentum: 5.258e-01\n",
      "best loss: 925.14\t\tLearning rate: 1.624e-03, Batch size: 34, Momentum: 6.309e-01\n",
      "best loss: 925.32\t\tLearning rate: 1.624e-03, Batch size: 4, Momentum: 4.206e-01\n",
      "best loss: 925.55\t\tLearning rate: 5.456e-04, Batch size: 39, Momentum: 8.938e-01\n",
      "best loss: 925.55\t\tLearning rate: 1.624e-03, Batch size: 19, Momentum: 8.938e-01\n",
      "best loss: 925.79\t\tLearning rate: 1.624e-03, Batch size: 39, Momentum: 3.155e-01\n",
      "best loss: 928.05\t\tLearning rate: 1.438e-02, Batch size: 2, Momentum: 5.258e-02\n",
      "best loss: 928.30\t\tLearning rate: 4.833e-03, Batch size: 4, Momentum: 5.258e-02\n",
      "best loss: 930.38\t\tLearning rate: 1.833e-04, Batch size: 2, Momentum: 9.464e-01\n",
      "best loss: 930.57\t\tLearning rate: 4.833e-03, Batch size: 47, Momentum: 2.103e-01\n",
      "best loss: 933.66\t\tLearning rate: 1.624e-03, Batch size: 34, Momentum: 7.361e-01\n",
      "best loss: 936.20\t\tLearning rate: 1.624e-03, Batch size: 37, Momentum: 3.681e-01\n",
      "best loss: 937.32\t\tLearning rate: 5.456e-04, Batch size: 7, Momentum: 8.413e-01\n",
      "best loss: 940.20\t\tLearning rate: 4.833e-03, Batch size: 14, Momentum: 3.155e-01\n",
      "best loss: 940.34\t\tLearning rate: 1.624e-03, Batch size: 32, Momentum: 3.681e-01\n",
      "best loss: 940.40\t\tLearning rate: 1.624e-03, Batch size: 29, Momentum: 5.784e-01\n",
      "best loss: 941.03\t\tLearning rate: 4.833e-03, Batch size: 32, Momentum: 2.103e-01\n",
      "best loss: 943.90\t\tLearning rate: 1.438e-02, Batch size: 14, Momentum: 5.258e-02\n",
      "best loss: 945.35\t\tLearning rate: 4.833e-03, Batch size: 39, Momentum: 1.052e-01\n",
      "best loss: 946.04\t\tLearning rate: 4.833e-03, Batch size: 2, Momentum: 3.681e-01\n",
      "best loss: 947.08\t\tLearning rate: 5.456e-04, Batch size: 32, Momentum: 7.361e-01\n",
      "best loss: 951.41\t\tLearning rate: 1.624e-03, Batch size: 12, Momentum: 6.835e-01\n",
      "best loss: 955.11\t\tLearning rate: 1.438e-02, Batch size: 9, Momentum: 0.000e+00\n",
      "best loss: 955.21\t\tLearning rate: 4.833e-03, Batch size: 50, Momentum: 3.681e-01\n",
      "best loss: 957.74\t\tLearning rate: 4.833e-03, Batch size: 12, Momentum: 3.155e-01\n",
      "best loss: 959.75\t\tLearning rate: 5.456e-04, Batch size: 29, Momentum: 9.990e-01\n",
      "best loss: 960.91\t\tLearning rate: 1.438e-02, Batch size: 29, Momentum: 0.000e+00\n",
      "best loss: 961.55\t\tLearning rate: 1.624e-03, Batch size: 7, Momentum: 9.990e-01\n",
      "best loss: 962.02\t\tLearning rate: 4.833e-03, Batch size: 17, Momentum: 4.206e-01\n",
      "best loss: 962.39\t\tLearning rate: 4.833e-03, Batch size: 9, Momentum: 2.103e-01\n",
      "best loss: 962.50\t\tLearning rate: 1.624e-03, Batch size: 44, Momentum: 8.413e-01\n",
      "best loss: 963.01\t\tLearning rate: 1.438e-02, Batch size: 7, Momentum: 2.103e-01\n",
      "best loss: 963.03\t\tLearning rate: 1.438e-02, Batch size: 42, Momentum: 0.000e+00\n",
      "best loss: 963.18\t\tLearning rate: 1.438e-02, Batch size: 14, Momentum: 1.052e-01\n",
      "best loss: 965.90\t\tLearning rate: 4.833e-03, Batch size: 32, Momentum: 3.681e-01\n",
      "best loss: 966.17\t\tLearning rate: 1.624e-03, Batch size: 27, Momentum: 7.361e-01\n",
      "best loss: 969.81\t\tLearning rate: 5.456e-04, Batch size: 44, Momentum: 8.938e-01\n",
      "best loss: 970.53\t\tLearning rate: 4.833e-03, Batch size: 27, Momentum: 5.258e-01\n",
      "best loss: 972.69\t\tLearning rate: 4.833e-03, Batch size: 12, Momentum: 4.732e-01\n",
      "best loss: 975.83\t\tLearning rate: 4.833e-03, Batch size: 24, Momentum: 4.206e-01\n",
      "best loss: 976.67\t\tLearning rate: 1.624e-03, Batch size: 14, Momentum: 6.309e-01\n",
      "best loss: 980.22\t\tLearning rate: 4.833e-03, Batch size: 17, Momentum: 5.258e-01\n",
      "best loss: 981.21\t\tLearning rate: 1.438e-02, Batch size: 42, Momentum: 1.577e-01\n",
      "best loss: 981.70\t\tLearning rate: 4.833e-03, Batch size: 44, Momentum: 5.784e-01\n",
      "best loss: 984.46\t\tLearning rate: 1.624e-03, Batch size: 29, Momentum: 8.413e-01\n",
      "best loss: 985.15\t\tLearning rate: 1.438e-02, Batch size: 32, Momentum: 1.052e-01\n",
      "best loss: 986.78\t\tLearning rate: 1.438e-02, Batch size: 44, Momentum: 1.577e-01\n",
      "best loss: 987.72\t\tLearning rate: 4.833e-03, Batch size: 50, Momentum: 5.784e-01\n",
      "best loss: 988.33\t\tLearning rate: 4.833e-03, Batch size: 44, Momentum: 4.206e-01\n",
      "best loss: 988.77\t\tLearning rate: 1.438e-02, Batch size: 29, Momentum: 5.258e-01\n",
      "best loss: 991.03\t\tLearning rate: 4.833e-03, Batch size: 42, Momentum: 4.206e-01\n",
      "best loss: 991.86\t\tLearning rate: 4.833e-03, Batch size: 47, Momentum: 4.732e-01\n",
      "best loss: 992.10\t\tLearning rate: 4.833e-03, Batch size: 17, Momentum: 3.681e-01\n",
      "best loss: 995.25\t\tLearning rate: 1.438e-02, Batch size: 19, Momentum: 5.258e-02\n",
      "best loss: 997.38\t\tLearning rate: 1.624e-03, Batch size: 27, Momentum: 7.887e-01\n",
      "best loss: 997.99\t\tLearning rate: 1.438e-02, Batch size: 39, Momentum: 2.629e-01\n",
      "best loss: 998.82\t\tLearning rate: 4.833e-03, Batch size: 14, Momentum: 7.887e-01\n",
      "best loss: 999.44\t\tLearning rate: 1.624e-03, Batch size: 29, Momentum: 7.887e-01\n",
      "best loss: 1000.52\t\tLearning rate: 1.438e-02, Batch size: 19, Momentum: 1.577e-01\n",
      "best loss: 1000.99\t\tLearning rate: 4.833e-03, Batch size: 14, Momentum: 4.732e-01\n",
      "best loss: 1004.31\t\tLearning rate: 1.438e-02, Batch size: 17, Momentum: 2.629e-01\n",
      "best loss: 1008.56\t\tLearning rate: 4.833e-03, Batch size: 2, Momentum: 8.413e-01\n",
      "best loss: 1008.61\t\tLearning rate: 1.624e-03, Batch size: 17, Momentum: 9.990e-01\n",
      "best loss: 1008.90\t\tLearning rate: 1.000e-08, Batch size: 42, Momentum: 5.258e-02\n",
      "best loss: 1013.27\t\tLearning rate: 1.438e-02, Batch size: 44, Momentum: 3.155e-01\n",
      "best loss: 1014.63\t\tLearning rate: 1.000e-08, Batch size: 14, Momentum: 2.629e-01\n",
      "best loss: 1014.78\t\tLearning rate: 1.438e-02, Batch size: 24, Momentum: 2.103e-01\n",
      "best loss: 1015.51\t\tLearning rate: 1.438e-02, Batch size: 37, Momentum: 1.052e-01\n",
      "best loss: 1015.76\t\tLearning rate: 1.438e-02, Batch size: 42, Momentum: 3.155e-01\n",
      "best loss: 1016.19\t\tLearning rate: 1.000e-08, Batch size: 22, Momentum: 4.206e-01\n",
      "best loss: 1018.45\t\tLearning rate: 4.833e-03, Batch size: 9, Momentum: 8.938e-01\n",
      "best loss: 1019.76\t\tLearning rate: 4.281e-02, Batch size: 29, Momentum: 3.681e-01\n",
      "best loss: 1020.27\t\tLearning rate: 1.438e-02, Batch size: 17, Momentum: 3.155e-01\n",
      "best loss: 1021.37\t\tLearning rate: 4.833e-03, Batch size: 12, Momentum: 9.990e-01\n",
      "best loss: 1022.77\t\tLearning rate: 4.833e-03, Batch size: 32, Momentum: 7.887e-01\n",
      "best loss: 1023.71\t\tLearning rate: 4.833e-03, Batch size: 34, Momentum: 6.835e-01\n",
      "best loss: 1024.63\t\tLearning rate: 4.833e-03, Batch size: 4, Momentum: 7.361e-01\n",
      "best loss: 1025.48\t\tLearning rate: 4.281e-02, Batch size: 19, Momentum: 1.052e-01\n",
      "best loss: 1028.20\t\tLearning rate: 1.438e-02, Batch size: 4, Momentum: 2.103e-01\n",
      "best loss: 1029.09\t\tLearning rate: 4.281e-02, Batch size: 29, Momentum: 0.000e+00\n",
      "best loss: 1029.25\t\tLearning rate: 1.438e-02, Batch size: 9, Momentum: 6.835e-01\n",
      "best loss: 1031.18\t\tLearning rate: 1.438e-02, Batch size: 37, Momentum: 6.309e-01\n",
      "best loss: 1031.68\t\tLearning rate: 4.281e-02, Batch size: 44, Momentum: 2.629e-01\n",
      "best loss: 1032.98\t\tLearning rate: 1.438e-02, Batch size: 39, Momentum: 4.206e-01\n",
      "best loss: 1033.70\t\tLearning rate: 4.281e-02, Batch size: 29, Momentum: 6.309e-01\n",
      "best loss: 1037.28\t\tLearning rate: 4.281e-02, Batch size: 44, Momentum: 1.052e-01\n",
      "best loss: 1037.39\t\tLearning rate: 4.833e-03, Batch size: 50, Momentum: 8.938e-01\n",
      "best loss: 1038.10\t\tLearning rate: 4.281e-02, Batch size: 12, Momentum: 6.835e-01\n",
      "best loss: 1040.70\t\tLearning rate: 1.438e-02, Batch size: 24, Momentum: 8.413e-01\n",
      "best loss: 1040.82\t\tLearning rate: 4.281e-02, Batch size: 50, Momentum: 3.681e-01\n",
      "best loss: 1040.93\t\tLearning rate: 1.438e-02, Batch size: 47, Momentum: 9.464e-01\n",
      "best loss: 1041.56\t\tLearning rate: 4.833e-03, Batch size: 4, Momentum: 8.938e-01\n",
      "best loss: 1045.11\t\tLearning rate: 4.281e-02, Batch size: 29, Momentum: 1.577e-01\n",
      "best loss: 1046.97\t\tLearning rate: 1.438e-02, Batch size: 42, Momentum: 7.887e-01\n",
      "best loss: 1047.62\t\tLearning rate: 4.833e-03, Batch size: 39, Momentum: 9.464e-01\n",
      "best loss: 1049.09\t\tLearning rate: 4.833e-03, Batch size: 12, Momentum: 9.464e-01\n",
      "best loss: 1049.24\t\tLearning rate: 4.281e-02, Batch size: 7, Momentum: 3.155e-01\n",
      "best loss: 1051.99\t\tLearning rate: 1.624e-03, Batch size: 27, Momentum: 9.990e-01\n",
      "best loss: 1053.63\t\tLearning rate: 1.438e-02, Batch size: 22, Momentum: 6.835e-01\n",
      "best loss: 1054.35\t\tLearning rate: 1.438e-02, Batch size: 37, Momentum: 6.835e-01\n",
      "best loss: 1056.28\t\tLearning rate: 1.274e-01, Batch size: 32, Momentum: 0.000e+00\n",
      "best loss: 1056.54\t\tLearning rate: 4.281e-02, Batch size: 29, Momentum: 7.887e-01\n",
      "best loss: 1057.23\t\tLearning rate: 4.281e-02, Batch size: 44, Momentum: 5.258e-02\n",
      "best loss: 1059.03\t\tLearning rate: 4.281e-02, Batch size: 22, Momentum: 2.629e-01\n",
      "best loss: 1059.45\t\tLearning rate: 4.281e-02, Batch size: 17, Momentum: 5.258e-01\n",
      "best loss: 1060.66\t\tLearning rate: 1.274e-01, Batch size: 19, Momentum: 1.577e-01\n",
      "best loss: 1062.30\t\tLearning rate: 4.281e-02, Batch size: 24, Momentum: 3.681e-01\n",
      "best loss: 1062.65\t\tLearning rate: 1.438e-02, Batch size: 17, Momentum: 7.361e-01\n",
      "best loss: 1069.59\t\tLearning rate: 4.281e-02, Batch size: 2, Momentum: 7.361e-01\n",
      "best loss: 1072.88\t\tLearning rate: 4.281e-02, Batch size: 22, Momentum: 4.732e-01\n",
      "best loss: 1073.72\t\tLearning rate: 3.793e-01, Batch size: 4, Momentum: 0.000e+00\n",
      "best loss: 1074.47\t\tLearning rate: 4.281e-02, Batch size: 47, Momentum: 2.103e-01\n",
      "best loss: 1077.00\t\tLearning rate: 4.281e-02, Batch size: 50, Momentum: 5.784e-01\n",
      "best loss: 1077.89\t\tLearning rate: 1.438e-02, Batch size: 12, Momentum: 6.835e-01\n",
      "best loss: 1081.15\t\tLearning rate: 1.438e-02, Batch size: 27, Momentum: 7.361e-01\n",
      "best loss: 1081.55\t\tLearning rate: 4.281e-02, Batch size: 32, Momentum: 5.784e-01\n",
      "best loss: 1081.75\t\tLearning rate: 4.281e-02, Batch size: 34, Momentum: 5.784e-01\n",
      "best loss: 1083.38\t\tLearning rate: 1.274e-01, Batch size: 2, Momentum: 4.732e-01\n",
      "best loss: 1084.97\t\tLearning rate: 4.281e-02, Batch size: 12, Momentum: 9.464e-01\n",
      "best loss: 1087.74\t\tLearning rate: 4.281e-02, Batch size: 37, Momentum: 5.784e-01\n",
      "best loss: 1087.75\t\tLearning rate: 1.438e-02, Batch size: 32, Momentum: 8.413e-01\n",
      "best loss: 1087.96\t\tLearning rate: 1.438e-02, Batch size: 34, Momentum: 6.835e-01\n",
      "best loss: 1088.27\t\tLearning rate: 4.281e-02, Batch size: 39, Momentum: 8.413e-01\n",
      "best loss: 1088.53\t\tLearning rate: 4.281e-02, Batch size: 29, Momentum: 2.629e-01\n",
      "best loss: 1089.81\t\tLearning rate: 4.281e-02, Batch size: 14, Momentum: 3.681e-01\n",
      "best loss: 1092.80\t\tLearning rate: 4.281e-02, Batch size: 50, Momentum: 7.361e-01\n",
      "best loss: 1094.42\t\tLearning rate: 4.281e-02, Batch size: 12, Momentum: 5.258e-01\n",
      "best loss: 1094.70\t\tLearning rate: 4.281e-02, Batch size: 4, Momentum: 8.938e-01\n",
      "best loss: 1096.31\t\tLearning rate: 1.274e-01, Batch size: 22, Momentum: 1.577e-01\n",
      "best loss: 1096.76\t\tLearning rate: 1.438e-02, Batch size: 14, Momentum: 8.413e-01\n",
      "best loss: 1100.19\t\tLearning rate: 1.274e-01, Batch size: 42, Momentum: 1.577e-01\n",
      "best loss: 1101.17\t\tLearning rate: 4.281e-02, Batch size: 12, Momentum: 7.361e-01\n",
      "best loss: 1101.63\t\tLearning rate: 1.274e-01, Batch size: 2, Momentum: 5.258e-01\n",
      "best loss: 1103.76\t\tLearning rate: 1.274e-01, Batch size: 14, Momentum: 1.577e-01\n",
      "best loss: 1105.07\t\tLearning rate: 8.859e-08, Batch size: 39, Momentum: 1.577e-01\n",
      "best loss: 1106.92\t\tLearning rate: 1.274e-01, Batch size: 39, Momentum: 2.103e-01\n",
      "best loss: 1108.78\t\tLearning rate: 1.274e-01, Batch size: 2, Momentum: 2.103e-01\n",
      "best loss: 1111.88\t\tLearning rate: 4.281e-02, Batch size: 34, Momentum: 8.938e-01\n",
      "best loss: 1113.88\t\tLearning rate: 1.274e-01, Batch size: 34, Momentum: 3.155e-01\n",
      "best loss: 1113.92\t\tLearning rate: 4.281e-02, Batch size: 9, Momentum: 6.835e-01\n",
      "best loss: 1114.08\t\tLearning rate: 1.274e-01, Batch size: 37, Momentum: 1.577e-01\n",
      "best loss: 1115.17\t\tLearning rate: 4.281e-02, Batch size: 39, Momentum: 7.361e-01\n",
      "best loss: 1115.39\t\tLearning rate: 4.281e-02, Batch size: 42, Momentum: 7.887e-01\n",
      "best loss: 1116.08\t\tLearning rate: 1.274e-01, Batch size: 19, Momentum: 2.103e-01\n",
      "best loss: 1122.59\t\tLearning rate: 1.274e-01, Batch size: 47, Momentum: 5.258e-02\n",
      "best loss: 1129.82\t\tLearning rate: 1.274e-01, Batch size: 17, Momentum: 3.681e-01\n",
      "best loss: 1130.79\t\tLearning rate: 1.274e-01, Batch size: 14, Momentum: 2.103e-01\n",
      "best loss: 1131.95\t\tLearning rate: 1.274e-01, Batch size: 42, Momentum: 4.732e-01\n",
      "best loss: 1135.11\t\tLearning rate: 1.274e-01, Batch size: 32, Momentum: 1.577e-01\n",
      "best loss: 1135.22\t\tLearning rate: 1.274e-01, Batch size: 37, Momentum: 3.155e-01\n",
      "best loss: 1136.21\t\tLearning rate: 1.274e-01, Batch size: 14, Momentum: 5.258e-01\n",
      "best loss: 1138.55\t\tLearning rate: 4.281e-02, Batch size: 42, Momentum: 5.784e-01\n",
      "best loss: 1138.84\t\tLearning rate: 3.793e-01, Batch size: 9, Momentum: 3.681e-01\n",
      "best loss: 1139.90\t\tLearning rate: 4.281e-02, Batch size: 9, Momentum: 8.938e-01\n",
      "best loss: 1140.61\t\tLearning rate: 1.274e-01, Batch size: 19, Momentum: 4.732e-01\n",
      "best loss: 1141.22\t\tLearning rate: 4.281e-02, Batch size: 27, Momentum: 8.938e-01\n",
      "best loss: 1141.42\t\tLearning rate: 1.274e-01, Batch size: 27, Momentum: 6.309e-01\n",
      "best loss: 1144.10\t\tLearning rate: 3.793e-01, Batch size: 50, Momentum: 1.577e-01\n",
      "best loss: 1144.87\t\tLearning rate: 3.793e-01, Batch size: 7, Momentum: 2.629e-01\n",
      "best loss: 1146.54\t\tLearning rate: 4.281e-02, Batch size: 32, Momentum: 9.464e-01\n",
      "best loss: 1146.67\t\tLearning rate: 1.274e-01, Batch size: 17, Momentum: 5.784e-01\n",
      "best loss: 1146.78\t\tLearning rate: 3.793e-01, Batch size: 2, Momentum: 2.629e-01\n",
      "best loss: 1146.91\t\tLearning rate: 1.274e-01, Batch size: 24, Momentum: 4.206e-01\n",
      "best loss: 1150.22\t\tLearning rate: 4.281e-02, Batch size: 2, Momentum: 7.887e-01\n",
      "best loss: 1151.72\t\tLearning rate: 3.793e-01, Batch size: 2, Momentum: 3.681e-01\n",
      "best loss: 1153.22\t\tLearning rate: 3.793e-01, Batch size: 19, Momentum: 2.629e-01\n",
      "best loss: 1155.68\t\tLearning rate: 2.637e-07, Batch size: 47, Momentum: 0.000e+00\n",
      "best loss: 1156.60\t\tLearning rate: 4.281e-02, Batch size: 37, Momentum: 8.413e-01\n",
      "best loss: 1158.71\t\tLearning rate: 1.438e-02, Batch size: 2, Momentum: 9.464e-01\n",
      "best loss: 1164.20\t\tLearning rate: 3.793e-01, Batch size: 50, Momentum: 2.629e-01\n",
      "best loss: 1167.76\t\tLearning rate: 1.274e-01, Batch size: 50, Momentum: 4.206e-01\n",
      "best loss: 1169.29\t\tLearning rate: 3.793e-01, Batch size: 39, Momentum: 2.103e-01\n",
      "best loss: 1170.17\t\tLearning rate: 3.793e-01, Batch size: 2, Momentum: 4.732e-01\n",
      "best loss: 1170.52\t\tLearning rate: 3.793e-01, Batch size: 14, Momentum: 7.887e-01\n",
      "best loss: 1170.86\t\tLearning rate: 1.274e-01, Batch size: 12, Momentum: 7.361e-01\n",
      "best loss: 1174.09\t\tLearning rate: 3.793e-01, Batch size: 29, Momentum: 3.155e-01\n",
      "best loss: 1175.40\t\tLearning rate: 4.281e-02, Batch size: 37, Momentum: 8.938e-01\n",
      "best loss: 1176.95\t\tLearning rate: 3.793e-01, Batch size: 17, Momentum: 2.629e-01\n",
      "best loss: 1177.01\t\tLearning rate: 3.793e-01, Batch size: 27, Momentum: 2.103e-01\n",
      "best loss: 1179.25\t\tLearning rate: 3.793e-01, Batch size: 9, Momentum: 1.577e-01\n",
      "best loss: 1179.50\t\tLearning rate: 3.793e-01, Batch size: 9, Momentum: 2.103e-01\n",
      "best loss: 1179.54\t\tLearning rate: 1.274e-01, Batch size: 34, Momentum: 7.361e-01\n",
      "best loss: 1180.42\t\tLearning rate: 3.793e-01, Batch size: 50, Momentum: 3.681e-01\n",
      "best loss: 1184.25\t\tLearning rate: 1.274e-01, Batch size: 47, Momentum: 5.784e-01\n",
      "best loss: 1184.57\t\tLearning rate: 3.793e-01, Batch size: 7, Momentum: 3.681e-01\n",
      "best loss: 1189.53\t\tLearning rate: 1.129e+00, Batch size: 22, Momentum: 1.052e-01\n",
      "best loss: 1190.17\t\tLearning rate: 1.274e-01, Batch size: 4, Momentum: 8.413e-01\n",
      "best loss: 1191.42\t\tLearning rate: 1.129e+00, Batch size: 44, Momentum: 2.103e-01\n",
      "best loss: 1193.61\t\tLearning rate: 1.274e-01, Batch size: 24, Momentum: 8.413e-01\n",
      "best loss: 1197.10\t\tLearning rate: 3.793e-01, Batch size: 22, Momentum: 6.309e-01\n",
      "best loss: 1199.39\t\tLearning rate: 3.793e-01, Batch size: 7, Momentum: 4.206e-01\n",
      "best loss: 1200.15\t\tLearning rate: 1.274e-01, Batch size: 12, Momentum: 9.464e-01\n",
      "best loss: 1205.06\t\tLearning rate: 3.793e-01, Batch size: 42, Momentum: 2.103e-01\n",
      "best loss: 1205.85\t\tLearning rate: 1.129e+00, Batch size: 4, Momentum: 0.000e+00\n",
      "best loss: 1207.95\t\tLearning rate: 3.793e-01, Batch size: 7, Momentum: 6.835e-01\n",
      "best loss: 1208.00\t\tLearning rate: 1.129e+00, Batch size: 29, Momentum: 5.258e-02\n",
      "best loss: 1209.07\t\tLearning rate: 1.274e-01, Batch size: 22, Momentum: 8.413e-01\n",
      "best loss: 1209.21\t\tLearning rate: 3.793e-01, Batch size: 4, Momentum: 4.732e-01\n",
      "best loss: 1210.29\t\tLearning rate: 1.129e+00, Batch size: 12, Momentum: 2.103e-01\n",
      "best loss: 1211.86\t\tLearning rate: 1.129e+00, Batch size: 4, Momentum: 4.206e-01\n",
      "best loss: 1213.08\t\tLearning rate: 1.129e+00, Batch size: 39, Momentum: 0.000e+00\n",
      "best loss: 1213.47\t\tLearning rate: 1.274e-01, Batch size: 19, Momentum: 9.464e-01\n",
      "best loss: 1213.47\t\tLearning rate: 1.129e+00, Batch size: 9, Momentum: 2.103e-01\n",
      "best loss: 1215.01\t\tLearning rate: 1.274e-01, Batch size: 9, Momentum: 7.887e-01\n",
      "best loss: 1215.12\t\tLearning rate: 3.793e-01, Batch size: 24, Momentum: 5.258e-01\n",
      "best loss: 1215.65\t\tLearning rate: 3.793e-01, Batch size: 34, Momentum: 4.732e-01\n",
      "best loss: 1216.80\t\tLearning rate: 1.129e+00, Batch size: 24, Momentum: 1.577e-01\n",
      "best loss: 1216.89\t\tLearning rate: 1.129e+00, Batch size: 42, Momentum: 1.052e-01\n",
      "best loss: 1223.70\t\tLearning rate: 1.129e+00, Batch size: 42, Momentum: 3.681e-01\n",
      "best loss: 1223.84\t\tLearning rate: 1.274e-01, Batch size: 2, Momentum: 8.938e-01\n",
      "best loss: 1224.02\t\tLearning rate: 1.129e+00, Batch size: 32, Momentum: 5.258e-01\n",
      "best loss: 1225.37\t\tLearning rate: 3.793e-01, Batch size: 9, Momentum: 7.361e-01\n",
      "best loss: 1226.12\t\tLearning rate: 3.793e-01, Batch size: 47, Momentum: 6.309e-01\n",
      "best loss: 1228.72\t\tLearning rate: 1.000e-08, Batch size: 47, Momentum: 1.577e-01\n",
      "best loss: 1229.78\t\tLearning rate: 1.129e+00, Batch size: 9, Momentum: 6.835e-01\n",
      "best loss: 1229.93\t\tLearning rate: 1.129e+00, Batch size: 29, Momentum: 3.155e-01\n",
      "best loss: 1231.67\t\tLearning rate: 1.129e+00, Batch size: 44, Momentum: 3.155e-01\n",
      "best loss: 1231.83\t\tLearning rate: 1.129e+00, Batch size: 24, Momentum: 3.155e-01\n",
      "best loss: 1233.71\t\tLearning rate: 3.793e-01, Batch size: 32, Momentum: 1.052e-01\n",
      "best loss: 1236.26\t\tLearning rate: 3.360e+00, Batch size: 7, Momentum: 1.052e-01\n",
      "best loss: 1236.75\t\tLearning rate: 1.129e+00, Batch size: 34, Momentum: 3.155e-01\n",
      "best loss: 1237.78\t\tLearning rate: 3.360e+00, Batch size: 44, Momentum: 5.258e-02\n",
      "best loss: 1238.09\t\tLearning rate: 1.129e+00, Batch size: 7, Momentum: 3.155e-01\n",
      "best loss: 1239.29\t\tLearning rate: 1.129e+00, Batch size: 7, Momentum: 6.309e-01\n",
      "best loss: 1239.65\t\tLearning rate: 1.129e+00, Batch size: 19, Momentum: 4.206e-01\n",
      "best loss: 1239.96\t\tLearning rate: 1.129e+00, Batch size: 47, Momentum: 4.732e-01\n",
      "best loss: 1241.29\t\tLearning rate: 1.274e-01, Batch size: 19, Momentum: 8.938e-01\n",
      "best loss: 1241.69\t\tLearning rate: 1.274e-01, Batch size: 14, Momentum: 9.990e-01\n",
      "best loss: 1241.79\t\tLearning rate: 1.129e+00, Batch size: 7, Momentum: 4.206e-01\n",
      "best loss: 1243.39\t\tLearning rate: 1.129e+00, Batch size: 47, Momentum: 5.258e-01\n",
      "best loss: 1244.54\t\tLearning rate: 1.129e+00, Batch size: 47, Momentum: 1.577e-01\n",
      "best loss: 1245.43\t\tLearning rate: 3.793e-01, Batch size: 32, Momentum: 8.413e-01\n",
      "best loss: 1245.56\t\tLearning rate: 3.793e-01, Batch size: 29, Momentum: 5.784e-01\n",
      "best loss: 1246.51\t\tLearning rate: 3.360e+00, Batch size: 22, Momentum: 0.000e+00\n",
      "best loss: 1247.27\t\tLearning rate: 1.129e+00, Batch size: 32, Momentum: 4.206e-01\n",
      "best loss: 1248.63\t\tLearning rate: 3.360e+00, Batch size: 19, Momentum: 0.000e+00\n",
      "best loss: 1249.40\t\tLearning rate: 3.793e-01, Batch size: 2, Momentum: 9.464e-01\n",
      "best loss: 1249.68\t\tLearning rate: 3.360e+00, Batch size: 47, Momentum: 5.258e-02\n",
      "best loss: 1250.52\t\tLearning rate: 3.360e+00, Batch size: 12, Momentum: 4.732e-01\n",
      "best loss: 1256.64\t\tLearning rate: 3.360e+00, Batch size: 7, Momentum: 2.629e-01\n",
      "best loss: 1257.27\t\tLearning rate: 3.793e-01, Batch size: 19, Momentum: 9.990e-01\n",
      "best loss: 1260.44\t\tLearning rate: 1.129e+00, Batch size: 17, Momentum: 7.361e-01\n",
      "best loss: 1260.51\t\tLearning rate: 3.360e+00, Batch size: 44, Momentum: 2.629e-01\n",
      "best loss: 1261.08\t\tLearning rate: 1.129e+00, Batch size: 19, Momentum: 4.732e-01\n",
      "best loss: 1261.33\t\tLearning rate: 3.360e+00, Batch size: 4, Momentum: 0.000e+00\n",
      "best loss: 1264.39\t\tLearning rate: 1.129e+00, Batch size: 12, Momentum: 5.258e-01\n",
      "best loss: 1264.55\t\tLearning rate: 3.793e-01, Batch size: 44, Momentum: 8.413e-01\n",
      "best loss: 1265.68\t\tLearning rate: 3.793e-01, Batch size: 9, Momentum: 8.413e-01\n",
      "best loss: 1268.82\t\tLearning rate: 1.129e+00, Batch size: 7, Momentum: 5.258e-01\n",
      "best loss: 1275.44\t\tLearning rate: 3.360e+00, Batch size: 29, Momentum: 5.258e-02\n",
      "best loss: 1278.22\t\tLearning rate: 3.360e+00, Batch size: 32, Momentum: 2.629e-01\n",
      "best loss: 1280.22\t\tLearning rate: 3.360e+00, Batch size: 34, Momentum: 2.103e-01\n",
      "best loss: 1281.65\t\tLearning rate: 3.360e+00, Batch size: 29, Momentum: 3.681e-01\n",
      "best loss: 1282.47\t\tLearning rate: 1.129e+00, Batch size: 34, Momentum: 7.361e-01\n",
      "best loss: 1284.59\t\tLearning rate: 3.793e-01, Batch size: 4, Momentum: 8.938e-01\n",
      "best loss: 1288.46\t\tLearning rate: 3.360e+00, Batch size: 9, Momentum: 4.206e-01\n",
      "best loss: 1289.63\t\tLearning rate: 1.000e+01, Batch size: 37, Momentum: 1.052e-01\n",
      "best loss: 1289.76\t\tLearning rate: 3.360e+00, Batch size: 22, Momentum: 1.577e-01\n",
      "best loss: 1290.22\t\tLearning rate: 1.000e+01, Batch size: 50, Momentum: 5.258e-02\n",
      "best loss: 1291.43\t\tLearning rate: 3.360e+00, Batch size: 22, Momentum: 3.155e-01\n",
      "best loss: 1297.20\t\tLearning rate: 3.360e+00, Batch size: 39, Momentum: 4.732e-01\n",
      "best loss: 1297.42\t\tLearning rate: 1.129e+00, Batch size: 12, Momentum: 7.361e-01\n",
      "best loss: 1297.96\t\tLearning rate: 3.360e+00, Batch size: 27, Momentum: 4.206e-01\n",
      "best loss: 1299.88\t\tLearning rate: 3.360e+00, Batch size: 27, Momentum: 6.309e-01\n",
      "best loss: 1299.92\t\tLearning rate: 1.129e+00, Batch size: 50, Momentum: 6.835e-01\n",
      "best loss: 1300.70\t\tLearning rate: 1.000e+01, Batch size: 19, Momentum: 1.052e-01\n",
      "best loss: 1303.23\t\tLearning rate: 1.000e+01, Batch size: 47, Momentum: 0.000e+00\n",
      "best loss: 1305.53\t\tLearning rate: 1.129e+00, Batch size: 32, Momentum: 9.990e-01\n",
      "best loss: 1305.74\t\tLearning rate: 3.360e+00, Batch size: 29, Momentum: 2.629e-01\n",
      "best loss: 1309.01\t\tLearning rate: 3.360e+00, Batch size: 12, Momentum: 6.835e-01\n",
      "best loss: 1309.29\t\tLearning rate: 3.360e+00, Batch size: 37, Momentum: 3.681e-01\n",
      "best loss: 1311.39\t\tLearning rate: 1.129e+00, Batch size: 22, Momentum: 8.413e-01\n",
      "best loss: 1311.94\t\tLearning rate: 3.360e+00, Batch size: 39, Momentum: 6.309e-01\n",
      "best loss: 1312.37\t\tLearning rate: 1.000e+01, Batch size: 7, Momentum: 2.103e-01\n",
      "best loss: 1313.01\t\tLearning rate: 3.793e-01, Batch size: 39, Momentum: 9.464e-01\n",
      "best loss: 1313.84\t\tLearning rate: 3.360e+00, Batch size: 9, Momentum: 2.629e-01\n",
      "best loss: 1313.88\t\tLearning rate: 3.793e-01, Batch size: 37, Momentum: 9.990e-01\n",
      "best loss: 1315.57\t\tLearning rate: 3.360e+00, Batch size: 47, Momentum: 6.835e-01\n",
      "best loss: 1315.68\t\tLearning rate: 1.000e+01, Batch size: 37, Momentum: 1.577e-01\n",
      "best loss: 1315.78\t\tLearning rate: 3.360e+00, Batch size: 24, Momentum: 4.206e-01\n",
      "best loss: 1325.94\t\tLearning rate: 1.000e+01, Batch size: 39, Momentum: 2.103e-01\n",
      "best loss: 1326.84\t\tLearning rate: 1.000e+01, Batch size: 47, Momentum: 3.681e-01\n",
      "best loss: 1326.88\t\tLearning rate: 3.360e+00, Batch size: 7, Momentum: 6.835e-01\n",
      "best loss: 1328.52\t\tLearning rate: 1.000e+01, Batch size: 39, Momentum: 2.629e-01\n",
      "best loss: 1328.95\t\tLearning rate: 3.360e+00, Batch size: 44, Momentum: 5.784e-01\n",
      "best loss: 1329.99\t\tLearning rate: 3.360e+00, Batch size: 27, Momentum: 5.258e-01\n",
      "best loss: 1330.54\t\tLearning rate: 1.000e+01, Batch size: 37, Momentum: 4.206e-01\n",
      "best loss: 1331.09\t\tLearning rate: 3.360e+00, Batch size: 22, Momentum: 7.361e-01\n",
      "best loss: 1332.62\t\tLearning rate: 3.360e+00, Batch size: 29, Momentum: 6.835e-01\n",
      "best loss: 1337.00\t\tLearning rate: 1.129e+00, Batch size: 22, Momentum: 9.464e-01\n",
      "best loss: 1339.10\t\tLearning rate: 3.360e+00, Batch size: 2, Momentum: 4.206e-01\n",
      "best loss: 1340.87\t\tLearning rate: 3.360e+00, Batch size: 19, Momentum: 8.413e-01\n",
      "best loss: 1341.84\t\tLearning rate: 1.000e+01, Batch size: 12, Momentum: 1.577e-01\n",
      "best loss: 1341.96\t\tLearning rate: 3.360e+00, Batch size: 12, Momentum: 7.361e-01\n",
      "best loss: 1343.65\t\tLearning rate: 1.129e+00, Batch size: 24, Momentum: 8.413e-01\n",
      "best loss: 1344.13\t\tLearning rate: 1.129e+00, Batch size: 47, Momentum: 8.938e-01\n",
      "best loss: 1344.39\t\tLearning rate: 1.000e+01, Batch size: 4, Momentum: 3.681e-01\n",
      "best loss: 1345.80\t\tLearning rate: 3.360e+00, Batch size: 34, Momentum: 9.990e-01\n",
      "best loss: 1346.89\t\tLearning rate: 1.000e+01, Batch size: 34, Momentum: 3.681e-01\n",
      "best loss: 1347.31\t\tLearning rate: 1.000e+01, Batch size: 32, Momentum: 3.155e-01\n",
      "best loss: 1349.07\t\tLearning rate: 3.360e+00, Batch size: 37, Momentum: 6.309e-01\n",
      "best loss: 1349.67\t\tLearning rate: 3.360e+00, Batch size: 32, Momentum: 6.309e-01\n",
      "best loss: 1351.17\t\tLearning rate: 1.000e-08, Batch size: 24, Momentum: 3.681e-01\n",
      "best loss: 1356.80\t\tLearning rate: 1.000e+01, Batch size: 2, Momentum: 4.732e-01\n",
      "best loss: 1356.82\t\tLearning rate: 3.360e+00, Batch size: 44, Momentum: 8.938e-01\n",
      "best loss: 1357.00\t\tLearning rate: 3.360e+00, Batch size: 2, Momentum: 9.990e-01\n",
      "best loss: 1357.11\t\tLearning rate: 3.360e+00, Batch size: 50, Momentum: 6.309e-01\n",
      "best loss: 1357.69\t\tLearning rate: 3.360e+00, Batch size: 50, Momentum: 7.887e-01\n",
      "best loss: 1358.34\t\tLearning rate: 1.129e+00, Batch size: 24, Momentum: 9.990e-01\n",
      "best loss: 1361.13\t\tLearning rate: 1.000e+01, Batch size: 44, Momentum: 4.732e-01\n",
      "best loss: 1364.07\t\tLearning rate: 1.000e+01, Batch size: 19, Momentum: 2.103e-01\n",
      "best loss: 1364.23\t\tLearning rate: 1.000e+01, Batch size: 32, Momentum: 5.258e-01\n",
      "best loss: 1365.45\t\tLearning rate: 1.000e+01, Batch size: 47, Momentum: 2.629e-01\n",
      "best loss: 1368.29\t\tLearning rate: 1.000e+01, Batch size: 4, Momentum: 5.784e-01\n",
      "best loss: 1369.51\t\tLearning rate: 3.360e+00, Batch size: 29, Momentum: 9.464e-01\n",
      "best loss: 1369.79\t\tLearning rate: 1.129e+00, Batch size: 29, Momentum: 9.990e-01\n",
      "best loss: 1370.08\t\tLearning rate: 3.360e+00, Batch size: 17, Momentum: 7.887e-01\n",
      "best loss: 1374.99\t\tLearning rate: 1.000e+01, Batch size: 39, Momentum: 5.784e-01\n",
      "best loss: 1376.86\t\tLearning rate: 1.000e+01, Batch size: 50, Momentum: 5.784e-01\n",
      "best loss: 1379.49\t\tLearning rate: 1.000e+01, Batch size: 37, Momentum: 4.732e-01\n",
      "best loss: 1379.95\t\tLearning rate: 1.000e+01, Batch size: 42, Momentum: 4.206e-01\n",
      "best loss: 1380.20\t\tLearning rate: 3.360e+00, Batch size: 14, Momentum: 7.887e-01\n",
      "best loss: 1386.31\t\tLearning rate: 1.000e+01, Batch size: 44, Momentum: 6.309e-01\n",
      "best loss: 1394.69\t\tLearning rate: 1.000e+01, Batch size: 39, Momentum: 6.309e-01\n",
      "best loss: 1395.45\t\tLearning rate: 1.000e+01, Batch size: 29, Momentum: 6.309e-01\n",
      "best loss: 1400.13\t\tLearning rate: 3.360e+00, Batch size: 22, Momentum: 8.413e-01\n",
      "best loss: 1403.64\t\tLearning rate: 1.000e+01, Batch size: 29, Momentum: 8.413e-01\n",
      "best loss: 1405.02\t\tLearning rate: 3.360e+00, Batch size: 14, Momentum: 9.464e-01\n",
      "best loss: 1406.89\t\tLearning rate: 1.000e+01, Batch size: 14, Momentum: 3.155e-01\n",
      "best loss: 1409.59\t\tLearning rate: 3.360e+00, Batch size: 44, Momentum: 9.990e-01\n",
      "best loss: 1410.58\t\tLearning rate: 3.360e+00, Batch size: 22, Momentum: 9.990e-01\n",
      "best loss: 1416.20\t\tLearning rate: 1.000e+01, Batch size: 27, Momentum: 7.887e-01\n",
      "best loss: 1416.33\t\tLearning rate: 1.000e+01, Batch size: 12, Momentum: 8.413e-01\n",
      "best loss: 1422.02\t\tLearning rate: 8.859e-08, Batch size: 4, Momentum: 1.577e-01\n",
      "best loss: 1426.83\t\tLearning rate: 1.000e+01, Batch size: 44, Momentum: 8.938e-01\n",
      "best loss: 1432.37\t\tLearning rate: 1.000e+01, Batch size: 37, Momentum: 8.938e-01\n",
      "best loss: 1447.27\t\tLearning rate: 1.000e+01, Batch size: 24, Momentum: 9.464e-01\n",
      "best loss: 1460.12\t\tLearning rate: 1.000e+01, Batch size: 2, Momentum: 8.938e-01\n",
      "best loss: 1595.63\t\tLearning rate: 1.000e-08, Batch size: 50, Momentum: 5.258e-01\n",
      "best loss: 1638.48\t\tLearning rate: 2.976e-08, Batch size: 42, Momentum: 1.052e-01\n",
      "best loss: 1685.15\t\tLearning rate: 2.069e-05, Batch size: 39, Momentum: 5.258e-01\n",
      "best loss: 2828.88\t\tLearning rate: 2.637e-07, Batch size: 27, Momentum: 5.258e-02\n",
      "best loss: 3399.05\t\tLearning rate: 1.000e-08, Batch size: 39, Momentum: 1.577e-01\n",
      "best loss: 3681.10\t\tLearning rate: 1.000e-08, Batch size: 29, Momentum: 1.052e-01\n",
      "best loss: 4382.84\t\tLearning rate: 1.129e+00, Batch size: 4, Momentum: 2.103e-01\n",
      "best loss: 6211.74\t\tLearning rate: 8.859e-08, Batch size: 4, Momentum: 5.258e-02\n",
      "best loss: 12938.69\t\tLearning rate: 2.976e-08, Batch size: 4, Momentum: 3.155e-01\n",
      "best loss: 15457.30\t\tLearning rate: 2.976e-08, Batch size: 4, Momentum: 5.258e-01\n",
      "best loss: 18872.60\t\tLearning rate: 2.637e-07, Batch size: 7, Momentum: 3.155e-01\n",
      "best loss: 22153.52\t\tLearning rate: 7.848e-07, Batch size: 9, Momentum: 5.258e-01\n",
      "best loss: 26470.69\t\tLearning rate: 2.976e-08, Batch size: 22, Momentum: 4.732e-01\n",
      "best loss: 29604.84\t\tLearning rate: 7.848e-07, Batch size: 50, Momentum: 3.681e-01\n",
      "best loss: 30181.32\t\tLearning rate: 2.637e-07, Batch size: 22, Momentum: 5.784e-01\n",
      "best loss: 30941.47\t\tLearning rate: 1.000e+01, Batch size: 7, Momentum: 2.629e-01\n",
      "best loss: 31332.00\t\tLearning rate: 6.158e-05, Batch size: 22, Momentum: 0.000e+00\n",
      "best loss: 31560.00\t\tLearning rate: 8.859e-08, Batch size: 42, Momentum: 7.361e-01\n",
      "best loss: 32615.09\t\tLearning rate: 1.000e-08, Batch size: 17, Momentum: 5.258e-02\n",
      "best loss: 33895.40\t\tLearning rate: 8.859e-08, Batch size: 47, Momentum: 2.629e-01\n",
      "best loss: 38392.33\t\tLearning rate: 1.000e-08, Batch size: 50, Momentum: 7.361e-01\n",
      "best loss: 38697.91\t\tLearning rate: 1.000e-08, Batch size: 24, Momentum: 1.052e-01\n",
      "best loss: 39160.87\t\tLearning rate: 3.793e-01, Batch size: 34, Momentum: 0.000e+00\n",
      "best loss: 50351.91\t\tLearning rate: 1.000e-08, Batch size: 47, Momentum: 0.000e+00\n",
      "best loss: 50564.41\t\tLearning rate: 1.000e-08, Batch size: 39, Momentum: 3.155e-01\n",
      "best loss: 53325.47\t\tLearning rate: 2.637e-07, Batch size: 32, Momentum: 2.629e-01\n",
      "best loss: 54165.33\t\tLearning rate: 8.859e-08, Batch size: 14, Momentum: 1.577e-01\n",
      "best loss: 55033.64\t\tLearning rate: 2.976e-08, Batch size: 22, Momentum: 7.361e-01\n",
      "best loss: 55038.09\t\tLearning rate: 8.859e-08, Batch size: 24, Momentum: 4.732e-01\n",
      "best loss: 56757.34\t\tLearning rate: 1.833e-04, Batch size: 37, Momentum: 1.052e-01\n",
      "best loss: 58681.16\t\tLearning rate: 1.000e-08, Batch size: 17, Momentum: 1.577e-01\n",
      "best loss: 60186.27\t\tLearning rate: 1.000e-08, Batch size: 44, Momentum: 8.413e-01\n",
      "best loss: 61214.26\t\tLearning rate: 8.859e-08, Batch size: 24, Momentum: 2.629e-01\n",
      "best loss: 61612.37\t\tLearning rate: 1.000e-08, Batch size: 29, Momentum: 0.000e+00\n",
      "best loss: 63074.09\t\tLearning rate: 2.976e-08, Batch size: 39, Momentum: 1.577e-01\n",
      "best loss: 68995.53\t\tLearning rate: 1.000e-08, Batch size: 19, Momentum: 4.206e-01\n",
      "best loss: 71069.01\t\tLearning rate: 1.000e-08, Batch size: 50, Momentum: 8.413e-01\n",
      "best loss: 71962.97\t\tLearning rate: 2.976e-08, Batch size: 19, Momentum: 2.103e-01\n",
      "best loss: 74946.08\t\tLearning rate: 2.637e-07, Batch size: 39, Momentum: 1.577e-01\n",
      "best loss: 75031.16\t\tLearning rate: 2.637e-07, Batch size: 32, Momentum: 6.309e-01\n",
      "best loss: 78979.63\t\tLearning rate: 1.000e-08, Batch size: 37, Momentum: 7.361e-01\n",
      "best loss: 85056.45\t\tLearning rate: 8.859e-08, Batch size: 44, Momentum: 6.309e-01\n",
      "best loss: 87656.31\t\tLearning rate: 1.000e-08, Batch size: 37, Momentum: 3.681e-01\n",
      "best loss: 88337.08\t\tLearning rate: 2.637e-07, Batch size: 32, Momentum: 4.732e-01\n",
      "best loss: 89566.20\t\tLearning rate: 1.000e+01, Batch size: 22, Momentum: 0.000e+00\n",
      "best loss: 89583.66\t\tLearning rate: 1.000e-08, Batch size: 37, Momentum: 2.629e-01\n",
      "best loss: 91511.20\t\tLearning rate: 8.859e-08, Batch size: 24, Momentum: 3.155e-01\n",
      "best loss: 92753.86\t\tLearning rate: 1.000e+01, Batch size: 14, Momentum: 2.103e-01\n",
      "best loss: 92994.19\t\tLearning rate: 1.000e-08, Batch size: 27, Momentum: 5.258e-01\n",
      "best loss: 95197.97\t\tLearning rate: 2.976e-08, Batch size: 32, Momentum: 0.000e+00\n",
      "best loss: 104526.56\t\tLearning rate: 8.859e-08, Batch size: 47, Momentum: 7.361e-01\n",
      "best loss: 104582.81\t\tLearning rate: 1.000e-08, Batch size: 42, Momentum: 2.103e-01\n",
      "best loss: 104996.37\t\tLearning rate: 1.000e-08, Batch size: 2, Momentum: 2.629e-01\n",
      "best loss: 108135.68\t\tLearning rate: 4.833e-03, Batch size: 37, Momentum: 2.103e-01\n",
      "best loss: 117959.71\t\tLearning rate: 1.000e-08, Batch size: 24, Momentum: 3.155e-01\n",
      "best loss: 122982.33\t\tLearning rate: 1.833e-04, Batch size: 29, Momentum: 1.052e-01\n",
      "best loss: 129780.39\t\tLearning rate: 4.833e-03, Batch size: 34, Momentum: 1.052e-01\n",
      "best loss: 150883.87\t\tLearning rate: 2.637e-07, Batch size: 42, Momentum: 5.258e-02\n",
      "best loss: 157669.67\t\tLearning rate: 1.000e-08, Batch size: 19, Momentum: 5.258e-01\n",
      "best loss: 160255.71\t\tLearning rate: 2.637e-07, Batch size: 14, Momentum: 1.052e-01\n",
      "best loss: 161389.66\t\tLearning rate: 2.336e-06, Batch size: 34, Momentum: 4.732e-01\n",
      "best loss: 162376.57\t\tLearning rate: 2.976e-08, Batch size: 22, Momentum: 6.309e-01\n",
      "best loss: 181934.00\t\tLearning rate: 5.456e-04, Batch size: 50, Momentum: 5.258e-02\n",
      "best loss: 201592.60\t\tLearning rate: 2.637e-07, Batch size: 24, Momentum: 2.629e-01\n",
      "best loss: 214387.48\t\tLearning rate: 2.976e-08, Batch size: 39, Momentum: 5.258e-02\n",
      "best loss: 258346.63\t\tLearning rate: 1.274e-01, Batch size: 17, Momentum: 0.000e+00\n",
      "best loss: 315889.03\t\tLearning rate: 2.976e-08, Batch size: 42, Momentum: 1.577e-01\n",
      "best loss: 371561.95\t\tLearning rate: 4.833e-03, Batch size: 37, Momentum: 5.258e-02\n",
      "best loss: 417769.41\t\tLearning rate: 4.833e-03, Batch size: 50, Momentum: 0.000e+00\n",
      "best loss: 497298.57\t\tLearning rate: 5.456e-04, Batch size: 17, Momentum: 0.000e+00\n",
      "best loss: 731292.35\t\tLearning rate: 4.833e-03, Batch size: 27, Momentum: 2.629e-01\n",
      "best loss: 816671.59\t\tLearning rate: 1.438e-02, Batch size: 19, Momentum: 0.000e+00\n",
      "best loss: 838912.13\t\tLearning rate: 1.624e-03, Batch size: 44, Momentum: 1.052e-01\n",
      "best loss: 871169.13\t\tLearning rate: 3.793e-01, Batch size: 50, Momentum: 0.000e+00\n",
      "best loss: 10508472.68\t\tLearning rate: 3.793e-01, Batch size: 9, Momentum: 5.258e-02\n"
     ]
    }
   ],
   "source": [
    "# print the hyperparameters ranked from best to worst\n",
    "sorted_results = sorted(results.items(), key=lambda x: x[1])\n",
    "for hp, loss in sorted_results:\n",
    "    print(f\"best loss: {loss:.2f}\\t\\tLearning rate: {hp[0]:.3e}, Batch size: {hp[1]}, Momentum: {hp[2]:.3e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phenotypes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
