{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solve for Gaussian approximations using optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening BSCCM\n",
      "Opened BSCCM\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# this only works on startup!\n",
    "from jax import config\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '2'\n",
    "from gpu_utils import limit_gpu_memory_growth\n",
    "limit_gpu_memory_growth()\n",
    "\n",
    "from cleanplots import *\n",
    "from tqdm import tqdm\n",
    "from information_estimation import *\n",
    "from image_utils import *\n",
    "from gaussian_process_utils import *\n",
    "\n",
    "from led_array.bsccm_utils import *\n",
    "from bsccm import BSCCM\n",
    "from jax import jit\n",
    "import numpy as onp\n",
    "import jax.numpy as np\n",
    "\n",
    "bsccm = BSCCM('/home/hpinkard_waller/data/BSCCM/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images, extract patches, and compute cov mats\n",
    "edge_crop = 32\n",
    "patch_size = 10\n",
    "num_images = 20000\n",
    "num_patches = 1000\n",
    "channel = 'DPC_Right'\n",
    "eigenvalue_floor = 1e0\n",
    "\n",
    "images = load_bsccm_images(bsccm, channel=channel, num_images=num_images, edge_crop=edge_crop, median_filter=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search through hyperparameter combos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss:  2442558.3000391778\n"
     ]
    }
   ],
   "source": [
    "learning_rates = np.logspace(1, -8, 20)\n",
    "batch_sizes = np.linspace(2, 50, 20).astype(int)\n",
    "momentums = np.linspace(0, 0.999, 20)\n",
    "\n",
    "# generate tuples of random hyperparameters\n",
    "hyperparameter_tuples = []\n",
    "for i in range(10000):\n",
    "    lr = onp.random.choice(learning_rates)\n",
    "    bs = onp.random.choice(batch_sizes)\n",
    "    m = onp.random.choice(momentums)\n",
    "    hyperparameter_tuples.append((lr, bs, m))\n",
    "\n",
    "results = {}\n",
    "for i, (learning_rate, batch_size, momentum) in enumerate(hyperparameter_tuples):\n",
    "    best_hp_loss = np.inf\n",
    "\n",
    "    patches = extract_patches(images, patch_size, num_patches=num_patches, seed=i)\n",
    "    best_cov_mat, cov_mat_initial, mean_vec, best_loss = run_optimization(patches, momentum, learning_rate, batch_size, eigenvalue_floor=1e-3)\n",
    "\n",
    "    if best_loss < best_hp_loss:\n",
    "        best_hp_loss = best_loss\n",
    "        best_hp = (learning_rate, batch_size, momentum)\n",
    "        \n",
    "    # collect results\n",
    "    results[(learning_rate, batch_size, momentum)] = best_loss\n",
    "\n",
    "    # print hyperparameters and their best loss\n",
    "    print(f\"best loss: {best_loss:.2f}\\t\\tLearning rate: {learning_rate:.3e}, Batch size: {batch_size}, Momentum: {momentum:.3e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best loss: 469.85\t\tLearning rate: 8.859e-08, Batch size: 2, Momentum: 7.361e-01\n",
      "best loss: 474.07\t\tLearning rate: 2.336e-06, Batch size: 2, Momentum: 2.103e-01\n",
      "best loss: 474.78\t\tLearning rate: 7.848e-07, Batch size: 2, Momentum: 7.361e-01\n",
      "best loss: 475.45\t\tLearning rate: 7.848e-07, Batch size: 2, Momentum: 2.629e-01\n",
      "best loss: 476.66\t\tLearning rate: 2.637e-07, Batch size: 4, Momentum: 1.577e-01\n",
      "best loss: 476.98\t\tLearning rate: 2.336e-06, Batch size: 4, Momentum: 4.206e-01\n",
      "best loss: 478.56\t\tLearning rate: 7.848e-07, Batch size: 4, Momentum: 6.309e-01\n",
      "best loss: 479.31\t\tLearning rate: 4.281e-02, Batch size: 4, Momentum: 8.938e-01\n",
      "best loss: 479.35\t\tLearning rate: 2.637e-07, Batch size: 4, Momentum: 4.206e-01\n",
      "best loss: 479.43\t\tLearning rate: 6.158e-05, Batch size: 2, Momentum: 3.155e-01\n",
      "best loss: 479.46\t\tLearning rate: 7.848e-07, Batch size: 4, Momentum: 6.835e-01\n",
      "best loss: 479.51\t\tLearning rate: 6.952e-06, Batch size: 2, Momentum: 5.258e-01\n",
      "best loss: 479.73\t\tLearning rate: 6.952e-06, Batch size: 2, Momentum: 5.258e-02\n",
      "best loss: 479.83\t\tLearning rate: 2.336e-06, Batch size: 4, Momentum: 5.784e-01\n",
      "best loss: 480.32\t\tLearning rate: 2.976e-08, Batch size: 2, Momentum: 6.309e-01\n",
      "best loss: 481.66\t\tLearning rate: 2.637e-07, Batch size: 7, Momentum: 9.464e-01\n",
      "best loss: 481.86\t\tLearning rate: 2.336e-06, Batch size: 2, Momentum: 1.577e-01\n",
      "best loss: 482.61\t\tLearning rate: 2.637e-07, Batch size: 4, Momentum: 5.784e-01\n",
      "best loss: 482.99\t\tLearning rate: 2.336e-06, Batch size: 7, Momentum: 7.361e-01\n",
      "best loss: 484.13\t\tLearning rate: 8.859e-08, Batch size: 2, Momentum: 3.155e-01\n",
      "best loss: 484.51\t\tLearning rate: 2.637e-07, Batch size: 14, Momentum: 9.990e-01\n",
      "best loss: 484.52\t\tLearning rate: 7.848e-07, Batch size: 12, Momentum: 2.629e-01\n",
      "best loss: 484.71\t\tLearning rate: 2.637e-07, Batch size: 9, Momentum: 8.938e-01\n",
      "best loss: 484.99\t\tLearning rate: 2.336e-06, Batch size: 9, Momentum: 1.052e-01\n",
      "best loss: 484.99\t\tLearning rate: 1.000e+01, Batch size: 22, Momentum: 3.681e-01\n",
      "best loss: 485.23\t\tLearning rate: 2.336e-06, Batch size: 9, Momentum: 2.629e-01\n",
      "best loss: 485.47\t\tLearning rate: 3.360e+00, Batch size: 9, Momentum: 9.990e-01\n",
      "best loss: 485.73\t\tLearning rate: 7.848e-07, Batch size: 9, Momentum: 2.629e-01\n",
      "best loss: 485.94\t\tLearning rate: 6.158e-05, Batch size: 7, Momentum: 0.000e+00\n",
      "best loss: 486.18\t\tLearning rate: 6.952e-06, Batch size: 12, Momentum: 4.732e-01\n",
      "best loss: 486.19\t\tLearning rate: 7.848e-07, Batch size: 7, Momentum: 6.835e-01\n",
      "best loss: 486.20\t\tLearning rate: 2.637e-07, Batch size: 27, Momentum: 5.258e-02\n",
      "best loss: 486.66\t\tLearning rate: 3.793e-01, Batch size: 22, Momentum: 7.887e-01\n",
      "best loss: 486.91\t\tLearning rate: 1.129e+00, Batch size: 9, Momentum: 2.629e-01\n",
      "best loss: 486.94\t\tLearning rate: 7.848e-07, Batch size: 17, Momentum: 6.835e-01\n",
      "best loss: 487.06\t\tLearning rate: 7.848e-07, Batch size: 2, Momentum: 7.887e-01\n",
      "best loss: 487.25\t\tLearning rate: 8.859e-08, Batch size: 14, Momentum: 9.990e-01\n",
      "best loss: 487.29\t\tLearning rate: 6.952e-06, Batch size: 22, Momentum: 2.103e-01\n",
      "best loss: 487.40\t\tLearning rate: 7.848e-07, Batch size: 27, Momentum: 5.784e-01\n",
      "best loss: 487.49\t\tLearning rate: 3.360e+00, Batch size: 9, Momentum: 8.938e-01\n",
      "best loss: 487.52\t\tLearning rate: 3.360e+00, Batch size: 37, Momentum: 3.155e-01\n",
      "best loss: 487.69\t\tLearning rate: 6.158e-05, Batch size: 7, Momentum: 4.206e-01\n",
      "best loss: 487.84\t\tLearning rate: 1.129e+00, Batch size: 29, Momentum: 9.464e-01\n",
      "best loss: 487.85\t\tLearning rate: 4.833e-03, Batch size: 14, Momentum: 6.309e-01\n",
      "best loss: 488.03\t\tLearning rate: 1.438e-02, Batch size: 27, Momentum: 2.103e-01\n",
      "best loss: 488.08\t\tLearning rate: 6.158e-05, Batch size: 34, Momentum: 2.629e-01\n",
      "best loss: 488.31\t\tLearning rate: 2.336e-06, Batch size: 14, Momentum: 4.732e-01\n",
      "best loss: 488.32\t\tLearning rate: 7.848e-07, Batch size: 19, Momentum: 6.309e-01\n",
      "best loss: 488.59\t\tLearning rate: 2.336e-06, Batch size: 14, Momentum: 3.681e-01\n",
      "best loss: 488.61\t\tLearning rate: 7.848e-07, Batch size: 22, Momentum: 5.784e-01\n",
      "best loss: 488.71\t\tLearning rate: 2.336e-06, Batch size: 22, Momentum: 4.206e-01\n",
      "best loss: 488.75\t\tLearning rate: 6.952e-06, Batch size: 19, Momentum: 2.629e-01\n",
      "best loss: 488.77\t\tLearning rate: 2.336e-06, Batch size: 12, Momentum: 4.206e-01\n",
      "best loss: 488.85\t\tLearning rate: 7.848e-07, Batch size: 29, Momentum: 9.464e-01\n",
      "best loss: 488.87\t\tLearning rate: 7.848e-07, Batch size: 12, Momentum: 9.464e-01\n",
      "best loss: 488.88\t\tLearning rate: 5.456e-04, Batch size: 42, Momentum: 3.155e-01\n",
      "best loss: 488.97\t\tLearning rate: 2.336e-06, Batch size: 22, Momentum: 3.681e-01\n",
      "best loss: 489.06\t\tLearning rate: 3.793e-01, Batch size: 14, Momentum: 2.629e-01\n",
      "best loss: 489.06\t\tLearning rate: 6.158e-05, Batch size: 27, Momentum: 2.629e-01\n",
      "best loss: 489.07\t\tLearning rate: 5.456e-04, Batch size: 32, Momentum: 5.258e-02\n",
      "best loss: 489.13\t\tLearning rate: 7.848e-07, Batch size: 17, Momentum: 7.887e-01\n",
      "best loss: 489.17\t\tLearning rate: 2.637e-07, Batch size: 24, Momentum: 9.464e-01\n",
      "best loss: 489.18\t\tLearning rate: 1.274e-01, Batch size: 12, Momentum: 0.000e+00\n",
      "best loss: 489.23\t\tLearning rate: 2.336e-06, Batch size: 9, Momentum: 6.835e-01\n",
      "best loss: 489.26\t\tLearning rate: 7.848e-07, Batch size: 12, Momentum: 1.577e-01\n",
      "best loss: 489.40\t\tLearning rate: 7.848e-07, Batch size: 22, Momentum: 7.887e-01\n",
      "best loss: 489.43\t\tLearning rate: 7.848e-07, Batch size: 34, Momentum: 6.835e-01\n",
      "best loss: 489.50\t\tLearning rate: 2.637e-07, Batch size: 32, Momentum: 6.835e-01\n",
      "best loss: 489.52\t\tLearning rate: 6.952e-06, Batch size: 14, Momentum: 4.732e-01\n",
      "best loss: 489.53\t\tLearning rate: 6.952e-06, Batch size: 17, Momentum: 2.629e-01\n",
      "best loss: 489.56\t\tLearning rate: 6.158e-05, Batch size: 32, Momentum: 5.258e-01\n",
      "best loss: 489.56\t\tLearning rate: 2.336e-06, Batch size: 22, Momentum: 6.835e-01\n",
      "best loss: 489.72\t\tLearning rate: 7.848e-07, Batch size: 14, Momentum: 8.413e-01\n",
      "best loss: 489.73\t\tLearning rate: 5.456e-04, Batch size: 32, Momentum: 7.361e-01\n",
      "best loss: 489.87\t\tLearning rate: 6.952e-06, Batch size: 27, Momentum: 0.000e+00\n",
      "best loss: 489.87\t\tLearning rate: 4.281e-02, Batch size: 19, Momentum: 7.887e-01\n",
      "best loss: 489.89\t\tLearning rate: 2.637e-07, Batch size: 24, Momentum: 0.000e+00\n",
      "best loss: 489.90\t\tLearning rate: 1.000e+01, Batch size: 34, Momentum: 8.413e-01\n",
      "best loss: 489.90\t\tLearning rate: 4.833e-03, Batch size: 29, Momentum: 3.155e-01\n",
      "best loss: 489.99\t\tLearning rate: 1.000e-08, Batch size: 19, Momentum: 9.990e-01\n",
      "best loss: 490.03\t\tLearning rate: 4.833e-03, Batch size: 32, Momentum: 6.309e-01\n",
      "best loss: 490.08\t\tLearning rate: 2.976e-08, Batch size: 22, Momentum: 9.990e-01\n",
      "best loss: 490.21\t\tLearning rate: 1.000e-08, Batch size: 27, Momentum: 4.206e-01\n",
      "best loss: 490.41\t\tLearning rate: 7.848e-07, Batch size: 42, Momentum: 6.835e-01\n",
      "best loss: 490.61\t\tLearning rate: 6.158e-05, Batch size: 32, Momentum: 2.103e-01\n",
      "best loss: 490.65\t\tLearning rate: 6.952e-06, Batch size: 42, Momentum: 4.206e-01\n",
      "best loss: 490.92\t\tLearning rate: 2.336e-06, Batch size: 19, Momentum: 5.784e-01\n",
      "best loss: 490.99\t\tLearning rate: 2.976e-08, Batch size: 7, Momentum: 7.361e-01\n",
      "best loss: 491.00\t\tLearning rate: 2.637e-07, Batch size: 47, Momentum: 9.990e-01\n",
      "best loss: 491.07\t\tLearning rate: 2.336e-06, Batch size: 22, Momentum: 2.103e-01\n",
      "best loss: 491.09\t\tLearning rate: 6.158e-05, Batch size: 27, Momentum: 4.206e-01\n",
      "best loss: 491.19\t\tLearning rate: 1.274e-01, Batch size: 32, Momentum: 1.577e-01\n",
      "best loss: 491.19\t\tLearning rate: 6.952e-06, Batch size: 24, Momentum: 3.681e-01\n",
      "best loss: 491.20\t\tLearning rate: 2.336e-06, Batch size: 24, Momentum: 7.361e-01\n",
      "best loss: 491.21\t\tLearning rate: 1.000e+01, Batch size: 47, Momentum: 9.464e-01\n",
      "best loss: 491.21\t\tLearning rate: 2.336e-06, Batch size: 44, Momentum: 7.361e-01\n",
      "best loss: 491.21\t\tLearning rate: 2.336e-06, Batch size: 7, Momentum: 9.464e-01\n",
      "best loss: 491.23\t\tLearning rate: 7.848e-07, Batch size: 19, Momentum: 5.258e-01\n",
      "best loss: 491.32\t\tLearning rate: 1.000e-08, Batch size: 19, Momentum: 0.000e+00\n",
      "best loss: 491.35\t\tLearning rate: 1.624e-03, Batch size: 27, Momentum: 8.413e-01\n",
      "best loss: 491.36\t\tLearning rate: 2.336e-06, Batch size: 19, Momentum: 2.629e-01\n",
      "best loss: 491.44\t\tLearning rate: 7.848e-07, Batch size: 12, Momentum: 6.835e-01\n",
      "best loss: 491.44\t\tLearning rate: 5.456e-04, Batch size: 27, Momentum: 5.784e-01\n",
      "best loss: 491.45\t\tLearning rate: 8.859e-08, Batch size: 14, Momentum: 7.887e-01\n",
      "best loss: 491.61\t\tLearning rate: 2.336e-06, Batch size: 50, Momentum: 5.784e-01\n",
      "best loss: 491.79\t\tLearning rate: 7.848e-07, Batch size: 44, Momentum: 1.577e-01\n",
      "best loss: 491.82\t\tLearning rate: 1.274e-01, Batch size: 47, Momentum: 3.155e-01\n",
      "best loss: 491.82\t\tLearning rate: 1.000e-08, Batch size: 44, Momentum: 9.990e-01\n",
      "best loss: 491.85\t\tLearning rate: 2.976e-08, Batch size: 37, Momentum: 1.052e-01\n",
      "best loss: 491.94\t\tLearning rate: 7.848e-07, Batch size: 50, Momentum: 4.732e-01\n",
      "best loss: 492.03\t\tLearning rate: 2.336e-06, Batch size: 12, Momentum: 1.577e-01\n",
      "best loss: 492.06\t\tLearning rate: 2.336e-06, Batch size: 32, Momentum: 4.732e-01\n",
      "best loss: 492.15\t\tLearning rate: 7.848e-07, Batch size: 44, Momentum: 5.258e-02\n",
      "best loss: 492.16\t\tLearning rate: 2.336e-06, Batch size: 44, Momentum: 3.155e-01\n",
      "best loss: 492.17\t\tLearning rate: 2.637e-07, Batch size: 29, Momentum: 9.990e-01\n",
      "best loss: 492.19\t\tLearning rate: 2.336e-06, Batch size: 9, Momentum: 6.309e-01\n",
      "best loss: 492.19\t\tLearning rate: 2.336e-06, Batch size: 17, Momentum: 2.103e-01\n",
      "best loss: 492.32\t\tLearning rate: 5.456e-04, Batch size: 39, Momentum: 5.258e-02\n",
      "best loss: 492.33\t\tLearning rate: 2.336e-06, Batch size: 39, Momentum: 1.577e-01\n",
      "best loss: 492.34\t\tLearning rate: 7.848e-07, Batch size: 4, Momentum: 0.000e+00\n",
      "best loss: 492.48\t\tLearning rate: 7.848e-07, Batch size: 7, Momentum: 5.258e-02\n",
      "best loss: 492.61\t\tLearning rate: 7.848e-07, Batch size: 29, Momentum: 6.309e-01\n",
      "best loss: 492.63\t\tLearning rate: 7.848e-07, Batch size: 32, Momentum: 5.258e-01\n",
      "best loss: 492.67\t\tLearning rate: 8.859e-08, Batch size: 2, Momentum: 6.309e-01\n",
      "best loss: 492.71\t\tLearning rate: 7.848e-07, Batch size: 14, Momentum: 1.052e-01\n",
      "best loss: 492.74\t\tLearning rate: 2.336e-06, Batch size: 42, Momentum: 7.887e-01\n",
      "best loss: 492.76\t\tLearning rate: 7.848e-07, Batch size: 34, Momentum: 5.258e-01\n",
      "best loss: 492.84\t\tLearning rate: 7.848e-07, Batch size: 39, Momentum: 7.887e-01\n",
      "best loss: 492.88\t\tLearning rate: 3.360e+00, Batch size: 24, Momentum: 8.413e-01\n",
      "best loss: 492.89\t\tLearning rate: 7.848e-07, Batch size: 9, Momentum: 6.835e-01\n",
      "best loss: 492.92\t\tLearning rate: 2.637e-07, Batch size: 37, Momentum: 9.464e-01\n",
      "best loss: 492.92\t\tLearning rate: 1.274e-01, Batch size: 12, Momentum: 4.732e-01\n",
      "best loss: 493.03\t\tLearning rate: 2.336e-06, Batch size: 39, Momentum: 8.413e-01\n",
      "best loss: 493.09\t\tLearning rate: 5.456e-04, Batch size: 44, Momentum: 1.577e-01\n",
      "best loss: 493.10\t\tLearning rate: 6.952e-06, Batch size: 47, Momentum: 5.258e-01\n",
      "best loss: 493.26\t\tLearning rate: 2.069e-05, Batch size: 19, Momentum: 1.577e-01\n",
      "best loss: 493.27\t\tLearning rate: 2.637e-07, Batch size: 17, Momentum: 9.990e-01\n",
      "best loss: 493.31\t\tLearning rate: 2.336e-06, Batch size: 14, Momentum: 0.000e+00\n",
      "best loss: 493.47\t\tLearning rate: 1.000e-08, Batch size: 12, Momentum: 9.464e-01\n",
      "best loss: 493.47\t\tLearning rate: 2.336e-06, Batch size: 27, Momentum: 2.629e-01\n",
      "best loss: 493.48\t\tLearning rate: 2.637e-07, Batch size: 22, Momentum: 9.464e-01\n",
      "best loss: 493.61\t\tLearning rate: 2.336e-06, Batch size: 47, Momentum: 3.155e-01\n",
      "best loss: 493.61\t\tLearning rate: 2.976e-08, Batch size: 29, Momentum: 9.990e-01\n",
      "best loss: 493.66\t\tLearning rate: 7.848e-07, Batch size: 34, Momentum: 7.361e-01\n",
      "best loss: 493.72\t\tLearning rate: 6.952e-06, Batch size: 44, Momentum: 1.052e-01\n",
      "best loss: 493.72\t\tLearning rate: 7.848e-07, Batch size: 50, Momentum: 8.413e-01\n",
      "best loss: 493.82\t\tLearning rate: 4.833e-03, Batch size: 19, Momentum: 1.052e-01\n",
      "best loss: 493.87\t\tLearning rate: 7.848e-07, Batch size: 12, Momentum: 5.784e-01\n",
      "best loss: 493.94\t\tLearning rate: 6.952e-06, Batch size: 22, Momentum: 3.681e-01\n",
      "best loss: 494.05\t\tLearning rate: 2.637e-07, Batch size: 29, Momentum: 6.309e-01\n",
      "best loss: 494.15\t\tLearning rate: 2.336e-06, Batch size: 27, Momentum: 4.732e-01\n",
      "best loss: 494.23\t\tLearning rate: 2.637e-07, Batch size: 24, Momentum: 5.258e-01\n",
      "best loss: 494.39\t\tLearning rate: 2.336e-06, Batch size: 32, Momentum: 5.258e-02\n",
      "best loss: 494.40\t\tLearning rate: 2.336e-06, Batch size: 17, Momentum: 7.887e-01\n",
      "best loss: 494.43\t\tLearning rate: 7.848e-07, Batch size: 37, Momentum: 8.938e-01\n",
      "best loss: 494.44\t\tLearning rate: 2.336e-06, Batch size: 29, Momentum: 5.258e-01\n",
      "best loss: 494.45\t\tLearning rate: 2.336e-06, Batch size: 34, Momentum: 5.258e-01\n",
      "best loss: 494.61\t\tLearning rate: 1.000e-08, Batch size: 7, Momentum: 8.413e-01\n",
      "best loss: 494.66\t\tLearning rate: 6.952e-06, Batch size: 24, Momentum: 5.784e-01\n",
      "best loss: 494.71\t\tLearning rate: 2.637e-07, Batch size: 32, Momentum: 6.309e-01\n",
      "best loss: 494.87\t\tLearning rate: 1.000e-08, Batch size: 2, Momentum: 6.835e-01\n",
      "best loss: 494.96\t\tLearning rate: 6.952e-06, Batch size: 50, Momentum: 2.629e-01\n",
      "best loss: 495.02\t\tLearning rate: 6.952e-06, Batch size: 44, Momentum: 7.361e-01\n",
      "best loss: 495.16\t\tLearning rate: 7.848e-07, Batch size: 50, Momentum: 9.464e-01\n",
      "best loss: 495.18\t\tLearning rate: 7.848e-07, Batch size: 42, Momentum: 2.629e-01\n",
      "best loss: 495.19\t\tLearning rate: 6.952e-06, Batch size: 42, Momentum: 2.629e-01\n",
      "best loss: 495.19\t\tLearning rate: 2.976e-08, Batch size: 27, Momentum: 8.938e-01\n",
      "best loss: 495.31\t\tLearning rate: 2.976e-08, Batch size: 9, Momentum: 7.361e-01\n",
      "best loss: 495.39\t\tLearning rate: 7.848e-07, Batch size: 50, Momentum: 4.206e-01\n",
      "best loss: 495.50\t\tLearning rate: 2.336e-06, Batch size: 39, Momentum: 3.681e-01\n",
      "best loss: 495.53\t\tLearning rate: 2.637e-07, Batch size: 12, Momentum: 1.577e-01\n",
      "best loss: 495.78\t\tLearning rate: 2.637e-07, Batch size: 39, Momentum: 9.990e-01\n",
      "best loss: 495.92\t\tLearning rate: 7.848e-07, Batch size: 37, Momentum: 5.784e-01\n",
      "best loss: 495.93\t\tLearning rate: 2.336e-06, Batch size: 29, Momentum: 1.577e-01\n",
      "best loss: 496.06\t\tLearning rate: 2.637e-07, Batch size: 22, Momentum: 3.155e-01\n",
      "best loss: 496.14\t\tLearning rate: 2.637e-07, Batch size: 42, Momentum: 6.835e-01\n",
      "best loss: 496.31\t\tLearning rate: 2.336e-06, Batch size: 17, Momentum: 8.938e-01\n",
      "best loss: 496.66\t\tLearning rate: 7.848e-07, Batch size: 22, Momentum: 9.990e-01\n",
      "best loss: 496.67\t\tLearning rate: 2.637e-07, Batch size: 37, Momentum: 9.990e-01\n",
      "best loss: 496.68\t\tLearning rate: 6.952e-06, Batch size: 37, Momentum: 9.464e-01\n",
      "best loss: 496.71\t\tLearning rate: 6.952e-06, Batch size: 12, Momentum: 5.784e-01\n",
      "best loss: 497.04\t\tLearning rate: 2.976e-08, Batch size: 44, Momentum: 9.464e-01\n",
      "best loss: 497.15\t\tLearning rate: 2.976e-08, Batch size: 7, Momentum: 8.413e-01\n",
      "best loss: 497.36\t\tLearning rate: 2.637e-07, Batch size: 47, Momentum: 8.938e-01\n",
      "best loss: 497.74\t\tLearning rate: 2.336e-06, Batch size: 37, Momentum: 6.835e-01\n",
      "best loss: 498.01\t\tLearning rate: 7.848e-07, Batch size: 34, Momentum: 8.938e-01\n",
      "best loss: 498.02\t\tLearning rate: 6.952e-06, Batch size: 24, Momentum: 7.887e-01\n",
      "best loss: 498.03\t\tLearning rate: 6.952e-06, Batch size: 44, Momentum: 5.258e-02\n",
      "best loss: 498.36\t\tLearning rate: 2.336e-06, Batch size: 22, Momentum: 6.309e-01\n",
      "best loss: 498.36\t\tLearning rate: 2.069e-05, Batch size: 24, Momentum: 9.464e-01\n",
      "best loss: 498.45\t\tLearning rate: 2.336e-06, Batch size: 12, Momentum: 2.629e-01\n",
      "best loss: 498.46\t\tLearning rate: 6.952e-06, Batch size: 12, Momentum: 9.464e-01\n",
      "best loss: 498.51\t\tLearning rate: 6.952e-06, Batch size: 47, Momentum: 5.258e-02\n",
      "best loss: 498.63\t\tLearning rate: 6.952e-06, Batch size: 34, Momentum: 5.784e-01\n",
      "best loss: 498.84\t\tLearning rate: 8.859e-08, Batch size: 44, Momentum: 7.361e-01\n",
      "best loss: 498.86\t\tLearning rate: 8.859e-08, Batch size: 37, Momentum: 9.990e-01\n",
      "best loss: 498.97\t\tLearning rate: 2.336e-06, Batch size: 24, Momentum: 3.681e-01\n",
      "best loss: 499.02\t\tLearning rate: 6.952e-06, Batch size: 27, Momentum: 2.629e-01\n",
      "best loss: 499.04\t\tLearning rate: 7.848e-07, Batch size: 50, Momentum: 8.938e-01\n",
      "best loss: 499.17\t\tLearning rate: 2.336e-06, Batch size: 32, Momentum: 8.413e-01\n",
      "best loss: 499.31\t\tLearning rate: 2.336e-06, Batch size: 7, Momentum: 5.258e-02\n",
      "best loss: 499.39\t\tLearning rate: 7.848e-07, Batch size: 42, Momentum: 5.258e-01\n",
      "best loss: 499.42\t\tLearning rate: 8.859e-08, Batch size: 14, Momentum: 5.784e-01\n",
      "best loss: 499.66\t\tLearning rate: 2.336e-06, Batch size: 37, Momentum: 5.258e-02\n",
      "best loss: 499.67\t\tLearning rate: 2.069e-05, Batch size: 9, Momentum: 8.938e-01\n",
      "best loss: 499.68\t\tLearning rate: 2.976e-08, Batch size: 12, Momentum: 8.938e-01\n",
      "best loss: 499.78\t\tLearning rate: 7.848e-07, Batch size: 19, Momentum: 3.155e-01\n",
      "best loss: 499.86\t\tLearning rate: 8.859e-08, Batch size: 19, Momentum: 6.309e-01\n",
      "best loss: 499.96\t\tLearning rate: 8.859e-08, Batch size: 42, Momentum: 9.990e-01\n",
      "best loss: 500.08\t\tLearning rate: 8.859e-08, Batch size: 29, Momentum: 9.464e-01\n",
      "best loss: 500.20\t\tLearning rate: 2.637e-07, Batch size: 39, Momentum: 4.732e-01\n",
      "best loss: 500.36\t\tLearning rate: 2.637e-07, Batch size: 9, Momentum: 7.361e-01\n",
      "best loss: 500.36\t\tLearning rate: 2.637e-07, Batch size: 50, Momentum: 5.784e-01\n",
      "best loss: 500.45\t\tLearning rate: 6.952e-06, Batch size: 37, Momentum: 8.413e-01\n",
      "best loss: 500.48\t\tLearning rate: 7.848e-07, Batch size: 42, Momentum: 1.052e-01\n",
      "best loss: 500.79\t\tLearning rate: 6.952e-06, Batch size: 32, Momentum: 2.629e-01\n",
      "best loss: 500.89\t\tLearning rate: 7.848e-07, Batch size: 37, Momentum: 4.206e-01\n",
      "best loss: 501.09\t\tLearning rate: 6.952e-06, Batch size: 14, Momentum: 8.413e-01\n",
      "best loss: 501.28\t\tLearning rate: 2.336e-06, Batch size: 29, Momentum: 2.629e-01\n",
      "best loss: 501.53\t\tLearning rate: 3.793e-01, Batch size: 29, Momentum: 2.103e-01\n",
      "best loss: 501.98\t\tLearning rate: 6.952e-06, Batch size: 14, Momentum: 5.784e-01\n",
      "best loss: 502.15\t\tLearning rate: 2.637e-07, Batch size: 17, Momentum: 9.464e-01\n",
      "best loss: 502.41\t\tLearning rate: 7.848e-07, Batch size: 39, Momentum: 5.258e-02\n",
      "best loss: 502.47\t\tLearning rate: 7.848e-07, Batch size: 32, Momentum: 6.835e-01\n",
      "best loss: 502.62\t\tLearning rate: 2.336e-06, Batch size: 24, Momentum: 8.413e-01\n",
      "best loss: 502.66\t\tLearning rate: 2.637e-07, Batch size: 37, Momentum: 5.258e-01\n",
      "best loss: 503.67\t\tLearning rate: 2.336e-06, Batch size: 4, Momentum: 9.990e-01\n",
      "best loss: 503.73\t\tLearning rate: 7.848e-07, Batch size: 9, Momentum: 2.103e-01\n",
      "best loss: 503.84\t\tLearning rate: 6.952e-06, Batch size: 29, Momentum: 4.732e-01\n",
      "best loss: 503.88\t\tLearning rate: 1.000e-08, Batch size: 42, Momentum: 4.206e-01\n",
      "best loss: 503.89\t\tLearning rate: 2.336e-06, Batch size: 47, Momentum: 1.577e-01\n",
      "best loss: 504.23\t\tLearning rate: 2.336e-06, Batch size: 29, Momentum: 6.309e-01\n",
      "best loss: 504.50\t\tLearning rate: 2.637e-07, Batch size: 37, Momentum: 3.681e-01\n",
      "best loss: 504.50\t\tLearning rate: 8.859e-08, Batch size: 12, Momentum: 4.732e-01\n",
      "best loss: 505.01\t\tLearning rate: 6.952e-06, Batch size: 47, Momentum: 8.413e-01\n",
      "best loss: 505.26\t\tLearning rate: 7.848e-07, Batch size: 22, Momentum: 3.155e-01\n",
      "best loss: 505.54\t\tLearning rate: 2.336e-06, Batch size: 39, Momentum: 1.052e-01\n",
      "best loss: 505.74\t\tLearning rate: 7.848e-07, Batch size: 44, Momentum: 4.732e-01\n",
      "best loss: 505.74\t\tLearning rate: 2.637e-07, Batch size: 22, Momentum: 6.309e-01\n",
      "best loss: 505.88\t\tLearning rate: 6.952e-06, Batch size: 24, Momentum: 5.258e-02\n",
      "best loss: 506.28\t\tLearning rate: 6.952e-06, Batch size: 34, Momentum: 0.000e+00\n",
      "best loss: 506.84\t\tLearning rate: 1.000e-08, Batch size: 47, Momentum: 8.413e-01\n",
      "best loss: 506.85\t\tLearning rate: 7.848e-07, Batch size: 24, Momentum: 8.413e-01\n",
      "best loss: 507.28\t\tLearning rate: 7.848e-07, Batch size: 24, Momentum: 5.784e-01\n",
      "best loss: 507.39\t\tLearning rate: 8.859e-08, Batch size: 7, Momentum: 3.155e-01\n",
      "best loss: 507.85\t\tLearning rate: 6.952e-06, Batch size: 50, Momentum: 0.000e+00\n",
      "best loss: 508.04\t\tLearning rate: 7.848e-07, Batch size: 9, Momentum: 3.681e-01\n",
      "best loss: 508.50\t\tLearning rate: 8.859e-08, Batch size: 12, Momentum: 7.361e-01\n",
      "best loss: 508.75\t\tLearning rate: 2.336e-06, Batch size: 22, Momentum: 0.000e+00\n",
      "best loss: 508.82\t\tLearning rate: 2.976e-08, Batch size: 24, Momentum: 8.413e-01\n",
      "best loss: 510.06\t\tLearning rate: 1.000e-08, Batch size: 24, Momentum: 9.464e-01\n",
      "best loss: 510.34\t\tLearning rate: 2.637e-07, Batch size: 12, Momentum: 2.629e-01\n",
      "best loss: 510.35\t\tLearning rate: 6.952e-06, Batch size: 42, Momentum: 9.464e-01\n",
      "best loss: 510.66\t\tLearning rate: 2.336e-06, Batch size: 12, Momentum: 8.938e-01\n",
      "best loss: 510.68\t\tLearning rate: 6.952e-06, Batch size: 29, Momentum: 8.938e-01\n",
      "best loss: 512.03\t\tLearning rate: 2.637e-07, Batch size: 39, Momentum: 7.361e-01\n",
      "best loss: 512.43\t\tLearning rate: 2.336e-06, Batch size: 34, Momentum: 9.990e-01\n",
      "best loss: 513.02\t\tLearning rate: 2.637e-07, Batch size: 47, Momentum: 7.887e-01\n",
      "best loss: 513.45\t\tLearning rate: 6.952e-06, Batch size: 29, Momentum: 7.887e-01\n",
      "best loss: 513.84\t\tLearning rate: 7.848e-07, Batch size: 39, Momentum: 2.629e-01\n",
      "best loss: 514.09\t\tLearning rate: 8.859e-08, Batch size: 42, Momentum: 7.361e-01\n",
      "best loss: 514.37\t\tLearning rate: 7.848e-07, Batch size: 27, Momentum: 1.577e-01\n",
      "best loss: 514.45\t\tLearning rate: 8.859e-08, Batch size: 12, Momentum: 4.206e-01\n",
      "best loss: 514.70\t\tLearning rate: 1.000e-08, Batch size: 12, Momentum: 8.413e-01\n",
      "best loss: 514.94\t\tLearning rate: 1.000e-08, Batch size: 50, Momentum: 8.413e-01\n",
      "best loss: 515.29\t\tLearning rate: 8.859e-08, Batch size: 34, Momentum: 7.361e-01\n",
      "best loss: 515.30\t\tLearning rate: 2.637e-07, Batch size: 39, Momentum: 3.681e-01\n",
      "best loss: 515.51\t\tLearning rate: 7.848e-07, Batch size: 50, Momentum: 2.629e-01\n",
      "best loss: 515.52\t\tLearning rate: 6.952e-06, Batch size: 29, Momentum: 1.052e-01\n",
      "best loss: 515.82\t\tLearning rate: 2.976e-08, Batch size: 34, Momentum: 9.990e-01\n",
      "best loss: 516.23\t\tLearning rate: 6.952e-06, Batch size: 39, Momentum: 6.835e-01\n",
      "best loss: 516.70\t\tLearning rate: 2.069e-05, Batch size: 4, Momentum: 2.629e-01\n",
      "best loss: 517.37\t\tLearning rate: 2.976e-08, Batch size: 7, Momentum: 2.629e-01\n",
      "best loss: 517.64\t\tLearning rate: 2.336e-06, Batch size: 29, Momentum: 0.000e+00\n",
      "best loss: 520.52\t\tLearning rate: 7.848e-07, Batch size: 9, Momentum: 3.155e-01\n",
      "best loss: 522.34\t\tLearning rate: 2.637e-07, Batch size: 22, Momentum: 5.258e-02\n",
      "best loss: 523.15\t\tLearning rate: 8.859e-08, Batch size: 24, Momentum: 6.835e-01\n",
      "best loss: 523.22\t\tLearning rate: 6.952e-06, Batch size: 12, Momentum: 8.938e-01\n",
      "best loss: 524.79\t\tLearning rate: 2.976e-08, Batch size: 34, Momentum: 6.309e-01\n",
      "best loss: 524.93\t\tLearning rate: 2.637e-07, Batch size: 37, Momentum: 6.835e-01\n",
      "best loss: 525.81\t\tLearning rate: 6.952e-06, Batch size: 19, Momentum: 6.309e-01\n",
      "best loss: 528.67\t\tLearning rate: 7.848e-07, Batch size: 47, Momentum: 5.258e-02\n",
      "best loss: 529.28\t\tLearning rate: 2.336e-06, Batch size: 14, Momentum: 2.629e-01\n",
      "best loss: 529.42\t\tLearning rate: 2.637e-07, Batch size: 39, Momentum: 3.155e-01\n",
      "best loss: 530.04\t\tLearning rate: 8.859e-08, Batch size: 7, Momentum: 1.052e-01\n",
      "best loss: 531.00\t\tLearning rate: 6.952e-06, Batch size: 17, Momentum: 5.784e-01\n",
      "best loss: 531.43\t\tLearning rate: 2.637e-07, Batch size: 44, Momentum: 8.413e-01\n",
      "best loss: 531.53\t\tLearning rate: 8.859e-08, Batch size: 12, Momentum: 5.784e-01\n",
      "best loss: 531.66\t\tLearning rate: 2.976e-08, Batch size: 44, Momentum: 3.155e-01\n",
      "best loss: 531.75\t\tLearning rate: 8.859e-08, Batch size: 34, Momentum: 5.258e-01\n",
      "best loss: 532.89\t\tLearning rate: 2.637e-07, Batch size: 42, Momentum: 3.155e-01\n",
      "best loss: 533.81\t\tLearning rate: 2.637e-07, Batch size: 19, Momentum: 3.155e-01\n",
      "best loss: 534.41\t\tLearning rate: 7.848e-07, Batch size: 47, Momentum: 2.103e-01\n",
      "best loss: 535.75\t\tLearning rate: 8.859e-08, Batch size: 37, Momentum: 5.784e-01\n",
      "best loss: 536.98\t\tLearning rate: 2.336e-06, Batch size: 27, Momentum: 1.577e-01\n",
      "best loss: 537.22\t\tLearning rate: 2.336e-06, Batch size: 34, Momentum: 3.155e-01\n",
      "best loss: 539.07\t\tLearning rate: 2.976e-08, Batch size: 7, Momentum: 5.258e-01\n",
      "best loss: 540.12\t\tLearning rate: 2.976e-08, Batch size: 19, Momentum: 3.681e-01\n",
      "best loss: 540.91\t\tLearning rate: 6.952e-06, Batch size: 12, Momentum: 6.309e-01\n",
      "best loss: 541.30\t\tLearning rate: 7.848e-07, Batch size: 34, Momentum: 0.000e+00\n",
      "best loss: 542.12\t\tLearning rate: 2.637e-07, Batch size: 44, Momentum: 5.784e-01\n",
      "best loss: 542.78\t\tLearning rate: 2.976e-08, Batch size: 47, Momentum: 6.835e-01\n",
      "best loss: 543.08\t\tLearning rate: 2.637e-07, Batch size: 24, Momentum: 2.629e-01\n",
      "best loss: 543.19\t\tLearning rate: 2.069e-05, Batch size: 14, Momentum: 5.258e-02\n",
      "best loss: 543.36\t\tLearning rate: 2.637e-07, Batch size: 17, Momentum: 5.258e-01\n",
      "best loss: 545.13\t\tLearning rate: 2.976e-08, Batch size: 42, Momentum: 7.361e-01\n",
      "best loss: 545.54\t\tLearning rate: 2.637e-07, Batch size: 17, Momentum: 0.000e+00\n",
      "best loss: 545.94\t\tLearning rate: 1.000e-08, Batch size: 7, Momentum: 5.784e-01\n",
      "best loss: 546.16\t\tLearning rate: 8.859e-08, Batch size: 14, Momentum: 2.103e-01\n",
      "best loss: 546.80\t\tLearning rate: 8.859e-08, Batch size: 47, Momentum: 3.681e-01\n",
      "best loss: 547.74\t\tLearning rate: 8.859e-08, Batch size: 19, Momentum: 5.258e-02\n",
      "best loss: 548.83\t\tLearning rate: 6.952e-06, Batch size: 4, Momentum: 8.938e-01\n",
      "best loss: 549.67\t\tLearning rate: 2.336e-06, Batch size: 19, Momentum: 9.990e-01\n",
      "best loss: 549.78\t\tLearning rate: 2.069e-05, Batch size: 42, Momentum: 5.258e-02\n",
      "best loss: 550.95\t\tLearning rate: 2.637e-07, Batch size: 9, Momentum: 0.000e+00\n",
      "best loss: 551.23\t\tLearning rate: 2.976e-08, Batch size: 4, Momentum: 0.000e+00\n",
      "best loss: 552.30\t\tLearning rate: 2.976e-08, Batch size: 32, Momentum: 6.835e-01\n",
      "best loss: 553.37\t\tLearning rate: 1.000e-08, Batch size: 17, Momentum: 7.887e-01\n",
      "best loss: 553.72\t\tLearning rate: 8.859e-08, Batch size: 22, Momentum: 2.629e-01\n",
      "best loss: 557.07\t\tLearning rate: 6.952e-06, Batch size: 4, Momentum: 6.835e-01\n",
      "best loss: 557.49\t\tLearning rate: 2.637e-07, Batch size: 29, Momentum: 2.629e-01\n",
      "best loss: 558.31\t\tLearning rate: 2.976e-08, Batch size: 47, Momentum: 5.784e-01\n",
      "best loss: 562.44\t\tLearning rate: 8.859e-08, Batch size: 9, Momentum: 4.206e-01\n",
      "best loss: 564.98\t\tLearning rate: 6.952e-06, Batch size: 17, Momentum: 7.887e-01\n",
      "best loss: 565.96\t\tLearning rate: 2.069e-05, Batch size: 12, Momentum: 3.155e-01\n",
      "best loss: 567.87\t\tLearning rate: 2.976e-08, Batch size: 9, Momentum: 5.258e-01\n",
      "best loss: 570.64\t\tLearning rate: 8.859e-08, Batch size: 39, Momentum: 1.577e-01\n",
      "best loss: 573.94\t\tLearning rate: 2.069e-05, Batch size: 17, Momentum: 5.258e-02\n",
      "best loss: 574.11\t\tLearning rate: 2.069e-05, Batch size: 7, Momentum: 2.629e-01\n",
      "best loss: 578.74\t\tLearning rate: 7.848e-07, Batch size: 37, Momentum: 1.577e-01\n",
      "best loss: 579.06\t\tLearning rate: 2.976e-08, Batch size: 22, Momentum: 6.309e-01\n",
      "best loss: 582.57\t\tLearning rate: 2.976e-08, Batch size: 14, Momentum: 0.000e+00\n",
      "best loss: 583.01\t\tLearning rate: 6.952e-06, Batch size: 29, Momentum: 8.413e-01\n",
      "best loss: 584.34\t\tLearning rate: 2.336e-06, Batch size: 24, Momentum: 2.103e-01\n",
      "best loss: 584.61\t\tLearning rate: 6.952e-06, Batch size: 17, Momentum: 8.413e-01\n",
      "best loss: 585.34\t\tLearning rate: 1.000e-08, Batch size: 12, Momentum: 6.835e-01\n",
      "best loss: 586.49\t\tLearning rate: 2.069e-05, Batch size: 34, Momentum: 0.000e+00\n",
      "best loss: 587.87\t\tLearning rate: 1.000e-08, Batch size: 14, Momentum: 7.361e-01\n",
      "best loss: 587.92\t\tLearning rate: 2.069e-05, Batch size: 50, Momentum: 0.000e+00\n",
      "best loss: 587.93\t\tLearning rate: 1.000e-08, Batch size: 22, Momentum: 4.206e-01\n",
      "best loss: 593.64\t\tLearning rate: 2.069e-05, Batch size: 32, Momentum: 5.784e-01\n",
      "best loss: 594.98\t\tLearning rate: 1.000e-08, Batch size: 12, Momentum: 4.206e-01\n",
      "best loss: 595.75\t\tLearning rate: 8.859e-08, Batch size: 9, Momentum: 1.577e-01\n",
      "best loss: 597.60\t\tLearning rate: 2.069e-05, Batch size: 9, Momentum: 7.361e-01\n",
      "best loss: 597.92\t\tLearning rate: 2.637e-07, Batch size: 17, Momentum: 5.258e-02\n",
      "best loss: 598.02\t\tLearning rate: 1.000e-08, Batch size: 50, Momentum: 6.835e-01\n",
      "best loss: 598.58\t\tLearning rate: 2.976e-08, Batch size: 24, Momentum: 7.361e-01\n",
      "best loss: 601.98\t\tLearning rate: 6.952e-06, Batch size: 24, Momentum: 8.938e-01\n",
      "best loss: 606.98\t\tLearning rate: 1.000e-08, Batch size: 14, Momentum: 4.732e-01\n",
      "best loss: 608.22\t\tLearning rate: 7.848e-07, Batch size: 44, Momentum: 2.103e-01\n",
      "best loss: 608.62\t\tLearning rate: 2.637e-07, Batch size: 39, Momentum: 0.000e+00\n",
      "best loss: 609.61\t\tLearning rate: 2.069e-05, Batch size: 37, Momentum: 5.258e-01\n",
      "best loss: 609.64\t\tLearning rate: 2.637e-07, Batch size: 37, Momentum: 2.103e-01\n",
      "best loss: 609.94\t\tLearning rate: 2.069e-05, Batch size: 22, Momentum: 2.103e-01\n",
      "best loss: 610.93\t\tLearning rate: 2.069e-05, Batch size: 29, Momentum: 4.206e-01\n",
      "best loss: 611.58\t\tLearning rate: 2.069e-05, Batch size: 2, Momentum: 3.155e-01\n",
      "best loss: 614.59\t\tLearning rate: 2.069e-05, Batch size: 17, Momentum: 7.361e-01\n",
      "best loss: 615.37\t\tLearning rate: 2.069e-05, Batch size: 22, Momentum: 0.000e+00\n",
      "best loss: 615.80\t\tLearning rate: 2.976e-08, Batch size: 32, Momentum: 5.784e-01\n",
      "best loss: 616.23\t\tLearning rate: 2.069e-05, Batch size: 19, Momentum: 5.784e-01\n",
      "best loss: 617.07\t\tLearning rate: 2.069e-05, Batch size: 4, Momentum: 2.103e-01\n",
      "best loss: 617.28\t\tLearning rate: 2.069e-05, Batch size: 27, Momentum: 5.784e-01\n",
      "best loss: 618.19\t\tLearning rate: 2.069e-05, Batch size: 24, Momentum: 5.784e-01\n",
      "best loss: 619.70\t\tLearning rate: 2.069e-05, Batch size: 47, Momentum: 5.258e-01\n",
      "best loss: 620.84\t\tLearning rate: 6.158e-05, Batch size: 2, Momentum: 0.000e+00\n",
      "best loss: 624.73\t\tLearning rate: 6.952e-06, Batch size: 42, Momentum: 7.887e-01\n",
      "best loss: 628.55\t\tLearning rate: 6.952e-06, Batch size: 42, Momentum: 9.990e-01\n",
      "best loss: 635.07\t\tLearning rate: 6.158e-05, Batch size: 19, Momentum: 4.732e-01\n",
      "best loss: 635.69\t\tLearning rate: 2.069e-05, Batch size: 22, Momentum: 5.258e-01\n",
      "best loss: 636.21\t\tLearning rate: 8.859e-08, Batch size: 32, Momentum: 1.052e-01\n",
      "best loss: 636.45\t\tLearning rate: 2.069e-05, Batch size: 19, Momentum: 4.206e-01\n",
      "best loss: 639.64\t\tLearning rate: 8.859e-08, Batch size: 9, Momentum: 0.000e+00\n",
      "best loss: 641.76\t\tLearning rate: 2.069e-05, Batch size: 14, Momentum: 7.361e-01\n",
      "best loss: 642.21\t\tLearning rate: 1.000e-08, Batch size: 22, Momentum: 6.309e-01\n",
      "best loss: 642.76\t\tLearning rate: 2.069e-05, Batch size: 7, Momentum: 7.887e-01\n",
      "best loss: 642.97\t\tLearning rate: 2.069e-05, Batch size: 44, Momentum: 5.784e-01\n",
      "best loss: 644.94\t\tLearning rate: 6.952e-06, Batch size: 17, Momentum: 9.464e-01\n",
      "best loss: 647.04\t\tLearning rate: 6.158e-05, Batch size: 27, Momentum: 1.577e-01\n",
      "best loss: 647.95\t\tLearning rate: 2.069e-05, Batch size: 7, Momentum: 5.258e-01\n",
      "best loss: 650.19\t\tLearning rate: 2.069e-05, Batch size: 32, Momentum: 6.835e-01\n",
      "best loss: 650.63\t\tLearning rate: 6.158e-05, Batch size: 4, Momentum: 4.206e-01\n",
      "best loss: 651.28\t\tLearning rate: 6.158e-05, Batch size: 9, Momentum: 0.000e+00\n",
      "best loss: 653.16\t\tLearning rate: 6.952e-06, Batch size: 7, Momentum: 9.990e-01\n",
      "best loss: 654.15\t\tLearning rate: 2.069e-05, Batch size: 47, Momentum: 4.732e-01\n",
      "best loss: 659.16\t\tLearning rate: 6.158e-05, Batch size: 37, Momentum: 1.052e-01\n",
      "best loss: 659.83\t\tLearning rate: 1.000e-08, Batch size: 9, Momentum: 4.206e-01\n",
      "best loss: 661.33\t\tLearning rate: 6.158e-05, Batch size: 29, Momentum: 1.577e-01\n",
      "best loss: 661.83\t\tLearning rate: 2.069e-05, Batch size: 37, Momentum: 7.887e-01\n",
      "best loss: 662.00\t\tLearning rate: 2.069e-05, Batch size: 7, Momentum: 8.413e-01\n",
      "best loss: 662.15\t\tLearning rate: 2.069e-05, Batch size: 42, Momentum: 3.155e-01\n",
      "best loss: 662.51\t\tLearning rate: 2.069e-05, Batch size: 42, Momentum: 7.887e-01\n",
      "best loss: 662.76\t\tLearning rate: 2.069e-05, Batch size: 14, Momentum: 2.629e-01\n",
      "best loss: 663.62\t\tLearning rate: 2.976e-08, Batch size: 22, Momentum: 3.155e-01\n",
      "best loss: 663.93\t\tLearning rate: 6.158e-05, Batch size: 19, Momentum: 1.577e-01\n",
      "best loss: 664.37\t\tLearning rate: 6.158e-05, Batch size: 29, Momentum: 5.784e-01\n",
      "best loss: 665.43\t\tLearning rate: 2.976e-08, Batch size: 42, Momentum: 5.784e-01\n",
      "best loss: 665.66\t\tLearning rate: 6.158e-05, Batch size: 17, Momentum: 1.052e-01\n",
      "best loss: 667.27\t\tLearning rate: 6.158e-05, Batch size: 37, Momentum: 1.577e-01\n",
      "best loss: 668.22\t\tLearning rate: 6.158e-05, Batch size: 37, Momentum: 4.206e-01\n",
      "best loss: 671.21\t\tLearning rate: 2.069e-05, Batch size: 19, Momentum: 5.258e-02\n",
      "best loss: 671.25\t\tLearning rate: 2.069e-05, Batch size: 47, Momentum: 8.413e-01\n",
      "best loss: 675.04\t\tLearning rate: 8.859e-08, Batch size: 19, Momentum: 5.784e-01\n",
      "best loss: 675.66\t\tLearning rate: 6.158e-05, Batch size: 27, Momentum: 3.155e-01\n",
      "best loss: 676.40\t\tLearning rate: 6.158e-05, Batch size: 17, Momentum: 3.155e-01\n",
      "best loss: 677.48\t\tLearning rate: 2.069e-05, Batch size: 39, Momentum: 5.258e-01\n",
      "best loss: 677.61\t\tLearning rate: 2.069e-05, Batch size: 29, Momentum: 5.784e-01\n",
      "best loss: 679.21\t\tLearning rate: 2.069e-05, Batch size: 24, Momentum: 4.732e-01\n",
      "best loss: 680.28\t\tLearning rate: 2.069e-05, Batch size: 9, Momentum: 5.258e-01\n",
      "best loss: 681.01\t\tLearning rate: 2.069e-05, Batch size: 22, Momentum: 4.732e-01\n",
      "best loss: 681.28\t\tLearning rate: 6.158e-05, Batch size: 27, Momentum: 3.681e-01\n",
      "best loss: 681.61\t\tLearning rate: 6.158e-05, Batch size: 19, Momentum: 5.258e-01\n",
      "best loss: 682.25\t\tLearning rate: 1.000e-08, Batch size: 42, Momentum: 5.258e-02\n",
      "best loss: 682.55\t\tLearning rate: 2.069e-05, Batch size: 14, Momentum: 7.887e-01\n",
      "best loss: 684.56\t\tLearning rate: 2.069e-05, Batch size: 37, Momentum: 2.629e-01\n",
      "best loss: 685.18\t\tLearning rate: 2.069e-05, Batch size: 19, Momentum: 6.309e-01\n",
      "best loss: 688.63\t\tLearning rate: 6.158e-05, Batch size: 47, Momentum: 3.681e-01\n",
      "best loss: 690.79\t\tLearning rate: 6.158e-05, Batch size: 19, Momentum: 2.103e-01\n",
      "best loss: 691.03\t\tLearning rate: 8.859e-08, Batch size: 24, Momentum: 3.155e-01\n",
      "best loss: 692.95\t\tLearning rate: 2.976e-08, Batch size: 34, Momentum: 1.577e-01\n",
      "best loss: 693.84\t\tLearning rate: 2.069e-05, Batch size: 37, Momentum: 7.361e-01\n",
      "best loss: 695.18\t\tLearning rate: 2.976e-08, Batch size: 22, Momentum: 5.258e-02\n",
      "best loss: 695.36\t\tLearning rate: 6.158e-05, Batch size: 50, Momentum: 0.000e+00\n",
      "best loss: 695.92\t\tLearning rate: 6.158e-05, Batch size: 22, Momentum: 2.103e-01\n",
      "best loss: 697.84\t\tLearning rate: 2.069e-05, Batch size: 32, Momentum: 5.258e-01\n",
      "best loss: 699.09\t\tLearning rate: 2.976e-08, Batch size: 50, Momentum: 5.258e-01\n",
      "best loss: 699.76\t\tLearning rate: 2.069e-05, Batch size: 2, Momentum: 9.464e-01\n",
      "best loss: 700.22\t\tLearning rate: 6.158e-05, Batch size: 50, Momentum: 1.577e-01\n",
      "best loss: 701.45\t\tLearning rate: 6.158e-05, Batch size: 42, Momentum: 2.103e-01\n",
      "best loss: 702.97\t\tLearning rate: 6.158e-05, Batch size: 12, Momentum: 4.732e-01\n",
      "best loss: 704.80\t\tLearning rate: 2.069e-05, Batch size: 19, Momentum: 3.681e-01\n",
      "best loss: 705.15\t\tLearning rate: 6.158e-05, Batch size: 2, Momentum: 1.577e-01\n",
      "best loss: 705.65\t\tLearning rate: 6.158e-05, Batch size: 4, Momentum: 6.835e-01\n",
      "best loss: 705.73\t\tLearning rate: 2.069e-05, Batch size: 2, Momentum: 7.887e-01\n",
      "best loss: 705.81\t\tLearning rate: 6.158e-05, Batch size: 7, Momentum: 8.938e-01\n",
      "best loss: 705.98\t\tLearning rate: 6.158e-05, Batch size: 39, Momentum: 5.258e-01\n",
      "best loss: 707.15\t\tLearning rate: 2.069e-05, Batch size: 27, Momentum: 8.938e-01\n",
      "best loss: 707.66\t\tLearning rate: 6.158e-05, Batch size: 22, Momentum: 4.206e-01\n",
      "best loss: 708.50\t\tLearning rate: 6.158e-05, Batch size: 50, Momentum: 8.938e-01\n",
      "best loss: 708.89\t\tLearning rate: 1.833e-04, Batch size: 2, Momentum: 3.155e-01\n",
      "best loss: 714.22\t\tLearning rate: 2.069e-05, Batch size: 4, Momentum: 7.887e-01\n",
      "best loss: 714.96\t\tLearning rate: 1.000e-08, Batch size: 39, Momentum: 2.629e-01\n",
      "best loss: 721.39\t\tLearning rate: 6.158e-05, Batch size: 27, Momentum: 2.103e-01\n",
      "best loss: 723.07\t\tLearning rate: 6.158e-05, Batch size: 12, Momentum: 6.835e-01\n",
      "best loss: 723.12\t\tLearning rate: 2.069e-05, Batch size: 44, Momentum: 6.309e-01\n",
      "best loss: 724.59\t\tLearning rate: 6.158e-05, Batch size: 4, Momentum: 5.784e-01\n",
      "best loss: 725.00\t\tLearning rate: 6.158e-05, Batch size: 42, Momentum: 4.732e-01\n",
      "best loss: 726.24\t\tLearning rate: 2.976e-08, Batch size: 29, Momentum: 2.629e-01\n",
      "best loss: 726.68\t\tLearning rate: 6.158e-05, Batch size: 14, Momentum: 3.155e-01\n",
      "best loss: 728.12\t\tLearning rate: 1.833e-04, Batch size: 14, Momentum: 1.052e-01\n",
      "best loss: 729.03\t\tLearning rate: 6.158e-05, Batch size: 39, Momentum: 4.732e-01\n",
      "best loss: 730.23\t\tLearning rate: 6.158e-05, Batch size: 37, Momentum: 6.309e-01\n",
      "best loss: 731.99\t\tLearning rate: 1.833e-04, Batch size: 29, Momentum: 5.258e-02\n",
      "best loss: 735.72\t\tLearning rate: 1.833e-04, Batch size: 14, Momentum: 5.258e-02\n",
      "best loss: 736.13\t\tLearning rate: 8.859e-08, Batch size: 47, Momentum: 0.000e+00\n",
      "best loss: 736.75\t\tLearning rate: 1.833e-04, Batch size: 2, Momentum: 1.577e-01\n",
      "best loss: 737.51\t\tLearning rate: 2.069e-05, Batch size: 22, Momentum: 8.413e-01\n",
      "best loss: 737.72\t\tLearning rate: 6.158e-05, Batch size: 44, Momentum: 4.732e-01\n",
      "best loss: 742.70\t\tLearning rate: 1.833e-04, Batch size: 22, Momentum: 0.000e+00\n",
      "best loss: 742.79\t\tLearning rate: 2.976e-08, Batch size: 24, Momentum: 5.258e-02\n",
      "best loss: 744.63\t\tLearning rate: 6.158e-05, Batch size: 29, Momentum: 7.887e-01\n",
      "best loss: 748.16\t\tLearning rate: 6.158e-05, Batch size: 37, Momentum: 2.103e-01\n",
      "best loss: 748.69\t\tLearning rate: 6.158e-05, Batch size: 19, Momentum: 9.464e-01\n",
      "best loss: 750.98\t\tLearning rate: 2.069e-05, Batch size: 50, Momentum: 8.938e-01\n",
      "best loss: 752.75\t\tLearning rate: 6.158e-05, Batch size: 14, Momentum: 9.464e-01\n",
      "best loss: 753.10\t\tLearning rate: 6.158e-05, Batch size: 32, Momentum: 6.309e-01\n",
      "best loss: 753.56\t\tLearning rate: 2.069e-05, Batch size: 7, Momentum: 7.361e-01\n",
      "best loss: 753.78\t\tLearning rate: 6.158e-05, Batch size: 2, Momentum: 9.464e-01\n",
      "best loss: 753.83\t\tLearning rate: 1.833e-04, Batch size: 12, Momentum: 3.155e-01\n",
      "best loss: 756.61\t\tLearning rate: 2.069e-05, Batch size: 12, Momentum: 8.938e-01\n",
      "best loss: 757.48\t\tLearning rate: 1.833e-04, Batch size: 12, Momentum: 5.784e-01\n",
      "best loss: 758.53\t\tLearning rate: 6.158e-05, Batch size: 7, Momentum: 9.464e-01\n",
      "best loss: 759.68\t\tLearning rate: 1.833e-04, Batch size: 39, Momentum: 3.155e-01\n",
      "best loss: 761.35\t\tLearning rate: 1.833e-04, Batch size: 12, Momentum: 1.052e-01\n",
      "best loss: 762.40\t\tLearning rate: 6.158e-05, Batch size: 32, Momentum: 7.361e-01\n",
      "best loss: 762.82\t\tLearning rate: 7.848e-07, Batch size: 9, Momentum: 5.258e-02\n",
      "best loss: 765.15\t\tLearning rate: 2.069e-05, Batch size: 47, Momentum: 2.103e-01\n",
      "best loss: 766.83\t\tLearning rate: 1.833e-04, Batch size: 7, Momentum: 2.103e-01\n",
      "best loss: 770.45\t\tLearning rate: 6.158e-05, Batch size: 39, Momentum: 1.052e-01\n",
      "best loss: 770.95\t\tLearning rate: 6.158e-05, Batch size: 12, Momentum: 5.258e-01\n",
      "best loss: 771.21\t\tLearning rate: 6.158e-05, Batch size: 17, Momentum: 8.938e-01\n",
      "best loss: 771.22\t\tLearning rate: 1.833e-04, Batch size: 2, Momentum: 6.835e-01\n",
      "best loss: 775.04\t\tLearning rate: 6.158e-05, Batch size: 17, Momentum: 5.258e-01\n",
      "best loss: 777.56\t\tLearning rate: 1.833e-04, Batch size: 4, Momentum: 4.732e-01\n",
      "best loss: 777.62\t\tLearning rate: 1.833e-04, Batch size: 44, Momentum: 2.629e-01\n",
      "best loss: 779.16\t\tLearning rate: 1.833e-04, Batch size: 9, Momentum: 3.155e-01\n",
      "best loss: 781.24\t\tLearning rate: 6.158e-05, Batch size: 44, Momentum: 7.887e-01\n",
      "best loss: 782.43\t\tLearning rate: 1.833e-04, Batch size: 47, Momentum: 4.206e-01\n",
      "best loss: 784.06\t\tLearning rate: 1.833e-04, Batch size: 50, Momentum: 1.577e-01\n",
      "best loss: 785.77\t\tLearning rate: 1.833e-04, Batch size: 27, Momentum: 5.258e-02\n",
      "best loss: 785.89\t\tLearning rate: 1.833e-04, Batch size: 50, Momentum: 3.681e-01\n",
      "best loss: 789.08\t\tLearning rate: 1.833e-04, Batch size: 9, Momentum: 7.361e-01\n",
      "best loss: 789.67\t\tLearning rate: 1.833e-04, Batch size: 22, Momentum: 7.887e-01\n",
      "best loss: 791.44\t\tLearning rate: 1.833e-04, Batch size: 44, Momentum: 7.887e-01\n",
      "best loss: 795.40\t\tLearning rate: 5.456e-04, Batch size: 2, Momentum: 0.000e+00\n",
      "best loss: 795.74\t\tLearning rate: 6.158e-05, Batch size: 2, Momentum: 8.938e-01\n",
      "best loss: 795.89\t\tLearning rate: 1.833e-04, Batch size: 19, Momentum: 5.258e-01\n",
      "best loss: 797.16\t\tLearning rate: 1.833e-04, Batch size: 17, Momentum: 5.784e-01\n",
      "best loss: 798.03\t\tLearning rate: 1.833e-04, Batch size: 14, Momentum: 3.155e-01\n",
      "best loss: 799.05\t\tLearning rate: 6.158e-05, Batch size: 29, Momentum: 3.681e-01\n",
      "best loss: 801.28\t\tLearning rate: 6.158e-05, Batch size: 37, Momentum: 4.732e-01\n",
      "best loss: 801.94\t\tLearning rate: 2.637e-07, Batch size: 32, Momentum: 5.258e-02\n",
      "best loss: 802.37\t\tLearning rate: 1.833e-04, Batch size: 19, Momentum: 2.629e-01\n",
      "best loss: 802.77\t\tLearning rate: 1.833e-04, Batch size: 4, Momentum: 6.309e-01\n",
      "best loss: 803.70\t\tLearning rate: 1.833e-04, Batch size: 50, Momentum: 4.206e-01\n",
      "best loss: 804.90\t\tLearning rate: 1.833e-04, Batch size: 4, Momentum: 0.000e+00\n",
      "best loss: 805.06\t\tLearning rate: 1.833e-04, Batch size: 34, Momentum: 2.629e-01\n",
      "best loss: 805.56\t\tLearning rate: 1.833e-04, Batch size: 47, Momentum: 5.258e-01\n",
      "best loss: 807.55\t\tLearning rate: 1.833e-04, Batch size: 22, Momentum: 4.206e-01\n",
      "best loss: 808.15\t\tLearning rate: 2.976e-08, Batch size: 14, Momentum: 3.681e-01\n",
      "best loss: 808.51\t\tLearning rate: 6.158e-05, Batch size: 12, Momentum: 7.887e-01\n",
      "best loss: 809.32\t\tLearning rate: 6.158e-05, Batch size: 22, Momentum: 9.464e-01\n",
      "best loss: 811.70\t\tLearning rate: 5.456e-04, Batch size: 50, Momentum: 1.052e-01\n",
      "best loss: 812.71\t\tLearning rate: 5.456e-04, Batch size: 29, Momentum: 5.258e-02\n",
      "best loss: 816.31\t\tLearning rate: 5.456e-04, Batch size: 12, Momentum: 0.000e+00\n",
      "best loss: 817.52\t\tLearning rate: 1.833e-04, Batch size: 9, Momentum: 5.784e-01\n",
      "best loss: 818.73\t\tLearning rate: 5.456e-04, Batch size: 14, Momentum: 0.000e+00\n",
      "best loss: 821.10\t\tLearning rate: 6.158e-05, Batch size: 17, Momentum: 5.784e-01\n",
      "best loss: 821.93\t\tLearning rate: 5.456e-04, Batch size: 19, Momentum: 0.000e+00\n",
      "best loss: 823.30\t\tLearning rate: 6.158e-05, Batch size: 12, Momentum: 8.938e-01\n",
      "best loss: 823.56\t\tLearning rate: 1.833e-04, Batch size: 12, Momentum: 8.938e-01\n",
      "best loss: 825.57\t\tLearning rate: 5.456e-04, Batch size: 29, Momentum: 0.000e+00\n",
      "best loss: 827.68\t\tLearning rate: 6.158e-05, Batch size: 12, Momentum: 9.990e-01\n",
      "best loss: 830.76\t\tLearning rate: 1.833e-04, Batch size: 14, Momentum: 4.732e-01\n",
      "best loss: 831.35\t\tLearning rate: 6.158e-05, Batch size: 32, Momentum: 9.464e-01\n",
      "best loss: 832.63\t\tLearning rate: 1.833e-04, Batch size: 17, Momentum: 4.732e-01\n",
      "best loss: 835.42\t\tLearning rate: 5.456e-04, Batch size: 44, Momentum: 2.629e-01\n",
      "best loss: 835.55\t\tLearning rate: 1.833e-04, Batch size: 12, Momentum: 4.732e-01\n",
      "best loss: 837.30\t\tLearning rate: 1.833e-04, Batch size: 24, Momentum: 7.361e-01\n",
      "best loss: 838.03\t\tLearning rate: 1.833e-04, Batch size: 7, Momentum: 5.784e-01\n",
      "best loss: 839.02\t\tLearning rate: 5.456e-04, Batch size: 44, Momentum: 4.732e-01\n",
      "best loss: 841.92\t\tLearning rate: 1.833e-04, Batch size: 29, Momentum: 1.577e-01\n",
      "best loss: 842.97\t\tLearning rate: 5.456e-04, Batch size: 2, Momentum: 5.258e-02\n",
      "best loss: 844.73\t\tLearning rate: 2.976e-08, Batch size: 29, Momentum: 2.103e-01\n",
      "best loss: 846.28\t\tLearning rate: 5.456e-04, Batch size: 4, Momentum: 7.361e-01\n",
      "best loss: 846.64\t\tLearning rate: 5.456e-04, Batch size: 24, Momentum: 3.155e-01\n",
      "best loss: 846.99\t\tLearning rate: 1.624e-03, Batch size: 7, Momentum: 3.681e-01\n",
      "best loss: 847.04\t\tLearning rate: 2.637e-07, Batch size: 22, Momentum: 2.629e-01\n",
      "best loss: 847.56\t\tLearning rate: 1.833e-04, Batch size: 34, Momentum: 5.784e-01\n",
      "best loss: 850.41\t\tLearning rate: 5.456e-04, Batch size: 22, Momentum: 1.052e-01\n",
      "best loss: 854.39\t\tLearning rate: 1.624e-03, Batch size: 22, Momentum: 5.258e-02\n",
      "best loss: 854.93\t\tLearning rate: 5.456e-04, Batch size: 47, Momentum: 1.052e-01\n",
      "best loss: 856.78\t\tLearning rate: 5.456e-04, Batch size: 42, Momentum: 1.577e-01\n",
      "best loss: 858.21\t\tLearning rate: 5.456e-04, Batch size: 17, Momentum: 4.206e-01\n",
      "best loss: 858.46\t\tLearning rate: 5.456e-04, Batch size: 29, Momentum: 6.309e-01\n",
      "best loss: 859.31\t\tLearning rate: 5.456e-04, Batch size: 12, Momentum: 4.206e-01\n",
      "best loss: 861.32\t\tLearning rate: 5.456e-04, Batch size: 27, Momentum: 3.155e-01\n",
      "best loss: 861.83\t\tLearning rate: 5.456e-04, Batch size: 4, Momentum: 2.103e-01\n",
      "best loss: 863.28\t\tLearning rate: 1.833e-04, Batch size: 12, Momentum: 7.887e-01\n",
      "best loss: 864.21\t\tLearning rate: 1.833e-04, Batch size: 44, Momentum: 6.309e-01\n",
      "best loss: 864.83\t\tLearning rate: 1.624e-03, Batch size: 14, Momentum: 0.000e+00\n",
      "best loss: 865.44\t\tLearning rate: 2.637e-07, Batch size: 24, Momentum: 3.155e-01\n",
      "best loss: 869.10\t\tLearning rate: 1.833e-04, Batch size: 27, Momentum: 8.938e-01\n",
      "best loss: 871.62\t\tLearning rate: 1.000e-08, Batch size: 7, Momentum: 4.732e-01\n",
      "best loss: 873.62\t\tLearning rate: 5.456e-04, Batch size: 47, Momentum: 5.258e-01\n",
      "best loss: 880.44\t\tLearning rate: 1.833e-04, Batch size: 19, Momentum: 6.309e-01\n",
      "best loss: 880.83\t\tLearning rate: 5.456e-04, Batch size: 34, Momentum: 5.784e-01\n",
      "best loss: 881.76\t\tLearning rate: 5.456e-04, Batch size: 44, Momentum: 3.681e-01\n",
      "best loss: 885.25\t\tLearning rate: 5.456e-04, Batch size: 27, Momentum: 7.887e-01\n",
      "best loss: 885.53\t\tLearning rate: 1.833e-04, Batch size: 34, Momentum: 2.103e-01\n",
      "best loss: 886.53\t\tLearning rate: 8.859e-08, Batch size: 32, Momentum: 0.000e+00\n",
      "best loss: 888.06\t\tLearning rate: 5.456e-04, Batch size: 2, Momentum: 9.990e-01\n",
      "best loss: 889.12\t\tLearning rate: 5.456e-04, Batch size: 32, Momentum: 8.938e-01\n",
      "best loss: 889.40\t\tLearning rate: 5.456e-04, Batch size: 42, Momentum: 2.103e-01\n",
      "best loss: 892.04\t\tLearning rate: 5.456e-04, Batch size: 42, Momentum: 8.938e-01\n",
      "best loss: 892.24\t\tLearning rate: 5.456e-04, Batch size: 17, Momentum: 8.413e-01\n",
      "best loss: 893.68\t\tLearning rate: 1.833e-04, Batch size: 24, Momentum: 9.990e-01\n",
      "best loss: 894.59\t\tLearning rate: 1.624e-03, Batch size: 19, Momentum: 1.577e-01\n",
      "best loss: 894.95\t\tLearning rate: 5.456e-04, Batch size: 27, Momentum: 5.258e-01\n",
      "best loss: 895.26\t\tLearning rate: 1.624e-03, Batch size: 4, Momentum: 1.577e-01\n",
      "best loss: 895.30\t\tLearning rate: 5.456e-04, Batch size: 42, Momentum: 4.206e-01\n",
      "best loss: 895.88\t\tLearning rate: 5.456e-04, Batch size: 7, Momentum: 4.732e-01\n",
      "best loss: 896.53\t\tLearning rate: 6.158e-05, Batch size: 47, Momentum: 8.938e-01\n",
      "best loss: 896.79\t\tLearning rate: 1.000e-08, Batch size: 22, Momentum: 5.784e-01\n",
      "best loss: 898.49\t\tLearning rate: 1.624e-03, Batch size: 29, Momentum: 1.052e-01\n",
      "best loss: 898.54\t\tLearning rate: 1.624e-03, Batch size: 17, Momentum: 0.000e+00\n",
      "best loss: 899.65\t\tLearning rate: 1.624e-03, Batch size: 47, Momentum: 0.000e+00\n",
      "best loss: 900.28\t\tLearning rate: 5.456e-04, Batch size: 42, Momentum: 6.835e-01\n",
      "best loss: 900.76\t\tLearning rate: 5.456e-04, Batch size: 19, Momentum: 4.732e-01\n",
      "best loss: 901.02\t\tLearning rate: 5.456e-04, Batch size: 37, Momentum: 4.732e-01\n",
      "best loss: 901.42\t\tLearning rate: 1.624e-03, Batch size: 2, Momentum: 4.206e-01\n",
      "best loss: 901.95\t\tLearning rate: 1.624e-03, Batch size: 9, Momentum: 1.577e-01\n",
      "best loss: 902.42\t\tLearning rate: 1.624e-03, Batch size: 39, Momentum: 0.000e+00\n",
      "best loss: 902.97\t\tLearning rate: 1.833e-04, Batch size: 12, Momentum: 8.413e-01\n",
      "best loss: 909.33\t\tLearning rate: 5.456e-04, Batch size: 47, Momentum: 6.835e-01\n",
      "best loss: 909.75\t\tLearning rate: 1.624e-03, Batch size: 47, Momentum: 1.577e-01\n",
      "best loss: 909.79\t\tLearning rate: 1.624e-03, Batch size: 4, Momentum: 3.155e-01\n",
      "best loss: 910.16\t\tLearning rate: 1.624e-03, Batch size: 39, Momentum: 2.103e-01\n",
      "best loss: 910.53\t\tLearning rate: 5.456e-04, Batch size: 24, Momentum: 4.206e-01\n",
      "best loss: 911.23\t\tLearning rate: 5.456e-04, Batch size: 12, Momentum: 7.361e-01\n",
      "best loss: 912.64\t\tLearning rate: 5.456e-04, Batch size: 32, Momentum: 6.835e-01\n",
      "best loss: 912.99\t\tLearning rate: 5.456e-04, Batch size: 2, Momentum: 1.577e-01\n",
      "best loss: 914.82\t\tLearning rate: 1.624e-03, Batch size: 34, Momentum: 3.155e-01\n",
      "best loss: 915.27\t\tLearning rate: 1.624e-03, Batch size: 22, Momentum: 1.577e-01\n",
      "best loss: 917.41\t\tLearning rate: 5.456e-04, Batch size: 37, Momentum: 5.258e-01\n",
      "best loss: 917.53\t\tLearning rate: 5.456e-04, Batch size: 37, Momentum: 9.990e-01\n",
      "best loss: 918.17\t\tLearning rate: 5.456e-04, Batch size: 42, Momentum: 7.887e-01\n",
      "best loss: 918.42\t\tLearning rate: 1.624e-03, Batch size: 27, Momentum: 5.258e-01\n",
      "best loss: 921.11\t\tLearning rate: 4.833e-03, Batch size: 44, Momentum: 3.681e-01\n",
      "best loss: 922.15\t\tLearning rate: 1.624e-03, Batch size: 12, Momentum: 1.577e-01\n",
      "best loss: 924.39\t\tLearning rate: 5.456e-04, Batch size: 2, Momentum: 6.835e-01\n",
      "best loss: 925.43\t\tLearning rate: 1.624e-03, Batch size: 29, Momentum: 5.258e-02\n",
      "best loss: 929.24\t\tLearning rate: 1.624e-03, Batch size: 2, Momentum: 1.052e-01\n",
      "best loss: 930.24\t\tLearning rate: 1.624e-03, Batch size: 32, Momentum: 5.258e-01\n",
      "best loss: 932.12\t\tLearning rate: 4.833e-03, Batch size: 17, Momentum: 2.629e-01\n",
      "best loss: 932.15\t\tLearning rate: 1.833e-04, Batch size: 29, Momentum: 9.990e-01\n",
      "best loss: 932.31\t\tLearning rate: 1.624e-03, Batch size: 50, Momentum: 4.206e-01\n",
      "best loss: 932.32\t\tLearning rate: 5.456e-04, Batch size: 12, Momentum: 8.413e-01\n",
      "best loss: 934.68\t\tLearning rate: 1.624e-03, Batch size: 14, Momentum: 6.835e-01\n",
      "best loss: 936.06\t\tLearning rate: 1.624e-03, Batch size: 29, Momentum: 4.206e-01\n",
      "best loss: 936.56\t\tLearning rate: 4.833e-03, Batch size: 42, Momentum: 3.155e-01\n",
      "best loss: 936.88\t\tLearning rate: 5.456e-04, Batch size: 17, Momentum: 6.835e-01\n",
      "best loss: 937.10\t\tLearning rate: 5.456e-04, Batch size: 34, Momentum: 6.835e-01\n",
      "best loss: 938.58\t\tLearning rate: 2.637e-07, Batch size: 39, Momentum: 5.258e-02\n",
      "best loss: 938.79\t\tLearning rate: 1.624e-03, Batch size: 50, Momentum: 5.784e-01\n",
      "best loss: 940.07\t\tLearning rate: 1.624e-03, Batch size: 4, Momentum: 4.732e-01\n",
      "best loss: 940.93\t\tLearning rate: 4.833e-03, Batch size: 39, Momentum: 0.000e+00\n",
      "best loss: 943.04\t\tLearning rate: 5.456e-04, Batch size: 7, Momentum: 5.784e-01\n",
      "best loss: 946.01\t\tLearning rate: 5.456e-04, Batch size: 12, Momentum: 9.990e-01\n",
      "best loss: 946.87\t\tLearning rate: 1.624e-03, Batch size: 50, Momentum: 5.258e-01\n",
      "best loss: 949.11\t\tLearning rate: 1.624e-03, Batch size: 2, Momentum: 1.577e-01\n",
      "best loss: 950.80\t\tLearning rate: 5.456e-04, Batch size: 4, Momentum: 4.206e-01\n",
      "best loss: 950.92\t\tLearning rate: 4.833e-03, Batch size: 50, Momentum: 4.732e-01\n",
      "best loss: 953.09\t\tLearning rate: 5.456e-04, Batch size: 22, Momentum: 8.413e-01\n",
      "best loss: 955.67\t\tLearning rate: 5.456e-04, Batch size: 2, Momentum: 8.938e-01\n",
      "best loss: 956.56\t\tLearning rate: 4.833e-03, Batch size: 37, Momentum: 3.155e-01\n",
      "best loss: 957.01\t\tLearning rate: 4.833e-03, Batch size: 44, Momentum: 1.577e-01\n",
      "best loss: 957.01\t\tLearning rate: 1.624e-03, Batch size: 14, Momentum: 4.732e-01\n",
      "best loss: 957.23\t\tLearning rate: 1.624e-03, Batch size: 9, Momentum: 2.629e-01\n",
      "best loss: 957.45\t\tLearning rate: 4.833e-03, Batch size: 34, Momentum: 6.835e-01\n",
      "best loss: 958.15\t\tLearning rate: 1.624e-03, Batch size: 37, Momentum: 5.258e-01\n",
      "best loss: 958.27\t\tLearning rate: 4.833e-03, Batch size: 34, Momentum: 1.577e-01\n",
      "best loss: 959.02\t\tLearning rate: 4.833e-03, Batch size: 14, Momentum: 0.000e+00\n",
      "best loss: 959.10\t\tLearning rate: 4.833e-03, Batch size: 29, Momentum: 5.258e-02\n",
      "best loss: 959.97\t\tLearning rate: 5.456e-04, Batch size: 12, Momentum: 9.464e-01\n",
      "best loss: 960.30\t\tLearning rate: 5.456e-04, Batch size: 9, Momentum: 7.887e-01\n",
      "best loss: 960.55\t\tLearning rate: 1.624e-03, Batch size: 9, Momentum: 2.103e-01\n",
      "best loss: 961.21\t\tLearning rate: 1.624e-03, Batch size: 17, Momentum: 3.681e-01\n",
      "best loss: 961.38\t\tLearning rate: 4.833e-03, Batch size: 50, Momentum: 0.000e+00\n",
      "best loss: 961.86\t\tLearning rate: 4.833e-03, Batch size: 4, Momentum: 3.681e-01\n",
      "best loss: 961.89\t\tLearning rate: 4.833e-03, Batch size: 27, Momentum: 1.052e-01\n",
      "best loss: 962.19\t\tLearning rate: 4.833e-03, Batch size: 17, Momentum: 5.258e-02\n",
      "best loss: 962.52\t\tLearning rate: 4.833e-03, Batch size: 34, Momentum: 9.464e-01\n",
      "best loss: 963.27\t\tLearning rate: 1.624e-03, Batch size: 50, Momentum: 6.835e-01\n",
      "best loss: 963.63\t\tLearning rate: 4.833e-03, Batch size: 19, Momentum: 2.103e-01\n",
      "best loss: 964.17\t\tLearning rate: 5.456e-04, Batch size: 14, Momentum: 8.938e-01\n",
      "best loss: 964.59\t\tLearning rate: 1.624e-03, Batch size: 14, Momentum: 4.206e-01\n",
      "best loss: 971.12\t\tLearning rate: 4.833e-03, Batch size: 2, Momentum: 2.103e-01\n",
      "best loss: 973.10\t\tLearning rate: 5.456e-04, Batch size: 9, Momentum: 9.464e-01\n",
      "best loss: 973.94\t\tLearning rate: 1.624e-03, Batch size: 4, Momentum: 7.361e-01\n",
      "best loss: 973.95\t\tLearning rate: 4.833e-03, Batch size: 7, Momentum: 3.681e-01\n",
      "best loss: 976.83\t\tLearning rate: 4.833e-03, Batch size: 39, Momentum: 2.103e-01\n",
      "best loss: 978.12\t\tLearning rate: 4.833e-03, Batch size: 19, Momentum: 6.309e-01\n",
      "best loss: 979.13\t\tLearning rate: 4.833e-03, Batch size: 14, Momentum: 2.103e-01\n",
      "best loss: 980.30\t\tLearning rate: 4.833e-03, Batch size: 39, Momentum: 4.206e-01\n",
      "best loss: 980.72\t\tLearning rate: 1.624e-03, Batch size: 17, Momentum: 5.784e-01\n",
      "best loss: 981.91\t\tLearning rate: 1.624e-03, Batch size: 12, Momentum: 6.309e-01\n",
      "best loss: 983.88\t\tLearning rate: 5.456e-04, Batch size: 37, Momentum: 8.938e-01\n",
      "best loss: 985.93\t\tLearning rate: 2.976e-08, Batch size: 32, Momentum: 2.103e-01\n",
      "best loss: 986.78\t\tLearning rate: 1.624e-03, Batch size: 37, Momentum: 6.835e-01\n",
      "best loss: 986.99\t\tLearning rate: 1.438e-02, Batch size: 2, Momentum: 2.103e-01\n",
      "best loss: 988.93\t\tLearning rate: 4.833e-03, Batch size: 39, Momentum: 5.784e-01\n",
      "best loss: 989.80\t\tLearning rate: 4.833e-03, Batch size: 12, Momentum: 6.309e-01\n",
      "best loss: 990.26\t\tLearning rate: 1.438e-02, Batch size: 27, Momentum: 5.258e-02\n",
      "best loss: 991.01\t\tLearning rate: 1.438e-02, Batch size: 32, Momentum: 1.052e-01\n",
      "best loss: 991.03\t\tLearning rate: 5.456e-04, Batch size: 22, Momentum: 9.990e-01\n",
      "best loss: 992.40\t\tLearning rate: 4.833e-03, Batch size: 14, Momentum: 2.629e-01\n",
      "best loss: 995.33\t\tLearning rate: 1.624e-03, Batch size: 12, Momentum: 8.413e-01\n",
      "best loss: 995.70\t\tLearning rate: 4.833e-03, Batch size: 7, Momentum: 4.732e-01\n",
      "best loss: 995.87\t\tLearning rate: 1.624e-03, Batch size: 44, Momentum: 5.784e-01\n",
      "best loss: 998.94\t\tLearning rate: 4.833e-03, Batch size: 14, Momentum: 3.155e-01\n",
      "best loss: 999.00\t\tLearning rate: 1.624e-03, Batch size: 29, Momentum: 5.784e-01\n",
      "best loss: 1001.02\t\tLearning rate: 1.438e-02, Batch size: 14, Momentum: 5.258e-02\n",
      "best loss: 1002.28\t\tLearning rate: 4.833e-03, Batch size: 7, Momentum: 6.835e-01\n",
      "best loss: 1003.50\t\tLearning rate: 4.281e-02, Batch size: 9, Momentum: 0.000e+00\n",
      "best loss: 1003.74\t\tLearning rate: 1.624e-03, Batch size: 14, Momentum: 8.938e-01\n",
      "best loss: 1004.25\t\tLearning rate: 4.833e-03, Batch size: 39, Momentum: 4.732e-01\n",
      "best loss: 1006.65\t\tLearning rate: 4.833e-03, Batch size: 27, Momentum: 4.206e-01\n",
      "best loss: 1006.73\t\tLearning rate: 1.438e-02, Batch size: 19, Momentum: 4.732e-01\n",
      "best loss: 1007.15\t\tLearning rate: 4.833e-03, Batch size: 2, Momentum: 4.206e-01\n",
      "best loss: 1007.55\t\tLearning rate: 1.438e-02, Batch size: 17, Momentum: 0.000e+00\n",
      "best loss: 1007.77\t\tLearning rate: 4.833e-03, Batch size: 37, Momentum: 6.309e-01\n",
      "best loss: 1009.38\t\tLearning rate: 1.438e-02, Batch size: 7, Momentum: 0.000e+00\n",
      "best loss: 1009.51\t\tLearning rate: 1.624e-03, Batch size: 19, Momentum: 9.990e-01\n",
      "best loss: 1011.99\t\tLearning rate: 4.833e-03, Batch size: 37, Momentum: 8.413e-01\n",
      "best loss: 1014.71\t\tLearning rate: 1.624e-03, Batch size: 34, Momentum: 7.361e-01\n",
      "best loss: 1016.17\t\tLearning rate: 1.438e-02, Batch size: 50, Momentum: 2.629e-01\n",
      "best loss: 1017.14\t\tLearning rate: 1.438e-02, Batch size: 4, Momentum: 2.103e-01\n",
      "best loss: 1017.24\t\tLearning rate: 4.281e-02, Batch size: 50, Momentum: 1.577e-01\n",
      "best loss: 1019.35\t\tLearning rate: 1.624e-03, Batch size: 9, Momentum: 9.464e-01\n",
      "best loss: 1020.24\t\tLearning rate: 4.833e-03, Batch size: 47, Momentum: 8.413e-01\n",
      "best loss: 1021.12\t\tLearning rate: 1.438e-02, Batch size: 34, Momentum: 2.103e-01\n",
      "best loss: 1021.26\t\tLearning rate: 5.456e-04, Batch size: 27, Momentum: 9.990e-01\n",
      "best loss: 1021.93\t\tLearning rate: 1.438e-02, Batch size: 12, Momentum: 4.206e-01\n",
      "best loss: 1022.74\t\tLearning rate: 1.438e-02, Batch size: 19, Momentum: 2.103e-01\n",
      "best loss: 1024.90\t\tLearning rate: 1.438e-02, Batch size: 22, Momentum: 2.629e-01\n",
      "best loss: 1024.91\t\tLearning rate: 1.624e-03, Batch size: 9, Momentum: 7.887e-01\n",
      "best loss: 1025.93\t\tLearning rate: 4.281e-02, Batch size: 47, Momentum: 0.000e+00\n",
      "best loss: 1026.00\t\tLearning rate: 1.624e-03, Batch size: 14, Momentum: 7.361e-01\n",
      "best loss: 1026.50\t\tLearning rate: 4.833e-03, Batch size: 17, Momentum: 5.784e-01\n",
      "best loss: 1026.73\t\tLearning rate: 4.833e-03, Batch size: 44, Momentum: 8.938e-01\n",
      "best loss: 1027.12\t\tLearning rate: 4.833e-03, Batch size: 27, Momentum: 4.732e-01\n",
      "best loss: 1027.55\t\tLearning rate: 4.833e-03, Batch size: 42, Momentum: 5.258e-01\n",
      "best loss: 1028.45\t\tLearning rate: 1.624e-03, Batch size: 19, Momentum: 7.887e-01\n",
      "best loss: 1028.56\t\tLearning rate: 4.833e-03, Batch size: 14, Momentum: 5.258e-01\n",
      "best loss: 1030.20\t\tLearning rate: 4.833e-03, Batch size: 42, Momentum: 7.887e-01\n",
      "best loss: 1030.52\t\tLearning rate: 4.833e-03, Batch size: 32, Momentum: 9.464e-01\n",
      "best loss: 1030.54\t\tLearning rate: 1.438e-02, Batch size: 27, Momentum: 4.206e-01\n",
      "best loss: 1030.75\t\tLearning rate: 4.281e-02, Batch size: 42, Momentum: 0.000e+00\n",
      "best loss: 1030.96\t\tLearning rate: 1.624e-03, Batch size: 39, Momentum: 9.990e-01\n",
      "best loss: 1031.58\t\tLearning rate: 4.281e-02, Batch size: 19, Momentum: 5.258e-02\n",
      "best loss: 1034.98\t\tLearning rate: 1.438e-02, Batch size: 2, Momentum: 3.155e-01\n",
      "best loss: 1035.05\t\tLearning rate: 4.833e-03, Batch size: 22, Momentum: 5.784e-01\n",
      "best loss: 1035.18\t\tLearning rate: 1.624e-03, Batch size: 17, Momentum: 7.361e-01\n",
      "best loss: 1035.64\t\tLearning rate: 4.281e-02, Batch size: 37, Momentum: 2.103e-01\n",
      "best loss: 1036.11\t\tLearning rate: 4.833e-03, Batch size: 7, Momentum: 3.155e-01\n",
      "best loss: 1036.63\t\tLearning rate: 1.624e-03, Batch size: 42, Momentum: 7.361e-01\n",
      "best loss: 1037.03\t\tLearning rate: 1.438e-02, Batch size: 4, Momentum: 3.155e-01\n",
      "best loss: 1037.18\t\tLearning rate: 1.624e-03, Batch size: 4, Momentum: 8.413e-01\n",
      "best loss: 1037.91\t\tLearning rate: 4.281e-02, Batch size: 2, Momentum: 2.103e-01\n",
      "best loss: 1039.60\t\tLearning rate: 4.833e-03, Batch size: 14, Momentum: 8.938e-01\n",
      "best loss: 1040.04\t\tLearning rate: 1.624e-03, Batch size: 44, Momentum: 8.413e-01\n",
      "best loss: 1040.93\t\tLearning rate: 4.833e-03, Batch size: 12, Momentum: 7.887e-01\n",
      "best loss: 1041.37\t\tLearning rate: 1.624e-03, Batch size: 32, Momentum: 8.938e-01\n",
      "best loss: 1043.02\t\tLearning rate: 1.624e-03, Batch size: 39, Momentum: 8.413e-01\n",
      "best loss: 1044.12\t\tLearning rate: 1.624e-03, Batch size: 42, Momentum: 9.464e-01\n",
      "best loss: 1046.14\t\tLearning rate: 4.281e-02, Batch size: 14, Momentum: 5.258e-02\n",
      "best loss: 1046.72\t\tLearning rate: 1.438e-02, Batch size: 44, Momentum: 2.629e-01\n",
      "best loss: 1047.55\t\tLearning rate: 4.281e-02, Batch size: 37, Momentum: 3.155e-01\n",
      "best loss: 1049.18\t\tLearning rate: 1.438e-02, Batch size: 34, Momentum: 5.258e-01\n",
      "best loss: 1049.70\t\tLearning rate: 1.438e-02, Batch size: 12, Momentum: 3.681e-01\n",
      "best loss: 1050.66\t\tLearning rate: 4.833e-03, Batch size: 47, Momentum: 7.361e-01\n",
      "best loss: 1051.50\t\tLearning rate: 4.833e-03, Batch size: 2, Momentum: 8.413e-01\n",
      "best loss: 1051.92\t\tLearning rate: 1.624e-03, Batch size: 2, Momentum: 9.990e-01\n",
      "best loss: 1053.51\t\tLearning rate: 1.438e-02, Batch size: 37, Momentum: 5.784e-01\n",
      "best loss: 1053.65\t\tLearning rate: 4.833e-03, Batch size: 24, Momentum: 7.361e-01\n",
      "best loss: 1055.14\t\tLearning rate: 4.281e-02, Batch size: 14, Momentum: 0.000e+00\n",
      "best loss: 1059.30\t\tLearning rate: 4.833e-03, Batch size: 7, Momentum: 9.464e-01\n",
      "best loss: 1060.28\t\tLearning rate: 4.281e-02, Batch size: 24, Momentum: 5.258e-02\n",
      "best loss: 1063.10\t\tLearning rate: 4.833e-03, Batch size: 22, Momentum: 6.835e-01\n",
      "best loss: 1063.17\t\tLearning rate: 4.833e-03, Batch size: 42, Momentum: 7.361e-01\n",
      "best loss: 1063.29\t\tLearning rate: 4.833e-03, Batch size: 14, Momentum: 7.361e-01\n",
      "best loss: 1065.98\t\tLearning rate: 1.438e-02, Batch size: 39, Momentum: 3.155e-01\n",
      "best loss: 1066.44\t\tLearning rate: 1.438e-02, Batch size: 9, Momentum: 5.258e-01\n",
      "best loss: 1066.88\t\tLearning rate: 4.833e-03, Batch size: 19, Momentum: 8.938e-01\n",
      "best loss: 1068.82\t\tLearning rate: 4.281e-02, Batch size: 24, Momentum: 2.103e-01\n",
      "best loss: 1068.90\t\tLearning rate: 1.624e-03, Batch size: 7, Momentum: 8.938e-01\n",
      "best loss: 1068.92\t\tLearning rate: 1.438e-02, Batch size: 50, Momentum: 6.835e-01\n",
      "best loss: 1069.65\t\tLearning rate: 4.833e-03, Batch size: 34, Momentum: 7.887e-01\n",
      "best loss: 1069.70\t\tLearning rate: 4.833e-03, Batch size: 9, Momentum: 8.413e-01\n",
      "best loss: 1071.11\t\tLearning rate: 1.624e-03, Batch size: 34, Momentum: 9.464e-01\n",
      "best loss: 1071.64\t\tLearning rate: 4.281e-02, Batch size: 14, Momentum: 4.206e-01\n",
      "best loss: 1071.92\t\tLearning rate: 1.000e-08, Batch size: 19, Momentum: 7.361e-01\n",
      "best loss: 1072.22\t\tLearning rate: 1.624e-03, Batch size: 39, Momentum: 8.938e-01\n",
      "best loss: 1072.63\t\tLearning rate: 4.833e-03, Batch size: 19, Momentum: 7.361e-01\n",
      "best loss: 1073.98\t\tLearning rate: 4.281e-02, Batch size: 17, Momentum: 1.052e-01\n",
      "best loss: 1074.98\t\tLearning rate: 4.833e-03, Batch size: 27, Momentum: 9.990e-01\n",
      "best loss: 1078.57\t\tLearning rate: 4.281e-02, Batch size: 17, Momentum: 1.577e-01\n",
      "best loss: 1079.86\t\tLearning rate: 4.833e-03, Batch size: 32, Momentum: 9.990e-01\n",
      "best loss: 1080.21\t\tLearning rate: 4.281e-02, Batch size: 19, Momentum: 1.577e-01\n",
      "best loss: 1083.81\t\tLearning rate: 4.281e-02, Batch size: 4, Momentum: 5.258e-01\n",
      "best loss: 1086.51\t\tLearning rate: 1.438e-02, Batch size: 27, Momentum: 3.681e-01\n",
      "best loss: 1086.79\t\tLearning rate: 1.438e-02, Batch size: 27, Momentum: 8.413e-01\n",
      "best loss: 1086.89\t\tLearning rate: 4.281e-02, Batch size: 34, Momentum: 2.629e-01\n",
      "best loss: 1089.64\t\tLearning rate: 4.281e-02, Batch size: 17, Momentum: 2.629e-01\n",
      "best loss: 1090.46\t\tLearning rate: 4.833e-03, Batch size: 50, Momentum: 9.464e-01\n",
      "best loss: 1091.21\t\tLearning rate: 4.281e-02, Batch size: 2, Momentum: 5.258e-01\n",
      "best loss: 1091.92\t\tLearning rate: 4.281e-02, Batch size: 27, Momentum: 3.155e-01\n",
      "best loss: 1091.96\t\tLearning rate: 1.438e-02, Batch size: 44, Momentum: 6.835e-01\n",
      "best loss: 1092.06\t\tLearning rate: 1.438e-02, Batch size: 2, Momentum: 6.309e-01\n",
      "best loss: 1092.25\t\tLearning rate: 1.274e-01, Batch size: 22, Momentum: 0.000e+00\n",
      "best loss: 1094.52\t\tLearning rate: 1.274e-01, Batch size: 17, Momentum: 1.052e-01\n",
      "best loss: 1094.53\t\tLearning rate: 4.281e-02, Batch size: 27, Momentum: 3.681e-01\n",
      "best loss: 1094.67\t\tLearning rate: 4.833e-03, Batch size: 50, Momentum: 8.938e-01\n",
      "best loss: 1094.84\t\tLearning rate: 1.438e-02, Batch size: 34, Momentum: 9.990e-01\n",
      "best loss: 1094.84\t\tLearning rate: 1.438e-02, Batch size: 32, Momentum: 6.309e-01\n",
      "best loss: 1095.60\t\tLearning rate: 1.438e-02, Batch size: 9, Momentum: 6.309e-01\n",
      "best loss: 1095.87\t\tLearning rate: 1.438e-02, Batch size: 22, Momentum: 6.309e-01\n",
      "best loss: 1096.77\t\tLearning rate: 4.281e-02, Batch size: 29, Momentum: 1.577e-01\n",
      "best loss: 1098.23\t\tLearning rate: 4.833e-03, Batch size: 42, Momentum: 9.990e-01\n",
      "best loss: 1098.72\t\tLearning rate: 1.438e-02, Batch size: 29, Momentum: 6.309e-01\n",
      "best loss: 1102.64\t\tLearning rate: 4.281e-02, Batch size: 32, Momentum: 2.103e-01\n",
      "best loss: 1102.92\t\tLearning rate: 4.281e-02, Batch size: 42, Momentum: 3.681e-01\n",
      "best loss: 1104.11\t\tLearning rate: 1.274e-01, Batch size: 9, Momentum: 2.103e-01\n",
      "best loss: 1104.78\t\tLearning rate: 1.274e-01, Batch size: 47, Momentum: 1.052e-01\n",
      "best loss: 1105.13\t\tLearning rate: 4.281e-02, Batch size: 37, Momentum: 3.681e-01\n",
      "best loss: 1105.85\t\tLearning rate: 1.624e-03, Batch size: 47, Momentum: 9.464e-01\n",
      "best loss: 1105.98\t\tLearning rate: 4.281e-02, Batch size: 50, Momentum: 4.206e-01\n",
      "best loss: 1107.88\t\tLearning rate: 1.438e-02, Batch size: 17, Momentum: 7.361e-01\n",
      "best loss: 1110.83\t\tLearning rate: 2.976e-08, Batch size: 34, Momentum: 2.103e-01\n",
      "best loss: 1111.62\t\tLearning rate: 1.274e-01, Batch size: 39, Momentum: 1.577e-01\n",
      "best loss: 1112.02\t\tLearning rate: 1.274e-01, Batch size: 34, Momentum: 2.103e-01\n",
      "best loss: 1112.20\t\tLearning rate: 1.438e-02, Batch size: 47, Momentum: 6.835e-01\n",
      "best loss: 1114.19\t\tLearning rate: 4.281e-02, Batch size: 39, Momentum: 2.629e-01\n",
      "best loss: 1116.55\t\tLearning rate: 4.833e-03, Batch size: 19, Momentum: 9.990e-01\n",
      "best loss: 1118.85\t\tLearning rate: 1.274e-01, Batch size: 24, Momentum: 5.258e-02\n",
      "best loss: 1119.68\t\tLearning rate: 4.281e-02, Batch size: 9, Momentum: 5.784e-01\n",
      "best loss: 1119.96\t\tLearning rate: 1.274e-01, Batch size: 29, Momentum: 9.990e-01\n",
      "best loss: 1120.01\t\tLearning rate: 4.281e-02, Batch size: 44, Momentum: 1.577e-01\n",
      "best loss: 1120.38\t\tLearning rate: 4.281e-02, Batch size: 19, Momentum: 5.784e-01\n",
      "best loss: 1121.05\t\tLearning rate: 1.438e-02, Batch size: 29, Momentum: 8.938e-01\n",
      "best loss: 1123.63\t\tLearning rate: 1.624e-03, Batch size: 4, Momentum: 9.464e-01\n",
      "best loss: 1123.84\t\tLearning rate: 1.438e-02, Batch size: 39, Momentum: 8.413e-01\n",
      "best loss: 1124.90\t\tLearning rate: 4.281e-02, Batch size: 42, Momentum: 3.155e-01\n",
      "best loss: 1126.77\t\tLearning rate: 4.281e-02, Batch size: 27, Momentum: 7.887e-01\n",
      "best loss: 1127.53\t\tLearning rate: 1.438e-02, Batch size: 44, Momentum: 8.413e-01\n",
      "best loss: 1127.65\t\tLearning rate: 4.833e-03, Batch size: 29, Momentum: 9.990e-01\n",
      "best loss: 1129.34\t\tLearning rate: 1.274e-01, Batch size: 19, Momentum: 5.258e-01\n",
      "best loss: 1130.63\t\tLearning rate: 4.281e-02, Batch size: 7, Momentum: 4.732e-01\n",
      "best loss: 1130.73\t\tLearning rate: 4.281e-02, Batch size: 2, Momentum: 5.784e-01\n",
      "best loss: 1131.34\t\tLearning rate: 2.637e-07, Batch size: 27, Momentum: 1.577e-01\n",
      "best loss: 1131.83\t\tLearning rate: 1.438e-02, Batch size: 34, Momentum: 6.309e-01\n",
      "best loss: 1132.29\t\tLearning rate: 4.281e-02, Batch size: 9, Momentum: 6.835e-01\n",
      "best loss: 1132.30\t\tLearning rate: 4.833e-03, Batch size: 2, Momentum: 7.887e-01\n",
      "best loss: 1132.98\t\tLearning rate: 4.281e-02, Batch size: 50, Momentum: 5.784e-01\n",
      "best loss: 1134.37\t\tLearning rate: 4.281e-02, Batch size: 44, Momentum: 4.206e-01\n",
      "best loss: 1134.49\t\tLearning rate: 1.438e-02, Batch size: 47, Momentum: 9.464e-01\n",
      "best loss: 1136.13\t\tLearning rate: 1.274e-01, Batch size: 44, Momentum: 2.629e-01\n",
      "best loss: 1136.84\t\tLearning rate: 1.274e-01, Batch size: 44, Momentum: 1.052e-01\n",
      "best loss: 1138.49\t\tLearning rate: 4.281e-02, Batch size: 50, Momentum: 6.835e-01\n",
      "best loss: 1140.82\t\tLearning rate: 1.274e-01, Batch size: 44, Momentum: 3.155e-01\n",
      "best loss: 1142.03\t\tLearning rate: 3.793e-01, Batch size: 22, Momentum: 5.258e-02\n",
      "best loss: 1142.43\t\tLearning rate: 1.274e-01, Batch size: 42, Momentum: 1.052e-01\n",
      "best loss: 1142.87\t\tLearning rate: 1.274e-01, Batch size: 2, Momentum: 2.629e-01\n",
      "best loss: 1144.59\t\tLearning rate: 4.281e-02, Batch size: 27, Momentum: 8.413e-01\n",
      "best loss: 1144.65\t\tLearning rate: 1.274e-01, Batch size: 22, Momentum: 2.103e-01\n",
      "best loss: 1145.55\t\tLearning rate: 1.274e-01, Batch size: 4, Momentum: 1.577e-01\n",
      "best loss: 1145.68\t\tLearning rate: 2.976e-08, Batch size: 42, Momentum: 5.258e-02\n",
      "best loss: 1146.79\t\tLearning rate: 1.274e-01, Batch size: 29, Momentum: 2.103e-01\n",
      "best loss: 1147.07\t\tLearning rate: 3.793e-01, Batch size: 34, Momentum: 0.000e+00\n",
      "best loss: 1147.30\t\tLearning rate: 3.793e-01, Batch size: 37, Momentum: 0.000e+00\n",
      "best loss: 1148.28\t\tLearning rate: 3.793e-01, Batch size: 4, Momentum: 0.000e+00\n",
      "best loss: 1149.45\t\tLearning rate: 3.793e-01, Batch size: 29, Momentum: 0.000e+00\n",
      "best loss: 1149.92\t\tLearning rate: 1.274e-01, Batch size: 12, Momentum: 2.629e-01\n",
      "best loss: 1150.16\t\tLearning rate: 1.438e-02, Batch size: 9, Momentum: 9.990e-01\n",
      "best loss: 1151.00\t\tLearning rate: 1.438e-02, Batch size: 39, Momentum: 9.464e-01\n",
      "best loss: 1151.19\t\tLearning rate: 1.274e-01, Batch size: 42, Momentum: 5.258e-01\n",
      "best loss: 1152.10\t\tLearning rate: 4.281e-02, Batch size: 12, Momentum: 9.990e-01\n",
      "best loss: 1152.19\t\tLearning rate: 1.274e-01, Batch size: 24, Momentum: 2.103e-01\n",
      "best loss: 1152.49\t\tLearning rate: 1.274e-01, Batch size: 17, Momentum: 3.155e-01\n",
      "best loss: 1152.68\t\tLearning rate: 1.438e-02, Batch size: 7, Momentum: 9.464e-01\n",
      "best loss: 1152.86\t\tLearning rate: 3.793e-01, Batch size: 42, Momentum: 2.103e-01\n",
      "best loss: 1153.13\t\tLearning rate: 1.274e-01, Batch size: 17, Momentum: 3.681e-01\n",
      "best loss: 1153.16\t\tLearning rate: 3.793e-01, Batch size: 2, Momentum: 1.577e-01\n",
      "best loss: 1153.60\t\tLearning rate: 1.274e-01, Batch size: 9, Momentum: 4.206e-01\n",
      "best loss: 1155.39\t\tLearning rate: 4.281e-02, Batch size: 22, Momentum: 7.887e-01\n",
      "best loss: 1156.63\t\tLearning rate: 3.793e-01, Batch size: 29, Momentum: 3.681e-01\n",
      "best loss: 1156.85\t\tLearning rate: 1.274e-01, Batch size: 24, Momentum: 4.206e-01\n",
      "best loss: 1157.27\t\tLearning rate: 4.281e-02, Batch size: 47, Momentum: 6.309e-01\n",
      "best loss: 1157.86\t\tLearning rate: 1.274e-01, Batch size: 32, Momentum: 5.784e-01\n",
      "best loss: 1157.98\t\tLearning rate: 4.281e-02, Batch size: 32, Momentum: 7.361e-01\n",
      "best loss: 1158.81\t\tLearning rate: 1.274e-01, Batch size: 39, Momentum: 5.784e-01\n",
      "best loss: 1159.17\t\tLearning rate: 4.281e-02, Batch size: 42, Momentum: 8.938e-01\n",
      "best loss: 1159.23\t\tLearning rate: 1.438e-02, Batch size: 17, Momentum: 8.938e-01\n",
      "best loss: 1159.31\t\tLearning rate: 3.793e-01, Batch size: 2, Momentum: 5.258e-02\n",
      "best loss: 1160.37\t\tLearning rate: 1.274e-01, Batch size: 42, Momentum: 2.103e-01\n",
      "best loss: 1160.88\t\tLearning rate: 3.793e-01, Batch size: 22, Momentum: 1.577e-01\n",
      "best loss: 1161.78\t\tLearning rate: 4.281e-02, Batch size: 44, Momentum: 5.784e-01\n",
      "best loss: 1162.12\t\tLearning rate: 4.281e-02, Batch size: 44, Momentum: 9.464e-01\n",
      "best loss: 1162.58\t\tLearning rate: 1.274e-01, Batch size: 2, Momentum: 1.577e-01\n",
      "best loss: 1165.97\t\tLearning rate: 1.274e-01, Batch size: 7, Momentum: 5.784e-01\n",
      "best loss: 1166.25\t\tLearning rate: 1.438e-02, Batch size: 7, Momentum: 9.990e-01\n",
      "best loss: 1166.46\t\tLearning rate: 1.438e-02, Batch size: 14, Momentum: 9.990e-01\n",
      "best loss: 1166.72\t\tLearning rate: 1.438e-02, Batch size: 9, Momentum: 9.464e-01\n",
      "best loss: 1167.27\t\tLearning rate: 4.281e-02, Batch size: 47, Momentum: 7.361e-01\n",
      "best loss: 1167.98\t\tLearning rate: 4.281e-02, Batch size: 39, Momentum: 7.887e-01\n",
      "best loss: 1169.09\t\tLearning rate: 3.793e-01, Batch size: 24, Momentum: 3.681e-01\n",
      "best loss: 1169.31\t\tLearning rate: 1.129e+00, Batch size: 19, Momentum: 0.000e+00\n",
      "best loss: 1170.31\t\tLearning rate: 1.274e-01, Batch size: 22, Momentum: 3.681e-01\n",
      "best loss: 1170.50\t\tLearning rate: 1.274e-01, Batch size: 27, Momentum: 5.258e-01\n",
      "best loss: 1172.59\t\tLearning rate: 3.793e-01, Batch size: 7, Momentum: 2.103e-01\n",
      "best loss: 1173.83\t\tLearning rate: 4.281e-02, Batch size: 37, Momentum: 6.835e-01\n",
      "best loss: 1175.06\t\tLearning rate: 1.274e-01, Batch size: 42, Momentum: 2.629e-01\n",
      "best loss: 1176.10\t\tLearning rate: 4.833e-03, Batch size: 7, Momentum: 9.990e-01\n",
      "best loss: 1176.53\t\tLearning rate: 1.438e-02, Batch size: 2, Momentum: 9.990e-01\n",
      "best loss: 1178.20\t\tLearning rate: 1.438e-02, Batch size: 42, Momentum: 8.938e-01\n",
      "best loss: 1179.49\t\tLearning rate: 1.274e-01, Batch size: 39, Momentum: 4.206e-01\n",
      "best loss: 1182.66\t\tLearning rate: 3.793e-01, Batch size: 7, Momentum: 5.258e-02\n",
      "best loss: 1183.58\t\tLearning rate: 3.793e-01, Batch size: 12, Momentum: 1.577e-01\n",
      "best loss: 1186.97\t\tLearning rate: 1.274e-01, Batch size: 37, Momentum: 7.361e-01\n",
      "best loss: 1188.30\t\tLearning rate: 3.793e-01, Batch size: 9, Momentum: 3.155e-01\n",
      "best loss: 1189.57\t\tLearning rate: 1.274e-01, Batch size: 4, Momentum: 2.629e-01\n",
      "best loss: 1189.99\t\tLearning rate: 4.281e-02, Batch size: 4, Momentum: 7.361e-01\n",
      "best loss: 1190.08\t\tLearning rate: 1.274e-01, Batch size: 4, Momentum: 4.206e-01\n",
      "best loss: 1190.25\t\tLearning rate: 1.274e-01, Batch size: 44, Momentum: 4.206e-01\n",
      "best loss: 1191.05\t\tLearning rate: 3.793e-01, Batch size: 29, Momentum: 3.155e-01\n",
      "best loss: 1192.17\t\tLearning rate: 4.281e-02, Batch size: 14, Momentum: 8.413e-01\n",
      "best loss: 1193.10\t\tLearning rate: 1.274e-01, Batch size: 12, Momentum: 1.577e-01\n",
      "best loss: 1193.26\t\tLearning rate: 1.274e-01, Batch size: 37, Momentum: 2.629e-01\n",
      "best loss: 1194.50\t\tLearning rate: 4.281e-02, Batch size: 17, Momentum: 8.938e-01\n",
      "best loss: 1194.75\t\tLearning rate: 1.129e+00, Batch size: 27, Momentum: 0.000e+00\n",
      "best loss: 1195.18\t\tLearning rate: 3.793e-01, Batch size: 2, Momentum: 1.052e-01\n",
      "best loss: 1198.04\t\tLearning rate: 3.793e-01, Batch size: 29, Momentum: 4.732e-01\n",
      "best loss: 1203.09\t\tLearning rate: 3.793e-01, Batch size: 7, Momentum: 1.052e-01\n",
      "best loss: 1204.21\t\tLearning rate: 3.793e-01, Batch size: 39, Momentum: 1.052e-01\n",
      "best loss: 1204.86\t\tLearning rate: 4.281e-02, Batch size: 7, Momentum: 8.938e-01\n",
      "best loss: 1204.87\t\tLearning rate: 3.793e-01, Batch size: 39, Momentum: 3.155e-01\n",
      "best loss: 1205.08\t\tLearning rate: 1.438e-02, Batch size: 29, Momentum: 9.464e-01\n",
      "best loss: 1208.49\t\tLearning rate: 1.129e+00, Batch size: 7, Momentum: 1.052e-01\n",
      "best loss: 1210.26\t\tLearning rate: 3.793e-01, Batch size: 9, Momentum: 1.052e-01\n",
      "best loss: 1211.01\t\tLearning rate: 1.000e-08, Batch size: 19, Momentum: 2.629e-01\n",
      "best loss: 1211.29\t\tLearning rate: 3.793e-01, Batch size: 32, Momentum: 5.784e-01\n",
      "best loss: 1211.45\t\tLearning rate: 3.793e-01, Batch size: 4, Momentum: 5.258e-01\n",
      "best loss: 1211.47\t\tLearning rate: 1.274e-01, Batch size: 27, Momentum: 8.413e-01\n",
      "best loss: 1211.88\t\tLearning rate: 1.129e+00, Batch size: 7, Momentum: 5.258e-02\n",
      "best loss: 1212.11\t\tLearning rate: 1.129e+00, Batch size: 47, Momentum: 5.258e-02\n",
      "best loss: 1213.10\t\tLearning rate: 1.274e-01, Batch size: 22, Momentum: 6.309e-01\n",
      "best loss: 1214.75\t\tLearning rate: 3.793e-01, Batch size: 19, Momentum: 5.258e-02\n",
      "best loss: 1216.28\t\tLearning rate: 3.793e-01, Batch size: 50, Momentum: 5.258e-02\n",
      "best loss: 1217.33\t\tLearning rate: 3.793e-01, Batch size: 24, Momentum: 2.629e-01\n",
      "best loss: 1218.35\t\tLearning rate: 4.281e-02, Batch size: 42, Momentum: 9.464e-01\n",
      "best loss: 1219.17\t\tLearning rate: 3.793e-01, Batch size: 2, Momentum: 6.309e-01\n",
      "best loss: 1219.96\t\tLearning rate: 3.793e-01, Batch size: 32, Momentum: 3.681e-01\n",
      "best loss: 1221.90\t\tLearning rate: 3.793e-01, Batch size: 44, Momentum: 4.732e-01\n",
      "best loss: 1222.05\t\tLearning rate: 1.274e-01, Batch size: 17, Momentum: 4.732e-01\n",
      "best loss: 1222.46\t\tLearning rate: 1.274e-01, Batch size: 7, Momentum: 8.413e-01\n",
      "best loss: 1223.95\t\tLearning rate: 1.274e-01, Batch size: 17, Momentum: 6.309e-01\n",
      "best loss: 1224.05\t\tLearning rate: 1.274e-01, Batch size: 39, Momentum: 6.309e-01\n",
      "best loss: 1224.69\t\tLearning rate: 1.129e+00, Batch size: 27, Momentum: 1.577e-01\n",
      "best loss: 1225.11\t\tLearning rate: 1.274e-01, Batch size: 32, Momentum: 7.361e-01\n",
      "best loss: 1225.38\t\tLearning rate: 1.274e-01, Batch size: 27, Momentum: 6.309e-01\n",
      "best loss: 1226.06\t\tLearning rate: 1.274e-01, Batch size: 37, Momentum: 8.413e-01\n",
      "best loss: 1227.13\t\tLearning rate: 1.274e-01, Batch size: 29, Momentum: 7.887e-01\n",
      "best loss: 1227.24\t\tLearning rate: 1.274e-01, Batch size: 12, Momentum: 7.887e-01\n",
      "best loss: 1229.31\t\tLearning rate: 3.793e-01, Batch size: 39, Momentum: 4.206e-01\n",
      "best loss: 1229.33\t\tLearning rate: 3.793e-01, Batch size: 37, Momentum: 1.577e-01\n",
      "best loss: 1230.12\t\tLearning rate: 3.793e-01, Batch size: 12, Momentum: 4.732e-01\n",
      "best loss: 1231.35\t\tLearning rate: 1.274e-01, Batch size: 42, Momentum: 8.938e-01\n",
      "best loss: 1232.34\t\tLearning rate: 1.129e+00, Batch size: 4, Momentum: 2.629e-01\n",
      "best loss: 1233.94\t\tLearning rate: 1.129e+00, Batch size: 22, Momentum: 5.258e-02\n",
      "best loss: 1235.71\t\tLearning rate: 3.793e-01, Batch size: 17, Momentum: 4.206e-01\n",
      "best loss: 1235.77\t\tLearning rate: 3.360e+00, Batch size: 34, Momentum: 5.258e-02\n",
      "best loss: 1236.35\t\tLearning rate: 1.274e-01, Batch size: 50, Momentum: 8.938e-01\n",
      "best loss: 1236.57\t\tLearning rate: 1.129e+00, Batch size: 44, Momentum: 0.000e+00\n",
      "best loss: 1238.03\t\tLearning rate: 3.793e-01, Batch size: 50, Momentum: 3.681e-01\n",
      "best loss: 1238.61\t\tLearning rate: 1.274e-01, Batch size: 4, Momentum: 6.309e-01\n",
      "best loss: 1239.68\t\tLearning rate: 3.793e-01, Batch size: 50, Momentum: 2.629e-01\n",
      "best loss: 1240.76\t\tLearning rate: 3.793e-01, Batch size: 22, Momentum: 3.155e-01\n",
      "best loss: 1240.78\t\tLearning rate: 1.129e+00, Batch size: 22, Momentum: 1.052e-01\n",
      "best loss: 1241.18\t\tLearning rate: 1.274e-01, Batch size: 7, Momentum: 4.732e-01\n",
      "best loss: 1241.31\t\tLearning rate: 1.274e-01, Batch size: 4, Momentum: 6.835e-01\n",
      "best loss: 1242.25\t\tLearning rate: 1.129e+00, Batch size: 14, Momentum: 5.258e-02\n",
      "best loss: 1242.38\t\tLearning rate: 1.129e+00, Batch size: 17, Momentum: 5.258e-02\n",
      "best loss: 1242.48\t\tLearning rate: 3.360e+00, Batch size: 32, Momentum: 5.258e-02\n",
      "best loss: 1242.56\t\tLearning rate: 3.793e-01, Batch size: 29, Momentum: 5.784e-01\n",
      "best loss: 1242.63\t\tLearning rate: 3.793e-01, Batch size: 12, Momentum: 4.206e-01\n",
      "best loss: 1244.31\t\tLearning rate: 3.793e-01, Batch size: 27, Momentum: 2.103e-01\n",
      "best loss: 1244.60\t\tLearning rate: 1.129e+00, Batch size: 34, Momentum: 3.681e-01\n",
      "best loss: 1246.29\t\tLearning rate: 1.129e+00, Batch size: 4, Momentum: 1.577e-01\n",
      "best loss: 1246.89\t\tLearning rate: 4.281e-02, Batch size: 27, Momentum: 9.464e-01\n",
      "best loss: 1247.16\t\tLearning rate: 3.793e-01, Batch size: 2, Momentum: 5.784e-01\n",
      "best loss: 1248.34\t\tLearning rate: 3.793e-01, Batch size: 32, Momentum: 6.835e-01\n",
      "best loss: 1249.18\t\tLearning rate: 1.129e+00, Batch size: 22, Momentum: 2.629e-01\n",
      "best loss: 1249.78\t\tLearning rate: 1.129e+00, Batch size: 24, Momentum: 1.052e-01\n",
      "best loss: 1250.62\t\tLearning rate: 1.000e-08, Batch size: 7, Momentum: 3.155e-01\n",
      "best loss: 1251.00\t\tLearning rate: 1.274e-01, Batch size: 27, Momentum: 5.784e-01\n",
      "best loss: 1251.01\t\tLearning rate: 2.637e-07, Batch size: 32, Momentum: 7.361e-01\n",
      "best loss: 1254.32\t\tLearning rate: 1.274e-01, Batch size: 29, Momentum: 8.413e-01\n",
      "best loss: 1256.00\t\tLearning rate: 1.274e-01, Batch size: 9, Momentum: 6.309e-01\n",
      "best loss: 1257.35\t\tLearning rate: 3.793e-01, Batch size: 50, Momentum: 4.732e-01\n",
      "best loss: 1258.47\t\tLearning rate: 4.281e-02, Batch size: 2, Momentum: 7.887e-01\n",
      "best loss: 1260.21\t\tLearning rate: 1.129e+00, Batch size: 50, Momentum: 2.103e-01\n",
      "best loss: 1262.81\t\tLearning rate: 3.793e-01, Batch size: 42, Momentum: 6.835e-01\n",
      "best loss: 1264.20\t\tLearning rate: 3.793e-01, Batch size: 24, Momentum: 5.784e-01\n",
      "best loss: 1264.69\t\tLearning rate: 3.793e-01, Batch size: 17, Momentum: 6.835e-01\n",
      "best loss: 1265.45\t\tLearning rate: 3.793e-01, Batch size: 22, Momentum: 7.361e-01\n",
      "best loss: 1267.31\t\tLearning rate: 3.360e+00, Batch size: 27, Momentum: 1.052e-01\n",
      "best loss: 1267.50\t\tLearning rate: 1.274e-01, Batch size: 4, Momentum: 9.990e-01\n",
      "best loss: 1268.48\t\tLearning rate: 3.793e-01, Batch size: 22, Momentum: 8.413e-01\n",
      "best loss: 1269.36\t\tLearning rate: 1.129e+00, Batch size: 47, Momentum: 2.629e-01\n",
      "best loss: 1271.88\t\tLearning rate: 3.360e+00, Batch size: 29, Momentum: 0.000e+00\n",
      "best loss: 1275.06\t\tLearning rate: 3.793e-01, Batch size: 27, Momentum: 6.309e-01\n",
      "best loss: 1275.69\t\tLearning rate: 3.793e-01, Batch size: 27, Momentum: 5.258e-01\n",
      "best loss: 1276.49\t\tLearning rate: 3.793e-01, Batch size: 44, Momentum: 5.258e-01\n",
      "best loss: 1277.45\t\tLearning rate: 3.360e+00, Batch size: 22, Momentum: 5.258e-02\n",
      "best loss: 1277.83\t\tLearning rate: 3.793e-01, Batch size: 7, Momentum: 6.309e-01\n",
      "best loss: 1277.85\t\tLearning rate: 3.793e-01, Batch size: 4, Momentum: 4.206e-01\n",
      "best loss: 1278.91\t\tLearning rate: 3.360e+00, Batch size: 32, Momentum: 0.000e+00\n",
      "best loss: 1279.28\t\tLearning rate: 3.793e-01, Batch size: 12, Momentum: 8.413e-01\n",
      "best loss: 1281.66\t\tLearning rate: 1.129e+00, Batch size: 24, Momentum: 2.103e-01\n",
      "best loss: 1281.97\t\tLearning rate: 3.793e-01, Batch size: 37, Momentum: 6.835e-01\n",
      "best loss: 1284.40\t\tLearning rate: 1.129e+00, Batch size: 32, Momentum: 5.258e-01\n",
      "best loss: 1284.77\t\tLearning rate: 3.793e-01, Batch size: 7, Momentum: 5.258e-01\n",
      "best loss: 1285.30\t\tLearning rate: 3.793e-01, Batch size: 42, Momentum: 7.361e-01\n",
      "best loss: 1285.48\t\tLearning rate: 3.793e-01, Batch size: 42, Momentum: 5.784e-01\n",
      "best loss: 1288.25\t\tLearning rate: 3.360e+00, Batch size: 44, Momentum: 5.258e-02\n",
      "best loss: 1290.25\t\tLearning rate: 1.274e-01, Batch size: 17, Momentum: 9.990e-01\n",
      "best loss: 1290.48\t\tLearning rate: 1.129e+00, Batch size: 14, Momentum: 3.681e-01\n",
      "best loss: 1291.54\t\tLearning rate: 3.793e-01, Batch size: 2, Momentum: 7.361e-01\n",
      "best loss: 1292.43\t\tLearning rate: 1.129e+00, Batch size: 32, Momentum: 3.155e-01\n",
      "best loss: 1293.29\t\tLearning rate: 3.793e-01, Batch size: 4, Momentum: 9.990e-01\n",
      "best loss: 1293.66\t\tLearning rate: 1.274e-01, Batch size: 50, Momentum: 9.464e-01\n",
      "best loss: 1294.61\t\tLearning rate: 1.129e+00, Batch size: 19, Momentum: 5.258e-01\n",
      "best loss: 1295.50\t\tLearning rate: 1.129e+00, Batch size: 32, Momentum: 2.629e-01\n",
      "best loss: 1296.15\t\tLearning rate: 1.129e+00, Batch size: 29, Momentum: 6.309e-01\n",
      "best loss: 1296.88\t\tLearning rate: 3.793e-01, Batch size: 9, Momentum: 8.413e-01\n",
      "best loss: 1298.21\t\tLearning rate: 1.129e+00, Batch size: 9, Momentum: 4.732e-01\n",
      "best loss: 1298.97\t\tLearning rate: 3.360e+00, Batch size: 50, Momentum: 3.155e-01\n",
      "best loss: 1299.79\t\tLearning rate: 3.793e-01, Batch size: 4, Momentum: 9.464e-01\n",
      "best loss: 1299.85\t\tLearning rate: 3.360e+00, Batch size: 39, Momentum: 2.103e-01\n",
      "best loss: 1301.02\t\tLearning rate: 1.000e+01, Batch size: 9, Momentum: 0.000e+00\n",
      "best loss: 1302.11\t\tLearning rate: 1.129e+00, Batch size: 39, Momentum: 6.309e-01\n",
      "best loss: 1302.38\t\tLearning rate: 3.793e-01, Batch size: 19, Momentum: 7.361e-01\n",
      "best loss: 1303.05\t\tLearning rate: 1.274e-01, Batch size: 14, Momentum: 9.990e-01\n",
      "best loss: 1303.88\t\tLearning rate: 1.129e+00, Batch size: 50, Momentum: 5.784e-01\n",
      "best loss: 1303.93\t\tLearning rate: 1.129e+00, Batch size: 39, Momentum: 4.732e-01\n",
      "best loss: 1304.08\t\tLearning rate: 3.360e+00, Batch size: 17, Momentum: 2.103e-01\n",
      "best loss: 1307.52\t\tLearning rate: 3.360e+00, Batch size: 12, Momentum: 2.103e-01\n",
      "best loss: 1307.61\t\tLearning rate: 1.129e+00, Batch size: 19, Momentum: 6.835e-01\n",
      "best loss: 1308.96\t\tLearning rate: 3.360e+00, Batch size: 29, Momentum: 2.103e-01\n",
      "best loss: 1309.10\t\tLearning rate: 1.129e+00, Batch size: 24, Momentum: 4.732e-01\n",
      "best loss: 1312.09\t\tLearning rate: 3.360e+00, Batch size: 24, Momentum: 2.103e-01\n",
      "best loss: 1312.35\t\tLearning rate: 3.360e+00, Batch size: 47, Momentum: 5.258e-02\n",
      "best loss: 1312.72\t\tLearning rate: 1.129e+00, Batch size: 14, Momentum: 6.309e-01\n",
      "best loss: 1313.34\t\tLearning rate: 1.129e+00, Batch size: 27, Momentum: 6.309e-01\n",
      "best loss: 1313.51\t\tLearning rate: 3.360e+00, Batch size: 50, Momentum: 4.206e-01\n",
      "best loss: 1314.48\t\tLearning rate: 3.793e-01, Batch size: 39, Momentum: 6.835e-01\n",
      "best loss: 1315.71\t\tLearning rate: 3.793e-01, Batch size: 44, Momentum: 9.464e-01\n",
      "best loss: 1316.06\t\tLearning rate: 3.360e+00, Batch size: 24, Momentum: 2.629e-01\n",
      "best loss: 1317.36\t\tLearning rate: 3.360e+00, Batch size: 17, Momentum: 5.258e-01\n",
      "best loss: 1317.45\t\tLearning rate: 1.000e+01, Batch size: 22, Momentum: 4.206e-01\n",
      "best loss: 1319.32\t\tLearning rate: 3.360e+00, Batch size: 2, Momentum: 1.577e-01\n",
      "best loss: 1319.82\t\tLearning rate: 3.793e-01, Batch size: 32, Momentum: 8.413e-01\n",
      "best loss: 1320.54\t\tLearning rate: 1.129e+00, Batch size: 14, Momentum: 5.784e-01\n",
      "best loss: 1321.05\t\tLearning rate: 1.000e+01, Batch size: 29, Momentum: 5.258e-02\n",
      "best loss: 1321.06\t\tLearning rate: 1.129e+00, Batch size: 9, Momentum: 6.835e-01\n",
      "best loss: 1323.50\t\tLearning rate: 3.360e+00, Batch size: 4, Momentum: 3.681e-01\n",
      "best loss: 1328.61\t\tLearning rate: 3.360e+00, Batch size: 37, Momentum: 5.784e-01\n",
      "best loss: 1329.61\t\tLearning rate: 1.129e+00, Batch size: 19, Momentum: 7.887e-01\n",
      "best loss: 1331.87\t\tLearning rate: 1.000e+01, Batch size: 17, Momentum: 0.000e+00\n",
      "best loss: 1332.02\t\tLearning rate: 3.360e+00, Batch size: 50, Momentum: 2.629e-01\n",
      "best loss: 1334.39\t\tLearning rate: 1.129e+00, Batch size: 27, Momentum: 5.258e-01\n",
      "best loss: 1335.87\t\tLearning rate: 3.360e+00, Batch size: 22, Momentum: 4.206e-01\n",
      "best loss: 1337.11\t\tLearning rate: 1.129e+00, Batch size: 4, Momentum: 9.990e-01\n",
      "best loss: 1337.77\t\tLearning rate: 1.129e+00, Batch size: 50, Momentum: 7.361e-01\n",
      "best loss: 1340.04\t\tLearning rate: 3.793e-01, Batch size: 37, Momentum: 7.887e-01\n",
      "best loss: 1340.24\t\tLearning rate: 3.360e+00, Batch size: 32, Momentum: 3.681e-01\n",
      "best loss: 1340.95\t\tLearning rate: 1.129e+00, Batch size: 44, Momentum: 6.835e-01\n",
      "best loss: 1342.21\t\tLearning rate: 1.000e+01, Batch size: 4, Momentum: 2.103e-01\n",
      "best loss: 1342.39\t\tLearning rate: 3.360e+00, Batch size: 34, Momentum: 3.155e-01\n",
      "best loss: 1343.13\t\tLearning rate: 3.360e+00, Batch size: 17, Momentum: 3.681e-01\n",
      "best loss: 1343.64\t\tLearning rate: 1.129e+00, Batch size: 32, Momentum: 6.835e-01\n",
      "best loss: 1344.78\t\tLearning rate: 1.274e-01, Batch size: 37, Momentum: 9.464e-01\n",
      "best loss: 1345.06\t\tLearning rate: 1.129e+00, Batch size: 42, Momentum: 8.413e-01\n",
      "best loss: 1345.40\t\tLearning rate: 1.129e+00, Batch size: 37, Momentum: 7.361e-01\n",
      "best loss: 1345.93\t\tLearning rate: 3.360e+00, Batch size: 47, Momentum: 4.732e-01\n",
      "best loss: 1346.55\t\tLearning rate: 1.129e+00, Batch size: 34, Momentum: 5.258e-01\n",
      "best loss: 1348.28\t\tLearning rate: 3.360e+00, Batch size: 19, Momentum: 4.732e-01\n",
      "best loss: 1348.84\t\tLearning rate: 1.129e+00, Batch size: 7, Momentum: 9.990e-01\n",
      "best loss: 1349.45\t\tLearning rate: 3.360e+00, Batch size: 17, Momentum: 4.206e-01\n",
      "best loss: 1350.84\t\tLearning rate: 3.793e-01, Batch size: 2, Momentum: 9.464e-01\n",
      "best loss: 1351.70\t\tLearning rate: 3.360e+00, Batch size: 24, Momentum: 4.732e-01\n",
      "best loss: 1352.03\t\tLearning rate: 1.000e+01, Batch size: 29, Momentum: 2.629e-01\n",
      "best loss: 1352.92\t\tLearning rate: 1.000e+01, Batch size: 50, Momentum: 2.629e-01\n",
      "best loss: 1353.22\t\tLearning rate: 3.360e+00, Batch size: 42, Momentum: 6.309e-01\n",
      "best loss: 1353.23\t\tLearning rate: 1.129e+00, Batch size: 17, Momentum: 6.835e-01\n",
      "best loss: 1353.52\t\tLearning rate: 1.129e+00, Batch size: 7, Momentum: 9.464e-01\n",
      "best loss: 1355.15\t\tLearning rate: 3.793e-01, Batch size: 7, Momentum: 8.413e-01\n",
      "best loss: 1356.04\t\tLearning rate: 3.360e+00, Batch size: 29, Momentum: 5.784e-01\n",
      "best loss: 1356.37\t\tLearning rate: 3.360e+00, Batch size: 7, Momentum: 4.732e-01\n",
      "best loss: 1360.90\t\tLearning rate: 3.360e+00, Batch size: 44, Momentum: 5.784e-01\n",
      "best loss: 1361.77\t\tLearning rate: 1.129e+00, Batch size: 22, Momentum: 8.938e-01\n",
      "best loss: 1361.78\t\tLearning rate: 1.000e+01, Batch size: 7, Momentum: 5.258e-01\n",
      "best loss: 1363.72\t\tLearning rate: 3.793e-01, Batch size: 34, Momentum: 9.990e-01\n",
      "best loss: 1366.18\t\tLearning rate: 1.129e+00, Batch size: 34, Momentum: 9.464e-01\n",
      "best loss: 1367.60\t\tLearning rate: 3.360e+00, Batch size: 9, Momentum: 5.784e-01\n",
      "best loss: 1367.97\t\tLearning rate: 1.000e+01, Batch size: 34, Momentum: 2.103e-01\n",
      "best loss: 1368.09\t\tLearning rate: 1.129e+00, Batch size: 44, Momentum: 9.464e-01\n",
      "best loss: 1368.10\t\tLearning rate: 1.000e+01, Batch size: 2, Momentum: 4.732e-01\n",
      "best loss: 1369.09\t\tLearning rate: 3.360e+00, Batch size: 42, Momentum: 4.732e-01\n",
      "best loss: 1369.89\t\tLearning rate: 1.000e+01, Batch size: 2, Momentum: 5.258e-01\n",
      "best loss: 1370.81\t\tLearning rate: 1.000e+01, Batch size: 9, Momentum: 3.681e-01\n",
      "best loss: 1374.59\t\tLearning rate: 1.129e+00, Batch size: 24, Momentum: 9.990e-01\n",
      "best loss: 1375.23\t\tLearning rate: 1.000e+01, Batch size: 24, Momentum: 4.732e-01\n",
      "best loss: 1378.01\t\tLearning rate: 1.129e+00, Batch size: 29, Momentum: 9.990e-01\n",
      "best loss: 1382.93\t\tLearning rate: 1.000e+01, Batch size: 34, Momentum: 3.681e-01\n",
      "best loss: 1383.60\t\tLearning rate: 1.000e+01, Batch size: 47, Momentum: 2.629e-01\n",
      "best loss: 1383.78\t\tLearning rate: 3.793e-01, Batch size: 47, Momentum: 9.990e-01\n",
      "best loss: 1384.00\t\tLearning rate: 1.000e+01, Batch size: 7, Momentum: 1.577e-01\n",
      "best loss: 1385.78\t\tLearning rate: 1.000e+01, Batch size: 22, Momentum: 2.629e-01\n",
      "best loss: 1386.00\t\tLearning rate: 1.000e+01, Batch size: 44, Momentum: 2.629e-01\n",
      "best loss: 1387.28\t\tLearning rate: 1.000e+01, Batch size: 39, Momentum: 5.258e-01\n",
      "best loss: 1388.51\t\tLearning rate: 1.129e+00, Batch size: 27, Momentum: 7.361e-01\n",
      "best loss: 1388.56\t\tLearning rate: 3.360e+00, Batch size: 19, Momentum: 3.155e-01\n",
      "best loss: 1391.31\t\tLearning rate: 1.000e+01, Batch size: 24, Momentum: 5.258e-01\n",
      "best loss: 1391.48\t\tLearning rate: 3.360e+00, Batch size: 39, Momentum: 6.835e-01\n",
      "best loss: 1392.57\t\tLearning rate: 1.000e+01, Batch size: 17, Momentum: 3.155e-01\n",
      "best loss: 1392.72\t\tLearning rate: 3.360e+00, Batch size: 29, Momentum: 6.835e-01\n",
      "best loss: 1393.42\t\tLearning rate: 1.000e+01, Batch size: 44, Momentum: 4.206e-01\n",
      "best loss: 1395.96\t\tLearning rate: 1.000e+01, Batch size: 27, Momentum: 9.464e-01\n",
      "best loss: 1401.17\t\tLearning rate: 1.000e+01, Batch size: 27, Momentum: 6.309e-01\n",
      "best loss: 1403.02\t\tLearning rate: 1.000e+01, Batch size: 24, Momentum: 7.887e-01\n",
      "best loss: 1403.37\t\tLearning rate: 1.000e+01, Batch size: 27, Momentum: 1.577e-01\n",
      "best loss: 1406.38\t\tLearning rate: 3.360e+00, Batch size: 12, Momentum: 7.361e-01\n",
      "best loss: 1408.12\t\tLearning rate: 3.360e+00, Batch size: 29, Momentum: 8.413e-01\n",
      "best loss: 1408.38\t\tLearning rate: 1.000e+01, Batch size: 19, Momentum: 4.206e-01\n",
      "best loss: 1408.45\t\tLearning rate: 1.000e+01, Batch size: 39, Momentum: 4.732e-01\n",
      "best loss: 1409.26\t\tLearning rate: 3.360e+00, Batch size: 47, Momentum: 8.938e-01\n",
      "best loss: 1409.39\t\tLearning rate: 3.360e+00, Batch size: 42, Momentum: 6.835e-01\n",
      "best loss: 1411.45\t\tLearning rate: 1.129e+00, Batch size: 19, Momentum: 9.990e-01\n",
      "best loss: 1411.50\t\tLearning rate: 1.000e+01, Batch size: 12, Momentum: 4.732e-01\n",
      "best loss: 1412.44\t\tLearning rate: 1.000e+01, Batch size: 22, Momentum: 5.784e-01\n",
      "best loss: 1414.61\t\tLearning rate: 1.000e+01, Batch size: 39, Momentum: 7.361e-01\n",
      "best loss: 1415.37\t\tLearning rate: 3.360e+00, Batch size: 12, Momentum: 6.835e-01\n",
      "best loss: 1416.20\t\tLearning rate: 1.000e+01, Batch size: 37, Momentum: 6.835e-01\n",
      "best loss: 1416.53\t\tLearning rate: 1.000e+01, Batch size: 19, Momentum: 8.413e-01\n",
      "best loss: 1417.30\t\tLearning rate: 1.000e+01, Batch size: 7, Momentum: 7.887e-01\n",
      "best loss: 1419.18\t\tLearning rate: 1.000e+01, Batch size: 34, Momentum: 5.784e-01\n",
      "best loss: 1419.48\t\tLearning rate: 1.129e+00, Batch size: 4, Momentum: 7.887e-01\n",
      "best loss: 1420.58\t\tLearning rate: 1.000e+01, Batch size: 27, Momentum: 4.732e-01\n",
      "best loss: 1421.47\t\tLearning rate: 3.360e+00, Batch size: 27, Momentum: 9.464e-01\n",
      "best loss: 1421.98\t\tLearning rate: 3.360e+00, Batch size: 17, Momentum: 7.887e-01\n",
      "best loss: 1424.75\t\tLearning rate: 3.360e+00, Batch size: 2, Momentum: 6.835e-01\n",
      "best loss: 1424.79\t\tLearning rate: 1.000e+01, Batch size: 47, Momentum: 6.309e-01\n",
      "best loss: 1425.34\t\tLearning rate: 3.360e+00, Batch size: 32, Momentum: 7.887e-01\n",
      "best loss: 1428.87\t\tLearning rate: 3.360e+00, Batch size: 44, Momentum: 9.464e-01\n",
      "best loss: 1435.22\t\tLearning rate: 1.000e+01, Batch size: 27, Momentum: 7.361e-01\n",
      "best loss: 1435.78\t\tLearning rate: 3.360e+00, Batch size: 12, Momentum: 7.887e-01\n",
      "best loss: 1439.69\t\tLearning rate: 1.000e+01, Batch size: 9, Momentum: 7.887e-01\n",
      "best loss: 1440.94\t\tLearning rate: 1.000e+01, Batch size: 17, Momentum: 8.938e-01\n",
      "best loss: 1443.11\t\tLearning rate: 1.000e+01, Batch size: 17, Momentum: 6.835e-01\n",
      "best loss: 1443.26\t\tLearning rate: 3.360e+00, Batch size: 14, Momentum: 9.464e-01\n",
      "best loss: 1445.14\t\tLearning rate: 3.360e+00, Batch size: 24, Momentum: 9.464e-01\n",
      "best loss: 1445.56\t\tLearning rate: 1.000e+01, Batch size: 4, Momentum: 5.258e-01\n",
      "best loss: 1447.68\t\tLearning rate: 1.000e+01, Batch size: 12, Momentum: 6.835e-01\n",
      "best loss: 1447.82\t\tLearning rate: 3.360e+00, Batch size: 22, Momentum: 8.938e-01\n",
      "best loss: 1449.81\t\tLearning rate: 1.000e+01, Batch size: 34, Momentum: 7.887e-01\n",
      "best loss: 1451.03\t\tLearning rate: 3.360e+00, Batch size: 37, Momentum: 9.464e-01\n",
      "best loss: 1452.47\t\tLearning rate: 1.000e+01, Batch size: 12, Momentum: 8.413e-01\n",
      "best loss: 1457.69\t\tLearning rate: 1.000e+01, Batch size: 9, Momentum: 8.938e-01\n",
      "best loss: 1460.99\t\tLearning rate: 1.000e+01, Batch size: 7, Momentum: 6.835e-01\n",
      "best loss: 1463.28\t\tLearning rate: 3.360e+00, Batch size: 12, Momentum: 9.990e-01\n",
      "best loss: 1463.84\t\tLearning rate: 1.000e+01, Batch size: 27, Momentum: 6.835e-01\n",
      "best loss: 1463.93\t\tLearning rate: 1.000e+01, Batch size: 50, Momentum: 8.413e-01\n",
      "best loss: 1470.91\t\tLearning rate: 1.000e+01, Batch size: 47, Momentum: 7.361e-01\n",
      "best loss: 1477.21\t\tLearning rate: 1.000e+01, Batch size: 17, Momentum: 8.413e-01\n",
      "best loss: 1479.86\t\tLearning rate: 1.000e+01, Batch size: 32, Momentum: 7.887e-01\n",
      "best loss: 1482.31\t\tLearning rate: 1.000e+01, Batch size: 44, Momentum: 8.413e-01\n",
      "best loss: 1488.90\t\tLearning rate: 1.000e+01, Batch size: 24, Momentum: 6.835e-01\n",
      "best loss: 1493.68\t\tLearning rate: 1.000e+01, Batch size: 4, Momentum: 8.938e-01\n",
      "best loss: 1499.70\t\tLearning rate: 1.000e+01, Batch size: 39, Momentum: 8.413e-01\n",
      "best loss: 1502.49\t\tLearning rate: 1.000e+01, Batch size: 32, Momentum: 9.464e-01\n",
      "best loss: 1504.66\t\tLearning rate: 3.360e+00, Batch size: 17, Momentum: 9.464e-01\n",
      "best loss: 1521.57\t\tLearning rate: 1.000e+01, Batch size: 12, Momentum: 9.990e-01\n",
      "best loss: 1524.97\t\tLearning rate: 1.438e-02, Batch size: 2, Momentum: 1.052e-01\n",
      "best loss: 1526.13\t\tLearning rate: 1.000e+01, Batch size: 24, Momentum: 9.464e-01\n",
      "best loss: 1887.57\t\tLearning rate: 2.637e-07, Batch size: 47, Momentum: 0.000e+00\n",
      "best loss: 1905.81\t\tLearning rate: 1.000e-08, Batch size: 22, Momentum: 2.103e-01\n",
      "best loss: 2048.37\t\tLearning rate: 2.637e-07, Batch size: 32, Momentum: 1.052e-01\n",
      "best loss: 2076.97\t\tLearning rate: 2.976e-08, Batch size: 47, Momentum: 0.000e+00\n",
      "best loss: 3193.98\t\tLearning rate: 1.000e-08, Batch size: 19, Momentum: 3.681e-01\n",
      "best loss: 3846.40\t\tLearning rate: 1.000e-08, Batch size: 42, Momentum: 1.577e-01\n",
      "best loss: 3916.51\t\tLearning rate: 1.000e-08, Batch size: 2, Momentum: 3.681e-01\n",
      "best loss: 4230.14\t\tLearning rate: 2.976e-08, Batch size: 4, Momentum: 5.784e-01\n",
      "best loss: 5552.51\t\tLearning rate: 2.976e-08, Batch size: 32, Momentum: 3.681e-01\n",
      "best loss: 9629.67\t\tLearning rate: 1.000e-08, Batch size: 44, Momentum: 2.103e-01\n",
      "best loss: 15024.86\t\tLearning rate: 2.976e-08, Batch size: 4, Momentum: 2.629e-01\n",
      "best loss: 22022.97\t\tLearning rate: 1.000e-08, Batch size: 7, Momentum: 5.258e-02\n",
      "best loss: 33532.86\t\tLearning rate: 3.793e-01, Batch size: 2, Momentum: 0.000e+00\n",
      "best loss: 47838.60\t\tLearning rate: 7.848e-07, Batch size: 12, Momentum: 0.000e+00\n",
      "best loss: 67436.21\t\tLearning rate: 8.859e-08, Batch size: 14, Momentum: 1.052e-01\n",
      "best loss: 79805.54\t\tLearning rate: 2.976e-08, Batch size: 4, Momentum: 9.464e-01\n",
      "best loss: 84348.41\t\tLearning rate: 2.336e-06, Batch size: 7, Momentum: 4.206e-01\n",
      "best loss: 84522.16\t\tLearning rate: 1.000e-08, Batch size: 12, Momentum: 6.309e-01\n",
      "best loss: 84903.55\t\tLearning rate: 3.793e-01, Batch size: 14, Momentum: 1.052e-01\n",
      "best loss: 92372.38\t\tLearning rate: 2.976e-08, Batch size: 37, Momentum: 6.309e-01\n",
      "best loss: 93153.52\t\tLearning rate: 1.000e-08, Batch size: 42, Momentum: 5.258e-01\n",
      "best loss: 93389.21\t\tLearning rate: 3.360e+00, Batch size: 7, Momentum: 3.681e-01\n",
      "best loss: 96717.11\t\tLearning rate: 1.000e+01, Batch size: 14, Momentum: 3.681e-01\n",
      "best loss: 104170.62\t\tLearning rate: 1.274e-01, Batch size: 7, Momentum: 0.000e+00\n",
      "best loss: 105576.26\t\tLearning rate: 3.793e-01, Batch size: 19, Momentum: 1.052e-01\n",
      "best loss: 112840.83\t\tLearning rate: 3.793e-01, Batch size: 34, Momentum: 1.052e-01\n",
      "best loss: 114126.84\t\tLearning rate: 1.000e-08, Batch size: 32, Momentum: 4.732e-01\n",
      "best loss: 114920.39\t\tLearning rate: 1.000e-08, Batch size: 22, Momentum: 6.835e-01\n",
      "best loss: 116603.56\t\tLearning rate: 8.859e-08, Batch size: 19, Momentum: 2.629e-01\n",
      "best loss: 119096.75\t\tLearning rate: 5.456e-04, Batch size: 19, Momentum: 5.258e-02\n",
      "best loss: 119510.96\t\tLearning rate: 2.976e-08, Batch size: 39, Momentum: 7.887e-01\n",
      "best loss: 119694.03\t\tLearning rate: 8.859e-08, Batch size: 17, Momentum: 2.629e-01\n",
      "best loss: 119814.83\t\tLearning rate: 2.976e-08, Batch size: 42, Momentum: 4.732e-01\n",
      "best loss: 122067.13\t\tLearning rate: 7.848e-07, Batch size: 50, Momentum: 6.835e-01\n",
      "best loss: 142129.69\t\tLearning rate: 8.859e-08, Batch size: 50, Momentum: 8.938e-01\n",
      "best loss: 147862.80\t\tLearning rate: 1.000e-08, Batch size: 50, Momentum: 1.052e-01\n",
      "best loss: 148479.75\t\tLearning rate: 1.000e-08, Batch size: 44, Momentum: 4.732e-01\n",
      "best loss: 149773.31\t\tLearning rate: 1.000e-08, Batch size: 14, Momentum: 4.206e-01\n",
      "best loss: 184048.34\t\tLearning rate: 1.000e-08, Batch size: 14, Momentum: 5.258e-02\n",
      "best loss: 186338.04\t\tLearning rate: 1.000e-08, Batch size: 29, Momentum: 6.835e-01\n",
      "best loss: 196847.55\t\tLearning rate: 2.976e-08, Batch size: 27, Momentum: 7.361e-01\n",
      "best loss: 212466.66\t\tLearning rate: 2.976e-08, Batch size: 19, Momentum: 5.258e-01\n",
      "best loss: 214844.89\t\tLearning rate: 2.336e-06, Batch size: 37, Momentum: 1.052e-01\n",
      "best loss: 220614.69\t\tLearning rate: 2.976e-08, Batch size: 32, Momentum: 0.000e+00\n",
      "best loss: 223866.40\t\tLearning rate: 1.274e-01, Batch size: 29, Momentum: 0.000e+00\n",
      "best loss: 228469.64\t\tLearning rate: 3.360e+00, Batch size: 27, Momentum: 3.681e-01\n",
      "best loss: 239135.01\t\tLearning rate: 2.976e-08, Batch size: 44, Momentum: 1.052e-01\n",
      "best loss: 241753.16\t\tLearning rate: 2.336e-06, Batch size: 42, Momentum: 5.258e-02\n",
      "best loss: 249823.55\t\tLearning rate: 2.976e-08, Batch size: 24, Momentum: 0.000e+00\n",
      "best loss: 251304.36\t\tLearning rate: 2.976e-08, Batch size: 9, Momentum: 5.784e-01\n",
      "best loss: 255990.31\t\tLearning rate: 8.859e-08, Batch size: 4, Momentum: 3.155e-01\n",
      "best loss: 270760.08\t\tLearning rate: 1.624e-03, Batch size: 34, Momentum: 0.000e+00\n",
      "best loss: 277021.29\t\tLearning rate: 7.848e-07, Batch size: 17, Momentum: 3.155e-01\n",
      "best loss: 285677.46\t\tLearning rate: 1.000e-08, Batch size: 17, Momentum: 9.464e-01\n",
      "best loss: 315036.97\t\tLearning rate: 2.976e-08, Batch size: 34, Momentum: 6.835e-01\n",
      "best loss: 327536.60\t\tLearning rate: 1.000e+01, Batch size: 32, Momentum: 0.000e+00\n",
      "best loss: 327993.86\t\tLearning rate: 8.859e-08, Batch size: 19, Momentum: 3.155e-01\n",
      "best loss: 328744.06\t\tLearning rate: 1.000e-08, Batch size: 7, Momentum: 6.309e-01\n",
      "best loss: 330437.84\t\tLearning rate: 1.000e-08, Batch size: 39, Momentum: 5.258e-02\n",
      "best loss: 352782.18\t\tLearning rate: 8.859e-08, Batch size: 44, Momentum: 4.732e-01\n",
      "best loss: 364977.10\t\tLearning rate: 1.000e-08, Batch size: 50, Momentum: 1.577e-01\n",
      "best loss: 365888.54\t\tLearning rate: 8.859e-08, Batch size: 32, Momentum: 5.258e-01\n",
      "best loss: 369051.22\t\tLearning rate: 3.360e+00, Batch size: 37, Momentum: 5.258e-01\n",
      "best loss: 372103.57\t\tLearning rate: 2.637e-07, Batch size: 29, Momentum: 6.835e-01\n",
      "best loss: 375362.24\t\tLearning rate: 1.000e-08, Batch size: 17, Momentum: 6.835e-01\n",
      "best loss: 395537.29\t\tLearning rate: 8.859e-08, Batch size: 24, Momentum: 7.361e-01\n",
      "best loss: 411969.96\t\tLearning rate: 2.976e-08, Batch size: 34, Momentum: 5.784e-01\n",
      "best loss: 415397.47\t\tLearning rate: 7.848e-07, Batch size: 50, Momentum: 7.887e-01\n",
      "best loss: 417110.86\t\tLearning rate: 1.000e-08, Batch size: 29, Momentum: 5.258e-02\n",
      "best loss: 425393.95\t\tLearning rate: 8.859e-08, Batch size: 42, Momentum: 6.835e-01\n",
      "best loss: 431740.90\t\tLearning rate: 8.859e-08, Batch size: 39, Momentum: 5.258e-01\n",
      "best loss: 442468.73\t\tLearning rate: 8.859e-08, Batch size: 22, Momentum: 3.681e-01\n",
      "best loss: 444781.44\t\tLearning rate: 2.637e-07, Batch size: 24, Momentum: 7.361e-01\n",
      "best loss: 445019.06\t\tLearning rate: 8.859e-08, Batch size: 29, Momentum: 7.361e-01\n",
      "best loss: 465342.23\t\tLearning rate: 2.976e-08, Batch size: 19, Momentum: 7.887e-01\n",
      "best loss: 476158.23\t\tLearning rate: 8.859e-08, Batch size: 7, Momentum: 6.835e-01\n",
      "best loss: 477265.24\t\tLearning rate: 1.000e-08, Batch size: 19, Momentum: 4.206e-01\n",
      "best loss: 497253.58\t\tLearning rate: 1.000e-08, Batch size: 42, Momentum: 6.835e-01\n",
      "best loss: 497901.51\t\tLearning rate: 1.833e-04, Batch size: 7, Momentum: 0.000e+00\n",
      "best loss: 499961.58\t\tLearning rate: 1.000e-08, Batch size: 29, Momentum: 9.990e-01\n",
      "best loss: 523320.41\t\tLearning rate: 8.859e-08, Batch size: 39, Momentum: 0.000e+00\n",
      "best loss: 531579.52\t\tLearning rate: 2.637e-07, Batch size: 9, Momentum: 1.052e-01\n",
      "best loss: 534910.87\t\tLearning rate: 8.859e-08, Batch size: 32, Momentum: 3.681e-01\n",
      "best loss: 547103.09\t\tLearning rate: 1.624e-03, Batch size: 19, Momentum: 1.052e-01\n",
      "best loss: 547775.01\t\tLearning rate: 8.859e-08, Batch size: 44, Momentum: 2.103e-01\n",
      "best loss: 576563.88\t\tLearning rate: 1.000e-08, Batch size: 32, Momentum: 3.681e-01\n",
      "best loss: 613121.31\t\tLearning rate: 4.833e-03, Batch size: 42, Momentum: 5.258e-02\n",
      "best loss: 614319.68\t\tLearning rate: 8.859e-08, Batch size: 50, Momentum: 1.052e-01\n",
      "best loss: 623894.62\t\tLearning rate: 2.637e-07, Batch size: 27, Momentum: 5.258e-01\n",
      "best loss: 654955.97\t\tLearning rate: 2.976e-08, Batch size: 17, Momentum: 0.000e+00\n",
      "best loss: 676440.94\t\tLearning rate: 2.637e-07, Batch size: 47, Momentum: 6.309e-01\n",
      "best loss: 697397.96\t\tLearning rate: 1.000e-08, Batch size: 24, Momentum: 4.732e-01\n",
      "best loss: 718845.86\t\tLearning rate: 2.637e-07, Batch size: 27, Momentum: 2.629e-01\n",
      "best loss: 729140.94\t\tLearning rate: 2.637e-07, Batch size: 42, Momentum: 0.000e+00\n",
      "best loss: 740132.15\t\tLearning rate: 1.000e-08, Batch size: 9, Momentum: 9.464e-01\n",
      "best loss: 755796.44\t\tLearning rate: 2.976e-08, Batch size: 27, Momentum: 2.629e-01\n",
      "best loss: 796774.93\t\tLearning rate: 8.859e-08, Batch size: 32, Momentum: 6.309e-01\n",
      "best loss: 807315.90\t\tLearning rate: 8.859e-08, Batch size: 24, Momentum: 7.887e-01\n",
      "best loss: 821176.86\t\tLearning rate: 8.859e-08, Batch size: 17, Momentum: 5.784e-01\n",
      "best loss: 822720.56\t\tLearning rate: 1.000e+01, Batch size: 44, Momentum: 0.000e+00\n",
      "best loss: 879262.24\t\tLearning rate: 1.624e-03, Batch size: 9, Momentum: 0.000e+00\n",
      "best loss: 901979.74\t\tLearning rate: 1.000e-08, Batch size: 34, Momentum: 4.206e-01\n",
      "best loss: 967712.75\t\tLearning rate: 2.637e-07, Batch size: 47, Momentum: 7.361e-01\n",
      "best loss: 1023280.70\t\tLearning rate: 5.456e-04, Batch size: 19, Momentum: 3.155e-01\n",
      "best loss: 1069532.20\t\tLearning rate: 1.000e-08, Batch size: 39, Momentum: 6.309e-01\n",
      "best loss: 1087282.05\t\tLearning rate: 8.859e-08, Batch size: 7, Momentum: 3.681e-01\n",
      "best loss: 1124066.20\t\tLearning rate: 8.859e-08, Batch size: 24, Momentum: 5.258e-02\n",
      "best loss: 1150760.91\t\tLearning rate: 5.456e-04, Batch size: 47, Momentum: 5.258e-02\n",
      "best loss: 1379220.97\t\tLearning rate: 1.000e-08, Batch size: 44, Momentum: 5.258e-01\n",
      "best loss: 1450481.25\t\tLearning rate: 2.976e-08, Batch size: 50, Momentum: 2.103e-01\n",
      "best loss: 1483796.27\t\tLearning rate: 8.859e-08, Batch size: 29, Momentum: 6.835e-01\n",
      "best loss: 1496492.74\t\tLearning rate: 1.274e-01, Batch size: 7, Momentum: 2.103e-01\n",
      "best loss: 1502122.70\t\tLearning rate: 2.637e-07, Batch size: 17, Momentum: 6.309e-01\n",
      "best loss: 1610686.54\t\tLearning rate: 8.859e-08, Batch size: 24, Momentum: 4.732e-01\n",
      "best loss: 1831625.18\t\tLearning rate: 2.637e-07, Batch size: 34, Momentum: 3.155e-01\n",
      "best loss: 3804784.03\t\tLearning rate: 4.833e-03, Batch size: 24, Momentum: 3.155e-01\n"
     ]
    }
   ],
   "source": [
    "# print the hyperparameters ranked from best to worst\n",
    "sorted_results = sorted(results.items(), key=lambda x: x[1])\n",
    "for hp, loss in sorted_results:\n",
    "    print(f\"best loss: {loss:.2f}\\t\\tLearning rate: {hp[0]:.3e}, Batch size: {hp[1]}, Momentum: {hp[2]:.3e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phenotypes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
