{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solve for Gaussian approximations using optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening BSCCM\n",
      "Opened BSCCM\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# this only works on startup!\n",
    "from jax import config\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "from gpu_utils import limit_gpu_memory_growth\n",
    "limit_gpu_memory_growth()\n",
    "\n",
    "from cleanplots import *\n",
    "from tqdm import tqdm\n",
    "from information_estimation import *\n",
    "from image_utils import *\n",
    "from gaussian_process_utils import *\n",
    "\n",
    "from led_array.bsccm_utils import *\n",
    "from bsccm import BSCCM\n",
    "from jax import jit\n",
    "import numpy as onp\n",
    "import jax.numpy as np\n",
    "\n",
    "bsccm = BSCCM('/home/hpinkard_waller/data/BSCCM/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images, extract patches, and compute cov mats\n",
    "edge_crop = 32\n",
    "patch_size = 20\n",
    "num_images = 20000\n",
    "num_patches = 1000\n",
    "channel = 'LED119'\n",
    "eigenvalue_floor = 1e0\n",
    "\n",
    "images = load_bsccm_images(bsccm, channel=channel, num_images=num_images, edge_crop=edge_crop, median_filter=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search through hyperparameter combos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = np.logspace(1, -8, 20)\n",
    "batch_sizes = np.linspace(2, 50, 20).astype(int)\n",
    "momentums = np.linspace(0, 0.999, 20)\n",
    "\n",
    "# generate tuples of random hyperparameters\n",
    "hyperparameter_tuples = []\n",
    "for i in range(10000):\n",
    "    lr = onp.random.choice(learning_rates)\n",
    "    bs = onp.random.choice(batch_sizes)\n",
    "    m = onp.random.choice(momentums)\n",
    "    hyperparameter_tuples.append((lr, bs, m))\n",
    "\n",
    "results = {}\n",
    "for i, (learning_rate, batch_size, momentum) in enumerate(hyperparameter_tuples):\n",
    "    best_hp_loss = np.inf\n",
    "\n",
    "    patches = extract_patches(images, patch_size, num_patches=num_patches, seed=i)\n",
    "    best_cov_mat, cov_mat_initial, mean_vec, best_loss = run_optimization(patches, momentum, learning_rate, batch_size, eigenvalue_floor=1e-3)\n",
    "\n",
    "    if best_loss < best_hp_loss:\n",
    "        best_hp_loss = best_loss\n",
    "        best_hp = (learning_rate, batch_size, momentum)\n",
    "        \n",
    "    # collect results\n",
    "    results[(learning_rate, batch_size, momentum)] = best_loss\n",
    "\n",
    "    # print hyperparameters and their best loss\n",
    "    print(f\"best loss: {best_loss:.2f}\\t\\tLearning rate: {learning_rate:.3e}, Batch size: {batch_size}, Momentum: {momentum:.3e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best loss: 1677.30\t\tLearning rate: 1.000e-08, Batch size: 2, Momentum: 3.681e-01\n",
      "best loss: 1710.50\t\tLearning rate: 1.000e+01, Batch size: 2, Momentum: 7.887e-01\n",
      "best loss: 1712.38\t\tLearning rate: 1.274e-01, Batch size: 2, Momentum: 2.103e-01\n",
      "best loss: 1713.47\t\tLearning rate: 1.438e-02, Batch size: 2, Momentum: 7.887e-01\n",
      "best loss: 1716.37\t\tLearning rate: 6.158e-05, Batch size: 2, Momentum: 6.309e-01\n",
      "best loss: 1716.63\t\tLearning rate: 1.624e-03, Batch size: 2, Momentum: 1.052e-01\n",
      "best loss: 1725.65\t\tLearning rate: 5.456e-04, Batch size: 2, Momentum: 1.577e-01\n",
      "best loss: 1733.78\t\tLearning rate: 2.637e-07, Batch size: 4, Momentum: 3.681e-01\n",
      "best loss: 1741.91\t\tLearning rate: 1.000e-08, Batch size: 4, Momentum: 9.990e-01\n",
      "best loss: 1744.23\t\tLearning rate: 1.129e+00, Batch size: 12, Momentum: 5.784e-01\n",
      "best loss: 1747.73\t\tLearning rate: 2.637e-07, Batch size: 7, Momentum: 8.413e-01\n",
      "best loss: 1752.28\t\tLearning rate: 8.859e-08, Batch size: 7, Momentum: 7.887e-01\n",
      "best loss: 1752.41\t\tLearning rate: 1.000e-08, Batch size: 9, Momentum: 9.990e-01\n",
      "best loss: 1753.96\t\tLearning rate: 1.833e-04, Batch size: 12, Momentum: 8.413e-01\n",
      "best loss: 1757.63\t\tLearning rate: 2.637e-07, Batch size: 4, Momentum: 2.103e-01\n",
      "best loss: 1757.76\t\tLearning rate: 2.637e-07, Batch size: 9, Momentum: 3.681e-01\n",
      "best loss: 1758.07\t\tLearning rate: 2.637e-07, Batch size: 9, Momentum: 5.784e-01\n",
      "best loss: 1758.90\t\tLearning rate: 2.336e-06, Batch size: 9, Momentum: 1.577e-01\n",
      "best loss: 1761.20\t\tLearning rate: 2.637e-07, Batch size: 9, Momentum: 6.309e-01\n",
      "best loss: 1761.85\t\tLearning rate: 2.976e-08, Batch size: 7, Momentum: 8.413e-01\n",
      "best loss: 1762.13\t\tLearning rate: 1.129e+00, Batch size: 27, Momentum: 6.835e-01\n",
      "best loss: 1762.47\t\tLearning rate: 1.000e+01, Batch size: 27, Momentum: 1.052e-01\n",
      "best loss: 1765.30\t\tLearning rate: 7.848e-07, Batch size: 19, Momentum: 2.103e-01\n",
      "best loss: 1765.91\t\tLearning rate: 3.360e+00, Batch size: 37, Momentum: 4.732e-01\n",
      "best loss: 1766.07\t\tLearning rate: 2.069e-05, Batch size: 39, Momentum: 9.464e-01\n",
      "best loss: 1766.93\t\tLearning rate: 5.456e-04, Batch size: 14, Momentum: 5.784e-01\n",
      "best loss: 1767.58\t\tLearning rate: 1.000e+01, Batch size: 22, Momentum: 8.938e-01\n",
      "best loss: 1767.63\t\tLearning rate: 1.438e-02, Batch size: 27, Momentum: 4.206e-01\n",
      "best loss: 1767.89\t\tLearning rate: 6.952e-06, Batch size: 27, Momentum: 2.629e-01\n",
      "best loss: 1768.22\t\tLearning rate: 1.000e+01, Batch size: 27, Momentum: 2.629e-01\n",
      "best loss: 1769.00\t\tLearning rate: 4.281e-02, Batch size: 22, Momentum: 8.938e-01\n",
      "best loss: 1769.74\t\tLearning rate: 6.158e-05, Batch size: 34, Momentum: 6.309e-01\n",
      "best loss: 1769.89\t\tLearning rate: 2.336e-06, Batch size: 47, Momentum: 1.052e-01\n",
      "best loss: 1771.05\t\tLearning rate: 6.952e-06, Batch size: 32, Momentum: 7.887e-01\n",
      "best loss: 1771.31\t\tLearning rate: 2.336e-06, Batch size: 50, Momentum: 3.155e-01\n",
      "best loss: 1771.36\t\tLearning rate: 7.848e-07, Batch size: 32, Momentum: 9.464e-01\n",
      "best loss: 1771.36\t\tLearning rate: 2.336e-06, Batch size: 14, Momentum: 4.732e-01\n",
      "best loss: 1771.70\t\tLearning rate: 2.637e-07, Batch size: 9, Momentum: 8.413e-01\n",
      "best loss: 1772.25\t\tLearning rate: 7.848e-07, Batch size: 14, Momentum: 5.258e-02\n",
      "best loss: 1772.53\t\tLearning rate: 8.859e-08, Batch size: 4, Momentum: 5.784e-01\n",
      "best loss: 1773.45\t\tLearning rate: 2.976e-08, Batch size: 9, Momentum: 7.361e-01\n",
      "best loss: 1774.15\t\tLearning rate: 8.859e-08, Batch size: 29, Momentum: 9.464e-01\n",
      "best loss: 1774.61\t\tLearning rate: 7.848e-07, Batch size: 27, Momentum: 5.258e-02\n",
      "best loss: 1775.05\t\tLearning rate: 2.336e-06, Batch size: 12, Momentum: 2.629e-01\n",
      "best loss: 1775.32\t\tLearning rate: 4.833e-03, Batch size: 22, Momentum: 4.206e-01\n",
      "best loss: 1775.50\t\tLearning rate: 8.859e-08, Batch size: 19, Momentum: 6.835e-01\n",
      "best loss: 1775.87\t\tLearning rate: 2.637e-07, Batch size: 9, Momentum: 5.258e-01\n",
      "best loss: 1776.54\t\tLearning rate: 3.360e+00, Batch size: 37, Momentum: 2.103e-01\n",
      "best loss: 1776.71\t\tLearning rate: 2.336e-06, Batch size: 39, Momentum: 5.258e-01\n",
      "best loss: 1776.75\t\tLearning rate: 7.848e-07, Batch size: 44, Momentum: 6.309e-01\n",
      "best loss: 1777.23\t\tLearning rate: 2.336e-06, Batch size: 50, Momentum: 4.206e-01\n",
      "best loss: 1777.31\t\tLearning rate: 3.360e+00, Batch size: 24, Momentum: 9.990e-01\n",
      "best loss: 1777.36\t\tLearning rate: 2.976e-08, Batch size: 9, Momentum: 9.990e-01\n",
      "best loss: 1778.42\t\tLearning rate: 1.624e-03, Batch size: 47, Momentum: 5.784e-01\n",
      "best loss: 1778.81\t\tLearning rate: 4.281e-02, Batch size: 34, Momentum: 6.835e-01\n",
      "best loss: 1780.95\t\tLearning rate: 7.848e-07, Batch size: 7, Momentum: 5.258e-02\n",
      "best loss: 1781.54\t\tLearning rate: 2.976e-08, Batch size: 24, Momentum: 9.990e-01\n",
      "best loss: 1782.36\t\tLearning rate: 8.859e-08, Batch size: 27, Momentum: 3.681e-01\n",
      "best loss: 1782.83\t\tLearning rate: 6.158e-05, Batch size: 24, Momentum: 6.309e-01\n",
      "best loss: 1783.17\t\tLearning rate: 2.336e-06, Batch size: 17, Momentum: 7.887e-01\n",
      "best loss: 1783.49\t\tLearning rate: 7.848e-07, Batch size: 22, Momentum: 8.938e-01\n",
      "best loss: 1784.90\t\tLearning rate: 7.848e-07, Batch size: 42, Momentum: 8.938e-01\n",
      "best loss: 1786.93\t\tLearning rate: 2.336e-06, Batch size: 50, Momentum: 4.732e-01\n",
      "best loss: 1787.50\t\tLearning rate: 5.456e-04, Batch size: 27, Momentum: 3.155e-01\n",
      "best loss: 1787.53\t\tLearning rate: 2.637e-07, Batch size: 19, Momentum: 5.784e-01\n",
      "best loss: 1791.68\t\tLearning rate: 2.336e-06, Batch size: 17, Momentum: 6.309e-01\n",
      "best loss: 1792.11\t\tLearning rate: 7.848e-07, Batch size: 39, Momentum: 9.464e-01\n",
      "best loss: 1793.98\t\tLearning rate: 8.859e-08, Batch size: 19, Momentum: 5.258e-01\n",
      "best loss: 1794.89\t\tLearning rate: 8.859e-08, Batch size: 50, Momentum: 8.413e-01\n",
      "best loss: 1796.09\t\tLearning rate: 2.336e-06, Batch size: 14, Momentum: 2.629e-01\n",
      "best loss: 1796.93\t\tLearning rate: 1.000e+01, Batch size: 7, Momentum: 2.629e-01\n",
      "best loss: 1797.17\t\tLearning rate: 8.859e-08, Batch size: 12, Momentum: 2.103e-01\n",
      "best loss: 1797.88\t\tLearning rate: 8.859e-08, Batch size: 24, Momentum: 7.361e-01\n",
      "best loss: 1800.65\t\tLearning rate: 7.848e-07, Batch size: 7, Momentum: 1.052e-01\n",
      "best loss: 1801.54\t\tLearning rate: 4.833e-03, Batch size: 22, Momentum: 4.732e-01\n",
      "best loss: 1802.86\t\tLearning rate: 7.848e-07, Batch size: 19, Momentum: 5.258e-01\n",
      "best loss: 1805.13\t\tLearning rate: 2.336e-06, Batch size: 27, Momentum: 1.577e-01\n",
      "best loss: 1805.21\t\tLearning rate: 2.976e-08, Batch size: 47, Momentum: 8.938e-01\n",
      "best loss: 1805.75\t\tLearning rate: 7.848e-07, Batch size: 39, Momentum: 2.629e-01\n",
      "best loss: 1806.35\t\tLearning rate: 7.848e-07, Batch size: 17, Momentum: 8.413e-01\n",
      "best loss: 1807.68\t\tLearning rate: 2.336e-06, Batch size: 27, Momentum: 6.309e-01\n",
      "best loss: 1808.53\t\tLearning rate: 7.848e-07, Batch size: 9, Momentum: 9.464e-01\n",
      "best loss: 1816.95\t\tLearning rate: 2.637e-07, Batch size: 47, Momentum: 4.206e-01\n",
      "best loss: 1818.31\t\tLearning rate: 7.848e-07, Batch size: 44, Momentum: 1.052e-01\n",
      "best loss: 1823.05\t\tLearning rate: 2.069e-05, Batch size: 17, Momentum: 6.309e-01\n",
      "best loss: 1825.93\t\tLearning rate: 7.848e-07, Batch size: 44, Momentum: 9.464e-01\n",
      "best loss: 1826.59\t\tLearning rate: 2.336e-06, Batch size: 39, Momentum: 1.577e-01\n",
      "best loss: 1829.86\t\tLearning rate: 2.336e-06, Batch size: 17, Momentum: 0.000e+00\n",
      "best loss: 1836.51\t\tLearning rate: 2.976e-08, Batch size: 19, Momentum: 5.258e-01\n",
      "best loss: 1838.19\t\tLearning rate: 2.976e-08, Batch size: 39, Momentum: 6.835e-01\n",
      "best loss: 1840.20\t\tLearning rate: 2.336e-06, Batch size: 29, Momentum: 3.155e-01\n",
      "best loss: 1843.31\t\tLearning rate: 2.976e-08, Batch size: 37, Momentum: 7.361e-01\n",
      "best loss: 1850.40\t\tLearning rate: 2.976e-08, Batch size: 9, Momentum: 6.309e-01\n",
      "best loss: 1850.72\t\tLearning rate: 2.976e-08, Batch size: 42, Momentum: 5.258e-01\n",
      "best loss: 1856.37\t\tLearning rate: 8.859e-08, Batch size: 37, Momentum: 3.155e-01\n",
      "best loss: 1860.69\t\tLearning rate: 2.637e-07, Batch size: 42, Momentum: 6.835e-01\n",
      "best loss: 1863.22\t\tLearning rate: 2.637e-07, Batch size: 47, Momentum: 1.577e-01\n",
      "best loss: 1875.25\t\tLearning rate: 1.000e-08, Batch size: 9, Momentum: 2.629e-01\n",
      "best loss: 1879.94\t\tLearning rate: 6.952e-06, Batch size: 7, Momentum: 5.258e-02\n",
      "best loss: 1882.42\t\tLearning rate: 2.637e-07, Batch size: 24, Momentum: 3.155e-01\n",
      "best loss: 1882.67\t\tLearning rate: 2.637e-07, Batch size: 47, Momentum: 5.258e-02\n",
      "best loss: 1883.88\t\tLearning rate: 2.637e-07, Batch size: 19, Momentum: 3.155e-01\n",
      "best loss: 1900.46\t\tLearning rate: 7.848e-07, Batch size: 29, Momentum: 7.887e-01\n",
      "best loss: 1904.58\t\tLearning rate: 2.976e-08, Batch size: 17, Momentum: 5.258e-02\n",
      "best loss: 1927.55\t\tLearning rate: 7.848e-07, Batch size: 37, Momentum: 9.464e-01\n",
      "best loss: 1994.38\t\tLearning rate: 2.336e-06, Batch size: 9, Momentum: 4.206e-01\n",
      "best loss: 2019.18\t\tLearning rate: 8.859e-08, Batch size: 50, Momentum: 1.052e-01\n",
      "best loss: 2103.24\t\tLearning rate: 6.952e-06, Batch size: 24, Momentum: 2.103e-01\n",
      "best loss: 2175.93\t\tLearning rate: 7.848e-07, Batch size: 24, Momentum: 9.464e-01\n",
      "best loss: 2207.42\t\tLearning rate: 6.952e-06, Batch size: 39, Momentum: 0.000e+00\n",
      "best loss: 2252.11\t\tLearning rate: 2.336e-06, Batch size: 22, Momentum: 7.361e-01\n",
      "best loss: 2362.39\t\tLearning rate: 6.952e-06, Batch size: 19, Momentum: 1.577e-01\n",
      "best loss: 2477.17\t\tLearning rate: 2.336e-06, Batch size: 29, Momentum: 8.938e-01\n",
      "best loss: 2484.36\t\tLearning rate: 2.336e-06, Batch size: 50, Momentum: 7.887e-01\n",
      "best loss: 2510.22\t\tLearning rate: 2.336e-06, Batch size: 50, Momentum: 8.938e-01\n",
      "best loss: 2528.55\t\tLearning rate: 2.069e-05, Batch size: 22, Momentum: 1.052e-01\n",
      "best loss: 2553.11\t\tLearning rate: 2.069e-05, Batch size: 39, Momentum: 1.052e-01\n",
      "best loss: 2554.96\t\tLearning rate: 6.952e-06, Batch size: 29, Momentum: 5.258e-01\n",
      "best loss: 2573.80\t\tLearning rate: 6.952e-06, Batch size: 32, Momentum: 1.052e-01\n",
      "best loss: 2641.03\t\tLearning rate: 2.336e-06, Batch size: 14, Momentum: 9.464e-01\n",
      "best loss: 2661.25\t\tLearning rate: 2.336e-06, Batch size: 19, Momentum: 8.938e-01\n",
      "best loss: 2665.34\t\tLearning rate: 6.952e-06, Batch size: 42, Momentum: 2.629e-01\n",
      "best loss: 2667.74\t\tLearning rate: 2.069e-05, Batch size: 50, Momentum: 1.577e-01\n",
      "best loss: 2668.65\t\tLearning rate: 2.069e-05, Batch size: 39, Momentum: 5.258e-02\n",
      "best loss: 2673.58\t\tLearning rate: 6.158e-05, Batch size: 34, Momentum: 0.000e+00\n",
      "best loss: 2702.86\t\tLearning rate: 2.069e-05, Batch size: 12, Momentum: 3.681e-01\n",
      "best loss: 2712.15\t\tLearning rate: 6.952e-06, Batch size: 27, Momentum: 7.361e-01\n",
      "best loss: 2727.05\t\tLearning rate: 6.952e-06, Batch size: 17, Momentum: 4.732e-01\n",
      "best loss: 2742.37\t\tLearning rate: 2.069e-05, Batch size: 9, Momentum: 1.577e-01\n",
      "best loss: 2766.42\t\tLearning rate: 6.952e-06, Batch size: 44, Momentum: 6.309e-01\n",
      "best loss: 2778.20\t\tLearning rate: 6.952e-06, Batch size: 12, Momentum: 5.784e-01\n",
      "best loss: 2785.69\t\tLearning rate: 2.336e-06, Batch size: 12, Momentum: 9.464e-01\n",
      "best loss: 2796.72\t\tLearning rate: 2.069e-05, Batch size: 27, Momentum: 4.732e-01\n",
      "best loss: 2797.20\t\tLearning rate: 2.336e-06, Batch size: 50, Momentum: 9.990e-01\n",
      "best loss: 2818.45\t\tLearning rate: 2.069e-05, Batch size: 50, Momentum: 4.206e-01\n",
      "best loss: 2865.06\t\tLearning rate: 2.069e-05, Batch size: 12, Momentum: 6.309e-01\n",
      "best loss: 2888.35\t\tLearning rate: 6.952e-06, Batch size: 27, Momentum: 7.887e-01\n",
      "best loss: 2890.94\t\tLearning rate: 6.158e-05, Batch size: 47, Momentum: 0.000e+00\n",
      "best loss: 2892.87\t\tLearning rate: 2.069e-05, Batch size: 2, Momentum: 3.681e-01\n",
      "best loss: 2900.95\t\tLearning rate: 6.158e-05, Batch size: 44, Momentum: 3.155e-01\n",
      "best loss: 2904.69\t\tLearning rate: 6.158e-05, Batch size: 9, Momentum: 5.258e-02\n",
      "best loss: 2908.10\t\tLearning rate: 2.069e-05, Batch size: 32, Momentum: 6.835e-01\n",
      "best loss: 2918.73\t\tLearning rate: 6.158e-05, Batch size: 27, Momentum: 4.732e-01\n",
      "best loss: 2934.35\t\tLearning rate: 6.952e-06, Batch size: 17, Momentum: 9.464e-01\n",
      "best loss: 2951.68\t\tLearning rate: 2.069e-05, Batch size: 14, Momentum: 3.681e-01\n",
      "best loss: 2951.75\t\tLearning rate: 2.069e-05, Batch size: 14, Momentum: 7.361e-01\n",
      "best loss: 2982.41\t\tLearning rate: 6.158e-05, Batch size: 7, Momentum: 3.155e-01\n",
      "best loss: 2987.88\t\tLearning rate: 6.158e-05, Batch size: 24, Momentum: 4.206e-01\n",
      "best loss: 2997.45\t\tLearning rate: 6.158e-05, Batch size: 24, Momentum: 3.681e-01\n",
      "best loss: 3032.61\t\tLearning rate: 6.952e-06, Batch size: 22, Momentum: 9.464e-01\n",
      "best loss: 3068.83\t\tLearning rate: 1.833e-04, Batch size: 39, Momentum: 1.577e-01\n",
      "best loss: 3074.91\t\tLearning rate: 6.158e-05, Batch size: 37, Momentum: 4.206e-01\n",
      "best loss: 3075.61\t\tLearning rate: 2.069e-05, Batch size: 2, Momentum: 4.732e-01\n",
      "best loss: 3081.24\t\tLearning rate: 6.952e-06, Batch size: 32, Momentum: 9.990e-01\n",
      "best loss: 3091.88\t\tLearning rate: 6.158e-05, Batch size: 12, Momentum: 3.681e-01\n",
      "best loss: 3103.99\t\tLearning rate: 6.158e-05, Batch size: 17, Momentum: 5.258e-01\n",
      "best loss: 3114.29\t\tLearning rate: 2.069e-05, Batch size: 50, Momentum: 8.413e-01\n",
      "best loss: 3119.85\t\tLearning rate: 1.833e-04, Batch size: 32, Momentum: 1.577e-01\n",
      "best loss: 3127.78\t\tLearning rate: 2.069e-05, Batch size: 47, Momentum: 7.887e-01\n",
      "best loss: 3159.19\t\tLearning rate: 1.833e-04, Batch size: 14, Momentum: 2.629e-01\n",
      "best loss: 3165.48\t\tLearning rate: 6.158e-05, Batch size: 27, Momentum: 4.206e-01\n",
      "best loss: 3183.61\t\tLearning rate: 6.158e-05, Batch size: 4, Momentum: 9.464e-01\n",
      "best loss: 3213.16\t\tLearning rate: 6.158e-05, Batch size: 39, Momentum: 6.835e-01\n",
      "best loss: 3222.01\t\tLearning rate: 5.456e-04, Batch size: 9, Momentum: 2.629e-01\n",
      "best loss: 3227.57\t\tLearning rate: 1.833e-04, Batch size: 17, Momentum: 2.629e-01\n",
      "best loss: 3234.79\t\tLearning rate: 6.158e-05, Batch size: 39, Momentum: 6.309e-01\n",
      "best loss: 3237.51\t\tLearning rate: 6.158e-05, Batch size: 9, Momentum: 6.309e-01\n",
      "best loss: 3239.04\t\tLearning rate: 1.833e-04, Batch size: 44, Momentum: 3.681e-01\n",
      "best loss: 3249.42\t\tLearning rate: 6.158e-05, Batch size: 44, Momentum: 9.464e-01\n",
      "best loss: 3262.29\t\tLearning rate: 1.833e-04, Batch size: 24, Momentum: 3.155e-01\n",
      "best loss: 3272.93\t\tLearning rate: 5.456e-04, Batch size: 9, Momentum: 5.258e-02\n",
      "best loss: 3274.59\t\tLearning rate: 1.833e-04, Batch size: 4, Momentum: 3.681e-01\n",
      "best loss: 3307.88\t\tLearning rate: 1.833e-04, Batch size: 4, Momentum: 5.258e-01\n",
      "best loss: 3319.23\t\tLearning rate: 6.158e-05, Batch size: 27, Momentum: 9.990e-01\n",
      "best loss: 3323.46\t\tLearning rate: 5.456e-04, Batch size: 27, Momentum: 1.052e-01\n",
      "best loss: 3337.88\t\tLearning rate: 1.833e-04, Batch size: 24, Momentum: 4.732e-01\n",
      "best loss: 3339.53\t\tLearning rate: 6.158e-05, Batch size: 14, Momentum: 9.464e-01\n",
      "best loss: 3343.58\t\tLearning rate: 1.833e-04, Batch size: 2, Momentum: 5.258e-01\n",
      "best loss: 3375.18\t\tLearning rate: 5.456e-04, Batch size: 27, Momentum: 2.629e-01\n",
      "best loss: 3376.47\t\tLearning rate: 5.456e-04, Batch size: 12, Momentum: 2.103e-01\n",
      "best loss: 3383.52\t\tLearning rate: 2.069e-05, Batch size: 14, Momentum: 9.990e-01\n",
      "best loss: 3419.47\t\tLearning rate: 5.456e-04, Batch size: 50, Momentum: 3.155e-01\n",
      "best loss: 3421.02\t\tLearning rate: 5.456e-04, Batch size: 4, Momentum: 3.155e-01\n",
      "best loss: 3429.04\t\tLearning rate: 5.456e-04, Batch size: 32, Momentum: 3.681e-01\n",
      "best loss: 3443.37\t\tLearning rate: 5.456e-04, Batch size: 14, Momentum: 4.206e-01\n",
      "best loss: 3449.88\t\tLearning rate: 5.456e-04, Batch size: 12, Momentum: 4.206e-01\n",
      "best loss: 3472.81\t\tLearning rate: 5.456e-04, Batch size: 44, Momentum: 4.206e-01\n",
      "best loss: 3518.83\t\tLearning rate: 5.456e-04, Batch size: 24, Momentum: 4.732e-01\n",
      "best loss: 3521.59\t\tLearning rate: 1.833e-04, Batch size: 24, Momentum: 7.887e-01\n",
      "best loss: 3524.32\t\tLearning rate: 1.833e-04, Batch size: 39, Momentum: 7.361e-01\n",
      "best loss: 3527.75\t\tLearning rate: 5.456e-04, Batch size: 50, Momentum: 4.206e-01\n",
      "best loss: 3534.23\t\tLearning rate: 5.456e-04, Batch size: 7, Momentum: 4.206e-01\n",
      "best loss: 3549.23\t\tLearning rate: 1.833e-04, Batch size: 39, Momentum: 8.413e-01\n",
      "best loss: 3550.97\t\tLearning rate: 5.456e-04, Batch size: 27, Momentum: 4.206e-01\n",
      "best loss: 3626.99\t\tLearning rate: 1.833e-04, Batch size: 37, Momentum: 9.464e-01\n",
      "best loss: 3640.81\t\tLearning rate: 1.833e-04, Batch size: 44, Momentum: 7.887e-01\n",
      "best loss: 3666.68\t\tLearning rate: 1.624e-03, Batch size: 4, Momentum: 3.681e-01\n",
      "best loss: 3682.75\t\tLearning rate: 5.456e-04, Batch size: 29, Momentum: 6.835e-01\n",
      "best loss: 3685.05\t\tLearning rate: 1.624e-03, Batch size: 32, Momentum: 2.629e-01\n",
      "best loss: 3694.85\t\tLearning rate: 2.976e-08, Batch size: 17, Momentum: 3.155e-01\n",
      "best loss: 3696.04\t\tLearning rate: 5.456e-04, Batch size: 34, Momentum: 7.887e-01\n",
      "best loss: 3707.91\t\tLearning rate: 1.624e-03, Batch size: 50, Momentum: 3.155e-01\n",
      "best loss: 3714.50\t\tLearning rate: 1.624e-03, Batch size: 9, Momentum: 4.206e-01\n",
      "best loss: 3793.30\t\tLearning rate: 1.833e-04, Batch size: 7, Momentum: 9.990e-01\n",
      "best loss: 3820.20\t\tLearning rate: 5.456e-04, Batch size: 22, Momentum: 8.938e-01\n",
      "best loss: 3821.15\t\tLearning rate: 4.833e-03, Batch size: 12, Momentum: 3.681e-01\n",
      "best loss: 3827.68\t\tLearning rate: 5.456e-04, Batch size: 9, Momentum: 9.464e-01\n",
      "best loss: 3838.58\t\tLearning rate: 1.624e-03, Batch size: 17, Momentum: 7.361e-01\n",
      "best loss: 3843.29\t\tLearning rate: 4.833e-03, Batch size: 34, Momentum: 3.155e-01\n",
      "best loss: 3854.72\t\tLearning rate: 4.833e-03, Batch size: 22, Momentum: 2.629e-01\n",
      "best loss: 3858.18\t\tLearning rate: 5.456e-04, Batch size: 4, Momentum: 9.464e-01\n",
      "best loss: 3858.26\t\tLearning rate: 4.833e-03, Batch size: 29, Momentum: 2.103e-01\n",
      "best loss: 3870.65\t\tLearning rate: 1.624e-03, Batch size: 4, Momentum: 7.887e-01\n",
      "best loss: 3874.54\t\tLearning rate: 4.833e-03, Batch size: 17, Momentum: 2.629e-01\n",
      "best loss: 3880.85\t\tLearning rate: 4.833e-03, Batch size: 4, Momentum: 3.155e-01\n",
      "best loss: 3884.80\t\tLearning rate: 1.624e-03, Batch size: 32, Momentum: 9.464e-01\n",
      "best loss: 3892.28\t\tLearning rate: 4.833e-03, Batch size: 44, Momentum: 3.155e-01\n",
      "best loss: 3894.38\t\tLearning rate: 4.833e-03, Batch size: 39, Momentum: 3.681e-01\n",
      "best loss: 3900.67\t\tLearning rate: 1.624e-03, Batch size: 17, Momentum: 8.413e-01\n",
      "best loss: 3919.51\t\tLearning rate: 1.624e-03, Batch size: 7, Momentum: 7.361e-01\n",
      "best loss: 3926.28\t\tLearning rate: 5.456e-04, Batch size: 19, Momentum: 9.464e-01\n",
      "best loss: 3931.11\t\tLearning rate: 1.624e-03, Batch size: 9, Momentum: 6.835e-01\n",
      "best loss: 3931.17\t\tLearning rate: 4.833e-03, Batch size: 27, Momentum: 6.309e-01\n",
      "best loss: 3943.61\t\tLearning rate: 1.438e-02, Batch size: 2, Momentum: 1.577e-01\n",
      "best loss: 3955.24\t\tLearning rate: 1.624e-03, Batch size: 50, Momentum: 7.887e-01\n",
      "best loss: 3956.47\t\tLearning rate: 1.624e-03, Batch size: 50, Momentum: 8.938e-01\n",
      "best loss: 3959.91\t\tLearning rate: 1.624e-03, Batch size: 4, Momentum: 9.464e-01\n",
      "best loss: 3969.50\t\tLearning rate: 4.833e-03, Batch size: 42, Momentum: 5.784e-01\n",
      "best loss: 3985.42\t\tLearning rate: 4.833e-03, Batch size: 24, Momentum: 4.732e-01\n",
      "best loss: 3993.04\t\tLearning rate: 4.833e-03, Batch size: 12, Momentum: 6.309e-01\n",
      "best loss: 4003.40\t\tLearning rate: 4.833e-03, Batch size: 32, Momentum: 4.732e-01\n",
      "best loss: 4009.44\t\tLearning rate: 4.833e-03, Batch size: 50, Momentum: 6.309e-01\n",
      "best loss: 4020.73\t\tLearning rate: 4.833e-03, Batch size: 44, Momentum: 8.413e-01\n",
      "best loss: 4027.26\t\tLearning rate: 1.438e-02, Batch size: 2, Momentum: 0.000e+00\n",
      "best loss: 4034.41\t\tLearning rate: 1.624e-03, Batch size: 24, Momentum: 8.938e-01\n",
      "best loss: 4037.42\t\tLearning rate: 1.438e-02, Batch size: 9, Momentum: 2.103e-01\n",
      "best loss: 4067.53\t\tLearning rate: 1.624e-03, Batch size: 34, Momentum: 8.938e-01\n",
      "best loss: 4070.79\t\tLearning rate: 1.624e-03, Batch size: 7, Momentum: 9.990e-01\n",
      "best loss: 4078.87\t\tLearning rate: 4.833e-03, Batch size: 32, Momentum: 7.887e-01\n",
      "best loss: 4085.76\t\tLearning rate: 1.624e-03, Batch size: 39, Momentum: 9.464e-01\n",
      "best loss: 4097.69\t\tLearning rate: 4.833e-03, Batch size: 37, Momentum: 7.361e-01\n",
      "best loss: 4111.19\t\tLearning rate: 4.833e-03, Batch size: 47, Momentum: 6.835e-01\n",
      "best loss: 4138.85\t\tLearning rate: 1.624e-03, Batch size: 9, Momentum: 9.990e-01\n",
      "best loss: 4164.26\t\tLearning rate: 1.438e-02, Batch size: 32, Momentum: 2.103e-01\n",
      "best loss: 4168.78\t\tLearning rate: 1.438e-02, Batch size: 39, Momentum: 4.732e-01\n",
      "best loss: 4170.79\t\tLearning rate: 4.833e-03, Batch size: 27, Momentum: 7.361e-01\n",
      "best loss: 4188.27\t\tLearning rate: 4.833e-03, Batch size: 22, Momentum: 8.938e-01\n",
      "best loss: 4191.31\t\tLearning rate: 4.281e-02, Batch size: 9, Momentum: 2.103e-01\n",
      "best loss: 4207.21\t\tLearning rate: 4.833e-03, Batch size: 42, Momentum: 7.887e-01\n",
      "best loss: 4207.75\t\tLearning rate: 4.281e-02, Batch size: 50, Momentum: 2.103e-01\n",
      "best loss: 4228.28\t\tLearning rate: 1.438e-02, Batch size: 34, Momentum: 5.258e-01\n",
      "best loss: 4245.89\t\tLearning rate: 4.281e-02, Batch size: 32, Momentum: 3.155e-01\n",
      "best loss: 4253.86\t\tLearning rate: 4.281e-02, Batch size: 47, Momentum: 2.629e-01\n",
      "best loss: 4256.17\t\tLearning rate: 4.281e-02, Batch size: 14, Momentum: 3.681e-01\n",
      "best loss: 4262.86\t\tLearning rate: 1.438e-02, Batch size: 37, Momentum: 5.784e-01\n",
      "best loss: 4266.77\t\tLearning rate: 4.281e-02, Batch size: 12, Momentum: 2.103e-01\n",
      "best loss: 4270.89\t\tLearning rate: 4.281e-02, Batch size: 32, Momentum: 5.258e-01\n",
      "best loss: 4295.21\t\tLearning rate: 4.281e-02, Batch size: 7, Momentum: 6.835e-01\n",
      "best loss: 4308.54\t\tLearning rate: 1.438e-02, Batch size: 17, Momentum: 6.309e-01\n",
      "best loss: 4312.14\t\tLearning rate: 1.274e-01, Batch size: 24, Momentum: 5.258e-02\n",
      "best loss: 4341.25\t\tLearning rate: 1.438e-02, Batch size: 37, Momentum: 7.887e-01\n",
      "best loss: 4346.86\t\tLearning rate: 4.281e-02, Batch size: 34, Momentum: 6.309e-01\n",
      "best loss: 4348.49\t\tLearning rate: 1.274e-01, Batch size: 32, Momentum: 1.577e-01\n",
      "best loss: 4364.35\t\tLearning rate: 1.438e-02, Batch size: 37, Momentum: 6.835e-01\n",
      "best loss: 4370.67\t\tLearning rate: 4.281e-02, Batch size: 22, Momentum: 5.258e-01\n",
      "best loss: 4377.48\t\tLearning rate: 1.438e-02, Batch size: 47, Momentum: 7.361e-01\n",
      "best loss: 4386.26\t\tLearning rate: 4.281e-02, Batch size: 44, Momentum: 4.206e-01\n",
      "best loss: 4402.68\t\tLearning rate: 1.438e-02, Batch size: 9, Momentum: 8.413e-01\n",
      "best loss: 4420.76\t\tLearning rate: 1.438e-02, Batch size: 4, Momentum: 9.464e-01\n",
      "best loss: 4442.93\t\tLearning rate: 1.274e-01, Batch size: 44, Momentum: 1.577e-01\n",
      "best loss: 4446.49\t\tLearning rate: 1.438e-02, Batch size: 44, Momentum: 8.413e-01\n",
      "best loss: 4461.62\t\tLearning rate: 4.281e-02, Batch size: 39, Momentum: 4.732e-01\n",
      "best loss: 4461.82\t\tLearning rate: 4.281e-02, Batch size: 9, Momentum: 5.784e-01\n",
      "best loss: 4489.63\t\tLearning rate: 1.274e-01, Batch size: 9, Momentum: 3.681e-01\n",
      "best loss: 4491.04\t\tLearning rate: 1.274e-01, Batch size: 50, Momentum: 2.103e-01\n",
      "best loss: 4492.85\t\tLearning rate: 1.274e-01, Batch size: 19, Momentum: 5.258e-01\n",
      "best loss: 4520.30\t\tLearning rate: 1.274e-01, Batch size: 9, Momentum: 3.155e-01\n",
      "best loss: 4529.38\t\tLearning rate: 4.281e-02, Batch size: 50, Momentum: 7.361e-01\n",
      "best loss: 4532.28\t\tLearning rate: 1.274e-01, Batch size: 4, Momentum: 3.681e-01\n",
      "best loss: 4558.68\t\tLearning rate: 1.274e-01, Batch size: 2, Momentum: 3.681e-01\n",
      "best loss: 4564.70\t\tLearning rate: 1.274e-01, Batch size: 17, Momentum: 6.309e-01\n",
      "best loss: 4588.91\t\tLearning rate: 3.793e-01, Batch size: 14, Momentum: 3.155e-01\n",
      "best loss: 4595.83\t\tLearning rate: 1.274e-01, Batch size: 39, Momentum: 4.732e-01\n",
      "best loss: 4598.61\t\tLearning rate: 1.274e-01, Batch size: 47, Momentum: 5.258e-01\n",
      "best loss: 4633.64\t\tLearning rate: 4.281e-02, Batch size: 19, Momentum: 7.887e-01\n",
      "best loss: 4637.39\t\tLearning rate: 3.793e-01, Batch size: 7, Momentum: 1.577e-01\n",
      "best loss: 4637.67\t\tLearning rate: 4.281e-02, Batch size: 9, Momentum: 8.413e-01\n",
      "best loss: 4638.97\t\tLearning rate: 4.281e-02, Batch size: 47, Momentum: 8.413e-01\n",
      "best loss: 4672.48\t\tLearning rate: 3.793e-01, Batch size: 32, Momentum: 1.577e-01\n",
      "best loss: 4677.78\t\tLearning rate: 1.274e-01, Batch size: 29, Momentum: 2.629e-01\n",
      "best loss: 4681.94\t\tLearning rate: 3.793e-01, Batch size: 37, Momentum: 2.103e-01\n",
      "best loss: 4682.23\t\tLearning rate: 4.281e-02, Batch size: 27, Momentum: 8.413e-01\n",
      "best loss: 4682.94\t\tLearning rate: 1.274e-01, Batch size: 9, Momentum: 6.835e-01\n",
      "best loss: 4690.52\t\tLearning rate: 1.438e-02, Batch size: 27, Momentum: 9.990e-01\n",
      "best loss: 4741.98\t\tLearning rate: 3.793e-01, Batch size: 50, Momentum: 3.681e-01\n",
      "best loss: 4769.88\t\tLearning rate: 3.793e-01, Batch size: 22, Momentum: 1.577e-01\n",
      "best loss: 4781.95\t\tLearning rate: 1.274e-01, Batch size: 47, Momentum: 7.887e-01\n",
      "best loss: 4794.72\t\tLearning rate: 3.793e-01, Batch size: 9, Momentum: 1.577e-01\n",
      "best loss: 4805.91\t\tLearning rate: 3.793e-01, Batch size: 44, Momentum: 4.206e-01\n",
      "best loss: 4816.07\t\tLearning rate: 1.274e-01, Batch size: 4, Momentum: 8.938e-01\n",
      "best loss: 4838.55\t\tLearning rate: 3.793e-01, Batch size: 12, Momentum: 5.784e-01\n",
      "best loss: 4884.17\t\tLearning rate: 1.129e+00, Batch size: 47, Momentum: 2.629e-01\n",
      "best loss: 4888.88\t\tLearning rate: 3.793e-01, Batch size: 44, Momentum: 5.784e-01\n",
      "best loss: 4894.23\t\tLearning rate: 3.793e-01, Batch size: 19, Momentum: 8.938e-01\n",
      "best loss: 4901.19\t\tLearning rate: 1.274e-01, Batch size: 37, Momentum: 9.464e-01\n",
      "best loss: 4912.30\t\tLearning rate: 3.793e-01, Batch size: 50, Momentum: 6.309e-01\n",
      "best loss: 4932.56\t\tLearning rate: 1.129e+00, Batch size: 4, Momentum: 2.103e-01\n",
      "best loss: 4973.33\t\tLearning rate: 1.129e+00, Batch size: 44, Momentum: 3.155e-01\n",
      "best loss: 4991.80\t\tLearning rate: 1.274e-01, Batch size: 47, Momentum: 9.990e-01\n",
      "best loss: 5012.09\t\tLearning rate: 3.793e-01, Batch size: 29, Momentum: 7.887e-01\n",
      "best loss: 5025.33\t\tLearning rate: 1.129e+00, Batch size: 47, Momentum: 3.681e-01\n",
      "best loss: 5039.35\t\tLearning rate: 1.129e+00, Batch size: 4, Momentum: 4.732e-01\n",
      "best loss: 5055.59\t\tLearning rate: 3.793e-01, Batch size: 32, Momentum: 7.361e-01\n",
      "best loss: 5057.62\t\tLearning rate: 1.274e-01, Batch size: 50, Momentum: 9.990e-01\n",
      "best loss: 5059.51\t\tLearning rate: 1.274e-01, Batch size: 47, Momentum: 9.464e-01\n",
      "best loss: 5089.60\t\tLearning rate: 1.129e+00, Batch size: 44, Momentum: 5.784e-01\n",
      "best loss: 5092.59\t\tLearning rate: 3.793e-01, Batch size: 24, Momentum: 8.413e-01\n",
      "best loss: 5101.17\t\tLearning rate: 3.360e+00, Batch size: 29, Momentum: 2.629e-01\n",
      "best loss: 5113.35\t\tLearning rate: 3.793e-01, Batch size: 7, Momentum: 7.887e-01\n",
      "best loss: 5117.62\t\tLearning rate: 3.360e+00, Batch size: 12, Momentum: 4.206e-01\n",
      "best loss: 5117.63\t\tLearning rate: 1.129e+00, Batch size: 32, Momentum: 5.258e-01\n",
      "best loss: 5126.40\t\tLearning rate: 3.793e-01, Batch size: 37, Momentum: 8.413e-01\n",
      "best loss: 5130.44\t\tLearning rate: 1.129e+00, Batch size: 39, Momentum: 6.835e-01\n",
      "best loss: 5130.67\t\tLearning rate: 1.129e+00, Batch size: 29, Momentum: 6.309e-01\n",
      "best loss: 5147.78\t\tLearning rate: 3.793e-01, Batch size: 14, Momentum: 8.938e-01\n",
      "best loss: 5164.62\t\tLearning rate: 3.793e-01, Batch size: 39, Momentum: 9.464e-01\n",
      "best loss: 5183.08\t\tLearning rate: 3.360e+00, Batch size: 44, Momentum: 3.681e-01\n",
      "best loss: 5190.42\t\tLearning rate: 3.793e-01, Batch size: 14, Momentum: 9.464e-01\n",
      "best loss: 5200.43\t\tLearning rate: 1.129e+00, Batch size: 34, Momentum: 6.835e-01\n",
      "best loss: 5218.70\t\tLearning rate: 1.129e+00, Batch size: 47, Momentum: 7.887e-01\n",
      "best loss: 5226.78\t\tLearning rate: 3.793e-01, Batch size: 34, Momentum: 9.464e-01\n",
      "best loss: 5248.57\t\tLearning rate: 3.793e-01, Batch size: 32, Momentum: 9.990e-01\n",
      "best loss: 5248.89\t\tLearning rate: 1.129e+00, Batch size: 22, Momentum: 8.413e-01\n",
      "best loss: 5307.05\t\tLearning rate: 3.360e+00, Batch size: 34, Momentum: 4.206e-01\n",
      "best loss: 5326.00\t\tLearning rate: 3.360e+00, Batch size: 29, Momentum: 5.258e-01\n",
      "best loss: 5365.96\t\tLearning rate: 3.360e+00, Batch size: 42, Momentum: 6.309e-01\n",
      "best loss: 5368.17\t\tLearning rate: 1.000e+01, Batch size: 12, Momentum: 3.681e-01\n",
      "best loss: 5383.33\t\tLearning rate: 1.129e+00, Batch size: 50, Momentum: 9.464e-01\n",
      "best loss: 5388.22\t\tLearning rate: 1.000e+01, Batch size: 37, Momentum: 2.103e-01\n",
      "best loss: 5416.21\t\tLearning rate: 3.360e+00, Batch size: 19, Momentum: 6.835e-01\n",
      "best loss: 5448.16\t\tLearning rate: 1.000e+01, Batch size: 37, Momentum: 3.681e-01\n",
      "best loss: 5453.04\t\tLearning rate: 3.360e+00, Batch size: 29, Momentum: 8.938e-01\n",
      "best loss: 5470.67\t\tLearning rate: 1.129e+00, Batch size: 24, Momentum: 9.990e-01\n",
      "best loss: 5531.36\t\tLearning rate: 3.360e+00, Batch size: 50, Momentum: 8.413e-01\n",
      "best loss: 5589.72\t\tLearning rate: 1.000e+01, Batch size: 22, Momentum: 4.732e-01\n",
      "best loss: 5595.95\t\tLearning rate: 1.000e+01, Batch size: 37, Momentum: 5.784e-01\n",
      "best loss: 5615.59\t\tLearning rate: 3.360e+00, Batch size: 50, Momentum: 9.464e-01\n",
      "best loss: 5651.95\t\tLearning rate: 1.000e+01, Batch size: 17, Momentum: 6.835e-01\n",
      "best loss: 5677.15\t\tLearning rate: 1.000e+01, Batch size: 17, Momentum: 7.361e-01\n",
      "best loss: 5684.87\t\tLearning rate: 3.360e+00, Batch size: 44, Momentum: 9.464e-01\n",
      "best loss: 5700.99\t\tLearning rate: 1.000e+01, Batch size: 44, Momentum: 7.361e-01\n",
      "best loss: 5720.46\t\tLearning rate: 1.000e+01, Batch size: 34, Momentum: 7.887e-01\n",
      "best loss: 5731.73\t\tLearning rate: 3.360e+00, Batch size: 9, Momentum: 9.990e-01\n",
      "best loss: 5740.98\t\tLearning rate: 1.000e+01, Batch size: 44, Momentum: 7.887e-01\n",
      "best loss: 5779.39\t\tLearning rate: 1.000e+01, Batch size: 12, Momentum: 7.887e-01\n",
      "best loss: 5816.34\t\tLearning rate: 1.000e+01, Batch size: 14, Momentum: 8.413e-01\n",
      "best loss: 5833.79\t\tLearning rate: 1.000e+01, Batch size: 2, Momentum: 8.413e-01\n",
      "best loss: 5928.86\t\tLearning rate: 1.000e+01, Batch size: 24, Momentum: 9.990e-01\n",
      "best loss: 6024.08\t\tLearning rate: 1.000e+01, Batch size: 47, Momentum: 9.990e-01\n",
      "best loss: 8461.97\t\tLearning rate: 4.833e-03, Batch size: 2, Momentum: 1.577e-01\n",
      "best loss: 8570.43\t\tLearning rate: 8.859e-08, Batch size: 4, Momentum: 6.309e-01\n",
      "best loss: 9566.93\t\tLearning rate: 6.158e-05, Batch size: 4, Momentum: 5.258e-02\n",
      "best loss: 12648.80\t\tLearning rate: 1.000e-08, Batch size: 4, Momentum: 5.258e-02\n",
      "best loss: 13196.67\t\tLearning rate: 8.859e-08, Batch size: 17, Momentum: 5.784e-01\n",
      "best loss: 16480.78\t\tLearning rate: 3.793e-01, Batch size: 7, Momentum: 3.681e-01\n",
      "best loss: 20354.27\t\tLearning rate: 2.069e-05, Batch size: 17, Momentum: 5.784e-01\n",
      "best loss: 25896.27\t\tLearning rate: 2.976e-08, Batch size: 14, Momentum: 5.784e-01\n",
      "best loss: 27058.79\t\tLearning rate: 2.976e-08, Batch size: 24, Momentum: 5.258e-02\n",
      "best loss: 29175.92\t\tLearning rate: 2.976e-08, Batch size: 12, Momentum: 8.413e-01\n",
      "best loss: 32798.03\t\tLearning rate: 2.976e-08, Batch size: 7, Momentum: 5.258e-02\n",
      "best loss: 35771.62\t\tLearning rate: 2.976e-08, Batch size: 19, Momentum: 0.000e+00\n",
      "best loss: 37142.94\t\tLearning rate: 3.360e+00, Batch size: 24, Momentum: 2.103e-01\n",
      "best loss: 39698.77\t\tLearning rate: 2.069e-05, Batch size: 14, Momentum: 5.784e-01\n",
      "best loss: 45411.47\t\tLearning rate: 2.976e-08, Batch size: 32, Momentum: 6.309e-01\n",
      "best loss: 47029.85\t\tLearning rate: 2.637e-07, Batch size: 50, Momentum: 5.258e-01\n",
      "best loss: 50994.03\t\tLearning rate: 1.000e-08, Batch size: 32, Momentum: 3.155e-01\n",
      "best loss: 51970.30\t\tLearning rate: 2.976e-08, Batch size: 37, Momentum: 7.887e-01\n",
      "best loss: 54922.77\t\tLearning rate: 3.793e-01, Batch size: 37, Momentum: 0.000e+00\n",
      "best loss: 55652.48\t\tLearning rate: 2.637e-07, Batch size: 29, Momentum: 3.681e-01\n",
      "best loss: 56791.82\t\tLearning rate: 1.438e-02, Batch size: 17, Momentum: 3.155e-01\n",
      "best loss: 59757.87\t\tLearning rate: 5.456e-04, Batch size: 17, Momentum: 2.629e-01\n",
      "best loss: 62924.41\t\tLearning rate: 1.438e-02, Batch size: 4, Momentum: 0.000e+00\n",
      "best loss: 64461.15\t\tLearning rate: 2.976e-08, Batch size: 14, Momentum: 0.000e+00\n",
      "best loss: 71122.17\t\tLearning rate: 3.793e-01, Batch size: 7, Momentum: 5.258e-02\n",
      "best loss: 76508.28\t\tLearning rate: 2.976e-08, Batch size: 12, Momentum: 7.361e-01\n",
      "best loss: 77859.16\t\tLearning rate: 8.859e-08, Batch size: 14, Momentum: 3.681e-01\n",
      "best loss: 81392.61\t\tLearning rate: 2.637e-07, Batch size: 39, Momentum: 1.577e-01\n",
      "best loss: 86673.67\t\tLearning rate: 2.976e-08, Batch size: 19, Momentum: 3.681e-01\n",
      "best loss: 88464.89\t\tLearning rate: 1.000e+01, Batch size: 29, Momentum: 0.000e+00\n",
      "best loss: 93882.77\t\tLearning rate: 3.360e+00, Batch size: 32, Momentum: 1.052e-01\n",
      "best loss: 98022.92\t\tLearning rate: 2.976e-08, Batch size: 12, Momentum: 1.577e-01\n",
      "best loss: 101484.17\t\tLearning rate: 1.000e-08, Batch size: 47, Momentum: 3.155e-01\n",
      "best loss: 109617.35\t\tLearning rate: 1.000e-08, Batch size: 17, Momentum: 1.052e-01\n",
      "best loss: 113975.21\t\tLearning rate: 6.158e-05, Batch size: 17, Momentum: 1.577e-01\n",
      "best loss: 116458.73\t\tLearning rate: 2.976e-08, Batch size: 7, Momentum: 3.155e-01\n",
      "best loss: 125937.10\t\tLearning rate: 1.000e-08, Batch size: 42, Momentum: 5.784e-01\n",
      "best loss: 135767.82\t\tLearning rate: 3.360e+00, Batch size: 9, Momentum: 3.681e-01\n",
      "best loss: 135882.73\t\tLearning rate: 8.859e-08, Batch size: 27, Momentum: 4.732e-01\n",
      "best loss: 141979.90\t\tLearning rate: 2.976e-08, Batch size: 44, Momentum: 1.052e-01\n",
      "best loss: 143285.94\t\tLearning rate: 1.000e-08, Batch size: 27, Momentum: 4.206e-01\n",
      "best loss: 148098.49\t\tLearning rate: 1.833e-04, Batch size: 12, Momentum: 1.052e-01\n",
      "best loss: 160883.37\t\tLearning rate: 8.859e-08, Batch size: 27, Momentum: 5.258e-02\n",
      "best loss: 168204.68\t\tLearning rate: 1.129e+00, Batch size: 44, Momentum: 4.206e-01\n",
      "best loss: 170491.27\t\tLearning rate: 5.456e-04, Batch size: 12, Momentum: 0.000e+00\n",
      "best loss: 179384.81\t\tLearning rate: 2.637e-07, Batch size: 37, Momentum: 1.052e-01\n",
      "best loss: 196431.36\t\tLearning rate: 1.624e-03, Batch size: 2, Momentum: 3.155e-01\n",
      "best loss: 196484.28\t\tLearning rate: 2.976e-08, Batch size: 50, Momentum: 6.309e-01\n",
      "best loss: 212229.90\t\tLearning rate: 8.859e-08, Batch size: 42, Momentum: 5.784e-01\n",
      "best loss: 225296.33\t\tLearning rate: 2.069e-05, Batch size: 17, Momentum: 0.000e+00\n",
      "best loss: 255963.54\t\tLearning rate: 1.129e+00, Batch size: 14, Momentum: 1.577e-01\n",
      "best loss: 259627.67\t\tLearning rate: 2.069e-05, Batch size: 32, Momentum: 5.258e-01\n",
      "best loss: 265759.82\t\tLearning rate: 1.129e+00, Batch size: 47, Momentum: 5.258e-02\n",
      "best loss: 287234.04\t\tLearning rate: 2.976e-08, Batch size: 14, Momentum: 5.258e-01\n",
      "best loss: 313885.67\t\tLearning rate: 4.281e-02, Batch size: 22, Momentum: 2.103e-01\n",
      "best loss: 314617.90\t\tLearning rate: 2.637e-07, Batch size: 17, Momentum: 4.206e-01\n",
      "best loss: 330813.87\t\tLearning rate: 2.976e-08, Batch size: 42, Momentum: 6.835e-01\n",
      "best loss: 342082.14\t\tLearning rate: 1.000e+01, Batch size: 19, Momentum: 0.000e+00\n",
      "best loss: 344459.41\t\tLearning rate: 8.859e-08, Batch size: 34, Momentum: 5.784e-01\n",
      "best loss: 347270.33\t\tLearning rate: 1.624e-03, Batch size: 47, Momentum: 0.000e+00\n",
      "best loss: 358384.93\t\tLearning rate: 2.637e-07, Batch size: 24, Momentum: 2.629e-01\n",
      "best loss: 407647.29\t\tLearning rate: 8.859e-08, Batch size: 32, Momentum: 6.835e-01\n",
      "best loss: 407865.73\t\tLearning rate: 1.000e-08, Batch size: 32, Momentum: 1.577e-01\n",
      "best loss: 412141.73\t\tLearning rate: 1.833e-04, Batch size: 42, Momentum: 3.155e-01\n",
      "best loss: 425030.40\t\tLearning rate: 4.833e-03, Batch size: 34, Momentum: 0.000e+00\n",
      "best loss: 440054.23\t\tLearning rate: 1.624e-03, Batch size: 32, Momentum: 5.258e-02\n",
      "best loss: 457751.04\t\tLearning rate: 6.158e-05, Batch size: 34, Momentum: 4.732e-01\n",
      "best loss: 497084.48\t\tLearning rate: 4.833e-03, Batch size: 22, Momentum: 5.258e-02\n",
      "best loss: 511248.74\t\tLearning rate: 2.069e-05, Batch size: 42, Momentum: 1.577e-01\n",
      "best loss: 544547.16\t\tLearning rate: 2.976e-08, Batch size: 27, Momentum: 5.784e-01\n",
      "best loss: 589528.31\t\tLearning rate: 3.793e-01, Batch size: 24, Momentum: 3.155e-01\n",
      "best loss: 599018.91\t\tLearning rate: 6.952e-06, Batch size: 34, Momentum: 2.103e-01\n",
      "best loss: 769895.95\t\tLearning rate: 2.976e-08, Batch size: 50, Momentum: 2.629e-01\n",
      "best loss: 884320.92\t\tLearning rate: 4.281e-02, Batch size: 44, Momentum: 2.629e-01\n",
      "best loss: 886650.32\t\tLearning rate: 2.069e-05, Batch size: 29, Momentum: 3.155e-01\n",
      "best loss: 912777.54\t\tLearning rate: 2.976e-08, Batch size: 34, Momentum: 2.103e-01\n",
      "best loss: 920751.89\t\tLearning rate: 1.000e+01, Batch size: 47, Momentum: 2.103e-01\n",
      "best loss: 1015666.59\t\tLearning rate: 4.281e-02, Batch size: 27, Momentum: 0.000e+00\n",
      "best loss: 1057827.40\t\tLearning rate: 4.281e-02, Batch size: 42, Momentum: 3.681e-01\n",
      "best loss: 1213584.55\t\tLearning rate: 1.624e-03, Batch size: 47, Momentum: 4.732e-01\n",
      "best loss: 1239950.17\t\tLearning rate: 1.438e-02, Batch size: 4, Momentum: 5.258e-02\n",
      "best loss: 1485476.30\t\tLearning rate: 2.069e-05, Batch size: 50, Momentum: 3.155e-01\n",
      "best loss: 1913349.52\t\tLearning rate: 1.833e-04, Batch size: 19, Momentum: 5.258e-02\n",
      "best loss: 1992032.50\t\tLearning rate: 4.281e-02, Batch size: 7, Momentum: 1.052e-01\n",
      "best loss: 2021942.56\t\tLearning rate: 6.158e-05, Batch size: 37, Momentum: 5.258e-02\n",
      "best loss: 2471216.21\t\tLearning rate: 4.833e-03, Batch size: 22, Momentum: 0.000e+00\n",
      "best loss: 2510129.51\t\tLearning rate: 1.000e+01, Batch size: 47, Momentum: 0.000e+00\n",
      "best loss: 2935639.11\t\tLearning rate: 2.069e-05, Batch size: 27, Momentum: 4.206e-01\n",
      "best loss: 2965675.66\t\tLearning rate: 1.624e-03, Batch size: 34, Momentum: 5.258e-02\n",
      "best loss: 3016867.83\t\tLearning rate: 6.158e-05, Batch size: 37, Momentum: 1.052e-01\n",
      "best loss: 3279520.96\t\tLearning rate: 4.281e-02, Batch size: 17, Momentum: 1.577e-01\n",
      "best loss: 3893347.19\t\tLearning rate: 3.793e-01, Batch size: 27, Momentum: 4.732e-01\n",
      "best loss: 4047270.65\t\tLearning rate: 3.360e+00, Batch size: 42, Momentum: 6.835e-01\n",
      "best loss: 4140529.83\t\tLearning rate: 1.438e-02, Batch size: 9, Momentum: 0.000e+00\n",
      "best loss: 4389511.56\t\tLearning rate: 1.624e-03, Batch size: 42, Momentum: 0.000e+00\n",
      "best loss: 5507673.74\t\tLearning rate: 4.281e-02, Batch size: 34, Momentum: 0.000e+00\n",
      "best loss: 6583909.96\t\tLearning rate: 1.438e-02, Batch size: 44, Momentum: 3.155e-01\n",
      "best loss: 11872639.83\t\tLearning rate: 3.360e+00, Batch size: 44, Momentum: 2.103e-01\n",
      "best loss: 12175916.22\t\tLearning rate: 5.456e-04, Batch size: 2, Momentum: 1.052e-01\n",
      "best loss: 17796749.42\t\tLearning rate: 1.274e-01, Batch size: 9, Momentum: 5.258e-01\n"
     ]
    }
   ],
   "source": [
    "# print the hyperparameters ranked from best to worst\n",
    "sorted_results = sorted(results.items(), key=lambda x: x[1])\n",
    "for hp, loss in sorted_results:\n",
    "    print(f\"best loss: {loss:.2f}\\t\\tLearning rate: {hp[0]:.3e}, Batch size: {hp[1]}, Momentum: {hp[2]:.3e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phenotypes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
