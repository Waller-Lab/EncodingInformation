{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solve for Gaussian approximations using optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening BSCCM\n",
      "Opened BSCCM\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# this only works on startup!\n",
    "from jax import config\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "from gpu_utils import limit_gpu_memory_growth\n",
    "limit_gpu_memory_growth()\n",
    "\n",
    "from cleanplots import *\n",
    "from tqdm import tqdm\n",
    "from information_estimation import *\n",
    "from image_utils import *\n",
    "from gaussian_process_utils import *\n",
    "\n",
    "from led_array.bsccm_utils import *\n",
    "from bsccm import BSCCM\n",
    "from jax import jit\n",
    "import numpy as onp\n",
    "import jax.numpy as np\n",
    "\n",
    "bsccm = BSCCM('/home/hpinkard_waller/data/BSCCM/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images, extract patches, and compute cov mats\n",
    "edge_crop = 32\n",
    "patch_size = 10\n",
    "num_images = 20000\n",
    "num_patches = 10000\n",
    "channel = 'LED119'\n",
    "eigenvalue_floor = 1e0\n",
    "\n",
    "images = load_bsccm_images(bsccm, channel=channel, num_images=num_images, edge_crop=edge_crop, median_filter=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search through hyperparameter combos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss:  456.54402027314313\n",
      "best loss: 460.61\t\tLearning rate: 5.456e-04, Batch size: 22, Momentum: 2.103e-01\n",
      "Initial loss:  456.9363668494204\n",
      "best loss: 458.07\t\tLearning rate: 4.833e-03, Batch size: 42, Momentum: 8.413e-01\n",
      "Initial loss:  452.5278359500718\n",
      "Iteration 540, validation loss: 455.73139949548415\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/hpinkard_waller/GitRepos/EncodingInformation/modeling_and_mi_estimation/optimization hparam search (early_stopping)/optimizing_gaussian_fits.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bwaller-fuoco.eecs.berkeley.edu/home/hpinkard_waller/GitRepos/EncodingInformation/modeling_and_mi_estimation/optimization%20hparam%20search%20%28early_stopping%29/optimizing_gaussian_fits.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m best_hp_loss \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39minf\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bwaller-fuoco.eecs.berkeley.edu/home/hpinkard_waller/GitRepos/EncodingInformation/modeling_and_mi_estimation/optimization%20hparam%20search%20%28early_stopping%29/optimizing_gaussian_fits.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m patches \u001b[39m=\u001b[39m extract_patches(images, patch_size, num_patches\u001b[39m=\u001b[39mnum_patches, seed\u001b[39m=\u001b[39mi)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bwaller-fuoco.eecs.berkeley.edu/home/hpinkard_waller/GitRepos/EncodingInformation/modeling_and_mi_estimation/optimization%20hparam%20search%20%28early_stopping%29/optimizing_gaussian_fits.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m best_cov_mat, cov_mat_initial, mean_vec, best_loss, train_loss_history, val_loss_history \u001b[39m=\u001b[39m run_optimization(patches, momentum, learning_rate, batch_size, eigenvalue_floor\u001b[39m=\u001b[39;49m\u001b[39m1e-3\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bwaller-fuoco.eecs.berkeley.edu/home/hpinkard_waller/GitRepos/EncodingInformation/modeling_and_mi_estimation/optimization%20hparam%20search%20%28early_stopping%29/optimizing_gaussian_fits.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mif\u001b[39;00m best_loss \u001b[39m<\u001b[39m best_hp_loss:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bwaller-fuoco.eecs.berkeley.edu/home/hpinkard_waller/GitRepos/EncodingInformation/modeling_and_mi_estimation/optimization%20hparam%20search%20%28early_stopping%29/optimizing_gaussian_fits.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m     best_hp_loss \u001b[39m=\u001b[39m best_loss\n",
      "File \u001b[0;32m~/GitRepos/EncodingInformation/gaussian_process_utils.py:479\u001b[0m, in \u001b[0;36mrun_optimization\u001b[0;34m(data, momentum, learning_rate, batch_size, eigenvalue_floor, patience, validation_fraction, max_iters)\u001b[0m\n\u001b[1;32m    474\u001b[0m eigvals, eig_vecs, velocity, train_loss \u001b[39m=\u001b[39m optmization_step(eigvals, eig_vecs, velocity, \n\u001b[1;32m    475\u001b[0m                                                      batch, mean_vec, momentum, learning_rate, eigenvalue_floor, patch_size)\n\u001b[1;32m    477\u001b[0m train_loss_history\u001b[39m.\u001b[39mappend(train_loss)\n\u001b[0;32m--> 479\u001b[0m validation_loss \u001b[39m=\u001b[39m loss_function(eigvals, eig_vecs, mean_vec, validation_data)   \n\u001b[1;32m    480\u001b[0m validation_loss_history\u001b[39m.\u001b[39mappend(validation_loss)\n\u001b[1;32m    482\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIteration \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, validation loss: \u001b[39m\u001b[39m{\u001b[39;00mvalidation_loss\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m, end\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\r\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/GitRepos/EncodingInformation/gaussian_process_utils.py:409\u001b[0m, in \u001b[0;36mloss_function\u001b[0;34m(eigvals, eig_vecs, mean_vec, data)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mloss_function\u001b[39m(eigvals, eig_vecs, mean_vec, data):\n\u001b[1;32m    408\u001b[0m     cov_mat \u001b[39m=\u001b[39m eig_vecs \u001b[39m@\u001b[39m np\u001b[39m.\u001b[39mdiag(eigvals) \u001b[39m@\u001b[39m eig_vecs\u001b[39m.\u001b[39mT\n\u001b[0;32m--> 409\u001b[0m     ll \u001b[39m=\u001b[39m gaussian_likelihood(cov_mat, mean_vec, data)\n\u001b[1;32m    410\u001b[0m     \u001b[39mreturn\u001b[39;00m batch_nll(ll)\n",
      "File \u001b[0;32m~/GitRepos/EncodingInformation/gaussian_process_utils.py:400\u001b[0m, in \u001b[0;36mgaussian_likelihood\u001b[0;34m(cov_mat, mean_vec, batch)\u001b[0m\n\u001b[1;32m    398\u001b[0m log_likelihoods \u001b[39m=\u001b[39m []\n\u001b[1;32m    399\u001b[0m \u001b[39mfor\u001b[39;00m sample \u001b[39min\u001b[39;00m batch:\n\u001b[0;32m--> 400\u001b[0m     ll \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39;49mscipy\u001b[39m.\u001b[39;49mstats\u001b[39m.\u001b[39;49mmultivariate_normal\u001b[39m.\u001b[39;49mlogpdf(sample\u001b[39m.\u001b[39;49mreshape(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m), mean\u001b[39m=\u001b[39;49mmean_vec, cov\u001b[39m=\u001b[39;49mcov_mat)\n\u001b[1;32m    401\u001b[0m     log_likelihoods\u001b[39m.\u001b[39mappend(ll)\n\u001b[1;32m    402\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray(log_likelihoods)\n",
      "File \u001b[0;32m~/mambaforge/envs/phenotypes/lib/python3.10/site-packages/jax/_src/scipy/stats/multivariate_normal.py:46\u001b[0m, in \u001b[0;36mlogpdf\u001b[0;34m(x, mean, cov, allow_singular)\u001b[0m\n\u001b[1;32m     44\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mmultivariate_normal.logpdf got incompatible shapes\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     45\u001b[0m L \u001b[39m=\u001b[39m lax\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39mcholesky(cov)\n\u001b[0;32m---> 46\u001b[0m y \u001b[39m=\u001b[39m jnp\u001b[39m.\u001b[39;49mvectorize(\n\u001b[1;32m     47\u001b[0m   partial(lax\u001b[39m.\u001b[39;49mlinalg\u001b[39m.\u001b[39;49mtriangular_solve, lower\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, transpose_a\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m),\n\u001b[1;32m     48\u001b[0m   signature\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m(n,n),(n)->(n)\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m     49\u001b[0m )(L, x \u001b[39m-\u001b[39;49m mean)\n\u001b[1;32m     50\u001b[0m \u001b[39mreturn\u001b[39;00m (\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m \u001b[39m*\u001b[39m jnp\u001b[39m.\u001b[39meinsum(\u001b[39m'\u001b[39m\u001b[39m...i,...i->...\u001b[39m\u001b[39m'\u001b[39m, y, y) \u001b[39m-\u001b[39m n\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m \u001b[39m*\u001b[39m jnp\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m\u001b[39m*\u001b[39mnp\u001b[39m.\u001b[39mpi)\n\u001b[1;32m     51\u001b[0m         \u001b[39m-\u001b[39m jnp\u001b[39m.\u001b[39mlog(L\u001b[39m.\u001b[39mdiagonal(axis1\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, axis2\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m))\u001b[39m.\u001b[39msum(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n",
      "File \u001b[0;32m~/mambaforge/envs/phenotypes/lib/python3.10/site-packages/jax/_src/numpy/vectorize.py:298\u001b[0m, in \u001b[0;36mvectorize.<locals>.wrapped\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    295\u001b[0m   rev_filled_shapes\u001b[39m.\u001b[39mappend(filled_shape[::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[1;32m    297\u001b[0m   squeeze_indices \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(i \u001b[39mfor\u001b[39;00m i, size \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(noncore_shape) \u001b[39mif\u001b[39;00m size \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[0;32m--> 298\u001b[0m   squeezed_arg \u001b[39m=\u001b[39m jnp\u001b[39m.\u001b[39;49msqueeze(arg, axis\u001b[39m=\u001b[39;49msqueeze_indices)\n\u001b[1;32m    299\u001b[0m   squeezed_args\u001b[39m.\u001b[39mappend(squeezed_arg)\n\u001b[1;32m    301\u001b[0m vectorized_func \u001b[39m=\u001b[39m checked_func\n",
      "File \u001b[0;32m~/mambaforge/envs/phenotypes/lib/python3.10/site-packages/jax/_src/numpy/lax_numpy.py:853\u001b[0m, in \u001b[0;36msqueeze\u001b[0;34m(a, axis)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    852\u001b[0m   shape \u001b[39m=\u001b[39m [shape]\n\u001b[0;32m--> 853\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39many\u001b[39m(ndim(s) \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m shape):\n\u001b[1;32m    854\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39munravel_index: shape should be a scalar or 1D sequence.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    855\u001b[0m out_indices \u001b[39m=\u001b[39m [\u001b[39m0\u001b[39m] \u001b[39m*\u001b[39m \u001b[39mlen\u001b[39m(shape)\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/mambaforge/envs/phenotypes/lib/python3.10/site-packages/jax/_src/pjit.py:248\u001b[0m, in \u001b[0;36mcache_miss\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    246\u001b[0m   \u001b[39mreturn\u001b[39;00m xc\u001b[39m.\u001b[39m_xla\u001b[39m.\u001b[39mPjitFunctionCache()\n\u001b[1;32m    247\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 248\u001b[0m   \u001b[39mreturn\u001b[39;00m _cpp_pjit_cache\n",
      "File \u001b[0;32m~/mambaforge/envs/phenotypes/lib/python3.10/site-packages/jax/_src/pjit.py:195\u001b[0m, in \u001b[0;36m_python_pjit_helper\u001b[0;34m(fun, infer_params_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    191\u001b[0m   wrapped\u001b[39m.\u001b[39mclear_cache \u001b[39m=\u001b[39m _python_pjit_evict_fn\n\u001b[1;32m    192\u001b[0m   \u001b[39mreturn\u001b[39;00m wrapped\n\u001b[0;32m--> 195\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_fastpath_data\u001b[39m(executable, out_tree, args_flat, out_flat):\n\u001b[1;32m    196\u001b[0m   out_flat, out_tree \u001b[39m=\u001b[39m pxla\u001b[39m.\u001b[39mreflatten_outputs_for_dispatch(out_tree, out_flat)\n\u001b[1;32m    198\u001b[0m   use_fastpath \u001b[39m=\u001b[39m (\n\u001b[1;32m    199\u001b[0m       executable \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    200\u001b[0m       \u001b[39misinstance\u001b[39m(executable, pxla\u001b[39m.\u001b[39mMeshExecutable) \u001b[39mand\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    206\u001b[0m       \u001b[39mall\u001b[39m(\u001b[39misinstance\u001b[39m(x, xc\u001b[39m.\u001b[39mArrayImpl) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m out_flat)\n\u001b[1;32m    207\u001b[0m   )\n",
      "File \u001b[0;32m~/mambaforge/envs/phenotypes/lib/python3.10/site-packages/jax/_src/core.py:2591\u001b[0m, in \u001b[0;36mbind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m   2589\u001b[0m   var_map[v] \u001b[39m=\u001b[39m v\n\u001b[1;32m   2590\u001b[0m   \u001b[39mreturn\u001b[39;00m v\n\u001b[0;32m-> 2591\u001b[0m names \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(it\u001b[39m.\u001b[39mchain\u001b[39m.\u001b[39mfrom_iterable(subst(name) \u001b[39mfor\u001b[39;00m name \u001b[39min\u001b[39;00m v\u001b[39m.\u001b[39maval\u001b[39m.\u001b[39mnamed_shape))\n\u001b[1;32m   2592\u001b[0m named_shape \u001b[39m=\u001b[39m {name: axis_frame(name)\u001b[39m.\u001b[39msize \u001b[39mfor\u001b[39;00m name \u001b[39min\u001b[39;00m names}\n\u001b[1;32m   2593\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(named_shape) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(names):\n",
      "File \u001b[0;32m~/mambaforge/envs/phenotypes/lib/python3.10/site-packages/jax/_src/core.py:362\u001b[0m, in \u001b[0;36mbind_with_trace\u001b[0;34m(self, trace, args, params)\u001b[0m\n\u001b[1;32m    360\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mval\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m    361\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 362\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mLiteral(val=\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mval\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[0;32m~/mambaforge/envs/phenotypes/lib/python3.10/site-packages/jax/_src/core.py:816\u001b[0m, in \u001b[0;36mprocess_primitive\u001b[0;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdevices\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    814\u001b[0m   \u001b[39mraise\u001b[39;00m ConcretizationTypeError(\u001b[39mself\u001b[39m,\n\u001b[1;32m    815\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe devices() method was called on \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_error_repr()\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 816\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_origin_msg()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/mambaforge/envs/phenotypes/lib/python3.10/site-packages/jax/_src/pjit.py:1241\u001b[0m, in \u001b[0;36m_pjit_call_impl\u001b[0;34m(jaxpr, in_shardings, out_shardings, resource_env, donated_invars, name, keep_unused, inline, *args)\u001b[0m\n\u001b[1;32m   1239\u001b[0m eq \u001b[39m=\u001b[39m []\n\u001b[1;32m   1240\u001b[0m \u001b[39mfor\u001b[39;00m s, o \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshardings, other\u001b[39m.\u001b[39mshardings):\n\u001b[0;32m-> 1241\u001b[0m   s \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(s, \u001b[39m\"\u001b[39m\u001b[39m_original_sharding\u001b[39m\u001b[39m\"\u001b[39m, s)\n\u001b[1;32m   1242\u001b[0m   o \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(o, \u001b[39m\"\u001b[39m\u001b[39m_original_sharding\u001b[39m\u001b[39m\"\u001b[39m, o)\n\u001b[1;32m   1243\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(s, GSPMDSharding) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(o, GSPMDSharding):\n",
      "File \u001b[0;32m~/mambaforge/envs/phenotypes/lib/python3.10/site-packages/jax/_src/pjit.py:1180\u001b[0m, in \u001b[0;36m_resolve_in_shardings\u001b[0;34m(args, pjit_in_shardings, out_shardings, pjit_mesh)\u001b[0m\n\u001b[1;32m   1160\u001b[0m     msg \u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mAn invalid value was encountered in the output of the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1161\u001b[0m            \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m`jit`-decorated function \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m. Because \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1162\u001b[0m            \u001b[39m\"\u001b[39m\u001b[39mconfig.jax_debug_nans and/or config.jax_debug_infs is set, the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1174\u001b[0m            \u001b[39m\"\u001b[39m\u001b[39mIf you see this error, consider opening a bug report at \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1175\u001b[0m            \u001b[39m\"\u001b[39m\u001b[39mhttps://github.com/google/jax.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1176\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFloatingPointError\u001b[39;00m(msg)\n\u001b[1;32m   1179\u001b[0m \u001b[39m@weakref_lru_cache\u001b[39m\n\u001b[0;32m-> 1180\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_jaxpr_as_fun\u001b[39m(jaxpr, in_shardings, out_shardings, resource_env,\n\u001b[1;32m   1181\u001b[0m                       donated_invars, name, keep_unused, inline):\n\u001b[1;32m   1182\u001b[0m   \u001b[39m# The input jaxpr to `_get_jaxpr_as_fun` is under a weakref_lru_cache so\u001b[39;00m\n\u001b[1;32m   1183\u001b[0m   \u001b[39m# returning `core.jaxpr_as_fun(jaxpr)` directly creates a strong reference to\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m   \u001b[39m# the jaxpr defeating the purpose of weakref_lru_cache. So return a function\u001b[39;00m\n\u001b[1;32m   1185\u001b[0m   \u001b[39m# that closes over a weakrefed jaxpr and gets called inside that function.\u001b[39;00m\n\u001b[1;32m   1186\u001b[0m   \u001b[39m# This way there won't be a strong reference to the jaxpr from the output\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m   \u001b[39m# function.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m   jaxpr \u001b[39m=\u001b[39m weakref\u001b[39m.\u001b[39mref(jaxpr)\n\u001b[1;32m   1189\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mlambda\u001b[39;00m \u001b[39m*\u001b[39margs: core\u001b[39m.\u001b[39mjaxpr_as_fun(jaxpr())(\u001b[39m*\u001b[39margs)  \u001b[39m# pylint: disable=unnecessary-lambda\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "learning_rates = np.logspace(1, -8, 20)\n",
    "batch_sizes = np.linspace(2, 50, 20).astype(int)\n",
    "momentums = np.linspace(0, 0.999, 20)\n",
    "\n",
    "# generate tuples of random hyperparameters\n",
    "hyperparameter_tuples = []\n",
    "for i in range(10000):\n",
    "    lr = onp.random.choice(learning_rates)\n",
    "    bs = onp.random.choice(batch_sizes)\n",
    "    m = onp.random.choice(momentums)\n",
    "    hyperparameter_tuples.append((lr, bs, m))\n",
    "\n",
    "results = {}\n",
    "for i, (learning_rate, batch_size, momentum) in enumerate(hyperparameter_tuples):\n",
    "    best_hp_loss = np.inf\n",
    "\n",
    "    patches = extract_patches(images, patch_size, num_patches=num_patches, seed=i)\n",
    "    best_cov_mat, cov_mat_initial, mean_vec, best_loss, train_loss_history, val_loss_history = run_optimization(patches, momentum, learning_rate, batch_size, eigenvalue_floor=1e-3)\n",
    "\n",
    "    if best_loss < best_hp_loss:\n",
    "        best_hp_loss = best_loss\n",
    "        best_hp = (learning_rate, batch_size, momentum)\n",
    "        \n",
    "    # collect results\n",
    "    results[(learning_rate, batch_size, momentum)] = best_loss\n",
    "\n",
    "    # print hyperparameters and their best loss\n",
    "    print(f\"best loss: {best_loss:.2f}\\t\\tLearning rate: {learning_rate:.3e}, Batch size: {batch_size}, Momentum: {momentum:.3e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best loss: 454.45\t\tLearning rate: 1.438e-02, Batch size: 19, Momentum: 7.361e-01\n",
      "best loss: 455.73\t\tLearning rate: 1.438e-02, Batch size: 32, Momentum: 5.258e-02\n",
      "best loss: 458.08\t\tLearning rate: 1.000e-08, Batch size: 47, Momentum: 2.103e-01\n",
      "best loss: 458.54\t\tLearning rate: 3.793e-01, Batch size: 19, Momentum: 4.732e-01\n",
      "best loss: 622.51\t\tLearning rate: 8.859e-08, Batch size: 14, Momentum: 6.835e-01\n"
     ]
    }
   ],
   "source": [
    "# print the hyperparameters ranked from best to worst\n",
    "sorted_results = sorted(results.items(), key=lambda x: x[1])\n",
    "for hp, loss in sorted_results:\n",
    "    print(f\"best loss: {loss:.2f}\\t\\tLearning rate: {hp[0]:.3e}, Batch size: {hp[1]}, Momentum: {hp[2]:.3e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phenotypes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
