{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening BSCCM\n",
      "Opened BSCCM\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# this only works on startup!\n",
    "from jax import config\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '2'\n",
    "from gpu_utils import limit_gpu_memory_growth\n",
    "limit_gpu_memory_growth()\n",
    "\n",
    "from cleanplots import *\n",
    "from tqdm import tqdm\n",
    "from information_estimation import *\n",
    "from image_utils import *\n",
    "\n",
    "from led_array.bsccm_utils import *\n",
    "from bsccm import BSCCM\n",
    "from jax import jit\n",
    "import numpy as onp\n",
    "import jax.numpy as np\n",
    "\n",
    "bsccm = BSCCM('/home/hpinkard_waller/data/BSCCM/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute a \"true\" reference covariance matrix\n",
    "num_images = 1000\n",
    "num_patches = 1000\n",
    "edge_crop = 32\n",
    "channel = 'LED119'\n",
    "ev_floor = 1e-5\n",
    "\n",
    "patch_sizes = [5, 10]\n",
    "\n",
    "images = load_bsccm_images(bsccm, channel=channel, num_images=num_images, edge_crop=edge_crop, median_filter=True)\n",
    "\n",
    "cov_mats_stationary_pd = []\n",
    "means = []\n",
    "for patch_size in patch_sizes:\n",
    "    patches = extract_patches(images, patch_size, num_patches=num_patches)\n",
    "    cov_mat = compute_cov_mat(patches)\n",
    "    cov_mat_pd = make_positive_definite(cov_mat, eigenvalue_floor=ev_floor, show_plot=False)\n",
    "    cov_mat_stationary = compute_stationary_cov_mat(patches)\n",
    "    cov_mat_stationary_pd = make_positive_definite(cov_mat_stationary, eigenvalue_floor=ev_floor, show_plot=False)\n",
    "    means.append(np.mean(patches))\n",
    "    cov_mats_stationary_pd.append(cov_mat_stationary_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stationary_log_likelihood(samples, cov_mat, mean, prefer_iterative=False):\n",
    "    \"\"\"\n",
    "    Compute the likelihood of a set of samples from a stationary process\n",
    "\n",
    "    :param samples: N x H x W array of samples\n",
    "    :param cov_mat: covariance matrix of the process\n",
    "    :param mean: float mean of the process\n",
    "    :param prefer_iterative: if True, compute likelihood iteratively, otherwise compute directly if possible\n",
    "\n",
    "    :return: N x 1 array of log likelihoods\n",
    "    \"\"\"\n",
    "    # samples is not going to be the same size as the covariance matrix\n",
    "    # if sample is smaller than cov_mat, throw an excpetion\n",
    "    # if sample is larger than cov_mat, then compute likelihood iteratively\n",
    "    # if sample is the same size as cov_mat, then compute likelihood directly, unless prefer_iterative is True\n",
    "    # check that mean if float or 1 element array\n",
    "    if not isinstance(mean, float) or mean.shape != tuple():\n",
    "        raise ValueError('Mean must be a float or a 1 element array')\n",
    "    N_samples = samples.shape[0]\n",
    "    # check for expected shape\n",
    "    if samples.ndim != 3 or samples.shape[1] != samples.shape[2]:\n",
    "        raise ValueError('Samples must be N x H x W')\n",
    "    sample_size = samples.shape[1]\n",
    "\n",
    "    if np.linalg.eigvalsh(cov_mat).min() < 0:\n",
    "        raise ValueError('Covariance matrix is not positive definite')\n",
    "    # precompute everything that will be the same for all samples\n",
    "    patch_size = int(np.sqrt(cov_mat.shape[0]))\n",
    "    vectorized_masks = []\n",
    "    variances = []\n",
    "    mean_multipliers = []\n",
    "    for i in tqdm(np.arange(sample_size), desc='precomputing masks and variances'):\n",
    "        for j in np.arange(sample_size):\n",
    "            if not prefer_iterative and i < patch_size - 1 and j < patch_size - 1:\n",
    "                # Add placeholders since these get sampled from the covariance matrix directly\n",
    "                variances.append(None)\n",
    "                mean_multipliers.append(None)\n",
    "                vectorized_masks.append(None)\n",
    "            else:\n",
    "                top_part = np.ones((min(i, patch_size - 1), patch_size), dtype=bool)\n",
    "                left_part = np.ones((1, min(j, patch_size - 1)), dtype=bool)\n",
    "                right_part = np.zeros((1, patch_size - min(j, patch_size - 1)), dtype=bool)\n",
    "                bottom_part = np.zeros((patch_size - min(i, patch_size - 1) - 1, patch_size), dtype=bool)\n",
    "                middle_row = np.hstack((left_part, right_part))\n",
    "                conditioning_mask = np.vstack((top_part, middle_row, bottom_part))\n",
    "\n",
    "                vectorized_mask = conditioning_mask.reshape(-1)\n",
    "                vectorized_masks.append(vectorized_mask)\n",
    "                # find the linear index in the covariance matrix of the pixel we want to predict\n",
    "                pixel_to_predict_index = np.min(np.array([i, patch_size - 1])) * patch_size + np.min(np.array([j, patch_size - 1]))\n",
    "                sigma_11 = cov_mat[vectorized_mask][:, vectorized_mask].reshape(pixel_to_predict_index, pixel_to_predict_index) \n",
    "                sigma_12 = cov_mat[vectorized_mask][:, pixel_to_predict_index].reshape(-1, 1)\n",
    "                sigma_21 = sigma_12.reshape(1, -1)\n",
    "                sigma_22 = cov_mat[pixel_to_predict_index, pixel_to_predict_index].reshape(1, 1)\n",
    "\n",
    "                variances.append(sigma_22 - sigma_21 @ np.linalg.inv(sigma_11) @ sigma_12)\n",
    "                mean_multipliers.append(sigma_21 @ np.linalg.inv(sigma_11))\n",
    "                # print(i, j, np.linalg.det(sigma_11))\n",
    "\n",
    "                # print(i,j, mean_multipliers[-1].mean())\n",
    "                if variances[-1] < 0:\n",
    "                    raise ValueError('Variance is negative {} {}'.format(i, j))\n",
    "\n",
    "    print('evaluating likelihood')\n",
    "    \n",
    "    log_likelihoods = []\n",
    "    if not prefer_iterative:\n",
    "        # compute the log_likelihood to the top left image subpatch of the image directly\n",
    "        top_left_subpatch = samples[:, :patch_size, :patch_size].reshape(N_samples, -1)\n",
    "        log_likelihoods.append(jax.scipy.stats.multivariate_normal.logpdf(top_left_subpatch, mean=mean, cov=cov_mat))\n",
    "\n",
    "\n",
    "    for i in tqdm(np.arange(sample_size), desc='generating sample'):\n",
    "        for j in np.arange(sample_size):\n",
    "\n",
    "            if not prefer_iterative and i < patch_size - 1 and j < patch_size - 1:\n",
    "                # already did this\n",
    "                pass\n",
    "            elif i == 0 and j == 0:\n",
    "                # top left pixel is not conditioned on anything\n",
    "                mean = 0\n",
    "                variance = cov_mat[0, 0]\n",
    "                # compute likelihood of top left pixel\n",
    "                log_likelihoods.append(jax.scipy.stats.norm.logpdf(samples[:, i, j], loc=mean, scale=np.sqrt(variance)))\n",
    "            else:\n",
    "                vectorized_mask = vectorized_masks[i * sample_size + j]\n",
    "                # get the relevant window of previous values\n",
    "                relevant_window = samples[:, max(i - patch_size + 1, 0):max(i - patch_size + 1, 0) + patch_size, \n",
    "                                                max(j - patch_size + 1, 0):max(j - patch_size + 1, 0) + patch_size]\n",
    "                previous_values = relevant_window.reshape(-1)[vectorized_mask].reshape(-1, 1)\n",
    "                \n",
    "                mean = mean_multipliers[i * sample_size + j] @ previous_values\n",
    "                variance = variances[i * sample_size + j]\n",
    "                # compute likelihood of pixel\n",
    "                log_likelihoods.append(jax.scipy.stats.norm.logpdf(samples[:, i, j], loc=mean, scale=np.sqrt(variance)))\n",
    "    return np.sum(np.array(log_likelihoods), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_patch = patches[0]\n",
    "test_patch = test_patch.reshape(1, test_patch.shape[0], test_patch.shape[1])\n",
    "\n",
    "cov_mat = cov_mats_stationary_pd[-1]\n",
    "mean = means[-1]\n",
    "direct = jax.scipy.stats.multivariate_normal.logpdf(test_patch.reshape(-1, cov_mat.shape[0]), mean=mean, cov=cov_mat)\n",
    "\n",
    "function = compute_stationary_log_likelihood(test_patch, cov_mats_stationary_pd, mean)\n",
    "function_iterative = compute_stationary_log_likelihood(test_patch, cov_mats_stationary_pd, mean, prefer_iterative=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean.shap"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phenotypes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
