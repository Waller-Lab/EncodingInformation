{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solve for Gaussian approximations using optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening BSCCM\n",
      "Opened BSCCM\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# this only works on startup!\n",
    "from jax import config\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'\n",
    "from gpu_utils import limit_gpu_memory_growth\n",
    "limit_gpu_memory_growth()\n",
    "\n",
    "from cleanplots import *\n",
    "from tqdm import tqdm\n",
    "from information_estimation import *\n",
    "from image_utils import *\n",
    "from gaussian_process_utils import *\n",
    "\n",
    "from led_array.bsccm_utils import *\n",
    "from bsccm import BSCCM\n",
    "from jax import jit\n",
    "import numpy as onp\n",
    "import jax.numpy as np\n",
    "\n",
    "bsccm = BSCCM('/home/hpinkard_waller/data/BSCCM/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images, extract patches, and compute cov mats\n",
    "edge_crop = 32\n",
    "patch_size = 10\n",
    "num_images = 20000\n",
    "num_patches = 1000\n",
    "channel = 'LED119'\n",
    "eigenvalue_floor = 1e0\n",
    "\n",
    "images = load_bsccm_images(bsccm, channel=channel, num_images=num_images, edge_crop=edge_crop, median_filter=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search through hyperparameter combos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss:  630162.0724254091\n",
      "best loss: 443.67\t\tLearning rate: 2.976e-08, Batch size: 4, Momentum: 8.413e-01\n",
      "Initial loss:  247570.5514104695\n",
      "best loss: 1370.08\t\tLearning rate: 3.360e+00, Batch size: 17, Momentum: 7.887e-01\n",
      "Initial loss:  457.2525714721856\n",
      "best loss: 451.93\t\tLearning rate: 1.438e-02, Batch size: 37, Momentum: 9.464e-01\n",
      "Initial loss:  184826.8824663631\n",
      "best loss: 933.66\t\tLearning rate: 1.624e-03, Batch size: 34, Momentum: 7.361e-01\n",
      "Initial loss:  457.2256598088446\n",
      "best loss: 450.88\t\tLearning rate: 6.952e-06, Batch size: 42, Momentum: 7.887e-01\n",
      "Initial loss:  329348.24360659026\n",
      "best loss: 1326.84\t\tLearning rate: 1.000e+01, Batch size: 47, Momentum: 3.681e-01\n",
      "Initial loss:  191530.43684099428\n",
      "best loss: 442.68\t\tLearning rate: 8.859e-08, Batch size: 7, Momentum: 6.309e-01\n",
      "Initial loss:  100856.11155377117\n",
      "best loss: 487.34\t\tLearning rate: 2.637e-07, Batch size: 42, Momentum: 2.103e-01\n",
      "Initial loss:  887472.1436367106\n",
      "best loss: 1297.42\t\tLearning rate: 1.129e+00, Batch size: 12, Momentum: 7.361e-01\n",
      "Initial loss:  241174.82122555887\n",
      "best loss: 440.15\t\tLearning rate: 7.848e-07, Batch size: 9, Momentum: 2.629e-01\n",
      "Initial loss:  340840.7882856652\n",
      "best loss: 1325.60\t\tLearning rate: 1.000e+01, Batch size: 27, Momentum: 3.681e-01\n",
      "Initial loss:  90974.88593179909\n",
      "best loss: 89566.20\t\tLearning rate: 1.000e+01, Batch size: 22, Momentum: 0.000e+00\n",
      "Initial loss:  843268.7366940194\n",
      "best loss: 537.55\t\tLearning rate: 6.952e-06, Batch size: 17, Momentum: 9.464e-01\n",
      "Initial loss:  456.1136919509378\n",
      "best loss: 448.64\t\tLearning rate: 1.438e-02, Batch size: 39, Momentum: 6.309e-01\n",
      "Initial loss:  521635.6358582735\n",
      "best loss: 456.64\t\tLearning rate: 8.859e-08, Batch size: 12, Momentum: 5.258e-01\n",
      "Initial loss:  858802.0724330324\n",
      "best loss: 61612.37\t\tLearning rate: 1.000e-08, Batch size: 29, Momentum: 0.000e+00\n",
      "Initial loss:  46671.87183863604\n",
      "best loss: 679.37\t\tLearning rate: 6.158e-05, Batch size: 4, Momentum: 5.784e-01\n",
      "Initial loss:  328117.01894786645\n",
      "best loss: 591.32\t\tLearning rate: 6.158e-05, Batch size: 19, Momentum: 5.258e-02\n",
      "Initial loss:  301113.57192344643\n",
      "best loss: 45735.13\t\tLearning rate: 2.637e-07, Batch size: 9, Momentum: 5.784e-01\n",
      "Initial loss:  87192.46097940007\n",
      "best loss: 1129.82\t\tLearning rate: 1.274e-01, Batch size: 17, Momentum: 3.681e-01\n",
      "Initial loss:  197263.58294910565\n",
      "best loss: 427.50\t\tLearning rate: 1.000e-08, Batch size: 2, Momentum: 8.413e-01\n",
      "Initial loss:  188354.6793105985\n",
      "best loss: 753.11\t\tLearning rate: 1.833e-04, Batch size: 32, Momentum: 1.577e-01\n",
      "Initial loss:  458.02293282671206\n",
      "best loss: 445.03\t\tLearning rate: 1.129e+00, Batch size: 7, Momentum: 1.577e-01\n",
      "Initial loss:  326478.31813851773\n",
      "best loss: 1374.99\t\tLearning rate: 1.000e+01, Batch size: 39, Momentum: 5.784e-01\n",
      "Initial loss:  462.8870320765543\n",
      "best loss: 447.93\t\tLearning rate: 6.158e-05, Batch size: 27, Momentum: 8.938e-01\n",
      "Initial loss:  306533.07858419267\n",
      "best loss: 32615.09\t\tLearning rate: 1.000e-08, Batch size: 17, Momentum: 5.258e-02\n",
      "Initial loss:  539899.4260689401\n",
      "best loss: 807.49\t\tLearning rate: 6.158e-05, Batch size: 32, Momentum: 8.938e-01\n",
      "Initial loss:  790000.9035501314\n",
      "best loss: 1367.60\t\tLearning rate: 3.360e+00, Batch size: 34, Momentum: 7.887e-01\n",
      "Initial loss:  453.32299212727565\n",
      "best loss: 448.74\t\tLearning rate: 1.624e-03, Batch size: 39, Momentum: 4.206e-01\n",
      "Initial loss:  229981.7011518544\n",
      "best loss: 883.43\t\tLearning rate: 1.833e-04, Batch size: 14, Momentum: 9.464e-01\n",
      "Initial loss:  452.39934809801645\n",
      "best loss: 450.80\t\tLearning rate: 2.336e-06, Batch size: 47, Momentum: 7.887e-01\n",
      "Initial loss:  469.4550737313406\n",
      "best loss: 446.17\t\tLearning rate: 4.281e-02, Batch size: 14, Momentum: 2.629e-01\n",
      "Initial loss:  469.8319893810582\n",
      "best loss: 456.85\t\tLearning rate: 6.158e-05, Batch size: 22, Momentum: 0.000e+00\n",
      "Initial loss:  451.24375656990145\n",
      "best loss: 444.25\t\tLearning rate: 1.000e-08, Batch size: 27, Momentum: 9.990e-01\n",
      "Initial loss:  121631.89987119034\n",
      "best loss: 1416.33\t\tLearning rate: 1.000e+01, Batch size: 12, Momentum: 8.413e-01\n",
      "Initial loss:  463.54352798775966\n",
      "best loss: 445.28\t\tLearning rate: 3.360e+00, Batch size: 19, Momentum: 9.464e-01\n",
      "Initial loss:  456.5586182207348\n",
      "best loss: 446.64\t\tLearning rate: 6.952e-06, Batch size: 44, Momentum: 3.155e-01\n",
      "Initial loss:  1021586.6970029385\n",
      "best loss: 1153.22\t\tLearning rate: 3.793e-01, Batch size: 19, Momentum: 2.629e-01\n",
      "Initial loss:  74590.74723208256\n",
      "best loss: 1153.37\t\tLearning rate: 4.281e-02, Batch size: 32, Momentum: 9.464e-01\n",
      "Initial loss:  460.0380599363739\n",
      "best loss: 449.27\t\tLearning rate: 5.456e-04, Batch size: 9, Momentum: 6.309e-01\n",
      "Initial loss:  92597.16845934842\n",
      "best loss: 1047.62\t\tLearning rate: 4.833e-03, Batch size: 39, Momentum: 9.464e-01\n",
      "Initial loss:  503590.3508872657\n",
      "best loss: 869.69\t\tLearning rate: 5.456e-04, Batch size: 7, Momentum: 8.413e-01\n",
      "Initial loss:  269447.3641277994\n",
      "best loss: 791.85\t\tLearning rate: 6.158e-05, Batch size: 19, Momentum: 7.361e-01\n",
      "Initial loss:  344361.3652718942\n",
      "best loss: 437.41\t\tLearning rate: 2.336e-06, Batch size: 7, Momentum: 7.887e-01\n",
      "Initial loss:  429179.6308840123\n",
      "best loss: 1325.94\t\tLearning rate: 1.000e+01, Batch size: 39, Momentum: 2.103e-01\n",
      "Initial loss:  451.1525219231694\n",
      "best loss: 447.28\t\tLearning rate: 2.976e-08, Batch size: 34, Momentum: 3.155e-01\n",
      "Initial loss:  688352.0089882732\n",
      "best loss: 1311.94\t\tLearning rate: 3.360e+00, Batch size: 39, Momentum: 6.309e-01\n",
      "Initial loss:  520513.1134761907\n",
      "best loss: 455.87\t\tLearning rate: 7.848e-07, Batch size: 50, Momentum: 5.258e-01\n",
      "Initial loss:  242278.91952920484\n",
      "best loss: 922.63\t\tLearning rate: 1.624e-03, Batch size: 32, Momentum: 7.361e-01\n",
      "Initial loss:  117386.27482553778\n",
      "best loss: 92994.19\t\tLearning rate: 1.000e-08, Batch size: 27, Momentum: 5.258e-01\n",
      "Initial loss:  660804.2413568886\n",
      "best loss: 639.28\t\tLearning rate: 6.952e-06, Batch size: 29, Momentum: 9.990e-01\n",
      "Initial loss:  450.02759666138286\n",
      "best loss: 447.78\t\tLearning rate: 6.158e-05, Batch size: 34, Momentum: 9.464e-01\n",
      "Initial loss:  236138.52316824518\n",
      "best loss: 1380.20\t\tLearning rate: 3.360e+00, Batch size: 14, Momentum: 7.887e-01\n",
      "Initial loss:  296757.1746825572\n",
      "best loss: 447.98\t\tLearning rate: 6.952e-06, Batch size: 42, Momentum: 2.103e-01\n",
      "Initial loss:  476255.05669212877\n",
      "best loss: 1303.23\t\tLearning rate: 1.000e+01, Batch size: 47, Momentum: 0.000e+00\n",
      "Initial loss:  195692.81111904333\n",
      "best loss: 6211.74\t\tLearning rate: 8.859e-08, Batch size: 4, Momentum: 5.258e-02\n",
      "Initial loss:  618055.8086515014\n",
      "best loss: 447.70\t\tLearning rate: 8.859e-08, Batch size: 14, Momentum: 7.887e-01\n",
      "Initial loss:  451.12561243049606\n",
      "best loss: 448.19\t\tLearning rate: 3.360e+00, Batch size: 34, Momentum: 7.887e-01\n",
      "Initial loss:  101712.34066108665\n",
      "best loss: 1368.29\t\tLearning rate: 1.000e+01, Batch size: 4, Momentum: 5.784e-01\n",
      "Initial loss:  1290723.846442493\n",
      "best loss: 877.56\t\tLearning rate: 5.456e-04, Batch size: 4, Momentum: 3.155e-01\n",
      "Initial loss:  637261.2568439471\n",
      "best loss: 1327.40\t\tLearning rate: 3.360e+00, Batch size: 44, Momentum: 5.784e-01\n",
      "Initial loss:  454.80489086182365\n",
      "best loss: 440.61\t\tLearning rate: 2.336e-06, Batch size: 7, Momentum: 3.681e-01\n",
      "Initial loss:  460.3718525045247\n",
      "best loss: 443.79\t\tLearning rate: 3.793e-01, Batch size: 7, Momentum: 6.835e-01\n",
      "Initial loss:  166439.86783057853\n",
      "best loss: 496.33\t\tLearning rate: 8.859e-08, Batch size: 50, Momentum: 1.577e-01\n",
      "Initial loss:  1021200.550817122\n",
      "best loss: 481.95\t\tLearning rate: 8.859e-08, Batch size: 19, Momentum: 4.206e-01\n",
      "Initial loss:  810078.0311044592\n",
      "best loss: 1460.12\t\tLearning rate: 1.000e+01, Batch size: 2, Momentum: 8.938e-01\n",
      "Initial loss:  839291.4364464779\n",
      "best loss: 1215.12\t\tLearning rate: 3.793e-01, Batch size: 24, Momentum: 5.258e-01\n",
      "Initial loss:  136052.30406514963\n",
      "best loss: 1237.78\t\tLearning rate: 3.360e+00, Batch size: 44, Momentum: 5.258e-02\n",
      "Initial loss:  267908.1405233997\n",
      "best loss: 491.23\t\tLearning rate: 8.859e-08, Batch size: 47, Momentum: 5.258e-02\n",
      "Initial loss:  287142.91305702645\n",
      "best loss: 1349.07\t\tLearning rate: 3.360e+00, Batch size: 37, Momentum: 6.309e-01\n",
      "Initial loss:  221274.6258031723\n",
      "best loss: 1122.59\t\tLearning rate: 1.274e-01, Batch size: 47, Momentum: 5.258e-02\n",
      "Initial loss:  466.98435294849895\n",
      "best loss: 449.01\t\tLearning rate: 4.833e-03, Batch size: 17, Momentum: 7.887e-01\n",
      "Initial loss:  456594.03796995664\n",
      "best loss: 918.80\t\tLearning rate: 5.456e-04, Batch size: 19, Momentum: 9.990e-01\n",
      "Initial loss:  616621.1755187379\n",
      "best loss: 822.42\t\tLearning rate: 1.833e-04, Batch size: 19, Momentum: 5.258e-01\n",
      "Initial loss:  324586.7736288529\n",
      "best loss: 1187.75\t\tLearning rate: 1.129e+00, Batch size: 4, Momentum: 0.000e+00\n",
      "Initial loss:  208160.63487393328\n",
      "best loss: 703.19\t\tLearning rate: 6.158e-05, Batch size: 32, Momentum: 1.577e-01\n",
      "Initial loss:  224292.36954494822\n",
      "best loss: 466.09\t\tLearning rate: 2.069e-05, Batch size: 12, Momentum: 8.938e-01\n",
      "Initial loss:  455.93758228780547\n",
      "best loss: 450.36\t\tLearning rate: 5.456e-04, Batch size: 37, Momentum: 0.000e+00\n",
      "Initial loss:  658457.1178280655\n",
      "best loss: 1313.01\t\tLearning rate: 3.793e-01, Batch size: 39, Momentum: 9.464e-01\n",
      "Initial loss:  258968.43367784756\n",
      "best loss: 930.57\t\tLearning rate: 4.833e-03, Batch size: 47, Momentum: 2.103e-01\n",
      "Initial loss:  456.37067343151483\n",
      "best loss: 440.66\t\tLearning rate: 2.637e-07, Batch size: 9, Momentum: 7.361e-01\n",
      "Initial loss:  247338.6886520288\n",
      "best loss: 453.09\t\tLearning rate: 7.848e-07, Batch size: 27, Momentum: 5.258e-02\n",
      "Initial loss:  643518.7165160953\n",
      "best loss: 1059.45\t\tLearning rate: 4.281e-02, Batch size: 17, Momentum: 5.258e-01\n",
      "Initial loss:  477.1470209954227\n",
      "best loss: 459.12\t\tLearning rate: 1.833e-04, Batch size: 42, Momentum: 6.309e-01\n",
      "Initial loss:  185700.08898489963\n",
      "best loss: 447.74\t\tLearning rate: 7.848e-07, Batch size: 27, Momentum: 7.361e-01\n",
      "Initial loss:  472105.62493966555\n",
      "best loss: 928.30\t\tLearning rate: 4.833e-03, Batch size: 4, Momentum: 5.258e-02\n",
      "Initial loss:  312854.91229176894\n",
      "best loss: 450.91\t\tLearning rate: 2.976e-08, Batch size: 47, Momentum: 8.938e-01\n",
      "Initial loss:  552019.336742214\n",
      "best loss: 162376.57\t\tLearning rate: 2.976e-08, Batch size: 22, Momentum: 6.309e-01\n",
      "Initial loss:  428356.14322472044\n",
      "best loss: 462.45\t\tLearning rate: 2.637e-07, Batch size: 22, Momentum: 3.681e-01\n",
      "Initial loss:  472.9371595088136\n",
      "best loss: 451.16\t\tLearning rate: 1.000e-08, Batch size: 17, Momentum: 4.206e-01\n",
      "Initial loss:  652917.7816336355\n",
      "best loss: 824.89\t\tLearning rate: 6.158e-05, Batch size: 50, Momentum: 8.938e-01\n",
      "Initial loss:  362806.1331405304\n",
      "best loss: 723.34\t\tLearning rate: 2.069e-05, Batch size: 14, Momentum: 8.413e-01\n",
      "Initial loss:  41612.30768802665\n",
      "best loss: 594.19\t\tLearning rate: 2.637e-07, Batch size: 19, Momentum: 1.577e-01\n",
      "Initial loss:  251667.38665472416\n",
      "best loss: 972.69\t\tLearning rate: 4.833e-03, Batch size: 12, Momentum: 4.732e-01\n",
      "Initial loss:  454.28711349081135\n",
      "best loss: 448.03\t\tLearning rate: 1.438e-02, Batch size: 34, Momentum: 2.629e-01\n",
      "Initial loss:  157317.70428605305\n",
      "best loss: 1011.51\t\tLearning rate: 1.624e-03, Batch size: 44, Momentum: 8.413e-01\n",
      "Initial loss:  121561.28043100976\n",
      "best loss: 449.38\t\tLearning rate: 6.952e-06, Batch size: 4, Momentum: 9.990e-01\n",
      "Initial loss:  473.7222815165241\n",
      "best loss: 459.43\t\tLearning rate: 1.833e-04, Batch size: 29, Momentum: 3.155e-01\n",
      "Initial loss:  346123.6478036364\n",
      "best loss: 448.96\t\tLearning rate: 7.848e-07, Batch size: 17, Momentum: 9.464e-01\n",
      "Initial loss:  175419.62198818935\n",
      "best loss: 880.04\t\tLearning rate: 1.624e-03, Batch size: 37, Momentum: 2.103e-01\n",
      "Initial loss:  192649.25314215146\n",
      "best loss: 451.49\t\tLearning rate: 2.336e-06, Batch size: 27, Momentum: 2.629e-01\n",
      "Initial loss:  890683.7564680157\n",
      "best loss: 1081.55\t\tLearning rate: 4.281e-02, Batch size: 32, Momentum: 5.784e-01\n",
      "Initial loss:  458.69876601207903\n",
      "best loss: 443.04\t\tLearning rate: 1.833e-04, Batch size: 12, Momentum: 8.413e-01\n",
      "Initial loss:  648573.4886556133\n",
      "best loss: 452.52\t\tLearning rate: 2.976e-08, Batch size: 47, Momentum: 9.990e-01\n",
      "Initial loss:  526290.2108268392\n",
      "best loss: 1223.84\t\tLearning rate: 1.274e-01, Batch size: 2, Momentum: 8.938e-01\n",
      "Initial loss:  361616.5171897674\n",
      "best loss: 902.28\t\tLearning rate: 5.456e-04, Batch size: 22, Momentum: 6.835e-01\n",
      "Initial loss:  231986.3808831255\n",
      "best loss: 1077.89\t\tLearning rate: 1.438e-02, Batch size: 12, Momentum: 6.835e-01\n",
      "Initial loss:  401778.816990863\n",
      "best loss: 454.04\t\tLearning rate: 2.336e-06, Batch size: 22, Momentum: 9.464e-01\n",
      "Initial loss:  157815.2291735608\n",
      "best loss: 461.73\t\tLearning rate: 1.000e-08, Batch size: 12, Momentum: 7.887e-01\n",
      "Initial loss:  822220.8044956627\n",
      "best loss: 462.56\t\tLearning rate: 6.952e-06, Batch size: 32, Momentum: 6.835e-01\n",
      "Initial loss:  342092.47376474255\n",
      "best loss: 129780.39\t\tLearning rate: 4.833e-03, Batch size: 34, Momentum: 1.052e-01\n",
      "Initial loss:  156850.18352885338\n",
      "best loss: 1330.54\t\tLearning rate: 1.000e+01, Batch size: 37, Momentum: 4.206e-01\n",
      "Initial loss:  647111.6232905453\n",
      "best loss: 1205.06\t\tLearning rate: 3.793e-01, Batch size: 42, Momentum: 2.103e-01\n",
      "Initial loss:  177770.48902671025\n",
      "best loss: 1041.56\t\tLearning rate: 4.833e-03, Batch size: 4, Momentum: 8.938e-01\n",
      "Initial loss:  389878.6542678176\n",
      "best loss: 486.06\t\tLearning rate: 2.069e-05, Batch size: 47, Momentum: 3.681e-01\n",
      "Initial loss:  466.10387506726636\n",
      "best loss: 447.53\t\tLearning rate: 1.000e+01, Batch size: 37, Momentum: 8.938e-01\n",
      "Initial loss:  144093.07815915605\n",
      "best loss: 446.27\t\tLearning rate: 2.976e-08, Batch size: 4, Momentum: 5.784e-01\n",
      "Initial loss:  666410.140616997\n",
      "best loss: 502.74\t\tLearning rate: 2.637e-07, Batch size: 50, Momentum: 6.309e-01\n",
      "Initial loss:  459.08387441609955\n",
      "best loss: 452.85\t\tLearning rate: 3.793e-01, Batch size: 44, Momentum: 1.577e-01\n",
      "Initial loss:  454.896353842027\n",
      "best loss: 449.25\t\tLearning rate: 4.281e-02, Batch size: 34, Momentum: 0.000e+00\n",
      "Initial loss:  117220.4046808448\n",
      "best loss: 1016.19\t\tLearning rate: 1.000e-08, Batch size: 22, Momentum: 4.206e-01\n",
      "Initial loss:  272208.27765917213\n",
      "best loss: 882.06\t\tLearning rate: 5.456e-04, Batch size: 12, Momentum: 4.732e-01\n",
      "Initial loss:  287532.4705542911\n",
      "best loss: 1432.37\t\tLearning rate: 1.000e+01, Batch size: 37, Momentum: 8.938e-01\n",
      "Initial loss:  90663.62062291504\n",
      "best loss: 799.12\t\tLearning rate: 1.833e-04, Batch size: 14, Momentum: 3.681e-01\n",
      "Initial loss:  457.9709142670803\n",
      "best loss: 448.32\t\tLearning rate: 3.360e+00, Batch size: 37, Momentum: 3.155e-01\n",
      "Initial loss:  770263.6147182334\n",
      "best loss: 962.39\t\tLearning rate: 4.833e-03, Batch size: 9, Momentum: 2.103e-01\n",
      "Initial loss:  158266.84114731316\n",
      "best loss: 1225.37\t\tLearning rate: 3.793e-01, Batch size: 9, Momentum: 7.361e-01\n",
      "Initial loss:  932993.7740569883\n",
      "best loss: 966.17\t\tLearning rate: 1.624e-03, Batch size: 27, Momentum: 7.361e-01\n",
      "Initial loss:  786924.0978039191\n",
      "best loss: 736.22\t\tLearning rate: 6.158e-05, Batch size: 29, Momentum: 6.835e-01\n",
      "Initial loss:  214576.00829652973\n",
      "best loss: 71962.97\t\tLearning rate: 2.976e-08, Batch size: 19, Momentum: 2.103e-01\n",
      "Initial loss:  476.4271104698346\n",
      "best loss: 461.07\t\tLearning rate: 2.976e-08, Batch size: 42, Momentum: 9.990e-01\n",
      "Initial loss:  515483.3017592511\n",
      "best loss: 568.75\t\tLearning rate: 8.859e-08, Batch size: 14, Momentum: 3.681e-01\n",
      "Initial loss:  1083718.0084865238\n",
      "best loss: 30941.47\t\tLearning rate: 1.000e+01, Batch size: 7, Momentum: 2.629e-01\n",
      "Initial loss:  283406.15703692\n",
      "best loss: 930.38\t\tLearning rate: 1.833e-04, Batch size: 2, Momentum: 9.464e-01\n",
      "Initial loss:  38477.145200467894\n",
      "best loss: 450.66\t\tLearning rate: 6.158e-05, Batch size: 29, Momentum: 1.052e-01\n",
      "Initial loss:  164113.42545652902\n",
      "best loss: 453.86\t\tLearning rate: 2.637e-07, Batch size: 22, Momentum: 5.784e-01\n",
      "Initial loss:  440.18872818249656\n",
      "best loss: 442.46\t\tLearning rate: 8.859e-08, Batch size: 9, Momentum: 9.464e-01\n",
      "Initial loss:  648587.2990423115\n",
      "best loss: 826.02\t\tLearning rate: 1.833e-04, Batch size: 27, Momentum: 5.784e-01\n",
      "Initial loss:  460.94815242562817\n",
      "best loss: 451.55\t\tLearning rate: 2.336e-06, Batch size: 29, Momentum: 9.464e-01\n",
      "Initial loss:  453.45148742875057\n",
      "best loss: 450.17\t\tLearning rate: 2.069e-05, Batch size: 44, Momentum: 5.784e-01\n",
      "Initial loss:  131913.78426180204\n",
      "best loss: 1190.17\t\tLearning rate: 1.274e-01, Batch size: 4, Momentum: 8.413e-01\n",
      "Initial loss:  412472.4895909497\n",
      "best loss: 1022.77\t\tLearning rate: 4.833e-03, Batch size: 32, Momentum: 7.887e-01\n",
      "Initial loss:  469.98874030964384\n",
      "best loss: 450.17\t\tLearning rate: 1.000e+01, Batch size: 50, Momentum: 8.938e-01\n",
      "Initial loss:  78386.67217606565\n",
      "best loss: 1365.45\t\tLearning rate: 1.000e+01, Batch size: 47, Momentum: 2.629e-01\n",
      "Initial loss:  460.461024858053\n",
      "best loss: 448.89\t\tLearning rate: 7.848e-07, Batch size: 37, Momentum: 8.413e-01\n",
      "Initial loss:  890734.6620383932\n",
      "best loss: 798.49\t\tLearning rate: 1.833e-04, Batch size: 4, Momentum: 3.155e-01\n",
      "Initial loss:  63001.000951692964\n",
      "best loss: 1228.72\t\tLearning rate: 1.000e-08, Batch size: 47, Momentum: 1.577e-01\n",
      "Initial loss:  59742.785044121294\n",
      "best loss: 467.03\t\tLearning rate: 2.637e-07, Batch size: 22, Momentum: 3.155e-01\n",
      "Initial loss:  732494.3003527886\n",
      "best loss: 816671.59\t\tLearning rate: 1.438e-02, Batch size: 19, Momentum: 0.000e+00\n",
      "Initial loss:  454.592154450397\n",
      "best loss: 441.98\t\tLearning rate: 3.360e+00, Batch size: 9, Momentum: 9.990e-01\n",
      "Initial loss:  143445.34761770474\n",
      "best loss: 489.13\t\tLearning rate: 2.637e-07, Batch size: 22, Momentum: 2.629e-01\n",
      "Initial loss:  418674.3195540735\n",
      "best loss: 946.04\t\tLearning rate: 4.833e-03, Batch size: 2, Momentum: 3.681e-01\n",
      "Initial loss:  182375.24337060112\n",
      "best loss: 431.62\t\tLearning rate: 2.637e-07, Batch size: 2, Momentum: 1.577e-01\n",
      "Initial loss:  76217.62190052691\n",
      "best loss: 1431.71\t\tLearning rate: 1.000e+01, Batch size: 37, Momentum: 8.413e-01\n",
      "Initial loss:  562274.6569330392\n",
      "best loss: 717.35\t\tLearning rate: 6.158e-05, Batch size: 29, Momentum: 9.990e-01\n",
      "Initial loss:  277028.3781495659\n",
      "best loss: 696.78\t\tLearning rate: 6.158e-05, Batch size: 12, Momentum: 5.258e-02\n",
      "Initial loss:  134267.17239409374\n",
      "best loss: 1046.97\t\tLearning rate: 1.438e-02, Batch size: 42, Momentum: 7.887e-01\n",
      "Initial loss:  492.2944605466266\n",
      "best loss: 458.33\t\tLearning rate: 2.637e-07, Batch size: 7, Momentum: 1.577e-01\n",
      "Initial loss:  825127.1351267386\n",
      "best loss: 912.17\t\tLearning rate: 1.624e-03, Batch size: 32, Momentum: 6.309e-01\n",
      "Initial loss:  50333.69096155673\n",
      "best loss: 895.53\t\tLearning rate: 1.624e-03, Batch size: 42, Momentum: 2.103e-01\n",
      "Initial loss:  605624.3469069009\n",
      "best loss: 29604.84\t\tLearning rate: 7.848e-07, Batch size: 50, Momentum: 3.681e-01\n",
      "Initial loss:  464.26318535634095\n",
      "best loss: 451.79\t\tLearning rate: 1.624e-03, Batch size: 19, Momentum: 1.577e-01\n",
      "Initial loss:  99003.40306103077\n",
      "best loss: 892.61\t\tLearning rate: 5.456e-04, Batch size: 29, Momentum: 4.732e-01\n",
      "Initial loss:  649565.2132988014\n",
      "best loss: 465.58\t\tLearning rate: 6.952e-06, Batch size: 9, Momentum: 3.681e-01\n",
      "Initial loss:  267655.10231277236\n",
      "best loss: 464.60\t\tLearning rate: 7.848e-07, Batch size: 47, Momentum: 4.206e-01\n",
      "Initial loss:  738270.7575111355\n",
      "best loss: 15457.30\t\tLearning rate: 2.976e-08, Batch size: 4, Momentum: 5.258e-01\n",
      "Initial loss:  461.4681052460058\n",
      "best loss: 443.44\t\tLearning rate: 4.281e-02, Batch size: 12, Momentum: 8.413e-01\n",
      "Initial loss:  490306.03113745106\n",
      "best loss: 747.85\t\tLearning rate: 2.976e-08, Batch size: 27, Momentum: 5.258e-01\n",
      "Initial loss:  350098.9088225385\n",
      "best loss: 1300.70\t\tLearning rate: 1.000e+01, Batch size: 19, Momentum: 1.052e-01\n",
      "Initial loss:  228856.16653679777\n",
      "best loss: 442.34\t\tLearning rate: 6.952e-06, Batch size: 9, Momentum: 1.052e-01\n",
      "Initial loss:  342925.44867292594\n",
      "best loss: 1216.80\t\tLearning rate: 1.129e+00, Batch size: 24, Momentum: 1.577e-01\n",
      "Initial loss:  472.24198360229434\n",
      "best loss: 465.73\t\tLearning rate: 7.848e-07, Batch size: 50, Momentum: 2.629e-01\n",
      "Initial loss:  449.2737174325774\n",
      "best loss: 438.60\t\tLearning rate: 1.833e-04, Batch size: 7, Momentum: 3.681e-01\n",
      "Initial loss:  29168.944389266824\n",
      "best loss: 1137.07\t\tLearning rate: 3.793e-01, Batch size: 7, Momentum: 2.629e-01\n",
      "Initial loss:  29594.86536245665\n",
      "best loss: 425.96\t\tLearning rate: 6.952e-06, Batch size: 2, Momentum: 4.732e-01\n",
      "Initial loss:  488284.93271213165\n",
      "best loss: 1311.39\t\tLearning rate: 1.129e+00, Batch size: 22, Momentum: 8.413e-01\n",
      "Initial loss:  72391.68248713383\n",
      "best loss: 455.90\t\tLearning rate: 2.637e-07, Batch size: 27, Momentum: 4.206e-01\n",
      "Initial loss:  450.53090926417894\n",
      "best loss: 448.81\t\tLearning rate: 8.859e-08, Batch size: 34, Momentum: 8.413e-01\n",
      "Initial loss:  1051137.1472048005\n",
      "best loss: 1008.56\t\tLearning rate: 4.833e-03, Batch size: 2, Momentum: 8.413e-01\n",
      "Initial loss:  420592.09534976416\n",
      "best loss: 1215.01\t\tLearning rate: 1.274e-01, Batch size: 9, Momentum: 7.887e-01\n",
      "Initial loss:  810840.7267855668\n",
      "best loss: 4382.84\t\tLearning rate: 1.129e+00, Batch size: 4, Momentum: 2.103e-01\n",
      "Initial loss:  24925.582786326828\n",
      "best loss: 1250.52\t\tLearning rate: 3.360e+00, Batch size: 12, Momentum: 4.732e-01\n",
      "Initial loss:  453.0138969655253\n",
      "best loss: 448.06\t\tLearning rate: 6.158e-05, Batch size: 37, Momentum: 2.103e-01\n",
      "Initial loss:  501047.29641026445\n",
      "best loss: 442.42\t\tLearning rate: 7.848e-07, Batch size: 9, Momentum: 2.629e-01\n",
      "Initial loss:  339133.93524993653\n",
      "best loss: 455.62\t\tLearning rate: 8.859e-08, Batch size: 37, Momentum: 7.887e-01\n",
      "Initial loss:  453.42630265053174\n",
      "best loss: 443.98\t\tLearning rate: 1.274e-01, Batch size: 14, Momentum: 8.938e-01\n",
      "Initial loss:  387082.86962639034\n",
      "best loss: 453.92\t\tLearning rate: 7.848e-07, Batch size: 22, Momentum: 4.732e-01\n",
      "Initial loss:  309406.7525106663\n",
      "best loss: 790.21\t\tLearning rate: 1.833e-04, Batch size: 39, Momentum: 9.990e-01\n",
      "Initial loss:  652639.8718275578\n",
      "best loss: 1138.84\t\tLearning rate: 3.793e-01, Batch size: 9, Momentum: 3.681e-01\n",
      "Initial loss:  209489.47054393435\n",
      "best loss: 455.03\t\tLearning rate: 1.000e-08, Batch size: 14, Momentum: 9.464e-01\n",
      "Initial loss:  462128.74873198854\n",
      "best loss: 795.97\t\tLearning rate: 1.833e-04, Batch size: 39, Momentum: 4.732e-01\n",
      "Initial loss:  292003.36508787767\n",
      "best loss: 914.93\t\tLearning rate: 4.833e-03, Batch size: 24, Momentum: 0.000e+00\n",
      "Initial loss:  726648.5134349572\n",
      "best loss: 1192.35\t\tLearning rate: 1.274e-01, Batch size: 39, Momentum: 7.887e-01\n",
      "Initial loss:  528321.3820179484\n",
      "best loss: 763.57\t\tLearning rate: 6.158e-05, Batch size: 4, Momentum: 4.206e-01\n",
      "Initial loss:  476.0373961272679\n",
      "best loss: 429.36\t\tLearning rate: 5.456e-04, Batch size: 2, Momentum: 1.052e-01\n",
      "Initial loss:  712032.9407447793\n",
      "best loss: 1141.42\t\tLearning rate: 1.274e-01, Batch size: 27, Momentum: 6.309e-01\n",
      "Initial loss:  836812.092920545\n",
      "best loss: 914.11\t\tLearning rate: 1.624e-03, Batch size: 4, Momentum: 4.732e-01\n",
      "Initial loss:  466.51193089365734\n",
      "best loss: 445.90\t\tLearning rate: 1.624e-03, Batch size: 17, Momentum: 1.052e-01\n",
      "Initial loss:  752259.9897397917\n",
      "best loss: 955.11\t\tLearning rate: 1.438e-02, Batch size: 9, Momentum: 0.000e+00\n",
      "Initial loss:  454.97813518820027\n",
      "best loss: 444.35\t\tLearning rate: 2.336e-06, Batch size: 14, Momentum: 2.629e-01\n",
      "Initial loss:  455.19832170132827\n",
      "best loss: 448.62\t\tLearning rate: 1.624e-03, Batch size: 17, Momentum: 3.681e-01\n",
      "Initial loss:  329495.5114912648\n",
      "best loss: 461.66\t\tLearning rate: 8.859e-08, Batch size: 47, Momentum: 7.887e-01\n",
      "Initial loss:  451.78159008226925\n",
      "best loss: 447.30\t\tLearning rate: 1.438e-02, Batch size: 39, Momentum: 1.577e-01\n",
      "Initial loss:  686156.6923637924\n",
      "best loss: 1215.65\t\tLearning rate: 3.793e-01, Batch size: 34, Momentum: 4.732e-01\n",
      "Initial loss:  316671.4250556851\n",
      "best loss: 499.29\t\tLearning rate: 1.000e-08, Batch size: 12, Momentum: 7.887e-01\n",
      "Initial loss:  291641.93782776874\n",
      "best loss: 214387.48\t\tLearning rate: 2.976e-08, Batch size: 39, Momentum: 5.258e-02\n",
      "Initial loss:  71536.55049727065\n",
      "best loss: 1167.93\t\tLearning rate: 3.793e-01, Batch size: 9, Momentum: 1.577e-01\n",
      "Initial loss:  358869.4319568242\n",
      "best loss: 1101.17\t\tLearning rate: 4.281e-02, Batch size: 12, Momentum: 7.361e-01\n",
      "Initial loss:  147734.6449413399\n",
      "best loss: 951.41\t\tLearning rate: 1.624e-03, Batch size: 12, Momentum: 6.835e-01\n",
      "Initial loss:  713836.8215172164\n",
      "best loss: 906.34\t\tLearning rate: 1.833e-04, Batch size: 50, Momentum: 9.990e-01\n",
      "Initial loss:  61176.916141140726\n",
      "best loss: 1179.54\t\tLearning rate: 1.274e-01, Batch size: 34, Momentum: 7.361e-01\n",
      "Initial loss:  413330.18723065953\n",
      "best loss: 1315.78\t\tLearning rate: 3.360e+00, Batch size: 24, Momentum: 4.206e-01\n",
      "Initial loss:  448.0059208194381\n",
      "best loss: 439.40\t\tLearning rate: 3.360e+00, Batch size: 9, Momentum: 9.464e-01\n",
      "Initial loss:  465.89924018866395\n",
      "best loss: 440.60\t\tLearning rate: 1.624e-03, Batch size: 12, Momentum: 3.681e-01\n",
      "Initial loss:  181507.6425785089\n",
      "best loss: 1170.17\t\tLearning rate: 3.793e-01, Batch size: 2, Momentum: 4.732e-01\n",
      "Initial loss:  456.9784886502998\n",
      "best loss: 448.37\t\tLearning rate: 1.624e-03, Batch size: 37, Momentum: 8.938e-01\n",
      "Initial loss:  672426.6168429431\n",
      "best loss: 1246.51\t\tLearning rate: 3.360e+00, Batch size: 22, Momentum: 0.000e+00\n",
      "Initial loss:  700202.2171449801\n",
      "best loss: 940.40\t\tLearning rate: 1.624e-03, Batch size: 29, Momentum: 5.784e-01\n",
      "Initial loss:  611501.4471312143\n",
      "best loss: 1141.22\t\tLearning rate: 4.281e-02, Batch size: 27, Momentum: 8.938e-01\n",
      "Initial loss:  708402.8830461781\n",
      "best loss: 443.39\t\tLearning rate: 6.952e-06, Batch size: 7, Momentum: 5.784e-01\n",
      "Initial loss:  232994.7495498171\n",
      "best loss: 1018.45\t\tLearning rate: 4.833e-03, Batch size: 9, Momentum: 8.938e-01\n",
      "Initial loss:  288925.7522850011\n",
      "best loss: 811.74\t\tLearning rate: 5.456e-04, Batch size: 42, Momentum: 2.103e-01\n",
      "Initial loss:  597798.2526273925\n",
      "best loss: 1364.07\t\tLearning rate: 1.000e+01, Batch size: 19, Momentum: 2.103e-01\n",
      "Initial loss:  578889.3432991523\n",
      "best loss: 744.90\t\tLearning rate: 6.158e-05, Batch size: 32, Momentum: 4.206e-01\n",
      "Initial loss:  452085.381004638\n",
      "best loss: 1028.20\t\tLearning rate: 1.438e-02, Batch size: 4, Momentum: 2.103e-01\n",
      "Initial loss:  457.0154318916582\n",
      "best loss: 449.92\t\tLearning rate: 2.336e-06, Batch size: 17, Momentum: 4.732e-01\n",
      "Initial loss:  244950.05089747146\n",
      "best loss: 613.51\t\tLearning rate: 6.158e-05, Batch size: 4, Momentum: 1.577e-01\n",
      "Initial loss:  312579.3529250642\n",
      "best loss: 799.30\t\tLearning rate: 1.833e-04, Batch size: 17, Momentum: 3.681e-01\n",
      "Initial loss:  211062.12683640947\n",
      "best loss: 1130.79\t\tLearning rate: 1.274e-01, Batch size: 14, Momentum: 2.103e-01\n",
      "Initial loss:  615600.3018762366\n",
      "best loss: 462.50\t\tLearning rate: 6.952e-06, Batch size: 14, Momentum: 9.464e-01\n",
      "Initial loss:  458.96513364305076\n",
      "best loss: 448.59\t\tLearning rate: 1.438e-02, Batch size: 29, Momentum: 4.732e-01\n",
      "Initial loss:  648174.981099996\n",
      "best loss: 925.09\t\tLearning rate: 1.624e-03, Batch size: 2, Momentum: 5.258e-01\n",
      "Initial loss:  160692.27366853456\n",
      "best loss: 453.70\t\tLearning rate: 2.637e-07, Batch size: 42, Momentum: 6.309e-01\n",
      "Initial loss:  764089.373864439\n",
      "best loss: 1049.09\t\tLearning rate: 4.833e-03, Batch size: 12, Momentum: 9.464e-01\n",
      "Initial loss:  240047.7887448343\n",
      "best loss: 1261.33\t\tLearning rate: 3.360e+00, Batch size: 4, Momentum: 0.000e+00\n",
      "Initial loss:  662583.080410827\n",
      "best loss: 1237.09\t\tLearning rate: 1.274e-01, Batch size: 19, Momentum: 9.464e-01\n",
      "Initial loss:  579152.5057498998\n",
      "best loss: 89583.66\t\tLearning rate: 1.000e-08, Batch size: 37, Momentum: 2.629e-01\n",
      "Initial loss:  322055.65360244975\n",
      "best loss: 853.06\t\tLearning rate: 5.456e-04, Batch size: 34, Momentum: 5.784e-01\n",
      "Initial loss:  512044.4714417649\n",
      "best loss: 796.51\t\tLearning rate: 2.069e-05, Batch size: 47, Momentum: 7.361e-01\n",
      "Initial loss:  667751.9890839694\n",
      "best loss: 1169.29\t\tLearning rate: 3.793e-01, Batch size: 39, Momentum: 2.103e-01\n",
      "Initial loss:  464.4775012007519\n",
      "best loss: 453.14\t\tLearning rate: 1.129e+00, Batch size: 50, Momentum: 8.413e-01\n",
      "Initial loss:  504822.16605402104\n",
      "best loss: 1069.59\t\tLearning rate: 4.281e-02, Batch size: 2, Momentum: 7.361e-01\n",
      "Initial loss:  150977.6588213677\n",
      "best loss: 816.70\t\tLearning rate: 5.456e-04, Batch size: 17, Momentum: 4.206e-01\n",
      "Initial loss:  488597.0511795372\n",
      "best loss: 529.50\t\tLearning rate: 8.859e-08, Batch size: 4, Momentum: 1.052e-01\n",
      "Initial loss:  320646.4006420874\n",
      "best loss: 827.35\t\tLearning rate: 1.833e-04, Batch size: 4, Momentum: 8.413e-01\n",
      "Initial loss:  563206.8134915093\n",
      "best loss: 984.46\t\tLearning rate: 1.624e-03, Batch size: 29, Momentum: 8.413e-01\n",
      "Initial loss:  933023.6295004613\n",
      "best loss: 1062.30\t\tLearning rate: 4.281e-02, Batch size: 24, Momentum: 3.681e-01\n",
      "Initial loss:  147608.02221996267\n",
      "best loss: 688.08\t\tLearning rate: 6.158e-05, Batch size: 24, Momentum: 6.309e-01\n",
      "Initial loss:  165148.36311731767\n",
      "best loss: 822.84\t\tLearning rate: 1.833e-04, Batch size: 4, Momentum: 5.258e-01\n",
      "Initial loss:  459.5267950034798\n",
      "best loss: 446.50\t\tLearning rate: 6.952e-06, Batch size: 29, Momentum: 1.577e-01\n",
      "Initial loss:  505366.97003948735\n",
      "best loss: 55038.09\t\tLearning rate: 8.859e-08, Batch size: 24, Momentum: 4.732e-01\n",
      "Initial loss:  368968.8962509185\n",
      "best loss: 472.48\t\tLearning rate: 2.637e-07, Batch size: 42, Momentum: 2.103e-01\n",
      "Initial loss:  446.78018996614014\n",
      "best loss: 440.91\t\tLearning rate: 2.637e-07, Batch size: 12, Momentum: 3.681e-01\n",
      "Initial loss:  322080.72084105405\n",
      "best loss: 1003.04\t\tLearning rate: 1.438e-02, Batch size: 44, Momentum: 3.155e-01\n",
      "Initial loss:  456.1747269850965\n",
      "best loss: 449.29\t\tLearning rate: 4.833e-03, Batch size: 47, Momentum: 3.681e-01\n",
      "Initial loss:  466.93551207033363\n",
      "best loss: 446.03\t\tLearning rate: 1.129e+00, Batch size: 27, Momentum: 8.938e-01\n",
      "Initial loss:  834535.3304030801\n",
      "best loss: 161389.66\t\tLearning rate: 2.336e-06, Batch size: 34, Momentum: 4.732e-01\n",
      "Initial loss:  110306.89153384877\n",
      "best loss: 889.47\t\tLearning rate: 1.624e-03, Batch size: 14, Momentum: 8.938e-01\n",
      "Initial loss:  456.876144577256\n",
      "best loss: 444.60\t\tLearning rate: 1.000e+01, Batch size: 27, Momentum: 9.464e-01\n",
      "Initial loss:  134340.03803875012\n",
      "best loss: 437.68\t\tLearning rate: 2.069e-05, Batch size: 4, Momentum: 4.732e-01\n",
      "Initial loss:  521032.8239933817\n",
      "best loss: 63643.25\t\tLearning rate: 7.848e-07, Batch size: 22, Momentum: 1.577e-01\n",
      "Initial loss:  629942.888067106\n",
      "best loss: 1056.54\t\tLearning rate: 4.281e-02, Batch size: 29, Momentum: 7.887e-01\n",
      "Initial loss:  440099.3310380961\n",
      "best loss: 449.59\t\tLearning rate: 2.336e-06, Batch size: 50, Momentum: 5.258e-01\n",
      "Initial loss:  459.6853478171684\n",
      "best loss: 447.28\t\tLearning rate: 1.274e-01, Batch size: 39, Momentum: 7.887e-01\n",
      "Initial loss:  844956.7484872607\n",
      "best loss: 458.91\t\tLearning rate: 2.069e-05, Batch size: 34, Momentum: 1.052e-01\n",
      "Initial loss:  159559.74640659936\n",
      "best loss: 454.72\t\tLearning rate: 2.976e-08, Batch size: 47, Momentum: 8.938e-01\n",
      "Initial loss:  1182445.1963363076\n",
      "best loss: 1040.93\t\tLearning rate: 1.438e-02, Batch size: 47, Momentum: 9.464e-01\n",
      "Initial loss:  451.83584498936733\n",
      "best loss: 450.51\t\tLearning rate: 1.438e-02, Batch size: 50, Momentum: 6.309e-01\n",
      "Initial loss:  442412.100250199\n",
      "best loss: 448.14\t\tLearning rate: 2.336e-06, Batch size: 9, Momentum: 1.052e-01\n",
      "Initial loss:  460549.0907486081\n",
      "best loss: 458.79\t\tLearning rate: 6.952e-06, Batch size: 2, Momentum: 9.990e-01\n",
      "Initial loss:  110835.24501774128\n",
      "best loss: 1179.50\t\tLearning rate: 3.793e-01, Batch size: 9, Momentum: 2.103e-01\n",
      "Initial loss:  213362.21449206726\n",
      "best loss: 871.17\t\tLearning rate: 5.456e-04, Batch size: 39, Momentum: 5.258e-01\n",
      "Initial loss:  163815.9538344974\n",
      "best loss: 1344.13\t\tLearning rate: 1.129e+00, Batch size: 47, Momentum: 8.938e-01\n",
      "Initial loss:  432444.2409127645\n",
      "best loss: 31332.00\t\tLearning rate: 6.158e-05, Batch size: 22, Momentum: 0.000e+00\n",
      "Initial loss:  299226.51878365385\n",
      "best loss: 1239.65\t\tLearning rate: 1.129e+00, Batch size: 19, Momentum: 4.206e-01\n",
      "Initial loss:  270190.15530182957\n",
      "best loss: 1124.89\t\tLearning rate: 1.274e-01, Batch size: 19, Momentum: 2.103e-01\n",
      "Initial loss:  456.3666852585296\n",
      "best loss: 448.52\t\tLearning rate: 1.000e-08, Batch size: 37, Momentum: 7.887e-01\n",
      "Initial loss:  423111.0839806956\n",
      "best loss: 571.25\t\tLearning rate: 2.637e-07, Batch size: 39, Momentum: 1.577e-01\n",
      "Initial loss:  453.74540400824253\n",
      "best loss: 449.50\t\tLearning rate: 2.069e-05, Batch size: 50, Momentum: 2.629e-01\n",
      "Initial loss:  27513.774792841774\n",
      "best loss: 1151.72\t\tLearning rate: 3.793e-01, Batch size: 2, Momentum: 3.681e-01\n",
      "Initial loss:  601034.4893916835\n",
      "best loss: 551.44\t\tLearning rate: 2.976e-08, Batch size: 14, Momentum: 4.732e-01\n",
      "Initial loss:  687133.002660453\n",
      "best loss: 1213.08\t\tLearning rate: 1.129e+00, Batch size: 39, Momentum: 0.000e+00\n",
      "Initial loss:  449.9547908203596\n",
      "best loss: 439.80\t\tLearning rate: 5.456e-04, Batch size: 9, Momentum: 6.309e-01\n",
      "Initial loss:  325031.7184329361\n",
      "best loss: 443.27\t\tLearning rate: 2.336e-06, Batch size: 12, Momentum: 1.052e-01\n",
      "Initial loss:  451.5256515000238\n",
      "best loss: 432.28\t\tLearning rate: 1.438e-02, Batch size: 4, Momentum: 4.206e-01\n",
      "Initial loss:  308259.31300387246\n",
      "best loss: 876.67\t\tLearning rate: 5.456e-04, Batch size: 29, Momentum: 8.938e-01\n",
      "Initial loss:  551021.333947252\n",
      "best loss: 483.51\t\tLearning rate: 8.859e-08, Batch size: 14, Momentum: 8.413e-01\n",
      "Initial loss:  818380.8439228222\n",
      "best loss: 474.09\t\tLearning rate: 8.859e-08, Batch size: 14, Momentum: 7.361e-01\n",
      "Initial loss:  274032.3702656454\n",
      "best loss: 458.37\t\tLearning rate: 2.069e-05, Batch size: 12, Momentum: 2.103e-01\n",
      "Initial loss:  617529.2066603404\n",
      "best loss: 784.04\t\tLearning rate: 1.833e-04, Batch size: 42, Momentum: 7.361e-01\n",
      "Initial loss:  313499.75384619524\n",
      "best loss: 448.43\t\tLearning rate: 7.848e-07, Batch size: 22, Momentum: 7.887e-01\n",
      "Initial loss:  182382.9854241146\n",
      "best loss: 924.14\t\tLearning rate: 4.833e-03, Batch size: 44, Momentum: 1.577e-01\n",
      "Initial loss:  205162.65817982945\n",
      "best loss: 1346.89\t\tLearning rate: 1.000e+01, Batch size: 34, Momentum: 3.681e-01\n",
      "Initial loss:  255862.98877237408\n",
      "best loss: 999.93\t\tLearning rate: 4.833e-03, Batch size: 34, Momentum: 6.835e-01\n",
      "Initial loss:  512944.9973940026\n",
      "best loss: 1209.21\t\tLearning rate: 3.793e-01, Batch size: 4, Momentum: 4.732e-01\n",
      "Initial loss:  804061.2137407486\n",
      "best loss: 1313.88\t\tLearning rate: 3.793e-01, Batch size: 37, Momentum: 9.990e-01\n",
      "Initial loss:  465.49768915751565\n",
      "best loss: 435.57\t\tLearning rate: 1.833e-04, Batch size: 4, Momentum: 3.681e-01\n",
      "Initial loss:  341071.80920559267\n",
      "best loss: 526.15\t\tLearning rate: 1.000e-08, Batch size: 44, Momentum: 8.938e-01\n",
      "Initial loss:  207310.15568552344\n",
      "best loss: 451.59\t\tLearning rate: 7.848e-07, Batch size: 12, Momentum: 0.000e+00\n",
      "Initial loss:  286140.045325896\n",
      "best loss: 997.99\t\tLearning rate: 1.438e-02, Batch size: 39, Momentum: 2.629e-01\n",
      "Initial loss:  792937.5262592371\n",
      "best loss: 520.13\t\tLearning rate: 2.976e-08, Batch size: 22, Momentum: 5.784e-01\n",
      "Initial loss:  448.836195225851\n",
      "best loss: 440.87\t\tLearning rate: 2.976e-08, Batch size: 9, Momentum: 2.629e-01\n",
      "Initial loss:  474.25418536044106\n",
      "best loss: 425.53\t\tLearning rate: 4.281e-02, Batch size: 2, Momentum: 1.052e-01\n",
      "Initial loss:  67241.17585567354\n",
      "best loss: 446.91\t\tLearning rate: 2.069e-05, Batch size: 14, Momentum: 6.309e-01\n",
      "Initial loss:  259883.2635735499\n",
      "best loss: 466.90\t\tLearning rate: 2.637e-07, Batch size: 37, Momentum: 7.361e-01\n",
      "Initial loss:  134160.24370380325\n",
      "best loss: 740.62\t\tLearning rate: 6.158e-05, Batch size: 32, Momentum: 4.732e-01\n",
      "Initial loss:  211600.4344748263\n",
      "best loss: 986.78\t\tLearning rate: 1.438e-02, Batch size: 44, Momentum: 1.577e-01\n",
      "Initial loss:  763201.6388122453\n",
      "best loss: 315889.03\t\tLearning rate: 2.976e-08, Batch size: 42, Momentum: 1.577e-01\n",
      "Initial loss:  146026.56950409382\n",
      "best loss: 1224.02\t\tLearning rate: 1.129e+00, Batch size: 32, Momentum: 5.258e-01\n",
      "Initial loss:  323911.85882859427\n",
      "best loss: 1059.03\t\tLearning rate: 4.281e-02, Batch size: 22, Momentum: 2.629e-01\n",
      "Initial loss:  282034.56318855105\n",
      "best loss: 829.08\t\tLearning rate: 5.456e-04, Batch size: 17, Momentum: 6.309e-01\n",
      "Initial loss:  637581.8236456375\n",
      "best loss: 452.55\t\tLearning rate: 2.336e-06, Batch size: 47, Momentum: 9.464e-01\n",
      "Initial loss:  337958.935846508\n",
      "best loss: 780.64\t\tLearning rate: 1.000e-08, Batch size: 47, Momentum: 3.155e-01\n",
      "Initial loss:  618105.0853264668\n",
      "best loss: 1328.52\t\tLearning rate: 1.000e+01, Batch size: 39, Momentum: 2.629e-01\n",
      "Initial loss:  243964.67565798952\n",
      "best loss: 855.62\t\tLearning rate: 1.833e-04, Batch size: 34, Momentum: 9.990e-01\n",
      "Initial loss:  57026.22964655161\n",
      "best loss: 916.01\t\tLearning rate: 1.624e-03, Batch size: 17, Momentum: 5.258e-01\n",
      "Initial loss:  286703.92147782614\n",
      "best loss: 61214.26\t\tLearning rate: 8.859e-08, Batch size: 24, Momentum: 2.629e-01\n",
      "Initial loss:  497375.0800765262\n",
      "best loss: 1111.88\t\tLearning rate: 4.281e-02, Batch size: 34, Momentum: 8.938e-01\n",
      "Initial loss:  528839.5121616469\n",
      "best loss: 452.01\t\tLearning rate: 2.336e-06, Batch size: 44, Momentum: 9.990e-01\n",
      "Initial loss:  805031.6321256161\n",
      "best loss: 444.26\t\tLearning rate: 2.976e-08, Batch size: 9, Momentum: 9.464e-01\n",
      "Initial loss:  1212915.3492497338\n",
      "best loss: 1249.68\t\tLearning rate: 3.360e+00, Batch size: 47, Momentum: 5.258e-02\n",
      "Initial loss:  128527.30701299415\n",
      "best loss: 1289.76\t\tLearning rate: 3.360e+00, Batch size: 22, Momentum: 1.577e-01\n",
      "Initial loss:  496232.0992258553\n",
      "best loss: 1103.76\t\tLearning rate: 1.274e-01, Batch size: 14, Momentum: 1.577e-01\n",
      "Initial loss:  824604.4384799725\n",
      "best loss: 1356.82\t\tLearning rate: 3.360e+00, Batch size: 44, Momentum: 8.938e-01\n",
      "Initial loss:  90770.33642064038\n",
      "best loss: 449.99\t\tLearning rate: 6.952e-06, Batch size: 17, Momentum: 1.577e-01\n",
      "Initial loss:  177159.11629691842\n",
      "best loss: 947.16\t\tLearning rate: 1.624e-03, Batch size: 47, Momentum: 8.413e-01\n",
      "Initial loss:  685575.9255488993\n",
      "best loss: 448.56\t\tLearning rate: 7.848e-07, Batch size: 47, Momentum: 7.887e-01\n",
      "Initial loss:  167275.51178859512\n",
      "best loss: 459.49\t\tLearning rate: 2.336e-06, Batch size: 27, Momentum: 5.258e-02\n",
      "Initial loss:  333907.5636398291\n",
      "best loss: 91511.20\t\tLearning rate: 8.859e-08, Batch size: 24, Momentum: 3.155e-01\n",
      "Initial loss:  817991.1468295215\n",
      "best loss: 1054.35\t\tLearning rate: 1.438e-02, Batch size: 37, Momentum: 6.835e-01\n",
      "Initial loss:  169440.1439928437\n",
      "best loss: 446.30\t\tLearning rate: 2.336e-06, Batch size: 12, Momentum: 3.155e-01\n",
      "Initial loss:  101292.23708738181\n",
      "best loss: 439.92\t\tLearning rate: 7.848e-07, Batch size: 9, Momentum: 7.887e-01\n",
      "Initial loss:  343327.6823700305\n",
      "best loss: 796.78\t\tLearning rate: 1.833e-04, Batch size: 22, Momentum: 9.464e-01\n",
      "Initial loss:  247578.7802571659\n",
      "best loss: 453.36\t\tLearning rate: 6.952e-06, Batch size: 50, Momentum: 4.206e-01\n",
      "Initial loss:  609285.5771169971\n",
      "best loss: 462.80\t\tLearning rate: 2.637e-07, Batch size: 34, Momentum: 5.784e-01\n",
      "Initial loss:  126202.76138515837\n",
      "best loss: 104526.56\t\tLearning rate: 8.859e-08, Batch size: 47, Momentum: 7.361e-01\n",
      "Initial loss:  671046.542239431\n",
      "best loss: 441.47\t\tLearning rate: 8.859e-08, Batch size: 4, Momentum: 3.681e-01\n",
      "Initial loss:  521902.38170022686\n",
      "best loss: 770.22\t\tLearning rate: 1.833e-04, Batch size: 14, Momentum: 8.413e-01\n",
      "Initial loss:  315304.6034493675\n",
      "best loss: 1409.59\t\tLearning rate: 3.360e+00, Batch size: 44, Momentum: 9.990e-01\n",
      "Initial loss:  156211.75920281612\n",
      "best loss: 433.00\t\tLearning rate: 6.952e-06, Batch size: 2, Momentum: 4.732e-01\n",
      "Initial loss:  329315.09597225615\n",
      "best loss: 1108.52\t\tLearning rate: 1.438e-02, Batch size: 17, Momentum: 7.361e-01\n",
      "Initial loss:  332912.64571859455\n",
      "best loss: 1115.39\t\tLearning rate: 4.281e-02, Batch size: 42, Momentum: 7.887e-01\n",
      "Initial loss:  453.86116667747154\n",
      "best loss: 446.82\t\tLearning rate: 2.069e-05, Batch size: 37, Momentum: 0.000e+00\n",
      "Initial loss:  266426.34198961145\n",
      "best loss: 812.35\t\tLearning rate: 1.833e-04, Batch size: 42, Momentum: 3.681e-01\n",
      "Initial loss:  376446.8878859566\n",
      "best loss: 38392.33\t\tLearning rate: 1.000e-08, Batch size: 50, Momentum: 7.361e-01\n",
      "Initial loss:  278460.3069117807\n",
      "best loss: 1100.19\t\tLearning rate: 1.274e-01, Batch size: 42, Momentum: 1.577e-01\n",
      "Initial loss:  360211.303070588\n",
      "best loss: 1289.63\t\tLearning rate: 1.000e+01, Batch size: 37, Momentum: 1.052e-01\n",
      "Initial loss:  352909.4808853859\n",
      "best loss: 451.61\t\tLearning rate: 2.336e-06, Batch size: 44, Momentum: 2.103e-01\n",
      "Initial loss:  954814.1504881444\n",
      "best loss: 871169.13\t\tLearning rate: 3.793e-01, Batch size: 50, Momentum: 0.000e+00\n",
      "Initial loss:  929625.0425605793\n",
      "best loss: 771.35\t\tLearning rate: 6.158e-05, Batch size: 19, Momentum: 5.784e-01\n",
      "Initial loss:  636144.4462685543\n",
      "best loss: 455.66\t\tLearning rate: 2.637e-07, Batch size: 39, Momentum: 7.887e-01\n",
      "Initial loss:  461.81263971992325\n",
      "best loss: 430.54\t\tLearning rate: 2.637e-07, Batch size: 2, Momentum: 8.938e-01\n",
      "Initial loss:  537.7222070368919\n",
      "best loss: 515.98\t\tLearning rate: 6.952e-06, Batch size: 39, Momentum: 5.258e-02\n",
      "Initial loss:  460.5374913463607\n",
      "best loss: 440.00\t\tLearning rate: 4.281e-02, Batch size: 4, Momentum: 8.938e-01\n",
      "Initial loss:  345452.58801599685\n",
      "best loss: 446.43\t\tLearning rate: 8.859e-08, Batch size: 19, Momentum: 7.361e-01\n",
      "Initial loss:  157494.49612490044\n",
      "best loss: 828.97\t\tLearning rate: 2.976e-08, Batch size: 14, Momentum: 4.732e-01\n",
      "Initial loss:  529635.3552964942\n",
      "best loss: 874.65\t\tLearning rate: 1.624e-03, Batch size: 27, Momentum: 2.103e-01\n",
      "Initial loss:  528347.7496869343\n",
      "best loss: 1229.93\t\tLearning rate: 1.129e+00, Batch size: 29, Momentum: 3.155e-01\n",
      "Initial loss:  611826.3808936782\n",
      "best loss: 1077.00\t\tLearning rate: 4.281e-02, Batch size: 50, Momentum: 5.784e-01\n",
      "Initial loss:  307083.1697147089\n",
      "best loss: 38697.91\t\tLearning rate: 1.000e-08, Batch size: 24, Momentum: 1.052e-01\n",
      "Initial loss:  461994.47636495694\n",
      "best loss: 1136.22\t\tLearning rate: 1.274e-01, Batch size: 14, Momentum: 5.258e-01\n",
      "Initial loss:  452.64051452556185\n",
      "best loss: 437.03\t\tLearning rate: 4.833e-03, Batch size: 7, Momentum: 9.990e-01\n",
      "Initial loss:  85865.21641604039\n",
      "best loss: 449.45\t\tLearning rate: 2.336e-06, Batch size: 29, Momentum: 6.835e-01\n",
      "Initial loss:  149322.6748677198\n",
      "best loss: 1164.20\t\tLearning rate: 3.793e-01, Batch size: 50, Momentum: 2.629e-01\n",
      "Initial loss:  229498.13019212498\n",
      "best loss: 862.34\t\tLearning rate: 5.456e-04, Batch size: 34, Momentum: 2.629e-01\n",
      "Initial loss:  455.08970181614467\n",
      "best loss: 447.75\t\tLearning rate: 1.129e+00, Batch size: 37, Momentum: 1.577e-01\n",
      "Initial loss:  231642.59035140384\n",
      "best loss: 965.90\t\tLearning rate: 4.833e-03, Batch size: 32, Momentum: 3.681e-01\n",
      "Initial loss:  186440.48836736885\n",
      "best loss: 1060.66\t\tLearning rate: 1.274e-01, Batch size: 19, Momentum: 1.577e-01\n",
      "Initial loss:  453074.96348694566\n",
      "best loss: 474.37\t\tLearning rate: 6.952e-06, Batch size: 47, Momentum: 1.577e-01\n",
      "Initial loss:  204930.65083772608\n",
      "best loss: 865.66\t\tLearning rate: 1.624e-03, Batch size: 9, Momentum: 2.629e-01\n",
      "Initial loss:  356623.89223843184\n",
      "best loss: 448.60\t\tLearning rate: 2.976e-08, Batch size: 27, Momentum: 9.464e-01\n",
      "Initial loss:  124720.65331285325\n",
      "best loss: 430.77\t\tLearning rate: 6.952e-06, Batch size: 2, Momentum: 0.000e+00\n",
      "Initial loss:  100346.75661637587\n",
      "best loss: 732.36\t\tLearning rate: 6.158e-05, Batch size: 2, Momentum: 5.784e-01\n",
      "Initial loss:  130494.29819139124\n",
      "best loss: 452.61\t\tLearning rate: 2.637e-07, Batch size: 37, Momentum: 9.990e-01\n",
      "Initial loss:  423261.0154740357\n",
      "best loss: 855.06\t\tLearning rate: 1.624e-03, Batch size: 14, Momentum: 7.361e-01\n",
      "Initial loss:  174685.03669897723\n",
      "best loss: 455.22\t\tLearning rate: 6.952e-06, Batch size: 34, Momentum: 8.413e-01\n",
      "Initial loss:  340652.0791826842\n",
      "best loss: 925.55\t\tLearning rate: 1.624e-03, Batch size: 19, Momentum: 8.938e-01\n",
      "Initial loss:  190458.11995724367\n",
      "best loss: 850.74\t\tLearning rate: 1.833e-04, Batch size: 4, Momentum: 7.361e-01\n",
      "Initial loss:  181824.039348697\n",
      "best loss: 894.29\t\tLearning rate: 4.833e-03, Batch size: 19, Momentum: 0.000e+00\n",
      "Initial loss:  451.09902549123467\n",
      "best loss: 444.56\t\tLearning rate: 1.000e+01, Batch size: 22, Momentum: 9.990e-01\n",
      "Initial loss:  457.04498578170615\n",
      "best loss: 445.87\t\tLearning rate: 1.833e-04, Batch size: 27, Momentum: 0.000e+00\n",
      "Initial loss:  460.06151296393057\n",
      "best loss: 437.46\t\tLearning rate: 1.129e+00, Batch size: 4, Momentum: 8.413e-01\n",
      "Initial loss:  162117.33765903156\n",
      "best loss: 422.89\t\tLearning rate: 2.976e-08, Batch size: 2, Momentum: 9.990e-01\n",
      "Initial loss:  130421.9761311241\n",
      "best loss: 454.47\t\tLearning rate: 7.848e-07, Batch size: 12, Momentum: 1.577e-01\n",
      "Initial loss:  727139.8759109498\n",
      "best loss: 988.33\t\tLearning rate: 4.833e-03, Batch size: 44, Momentum: 4.206e-01\n",
      "Initial loss:  454.5690609821635\n",
      "best loss: 446.96\t\tLearning rate: 2.336e-06, Batch size: 17, Momentum: 3.155e-01\n",
      "Initial loss:  172920.67985056544\n",
      "best loss: 1051.99\t\tLearning rate: 1.624e-03, Batch size: 27, Momentum: 9.990e-01\n",
      "Initial loss:  448.50984811150465\n",
      "best loss: 428.09\t\tLearning rate: 6.952e-06, Batch size: 2, Momentum: 3.681e-01\n",
      "Initial loss:  88019.90837110904\n",
      "best loss: 1088.53\t\tLearning rate: 4.281e-02, Batch size: 29, Momentum: 2.629e-01\n",
      "Initial loss:  931612.7940008439\n",
      "best loss: 1158.71\t\tLearning rate: 1.438e-02, Batch size: 2, Momentum: 9.464e-01\n",
      "Initial loss:  137651.11092588666\n",
      "best loss: 1337.00\t\tLearning rate: 1.129e+00, Batch size: 22, Momentum: 9.464e-01\n",
      "Initial loss:  947281.0831906094\n",
      "best loss: 1243.39\t\tLearning rate: 1.129e+00, Batch size: 47, Momentum: 5.258e-01\n",
      "Initial loss:  1802890.1345078007\n",
      "best loss: 805.03\t\tLearning rate: 1.833e-04, Batch size: 37, Momentum: 2.629e-01\n",
      "Initial loss:  276553.0391382346\n",
      "best loss: 472.71\t\tLearning rate: 2.069e-05, Batch size: 32, Momentum: 5.258e-02\n",
      "Initial loss:  489970.76040401316\n",
      "best loss: 104582.81\t\tLearning rate: 1.000e-08, Batch size: 42, Momentum: 2.103e-01\n",
      "Initial loss:  157856.92525949128\n",
      "best loss: 1422.02\t\tLearning rate: 8.859e-08, Batch size: 4, Momentum: 1.577e-01\n",
      "Initial loss:  504763.5211944995\n",
      "best loss: 201592.60\t\tLearning rate: 2.637e-07, Batch size: 24, Momentum: 2.629e-01\n",
      "Initial loss:  462.185537202948\n",
      "best loss: 451.31\t\tLearning rate: 5.456e-04, Batch size: 34, Momentum: 4.732e-01\n",
      "Initial loss:  625186.3904369893\n",
      "best loss: 1290.22\t\tLearning rate: 1.000e+01, Batch size: 50, Momentum: 5.258e-02\n",
      "Initial loss:  458.0140977673274\n",
      "best loss: 444.40\t\tLearning rate: 2.069e-05, Batch size: 19, Momentum: 2.629e-01\n",
      "Initial loss:  475529.7394893344\n",
      "best loss: 449.46\t\tLearning rate: 2.336e-06, Batch size: 24, Momentum: 8.413e-01\n",
      "Initial loss:  607505.1293475427\n",
      "best loss: 1394.69\t\tLearning rate: 1.000e+01, Batch size: 39, Momentum: 6.309e-01\n",
      "Initial loss:  320953.78551316104\n",
      "best loss: 448.82\t\tLearning rate: 8.859e-08, Batch size: 34, Momentum: 9.990e-01\n",
      "Initial loss:  690390.5946202688\n",
      "best loss: 1341.84\t\tLearning rate: 1.000e+01, Batch size: 12, Momentum: 1.577e-01\n",
      "Initial loss:  555089.178596223\n",
      "best loss: 452.27\t\tLearning rate: 2.336e-06, Batch size: 27, Momentum: 6.309e-01\n",
      "Initial loss:  460.9744221333874\n",
      "best loss: 454.62\t\tLearning rate: 1.274e-01, Batch size: 47, Momentum: 6.835e-01\n",
      "Initial loss:  74950.39430350492\n",
      "best loss: 1115.17\t\tLearning rate: 4.281e-02, Batch size: 39, Momentum: 7.361e-01\n",
      "Initial loss:  501049.83598573855\n",
      "best loss: 856.29\t\tLearning rate: 5.456e-04, Batch size: 27, Momentum: 7.361e-01\n",
      "Initial loss:  139433.173776984\n",
      "best loss: 1213.47\t\tLearning rate: 1.129e+00, Batch size: 9, Momentum: 2.103e-01\n",
      "Initial loss:  117072.76852364826\n",
      "best loss: 1076.35\t\tLearning rate: 4.281e-02, Batch size: 29, Momentum: 3.681e-01\n",
      "Initial loss:  891178.9378582904\n",
      "best loss: 63074.09\t\tLearning rate: 2.976e-08, Batch size: 39, Momentum: 1.577e-01\n",
      "Initial loss:  452952.0018059804\n",
      "best loss: 1089.81\t\tLearning rate: 4.281e-02, Batch size: 14, Momentum: 3.681e-01\n",
      "Initial loss:  532372.3307397282\n",
      "best loss: 712.73\t\tLearning rate: 2.069e-05, Batch size: 39, Momentum: 3.681e-01\n",
      "Initial loss:  455.49722107905194\n",
      "best loss: 448.37\t\tLearning rate: 1.438e-02, Batch size: 27, Momentum: 4.206e-01\n",
      "Initial loss:  404177.2760141134\n",
      "best loss: 1049.24\t\tLearning rate: 4.281e-02, Batch size: 7, Momentum: 3.155e-01\n",
      "Initial loss:  359501.2638037\n",
      "best loss: 88337.08\t\tLearning rate: 2.637e-07, Batch size: 32, Momentum: 4.732e-01\n",
      "Initial loss:  531555.8292101666\n",
      "best loss: 1135.22\t\tLearning rate: 1.274e-01, Batch size: 37, Momentum: 3.155e-01\n",
      "Initial loss:  420335.04638367647\n",
      "best loss: 450.57\t\tLearning rate: 2.637e-07, Batch size: 32, Momentum: 9.464e-01\n",
      "Initial loss:  389266.73637891695\n",
      "best loss: 1018.41\t\tLearning rate: 1.438e-02, Batch size: 44, Momentum: 3.155e-01\n",
      "Initial loss:  346397.6897900673\n",
      "best loss: 423.50\t\tLearning rate: 8.859e-08, Batch size: 2, Momentum: 8.413e-01\n",
      "Initial loss:  457.89497670425044\n",
      "best loss: 449.23\t\tLearning rate: 4.281e-02, Batch size: 42, Momentum: 4.732e-01\n",
      "Initial loss:  60647.132466161995\n",
      "best loss: 462.25\t\tLearning rate: 2.637e-07, Batch size: 14, Momentum: 4.732e-01\n",
      "Initial loss:  210762.3475402444\n",
      "best loss: 1238.09\t\tLearning rate: 1.129e+00, Batch size: 7, Momentum: 3.155e-01\n",
      "Initial loss:  243074.2717362989\n",
      "best loss: 56757.34\t\tLearning rate: 1.833e-04, Batch size: 37, Momentum: 1.052e-01\n",
      "Initial loss:  973971.882009876\n",
      "best loss: 451.53\t\tLearning rate: 2.336e-06, Batch size: 22, Momentum: 8.413e-01\n",
      "Initial loss:  392118.3879263635\n",
      "best loss: 162137.08\t\tLearning rate: 1.000e-08, Batch size: 39, Momentum: 3.155e-01\n",
      "Initial loss:  271647.04692338663\n",
      "best loss: 677.15\t\tLearning rate: 2.069e-05, Batch size: 12, Momentum: 4.732e-01\n",
      "Initial loss:  642944.1538973888\n",
      "best loss: 813.69\t\tLearning rate: 1.833e-04, Batch size: 17, Momentum: 5.784e-01\n",
      "Initial loss:  283414.6117713155\n",
      "best loss: 1326.88\t\tLearning rate: 3.360e+00, Batch size: 7, Momentum: 6.835e-01\n",
      "Initial loss:  454.9090993268637\n",
      "best loss: 449.52\t\tLearning rate: 2.976e-08, Batch size: 44, Momentum: 3.155e-01\n",
      "Initial loss:  558024.326380798\n",
      "best loss: 157669.67\t\tLearning rate: 1.000e-08, Batch size: 19, Momentum: 5.258e-01\n",
      "Initial loss:  150345.167829374\n",
      "best loss: 38580.77\t\tLearning rate: 1.000e-08, Batch size: 32, Momentum: 2.629e-01\n",
      "Initial loss:  504810.1836501667\n",
      "best loss: 808.27\t\tLearning rate: 6.158e-05, Batch size: 29, Momentum: 6.835e-01\n",
      "Initial loss:  195242.4360234615\n",
      "best loss: 822.24\t\tLearning rate: 1.833e-04, Batch size: 50, Momentum: 5.258e-01\n",
      "Initial loss:  263316.5318167779\n",
      "best loss: 493.11\t\tLearning rate: 1.000e-08, Batch size: 32, Momentum: 5.258e-01\n",
      "Initial loss:  268932.1046724208\n",
      "best loss: 791.37\t\tLearning rate: 1.833e-04, Batch size: 17, Momentum: 8.413e-01\n",
      "Initial loss:  471.4194007931276\n",
      "best loss: 452.58\t\tLearning rate: 3.793e-01, Batch size: 32, Momentum: 4.732e-01\n",
      "Initial loss:  455.1366060094656\n",
      "best loss: 449.58\t\tLearning rate: 2.976e-08, Batch size: 27, Momentum: 2.629e-01\n",
      "Initial loss:  1306114.054119994\n",
      "best loss: 1177.01\t\tLearning rate: 3.793e-01, Batch size: 27, Momentum: 2.103e-01\n",
      "Initial loss:  396330.95001309155\n",
      "best loss: 1037.28\t\tLearning rate: 4.281e-02, Batch size: 44, Momentum: 1.052e-01\n",
      "Initial loss:  673610.9341362384\n",
      "best loss: 181934.00\t\tLearning rate: 5.456e-04, Batch size: 50, Momentum: 5.258e-02\n",
      "Initial loss:  891788.0779273502\n",
      "best loss: 754.21\t\tLearning rate: 2.069e-05, Batch size: 17, Momentum: 5.784e-01\n",
      "Initial loss:  166890.20791009397\n",
      "best loss: 914.13\t\tLearning rate: 5.456e-04, Batch size: 50, Momentum: 8.413e-01\n",
      "Initial loss:  510028.7104383062\n",
      "best loss: 1231.67\t\tLearning rate: 1.129e+00, Batch size: 44, Momentum: 3.155e-01\n",
      "Initial loss:  131427.13856992763\n",
      "best loss: 1170.52\t\tLearning rate: 3.793e-01, Batch size: 14, Momentum: 7.887e-01\n",
      "Initial loss:  965443.2188324011\n",
      "best loss: 1208.00\t\tLearning rate: 1.129e+00, Batch size: 29, Momentum: 5.258e-02\n",
      "Initial loss:  257497.64128544548\n",
      "best loss: 975.83\t\tLearning rate: 4.833e-03, Batch size: 24, Momentum: 4.206e-01\n",
      "Initial loss:  872648.8349314034\n",
      "best loss: 883.49\t\tLearning rate: 5.456e-04, Batch size: 29, Momentum: 8.413e-01\n",
      "Initial loss:  352529.2651671978\n",
      "best loss: 445.28\t\tLearning rate: 6.952e-06, Batch size: 42, Momentum: 2.103e-01\n",
      "Initial loss:  127936.62107766743\n",
      "best loss: 1065.24\t\tLearning rate: 1.274e-01, Batch size: 32, Momentum: 0.000e+00\n",
      "Initial loss:  627743.6041553669\n",
      "best loss: 816.48\t\tLearning rate: 6.158e-05, Batch size: 19, Momentum: 6.835e-01\n",
      "Initial loss:  161057.8649011525\n",
      "best loss: 1361.13\t\tLearning rate: 1.000e+01, Batch size: 44, Momentum: 4.732e-01\n",
      "Initial loss:  268782.1587546589\n",
      "best loss: 1315.57\t\tLearning rate: 3.360e+00, Batch size: 47, Momentum: 6.835e-01\n",
      "Initial loss:  898757.0969781077\n",
      "best loss: 462.88\t\tLearning rate: 6.952e-06, Batch size: 22, Momentum: 6.835e-01\n",
      "Initial loss:  207784.9204114878\n",
      "best loss: 664.70\t\tLearning rate: 2.069e-05, Batch size: 9, Momentum: 5.258e-01\n",
      "Initial loss:  160421.8993104317\n",
      "best loss: 1074.47\t\tLearning rate: 4.281e-02, Batch size: 47, Momentum: 2.103e-01\n",
      "Initial loss:  440.1249250645727\n",
      "best loss: 438.98\t\tLearning rate: 2.336e-06, Batch size: 4, Momentum: 3.155e-01\n",
      "Initial loss:  775121.1094025981\n",
      "best loss: 55033.64\t\tLearning rate: 2.976e-08, Batch size: 22, Momentum: 7.361e-01\n",
      "Initial loss:  545447.3001874873\n",
      "best loss: 1239.29\t\tLearning rate: 1.129e+00, Batch size: 7, Momentum: 6.309e-01\n",
      "Initial loss:  526748.1542648902\n",
      "best loss: 853.50\t\tLearning rate: 5.456e-04, Batch size: 14, Momentum: 7.361e-01\n",
      "Initial loss:  490249.5653252523\n",
      "best loss: 913.38\t\tLearning rate: 5.456e-04, Batch size: 12, Momentum: 9.464e-01\n",
      "Initial loss:  425879.59506613977\n",
      "best loss: 50564.41\t\tLearning rate: 1.000e-08, Batch size: 39, Momentum: 3.155e-01\n",
      "Initial loss:  461470.293335326\n",
      "best loss: 457.75\t\tLearning rate: 2.637e-07, Batch size: 12, Momentum: 3.155e-01\n",
      "Initial loss:  449611.67540533346\n",
      "best loss: 1297.96\t\tLearning rate: 3.360e+00, Batch size: 27, Momentum: 4.206e-01\n",
      "Initial loss:  454.7064442265652\n",
      "best loss: 445.04\t\tLearning rate: 4.833e-03, Batch size: 27, Momentum: 5.784e-01\n",
      "Initial loss:  352555.8656923472\n",
      "best loss: 536.28\t\tLearning rate: 2.976e-08, Batch size: 9, Momentum: 3.681e-01\n",
      "Initial loss:  460.2719859012736\n",
      "best loss: 445.70\t\tLearning rate: 1.129e+00, Batch size: 17, Momentum: 1.052e-01\n",
      "Initial loss:  417284.0395932485\n",
      "best loss: 449.33\t\tLearning rate: 7.848e-07, Batch size: 12, Momentum: 5.784e-01\n",
      "Initial loss:  1494066.579867683\n",
      "best loss: 466.39\t\tLearning rate: 1.000e-08, Batch size: 27, Momentum: 9.464e-01\n",
      "Initial loss:  421209.8339933664\n",
      "best loss: 446.34\t\tLearning rate: 7.848e-07, Batch size: 19, Momentum: 3.155e-01\n",
      "Initial loss:  54745.59751368783\n",
      "best loss: 1096.31\t\tLearning rate: 1.274e-01, Batch size: 22, Momentum: 1.577e-01\n",
      "Initial loss:  474298.58577146695\n",
      "best loss: 947.29\t\tLearning rate: 4.833e-03, Batch size: 37, Momentum: 2.103e-01\n",
      "Initial loss:  453.94790415058617\n",
      "best loss: 450.67\t\tLearning rate: 8.859e-08, Batch size: 42, Momentum: 4.206e-01\n",
      "Initial loss:  162792.10689203936\n",
      "best loss: 1358.34\t\tLearning rate: 1.129e+00, Batch size: 24, Momentum: 9.990e-01\n",
      "Initial loss:  661878.7805339678\n",
      "best loss: 95197.97\t\tLearning rate: 2.976e-08, Batch size: 32, Momentum: 0.000e+00\n",
      "Initial loss:  239427.38375843523\n",
      "best loss: 1176.95\t\tLearning rate: 3.793e-01, Batch size: 17, Momentum: 2.629e-01\n",
      "Initial loss:  116925.57728501529\n",
      "best loss: 1056.28\t\tLearning rate: 1.274e-01, Batch size: 32, Momentum: 0.000e+00\n",
      "Initial loss:  459.59545501523945\n",
      "best loss: 448.22\t\tLearning rate: 2.069e-05, Batch size: 27, Momentum: 5.258e-02\n",
      "Initial loss:  377443.6449851238\n",
      "best loss: 1416.20\t\tLearning rate: 1.000e+01, Batch size: 27, Momentum: 7.887e-01\n",
      "Initial loss:  449.3335383707825\n",
      "best loss: 446.76\t\tLearning rate: 1.438e-02, Batch size: 17, Momentum: 9.464e-01\n",
      "Initial loss:  418355.0093110055\n",
      "best loss: 991.03\t\tLearning rate: 4.833e-03, Batch size: 42, Momentum: 4.206e-01\n",
      "Initial loss:  457.46015132772806\n",
      "best loss: 444.51\t\tLearning rate: 1.129e+00, Batch size: 19, Momentum: 9.990e-01\n",
      "Initial loss:  78869.52801916479\n",
      "best loss: 453.32\t\tLearning rate: 8.859e-08, Batch size: 29, Momentum: 6.835e-01\n",
      "Initial loss:  713439.0177552578\n",
      "best loss: 765.57\t\tLearning rate: 2.069e-05, Batch size: 50, Momentum: 9.990e-01\n",
      "Initial loss:  559393.2233240354\n",
      "best loss: 449.53\t\tLearning rate: 2.336e-06, Batch size: 50, Momentum: 4.732e-01\n",
      "Initial loss:  340594.54334227677\n",
      "best loss: 444.77\t\tLearning rate: 7.848e-07, Batch size: 19, Momentum: 9.464e-01\n",
      "Initial loss:  416024.4203800841\n",
      "best loss: 447.24\t\tLearning rate: 6.952e-06, Batch size: 34, Momentum: 2.103e-01\n",
      "Initial loss:  186183.38481394362\n",
      "best loss: 819.09\t\tLearning rate: 1.833e-04, Batch size: 27, Momentum: 9.464e-01\n",
      "Initial loss:  218665.38044608518\n",
      "best loss: 822.72\t\tLearning rate: 1.624e-03, Batch size: 17, Momentum: 0.000e+00\n",
      "Initial loss:  457.224538724111\n",
      "best loss: 448.91\t\tLearning rate: 3.360e+00, Batch size: 29, Momentum: 0.000e+00\n",
      "Initial loss:  468.4370861648932\n",
      "best loss: 446.14\t\tLearning rate: 3.360e+00, Batch size: 14, Momentum: 6.309e-01\n",
      "Initial loss:  372179.41023791453\n",
      "best loss: 1685.15\t\tLearning rate: 2.069e-05, Batch size: 39, Momentum: 5.258e-01\n",
      "Initial loss:  977997.2909186464\n",
      "best loss: 68995.53\t\tLearning rate: 1.000e-08, Batch size: 19, Momentum: 4.206e-01\n",
      "Initial loss:  301563.8837580365\n",
      "best loss: 1312.37\t\tLearning rate: 1.000e+01, Batch size: 7, Momentum: 2.103e-01\n",
      "Initial loss:  463.55927020282513\n",
      "best loss: 440.57\t\tLearning rate: 4.281e-02, Batch size: 9, Momentum: 3.155e-01\n",
      "Initial loss:  131041.4258509886\n",
      "best loss: 482.78\t\tLearning rate: 8.859e-08, Batch size: 44, Momentum: 4.206e-01\n",
      "Initial loss:  185986.17921123028\n",
      "best loss: 943.90\t\tLearning rate: 1.438e-02, Batch size: 14, Momentum: 5.258e-02\n",
      "Initial loss:  459.1802626199629\n",
      "best loss: 448.64\t\tLearning rate: 2.637e-07, Batch size: 29, Momentum: 5.258e-01\n",
      "Initial loss:  151121.84763248602\n",
      "best loss: 3399.05\t\tLearning rate: 1.000e-08, Batch size: 39, Momentum: 1.577e-01\n",
      "Initial loss:  396845.8767783976\n",
      "best loss: 766.29\t\tLearning rate: 1.833e-04, Batch size: 39, Momentum: 6.835e-01\n",
      "Initial loss:  273076.3055112132\n",
      "best loss: 824.29\t\tLearning rate: 1.833e-04, Batch size: 24, Momentum: 5.258e-01\n",
      "Initial loss:  760340.1657282305\n",
      "best loss: 787.10\t\tLearning rate: 6.158e-05, Batch size: 17, Momentum: 5.784e-01\n",
      "Initial loss:  494.786027488574\n",
      "best loss: 443.51\t\tLearning rate: 6.952e-06, Batch size: 7, Momentum: 4.206e-01\n",
      "Initial loss:  243777.18043093968\n",
      "best loss: 464.18\t\tLearning rate: 6.952e-06, Batch size: 4, Momentum: 2.103e-01\n",
      "Initial loss:  875763.9882580327\n",
      "best loss: 160255.71\t\tLearning rate: 2.637e-07, Batch size: 14, Momentum: 1.052e-01\n",
      "Initial loss:  461.3854000729209\n",
      "best loss: 450.29\t\tLearning rate: 2.336e-06, Batch size: 34, Momentum: 9.990e-01\n",
      "Initial loss:  455.60859357031234\n",
      "best loss: 448.69\t\tLearning rate: 6.158e-05, Batch size: 27, Momentum: 5.258e-02\n",
      "Initial loss:  189039.14035284054\n",
      "best loss: 447.91\t\tLearning rate: 2.069e-05, Batch size: 7, Momentum: 5.784e-01\n",
      "Initial loss:  456.8714633648644\n",
      "best loss: 449.47\t\tLearning rate: 1.000e+01, Batch size: 42, Momentum: 9.990e-01\n",
      "Initial loss:  450.89415831598023\n",
      "best loss: 445.14\t\tLearning rate: 2.336e-06, Batch size: 12, Momentum: 8.938e-01\n",
      "Initial loss:  459.83587495722986\n",
      "best loss: 450.30\t\tLearning rate: 1.438e-02, Batch size: 19, Momentum: 2.103e-01\n",
      "Initial loss:  387343.0040740611\n",
      "best loss: 450.16\t\tLearning rate: 8.859e-08, Batch size: 34, Momentum: 8.413e-01\n",
      "Initial loss:  590398.8054147002\n",
      "best loss: 468.22\t\tLearning rate: 2.336e-06, Batch size: 29, Momentum: 1.052e-01\n",
      "Initial loss:  938338.0738729818\n",
      "best loss: 1264.39\t\tLearning rate: 1.129e+00, Batch size: 12, Momentum: 5.258e-01\n",
      "Initial loss:  456.04931705172373\n",
      "best loss: 446.82\t\tLearning rate: 1.438e-02, Batch size: 32, Momentum: 4.206e-01\n",
      "Initial loss:  624045.1008248952\n",
      "best loss: 1092.80\t\tLearning rate: 4.281e-02, Batch size: 50, Momentum: 7.361e-01\n",
      "Initial loss:  376573.64761643874\n",
      "best loss: 1031.68\t\tLearning rate: 4.281e-02, Batch size: 44, Momentum: 2.629e-01\n",
      "Initial loss:  455.8105978896111\n",
      "best loss: 446.27\t\tLearning rate: 7.848e-07, Batch size: 27, Momentum: 2.103e-01\n",
      "Initial loss:  494725.6857239631\n",
      "best loss: 454.81\t\tLearning rate: 2.637e-07, Batch size: 7, Momentum: 4.206e-01\n",
      "Initial loss:  597139.1062348228\n",
      "best loss: 1405.02\t\tLearning rate: 3.360e+00, Batch size: 14, Momentum: 9.464e-01\n",
      "Initial loss:  364347.5908042675\n",
      "best loss: 447.25\t\tLearning rate: 7.848e-07, Batch size: 22, Momentum: 8.413e-01\n",
      "Initial loss:  119799.67670963488\n",
      "best loss: 960.91\t\tLearning rate: 1.438e-02, Batch size: 29, Momentum: 0.000e+00\n",
      "Initial loss:  720096.6183263334\n",
      "best loss: 925.14\t\tLearning rate: 1.624e-03, Batch size: 34, Momentum: 6.309e-01\n",
      "Initial loss:  1672658.1739148283\n",
      "best loss: 1229.78\t\tLearning rate: 1.129e+00, Batch size: 9, Momentum: 6.835e-01\n",
      "Initial loss:  229695.63566472117\n",
      "best loss: 1386.31\t\tLearning rate: 1.000e+01, Batch size: 44, Momentum: 6.309e-01\n",
      "Initial loss:  888033.9217592591\n",
      "best loss: 22153.52\t\tLearning rate: 7.848e-07, Batch size: 9, Momentum: 5.258e-01\n",
      "Initial loss:  183327.60046058975\n",
      "best loss: 637.78\t\tLearning rate: 2.637e-07, Batch size: 27, Momentum: 0.000e+00\n",
      "Initial loss:  130700.85763610486\n",
      "best loss: 985.15\t\tLearning rate: 1.438e-02, Batch size: 32, Momentum: 1.052e-01\n",
      "Initial loss:  750030.2471089854\n",
      "best loss: 441.63\t\tLearning rate: 2.336e-06, Batch size: 7, Momentum: 6.309e-01\n",
      "Initial loss:  51939.45051644767\n",
      "best loss: 437.87\t\tLearning rate: 2.069e-05, Batch size: 4, Momentum: 1.052e-01\n",
      "Initial loss:  150618.34620099934\n",
      "best loss: 925.55\t\tLearning rate: 5.456e-04, Batch size: 39, Momentum: 8.938e-01\n",
      "Initial loss:  497436.33334323054\n",
      "best loss: 108135.68\t\tLearning rate: 4.833e-03, Batch size: 37, Momentum: 2.103e-01\n",
      "Initial loss:  449.47114654783536\n",
      "best loss: 440.80\t\tLearning rate: 1.833e-04, Batch size: 9, Momentum: 8.938e-01\n",
      "Initial loss:  796090.5983763589\n",
      "best loss: 1257.27\t\tLearning rate: 3.793e-01, Batch size: 19, Momentum: 9.990e-01\n",
      "Initial loss:  56675.10298163703\n",
      "best loss: 1081.15\t\tLearning rate: 1.438e-02, Batch size: 27, Momentum: 7.361e-01\n",
      "Initial loss:  711976.797287491\n",
      "best loss: 456.67\t\tLearning rate: 2.976e-08, Batch size: 42, Momentum: 8.938e-01\n",
      "Initial loss:  384416.9233914049\n",
      "best loss: 1261.08\t\tLearning rate: 1.129e+00, Batch size: 19, Momentum: 4.732e-01\n",
      "Initial loss:  709964.8056799269\n",
      "best loss: 469.70\t\tLearning rate: 1.000e-08, Batch size: 37, Momentum: 8.938e-01\n",
      "Initial loss:  955111.9863586562\n",
      "best loss: 460.10\t\tLearning rate: 6.952e-06, Batch size: 19, Momentum: 7.361e-01\n",
      "Initial loss:  776481.3863462964\n",
      "best loss: 876.71\t\tLearning rate: 1.000e-08, Batch size: 47, Momentum: 6.309e-01\n",
      "Initial loss:  143256.69154139888\n",
      "best loss: 1313.84\t\tLearning rate: 3.360e+00, Batch size: 9, Momentum: 2.629e-01\n",
      "Initial loss:  455.65448672427647\n",
      "best loss: 445.47\t\tLearning rate: 1.000e-08, Batch size: 22, Momentum: 9.464e-01\n",
      "Initial loss:  508619.7832668338\n",
      "best loss: 630.47\t\tLearning rate: 8.859e-08, Batch size: 29, Momentum: 6.309e-01\n",
      "Initial loss:  925120.1750727502\n",
      "best loss: 963.01\t\tLearning rate: 1.438e-02, Batch size: 7, Momentum: 2.103e-01\n",
      "Initial loss:  294342.4822417758\n",
      "best loss: 78979.63\t\tLearning rate: 1.000e-08, Batch size: 37, Momentum: 7.361e-01\n",
      "Initial loss:  123899.22215419209\n",
      "best loss: 1144.87\t\tLearning rate: 3.793e-01, Batch size: 7, Momentum: 2.629e-01\n",
      "Initial loss:  727927.5689077352\n",
      "best loss: 1139.90\t\tLearning rate: 4.281e-02, Batch size: 9, Momentum: 8.938e-01\n",
      "Initial loss:  300362.5704083361\n",
      "best loss: 528.78\t\tLearning rate: 2.976e-08, Batch size: 29, Momentum: 2.103e-01\n",
      "Initial loss:  165903.76777023997\n",
      "best loss: 258346.63\t\tLearning rate: 1.274e-01, Batch size: 17, Momentum: 0.000e+00\n",
      "Initial loss:  431608.35482615035\n",
      "best loss: 845.38\t\tLearning rate: 1.624e-03, Batch size: 17, Momentum: 3.155e-01\n",
      "Initial loss:  265681.2179987663\n",
      "best loss: 840.95\t\tLearning rate: 6.158e-05, Batch size: 39, Momentum: 7.887e-01\n",
      "Initial loss:  455.03249130918186\n",
      "best loss: 450.12\t\tLearning rate: 1.000e-08, Batch size: 34, Momentum: 9.464e-01\n",
      "Initial loss:  671984.4603364296\n",
      "best loss: 962.50\t\tLearning rate: 1.624e-03, Batch size: 44, Momentum: 8.413e-01\n",
      "Initial loss:  328145.6268739872\n",
      "best loss: 87656.31\t\tLearning rate: 1.000e-08, Batch size: 37, Momentum: 3.681e-01\n",
      "Initial loss:  561586.285879563\n",
      "best loss: 658.48\t\tLearning rate: 8.859e-08, Batch size: 17, Momentum: 5.258e-01\n",
      "Initial loss:  456.4920656610413\n",
      "best loss: 450.85\t\tLearning rate: 6.952e-06, Batch size: 50, Momentum: 5.258e-01\n",
      "Initial loss:  856006.5626207823\n",
      "best loss: 1109.90\t\tLearning rate: 1.274e-01, Batch size: 2, Momentum: 2.103e-01\n",
      "Initial loss:  362301.08034945227\n",
      "best loss: 459.64\t\tLearning rate: 2.336e-06, Batch size: 27, Momentum: 0.000e+00\n",
      "Initial loss:  21072.953645441536\n",
      "best loss: 448.51\t\tLearning rate: 1.000e-08, Batch size: 4, Momentum: 8.938e-01\n",
      "Initial loss:  311896.70750704454\n",
      "best loss: 462.76\t\tLearning rate: 7.848e-07, Batch size: 47, Momentum: 3.681e-01\n",
      "Initial loss:  573367.6888072977\n",
      "best loss: 1210.29\t\tLearning rate: 1.129e+00, Batch size: 12, Momentum: 2.103e-01\n",
      "Initial loss:  521001.40738427517\n",
      "best loss: 872.61\t\tLearning rate: 1.624e-03, Batch size: 27, Momentum: 1.577e-01\n",
      "Initial loss:  149841.60499145908\n",
      "best loss: 1167.76\t\tLearning rate: 1.274e-01, Batch size: 50, Momentum: 4.206e-01\n",
      "Initial loss:  301273.1077702937\n",
      "best loss: 1357.69\t\tLearning rate: 3.360e+00, Batch size: 50, Momentum: 7.887e-01\n",
      "Initial loss:  303395.9392892887\n",
      "best loss: 1072.88\t\tLearning rate: 4.281e-02, Batch size: 22, Momentum: 4.732e-01\n",
      "Initial loss:  447.4232114312614\n",
      "best loss: 435.24\t\tLearning rate: 6.952e-06, Batch size: 2, Momentum: 4.206e-01\n",
      "Initial loss:  456.82861872105747\n",
      "best loss: 446.06\t\tLearning rate: 1.833e-04, Batch size: 14, Momentum: 7.361e-01\n",
      "Initial loss:  641910.8260737648\n",
      "best loss: 694.21\t\tLearning rate: 6.158e-05, Batch size: 7, Momentum: 0.000e+00\n",
      "Initial loss:  479171.8927404413\n",
      "best loss: 1364.23\t\tLearning rate: 1.000e+01, Batch size: 32, Momentum: 5.258e-01\n",
      "Initial loss:  457.7293949956616\n",
      "best loss: 448.20\t\tLearning rate: 1.833e-04, Batch size: 34, Momentum: 7.361e-01\n",
      "Initial loss:  962180.3777450816\n",
      "best loss: 853.10\t\tLearning rate: 5.456e-04, Batch size: 42, Momentum: 4.206e-01\n",
      "Initial loss:  411508.57991131686\n",
      "best loss: 1241.79\t\tLearning rate: 1.129e+00, Batch size: 7, Momentum: 4.206e-01\n",
      "Initial loss:  317690.45550977264\n",
      "best loss: 656.82\t\tLearning rate: 2.976e-08, Batch size: 39, Momentum: 0.000e+00\n",
      "Initial loss:  294389.5560666852\n",
      "best loss: 928.05\t\tLearning rate: 1.438e-02, Batch size: 2, Momentum: 5.258e-02\n",
      "Initial loss:  576130.4472916828\n",
      "best loss: 1174.09\t\tLearning rate: 3.793e-01, Batch size: 29, Momentum: 3.155e-01\n",
      "Initial loss:  936691.5713888756\n",
      "best loss: 1395.45\t\tLearning rate: 1.000e+01, Batch size: 29, Momentum: 6.309e-01\n",
      "Initial loss:  184504.88097940665\n",
      "best loss: 470.96\t\tLearning rate: 2.069e-05, Batch size: 19, Momentum: 2.629e-01\n",
      "Initial loss:  274129.02452672826\n",
      "best loss: 449.38\t\tLearning rate: 6.952e-06, Batch size: 24, Momentum: 8.938e-01\n",
      "Initial loss:  452.04172093854885\n",
      "best loss: 449.26\t\tLearning rate: 2.637e-07, Batch size: 27, Momentum: 5.784e-01\n",
      "Initial loss:  785383.200678019\n",
      "best loss: 1087.96\t\tLearning rate: 1.438e-02, Batch size: 34, Momentum: 6.835e-01\n",
      "Initial loss:  670273.3799126551\n",
      "best loss: 1096.76\t\tLearning rate: 1.438e-02, Batch size: 14, Momentum: 8.413e-01\n",
      "Initial loss:  65999.71892003242\n",
      "best loss: 449.62\t\tLearning rate: 2.336e-06, Batch size: 34, Momentum: 1.577e-01\n",
      "Initial loss:  116782.16954734758\n",
      "best loss: 969.81\t\tLearning rate: 5.456e-04, Batch size: 44, Momentum: 8.938e-01\n",
      "Initial loss:  736903.2023563854\n",
      "best loss: 731292.35\t\tLearning rate: 4.833e-03, Batch size: 27, Momentum: 2.629e-01\n",
      "Initial loss:  302927.5539788879\n",
      "best loss: 1057.23\t\tLearning rate: 4.281e-02, Batch size: 44, Momentum: 5.258e-02\n",
      "Initial loss:  606255.2368586409\n",
      "best loss: 870.60\t\tLearning rate: 1.833e-04, Batch size: 42, Momentum: 9.990e-01\n",
      "Initial loss:  83077.6614659506\n",
      "best loss: 556.59\t\tLearning rate: 2.976e-08, Batch size: 12, Momentum: 2.103e-01\n",
      "Initial loss:  131597.6478482864\n",
      "best loss: 1209.07\t\tLearning rate: 1.274e-01, Batch size: 22, Momentum: 8.413e-01\n",
      "Initial loss:  151250.75729941193\n",
      "best loss: 1207.95\t\tLearning rate: 3.793e-01, Batch size: 7, Momentum: 6.835e-01\n",
      "Initial loss:  385709.5472962318\n",
      "best loss: 724.42\t\tLearning rate: 2.069e-05, Batch size: 17, Momentum: 6.835e-01\n",
      "Initial loss:  454.73926219019523\n",
      "best loss: 447.47\t\tLearning rate: 1.624e-03, Batch size: 47, Momentum: 8.413e-01\n",
      "Initial loss:  448.74383402230757\n",
      "best loss: 437.61\t\tLearning rate: 8.859e-08, Batch size: 7, Momentum: 8.413e-01\n",
      "Initial loss:  271700.5443373707\n",
      "best loss: 1191.42\t\tLearning rate: 1.129e+00, Batch size: 44, Momentum: 2.103e-01\n",
      "Initial loss:  471814.374041541\n",
      "best loss: 451.32\t\tLearning rate: 6.952e-06, Batch size: 9, Momentum: 1.052e-01\n",
      "Initial loss:  65572.84742868097\n",
      "best loss: 963.18\t\tLearning rate: 1.438e-02, Batch size: 14, Momentum: 1.052e-01\n",
      "Initial loss:  463.27496463996334\n",
      "best loss: 444.93\t\tLearning rate: 2.637e-07, Batch size: 17, Momentum: 7.361e-01\n",
      "Initial loss:  459.3137349846801\n",
      "best loss: 440.71\t\tLearning rate: 2.637e-07, Batch size: 9, Momentum: 5.784e-01\n",
      "Initial loss:  181761.76429069322\n",
      "best loss: 457.26\t\tLearning rate: 8.859e-08, Batch size: 14, Momentum: 7.361e-01\n",
      "Initial loss:  135514.66499304437\n",
      "best loss: 447.04\t\tLearning rate: 2.336e-06, Batch size: 39, Momentum: 7.887e-01\n",
      "Initial loss:  443625.2420859512\n",
      "best loss: 881.41\t\tLearning rate: 5.456e-04, Batch size: 42, Momentum: 8.413e-01\n",
      "Initial loss:  66025.29716856644\n",
      "best loss: 1180.42\t\tLearning rate: 3.793e-01, Batch size: 50, Momentum: 3.681e-01\n",
      "Initial loss:  479318.94489317085\n",
      "best loss: 18872.60\t\tLearning rate: 2.637e-07, Batch size: 7, Momentum: 3.155e-01\n",
      "Initial loss:  834454.2715270849\n",
      "best loss: 1004.31\t\tLearning rate: 1.438e-02, Batch size: 17, Momentum: 2.629e-01\n",
      "Initial loss:  355216.38412003353\n",
      "best loss: 451.10\t\tLearning rate: 2.336e-06, Batch size: 44, Momentum: 6.835e-01\n",
      "Initial loss:  737236.7102217221\n",
      "best loss: 53325.47\t\tLearning rate: 2.637e-07, Batch size: 32, Momentum: 2.629e-01\n",
      "Initial loss:  741403.0073420504\n",
      "best loss: 489.11\t\tLearning rate: 8.859e-08, Batch size: 50, Momentum: 5.258e-01\n",
      "Initial loss:  705134.215882733\n",
      "best loss: 450.60\t\tLearning rate: 2.336e-06, Batch size: 44, Momentum: 7.361e-01\n",
      "Initial loss:  455.684186744834\n",
      "best loss: 448.32\t\tLearning rate: 1.274e-01, Batch size: 22, Momentum: 8.938e-01\n",
      "Initial loss:  706323.3449287919\n",
      "best loss: 1025.48\t\tLearning rate: 4.281e-02, Batch size: 19, Momentum: 1.052e-01\n",
      "Initial loss:  90908.7953328317\n",
      "best loss: 497.83\t\tLearning rate: 1.000e-08, Batch size: 19, Momentum: 6.309e-01\n",
      "Initial loss:  243697.72777752453\n",
      "best loss: 566.07\t\tLearning rate: 1.000e-08, Batch size: 32, Momentum: 2.629e-01\n",
      "Initial loss:  457.80033599881745\n",
      "best loss: 447.53\t\tLearning rate: 1.000e+01, Batch size: 37, Momentum: 8.413e-01\n",
      "Initial loss:  469.45587382754036\n",
      "best loss: 456.73\t\tLearning rate: 2.976e-08, Batch size: 37, Momentum: 2.629e-01\n",
      "Initial loss:  120713.19179209438\n",
      "best loss: 1410.58\t\tLearning rate: 3.360e+00, Batch size: 22, Momentum: 9.990e-01\n",
      "Initial loss:  88074.43691500448\n",
      "best loss: 435.59\t\tLearning rate: 1.000e-08, Batch size: 2, Momentum: 9.464e-01\n",
      "Initial loss:  548118.8037406064\n",
      "best loss: 54165.33\t\tLearning rate: 8.859e-08, Batch size: 14, Momentum: 1.577e-01\n",
      "Initial loss:  134124.90165183163\n",
      "best loss: 454.01\t\tLearning rate: 7.848e-07, Batch size: 50, Momentum: 5.784e-01\n",
      "Initial loss:  52307.50180951181\n",
      "best loss: 451.31\t\tLearning rate: 7.848e-07, Batch size: 19, Momentum: 8.413e-01\n",
      "Initial loss:  270440.83731352503\n",
      "best loss: 435.26\t\tLearning rate: 2.336e-06, Batch size: 2, Momentum: 3.155e-01\n",
      "Initial loss:  449.88102304728164\n",
      "best loss: 445.68\t\tLearning rate: 1.833e-04, Batch size: 22, Momentum: 9.990e-01\n",
      "Initial loss:  337661.4925744426\n",
      "best loss: 981.70\t\tLearning rate: 4.833e-03, Batch size: 44, Momentum: 5.784e-01\n",
      "Initial loss:  458.59468164833874\n",
      "best loss: 444.34\t\tLearning rate: 1.833e-04, Batch size: 22, Momentum: 5.258e-01\n",
      "Initial loss:  339381.0632538574\n",
      "best loss: 868.15\t\tLearning rate: 1.624e-03, Batch size: 50, Momentum: 1.577e-01\n",
      "Initial loss:  521359.4196536326\n",
      "best loss: 852.88\t\tLearning rate: 5.456e-04, Batch size: 47, Momentum: 2.103e-01\n",
      "Initial loss:  632013.3481932151\n",
      "best loss: 474.90\t\tLearning rate: 6.952e-06, Batch size: 17, Momentum: 7.361e-01\n",
      "Initial loss:  68683.76056337071\n",
      "best loss: 459.75\t\tLearning rate: 2.637e-07, Batch size: 42, Momentum: 3.155e-01\n",
      "Initial loss:  762449.0761195684\n",
      "best loss: 1239.96\t\tLearning rate: 1.129e+00, Batch size: 47, Momentum: 4.732e-01\n",
      "Initial loss:  289048.6148987056\n",
      "best loss: 1447.27\t\tLearning rate: 1.000e+01, Batch size: 24, Momentum: 9.464e-01\n",
      "Initial loss:  400788.90826531465\n",
      "best loss: 1014.78\t\tLearning rate: 1.438e-02, Batch size: 24, Momentum: 2.103e-01\n",
      "Initial loss:  279967.12515364715\n",
      "best loss: 75031.16\t\tLearning rate: 2.637e-07, Batch size: 32, Momentum: 6.309e-01\n",
      "Initial loss:  582336.9180043632\n",
      "best loss: 451.59\t\tLearning rate: 2.336e-06, Batch size: 50, Momentum: 7.887e-01\n",
      "Initial loss:  551799.0504688905\n",
      "best loss: 1114.08\t\tLearning rate: 1.274e-01, Batch size: 37, Momentum: 1.577e-01\n",
      "Initial loss:  207625.51284973725\n",
      "best loss: 656.26\t\tLearning rate: 2.976e-08, Batch size: 42, Momentum: 2.629e-01\n",
      "Initial loss:  562981.0306795911\n",
      "best loss: 1638.48\t\tLearning rate: 2.976e-08, Batch size: 42, Momentum: 1.052e-01\n",
      "Initial loss:  400736.62658069306\n",
      "best loss: 454.67\t\tLearning rate: 2.336e-06, Batch size: 39, Momentum: 9.464e-01\n",
      "Initial loss:  351394.1841306136\n",
      "best loss: 1284.59\t\tLearning rate: 3.793e-01, Batch size: 4, Momentum: 8.938e-01\n",
      "Initial loss:  1011100.8189512388\n",
      "best loss: 456.41\t\tLearning rate: 6.952e-06, Batch size: 27, Momentum: 6.309e-01\n",
      "Initial loss:  726698.8438953968\n",
      "best loss: 1179.25\t\tLearning rate: 3.793e-01, Batch size: 9, Momentum: 1.577e-01\n",
      "Initial loss:  497433.7130861389\n",
      "best loss: 1332.62\t\tLearning rate: 3.360e+00, Batch size: 29, Momentum: 6.835e-01\n",
      "Initial loss:  754761.2870953776\n",
      "best loss: 442.37\t\tLearning rate: 1.000e-08, Batch size: 7, Momentum: 9.990e-01\n",
      "Initial loss:  356371.74426938285\n",
      "best loss: 444.61\t\tLearning rate: 2.637e-07, Batch size: 2, Momentum: 0.000e+00\n",
      "Initial loss:  459.44671834551684\n",
      "best loss: 441.51\t\tLearning rate: 1.000e+01, Batch size: 14, Momentum: 5.784e-01\n",
      "Initial loss:  455997.31662763795\n",
      "best loss: 451.17\t\tLearning rate: 2.637e-07, Batch size: 27, Momentum: 7.887e-01\n",
      "Initial loss:  343399.9321469385\n",
      "best loss: 1231.83\t\tLearning rate: 1.129e+00, Batch size: 24, Momentum: 3.155e-01\n",
      "Initial loss:  465471.3711800659\n",
      "best loss: 744.31\t\tLearning rate: 2.976e-08, Batch size: 24, Momentum: 1.577e-01\n",
      "Initial loss:  456.3191180819657\n",
      "best loss: 447.70\t\tLearning rate: 3.793e-01, Batch size: 39, Momentum: 9.990e-01\n",
      "Initial loss:  457.0490080597491\n",
      "best loss: 448.24\t\tLearning rate: 1.000e-08, Batch size: 27, Momentum: 4.732e-01\n",
      "Initial loss:  178008.20522056354\n",
      "best loss: 1136.21\t\tLearning rate: 1.274e-01, Batch size: 14, Momentum: 5.258e-01\n",
      "Initial loss:  574332.6648072144\n",
      "best loss: 1032.98\t\tLearning rate: 1.438e-02, Batch size: 39, Momentum: 4.206e-01\n",
      "Initial loss:  547886.3059888385\n",
      "best loss: 484.91\t\tLearning rate: 2.069e-05, Batch size: 42, Momentum: 5.258e-02\n",
      "Initial loss:  548939.8952208558\n",
      "best loss: 980.22\t\tLearning rate: 4.833e-03, Batch size: 17, Momentum: 5.258e-01\n",
      "Initial loss:  510897.29466092295\n",
      "best loss: 473.82\t\tLearning rate: 7.848e-07, Batch size: 32, Momentum: 1.577e-01\n",
      "Initial loss:  359328.3998490822\n",
      "best loss: 1087.75\t\tLearning rate: 1.438e-02, Batch size: 32, Momentum: 8.413e-01\n",
      "Initial loss:  441131.59741964325\n",
      "best loss: 1175.40\t\tLearning rate: 4.281e-02, Batch size: 37, Momentum: 8.938e-01\n",
      "Initial loss:  460.6863808894598\n",
      "best loss: 451.39\t\tLearning rate: 1.624e-03, Batch size: 44, Momentum: 2.629e-01\n",
      "Initial loss:  155752.8104829386\n",
      "best loss: 559.32\t\tLearning rate: 7.848e-07, Batch size: 22, Momentum: 1.577e-01\n",
      "Initial loss:  188222.3143304612\n",
      "best loss: 995.25\t\tLearning rate: 1.438e-02, Batch size: 19, Momentum: 5.258e-02\n",
      "Initial loss:  871611.7300995449\n",
      "best loss: 991.86\t\tLearning rate: 4.833e-03, Batch size: 47, Momentum: 4.732e-01\n",
      "Initial loss:  147442.6759848685\n",
      "best loss: 33895.40\t\tLearning rate: 8.859e-08, Batch size: 47, Momentum: 2.629e-01\n",
      "Initial loss:  348603.507352895\n",
      "best loss: 513.45\t\tLearning rate: 2.069e-05, Batch size: 17, Momentum: 1.577e-01\n",
      "Initial loss:  282428.80546137044\n",
      "best loss: 506.94\t\tLearning rate: 1.000e-08, Batch size: 9, Momentum: 5.784e-01\n",
      "Initial loss:  106747.8677764502\n",
      "best loss: 448.63\t\tLearning rate: 6.952e-06, Batch size: 39, Momentum: 6.835e-01\n",
      "Initial loss:  743750.7239072409\n",
      "best loss: 117959.71\t\tLearning rate: 1.000e-08, Batch size: 24, Momentum: 3.155e-01\n",
      "Initial loss:  458.7563345801087\n",
      "best loss: 445.89\t\tLearning rate: 1.624e-03, Batch size: 17, Momentum: 3.155e-01\n",
      "Initial loss:  300632.6198325366\n",
      "best loss: 1249.40\t\tLearning rate: 3.793e-01, Batch size: 2, Momentum: 9.464e-01\n",
      "Initial loss:  608362.1285199441\n",
      "best loss: 461.08\t\tLearning rate: 2.069e-05, Batch size: 27, Momentum: 5.784e-01\n",
      "Initial loss:  196067.29356153856\n",
      "best loss: 1038.10\t\tLearning rate: 4.281e-02, Batch size: 12, Momentum: 6.835e-01\n",
      "Initial loss:  45865.53780037022\n",
      "best loss: 1211.86\t\tLearning rate: 1.129e+00, Batch size: 4, Momentum: 4.206e-01\n",
      "Initial loss:  816936.0347604543\n",
      "best loss: 460.68\t\tLearning rate: 2.976e-08, Batch size: 50, Momentum: 8.938e-01\n",
      "Initial loss:  1129720.5236264672\n",
      "best loss: 526.17\t\tLearning rate: 2.069e-05, Batch size: 42, Momentum: 2.629e-01\n",
      "Initial loss:  1398889.9804194053\n",
      "best loss: 443.28\t\tLearning rate: 1.000e-08, Batch size: 7, Momentum: 9.990e-01\n",
      "Initial loss:  849410.9029296829\n",
      "best loss: 1033.70\t\tLearning rate: 4.281e-02, Batch size: 29, Momentum: 6.309e-01\n",
      "Initial loss:  584762.5138684562\n",
      "best loss: 446.20\t\tLearning rate: 2.637e-07, Batch size: 14, Momentum: 9.990e-01\n",
      "Initial loss:  471.2796238711561\n",
      "best loss: 452.90\t\tLearning rate: 1.000e-08, Batch size: 12, Momentum: 8.938e-01\n",
      "Initial loss:  493453.62990057113\n",
      "best loss: 468.41\t\tLearning rate: 2.637e-07, Batch size: 29, Momentum: 5.784e-01\n",
      "Initial loss:  200166.7415598203\n",
      "best loss: 992.10\t\tLearning rate: 4.833e-03, Batch size: 17, Momentum: 3.681e-01\n",
      "Initial loss:  1041596.4429989345\n",
      "best loss: 900.23\t\tLearning rate: 1.624e-03, Batch size: 9, Momentum: 6.309e-01\n",
      "Initial loss:  455.05678481537996\n",
      "best loss: 447.13\t\tLearning rate: 6.158e-05, Batch size: 44, Momentum: 4.732e-01\n",
      "Initial loss:  638845.2435679252\n",
      "best loss: 1106.92\t\tLearning rate: 1.274e-01, Batch size: 39, Momentum: 2.103e-01\n",
      "Initial loss:  455.65725488162906\n",
      "best loss: 446.91\t\tLearning rate: 4.833e-03, Batch size: 37, Momentum: 1.577e-01\n",
      "Initial loss:  201694.06604609726\n",
      "best loss: 453.81\t\tLearning rate: 2.069e-05, Batch size: 39, Momentum: 4.732e-01\n",
      "Initial loss:  382572.82561460516\n",
      "best loss: 457.24\t\tLearning rate: 1.000e-08, Batch size: 9, Momentum: 9.464e-01\n",
      "Initial loss:  467.74544887961383\n",
      "best loss: 449.32\t\tLearning rate: 1.000e+01, Batch size: 44, Momentum: 7.887e-01\n",
      "Initial loss:  844514.0417512384\n",
      "best loss: 1184.25\t\tLearning rate: 1.274e-01, Batch size: 47, Momentum: 5.784e-01\n",
      "Initial loss:  94949.88506141631\n",
      "best loss: 608.16\t\tLearning rate: 2.069e-05, Batch size: 4, Momentum: 7.361e-01\n",
      "Initial loss:  877320.3340858633\n",
      "best loss: 1426.83\t\tLearning rate: 1.000e+01, Batch size: 44, Momentum: 8.938e-01\n",
      "Initial loss:  894281.7965334102\n",
      "best loss: 976.67\t\tLearning rate: 1.624e-03, Batch size: 14, Momentum: 6.309e-01\n",
      "Initial loss:  456.6626776111346\n",
      "best loss: 443.71\t\tLearning rate: 5.456e-04, Batch size: 14, Momentum: 3.681e-01\n",
      "Initial loss:  1032348.9385731127\n",
      "best loss: 1094.70\t\tLearning rate: 4.281e-02, Batch size: 4, Momentum: 8.938e-01\n",
      "Initial loss:  539111.6901488426\n",
      "best loss: 1331.09\t\tLearning rate: 3.360e+00, Batch size: 22, Momentum: 7.361e-01\n",
      "Initial loss:  548172.5595477896\n",
      "best loss: 1288.46\t\tLearning rate: 3.360e+00, Batch size: 9, Momentum: 4.206e-01\n",
      "Initial loss:  452.89768261603024\n",
      "best loss: 447.83\t\tLearning rate: 2.637e-07, Batch size: 39, Momentum: 8.413e-01\n",
      "Initial loss:  1098191.316847946\n",
      "best loss: 497.64\t\tLearning rate: 2.336e-06, Batch size: 9, Momentum: 2.103e-01\n",
      "Initial loss:  863497.8578303569\n",
      "best loss: 458.43\t\tLearning rate: 2.336e-06, Batch size: 39, Momentum: 8.413e-01\n",
      "Initial loss:  625593.5259715779\n",
      "best loss: 905.87\t\tLearning rate: 1.624e-03, Batch size: 17, Momentum: 5.784e-01\n",
      "Initial loss:  457.11572139365245\n",
      "best loss: 447.05\t\tLearning rate: 6.158e-05, Batch size: 47, Momentum: 8.413e-01\n",
      "Initial loss:  142475.35480675838\n",
      "best loss: 842.40\t\tLearning rate: 5.456e-04, Batch size: 4, Momentum: 2.103e-01\n",
      "Initial loss:  742083.4926004612\n",
      "best loss: 477.67\t\tLearning rate: 1.000e-08, Batch size: 12, Momentum: 5.258e-01\n",
      "Initial loss:  75107.32014193696\n",
      "best loss: 434.57\t\tLearning rate: 8.859e-08, Batch size: 2, Momentum: 4.732e-01\n",
      "Initial loss:  452.3771264677927\n",
      "best loss: 449.95\t\tLearning rate: 1.624e-03, Batch size: 39, Momentum: 9.990e-01\n",
      "Initial loss:  1033113.0436975756\n",
      "best loss: 921.51\t\tLearning rate: 1.624e-03, Batch size: 24, Momentum: 6.309e-01\n",
      "Initial loss:  160825.37056835328\n",
      "best loss: 456.42\t\tLearning rate: 8.859e-08, Batch size: 44, Momentum: 7.361e-01\n",
      "Initial loss:  556790.0762159333\n",
      "best loss: 1116.08\t\tLearning rate: 1.274e-01, Batch size: 19, Momentum: 2.103e-01\n",
      "Initial loss:  167018.95610622223\n",
      "best loss: 981.21\t\tLearning rate: 1.438e-02, Batch size: 42, Momentum: 1.577e-01\n",
      "Initial loss:  149896.33329431416\n",
      "best loss: 667.50\t\tLearning rate: 8.859e-08, Batch size: 14, Momentum: 3.681e-01\n",
      "Initial loss:  395934.3208783277\n",
      "best loss: 445.40\t\tLearning rate: 2.637e-07, Batch size: 27, Momentum: 7.887e-01\n",
      "Initial loss:  665682.5139888885\n",
      "best loss: 831.90\t\tLearning rate: 1.833e-04, Batch size: 12, Momentum: 4.732e-01\n",
      "Initial loss:  539974.0626449683\n",
      "best loss: 457.55\t\tLearning rate: 2.336e-06, Batch size: 50, Momentum: 9.990e-01\n",
      "Initial loss:  249621.30268558892\n",
      "best loss: 448.02\t\tLearning rate: 7.848e-07, Batch size: 34, Momentum: 7.887e-01\n",
      "Initial loss:  277103.84202232474\n",
      "best loss: 477.80\t\tLearning rate: 2.637e-07, Batch size: 27, Momentum: 1.577e-01\n",
      "Initial loss:  1032748.8557094465\n",
      "best loss: 1244.54\t\tLearning rate: 1.129e+00, Batch size: 47, Momentum: 1.577e-01\n",
      "Initial loss:  455.32101864739735\n",
      "best loss: 451.58\t\tLearning rate: 4.281e-02, Batch size: 50, Momentum: 5.258e-02\n",
      "Initial loss:  726189.0829398977\n",
      "best loss: 451.19\t\tLearning rate: 2.336e-06, Batch size: 24, Momentum: 5.258e-01\n",
      "Initial loss:  361038.7770199443\n",
      "best loss: 433.60\t\tLearning rate: 1.000e-08, Batch size: 4, Momentum: 9.990e-01\n",
      "Initial loss:  435882.98998532165\n",
      "best loss: 903.78\t\tLearning rate: 5.456e-04, Batch size: 12, Momentum: 5.784e-01\n",
      "Initial loss:  412403.8025416687\n",
      "best loss: 1053.63\t\tLearning rate: 1.438e-02, Batch size: 22, Momentum: 6.835e-01\n",
      "Initial loss:  777145.8744818\n",
      "best loss: 1024.63\t\tLearning rate: 4.833e-03, Batch size: 4, Momentum: 7.361e-01\n",
      "Initial loss:  371178.01327435183\n",
      "best loss: 998.82\t\tLearning rate: 4.833e-03, Batch size: 14, Momentum: 7.887e-01\n",
      "Initial loss:  465.85148064720164\n",
      "best loss: 444.91\t\tLearning rate: 4.833e-03, Batch size: 9, Momentum: 6.835e-01\n",
      "Initial loss:  706374.741538784\n",
      "best loss: 669.52\t\tLearning rate: 2.976e-08, Batch size: 14, Momentum: 4.206e-01\n",
      "Initial loss:  456.1912068225991\n",
      "best loss: 447.87\t\tLearning rate: 1.833e-04, Batch size: 42, Momentum: 5.258e-01\n",
      "Initial loss:  95695.56162332869\n",
      "best loss: 446.19\t\tLearning rate: 8.859e-08, Batch size: 22, Momentum: 8.938e-01\n",
      "Initial loss:  435347.1316862097\n",
      "best loss: 868.08\t\tLearning rate: 5.456e-04, Batch size: 29, Momentum: 5.784e-01\n",
      "Initial loss:  444.571806843561\n",
      "best loss: 439.88\t\tLearning rate: 1.833e-04, Batch size: 4, Momentum: 8.413e-01\n",
      "Initial loss:  383208.2199949445\n",
      "best loss: 451.17\t\tLearning rate: 7.848e-07, Batch size: 9, Momentum: 1.052e-01\n",
      "Initial loss:  200041.18350514502\n",
      "best loss: 469.31\t\tLearning rate: 6.158e-05, Batch size: 2, Momentum: 6.309e-01\n",
      "Initial loss:  573726.4047768475\n",
      "best loss: 485.32\t\tLearning rate: 2.069e-05, Batch size: 2, Momentum: 3.681e-01\n",
      "Initial loss:  151315.99636785025\n",
      "best loss: 955.21\t\tLearning rate: 4.833e-03, Batch size: 50, Momentum: 3.681e-01\n",
      "Initial loss:  116586.43461732437\n",
      "best loss: 444.73\t\tLearning rate: 2.069e-05, Batch size: 9, Momentum: 2.103e-01\n",
      "Initial loss:  452.44076058157145\n",
      "best loss: 449.56\t\tLearning rate: 1.000e-08, Batch size: 47, Momentum: 7.361e-01\n",
      "Initial loss:  457.68482973041876\n",
      "best loss: 435.66\t\tLearning rate: 2.976e-08, Batch size: 4, Momentum: 7.887e-01\n",
      "Initial loss:  89458.10381518764\n",
      "best loss: 460.82\t\tLearning rate: 2.637e-07, Batch size: 4, Momentum: 4.206e-01\n",
      "Initial loss:  457.5940485454428\n",
      "best loss: 448.59\t\tLearning rate: 2.976e-08, Batch size: 50, Momentum: 1.577e-01\n",
      "Initial loss:  513.4699003721126\n",
      "best loss: 448.83\t\tLearning rate: 3.793e-01, Batch size: 42, Momentum: 9.990e-01\n",
      "Initial loss:  235590.9019238418\n",
      "best loss: 959.75\t\tLearning rate: 5.456e-04, Batch size: 29, Momentum: 9.990e-01\n",
      "Initial loss:  420363.39049442275\n",
      "best loss: 891.19\t\tLearning rate: 1.833e-04, Batch size: 19, Momentum: 8.413e-01\n",
      "Initial loss:  337213.6850112112\n",
      "best loss: 573.43\t\tLearning rate: 2.069e-05, Batch size: 44, Momentum: 3.155e-01\n",
      "Initial loss:  450.4800172094569\n",
      "best loss: 447.98\t\tLearning rate: 5.456e-04, Batch size: 44, Momentum: 5.258e-01\n",
      "Initial loss:  253366.3087560079\n",
      "best loss: 1140.61\t\tLearning rate: 1.274e-01, Batch size: 19, Momentum: 4.732e-01\n",
      "Initial loss:  456.5967809312465\n",
      "best loss: 448.85\t\tLearning rate: 1.624e-03, Batch size: 32, Momentum: 2.103e-01\n",
      "Initial loss:  657079.2490404538\n",
      "best loss: 1045.11\t\tLearning rate: 4.281e-02, Batch size: 29, Momentum: 1.577e-01\n",
      "Initial loss:  72824.36124161705\n",
      "best loss: 1062.65\t\tLearning rate: 1.438e-02, Batch size: 17, Momentum: 7.361e-01\n",
      "Initial loss:  453.82738803451105\n",
      "best loss: 448.04\t\tLearning rate: 2.976e-08, Batch size: 47, Momentum: 8.413e-01\n",
      "Initial loss:  990230.7974471222\n",
      "best loss: 431.76\t\tLearning rate: 7.848e-07, Batch size: 2, Momentum: 7.361e-01\n",
      "Initial loss:  454.49488721831443\n",
      "best loss: 446.55\t\tLearning rate: 2.336e-06, Batch size: 34, Momentum: 9.990e-01\n",
      "Initial loss:  49673.85491173998\n",
      "best loss: 785.77\t\tLearning rate: 8.859e-08, Batch size: 22, Momentum: 0.000e+00\n",
      "Initial loss:  506045.7260196656\n",
      "best loss: 2558.64\t\tLearning rate: 1.000e-08, Batch size: 47, Momentum: 0.000e+00\n",
      "Initial loss:  1045208.1696718296\n",
      "best loss: 1309.29\t\tLearning rate: 3.360e+00, Batch size: 37, Momentum: 3.681e-01\n",
      "Initial loss:  485195.40982537257\n",
      "best loss: 450.59\t\tLearning rate: 8.859e-08, Batch size: 27, Momentum: 7.887e-01\n",
      "Initial loss:  1056285.6404612225\n",
      "best loss: 1155.89\t\tLearning rate: 4.281e-02, Batch size: 17, Momentum: 9.990e-01\n",
      "Initial loss:  248975.66540933104\n",
      "best loss: 673.73\t\tLearning rate: 2.069e-05, Batch size: 24, Momentum: 9.464e-01\n",
      "Initial loss:  88974.26573641272\n",
      "best loss: 836.91\t\tLearning rate: 1.833e-04, Batch size: 12, Momentum: 5.258e-01\n",
      "Initial loss:  455.50891048254675\n",
      "best loss: 445.87\t\tLearning rate: 2.976e-08, Batch size: 14, Momentum: 3.155e-01\n",
      "Initial loss:  455.0505791422728\n",
      "best loss: 430.36\t\tLearning rate: 2.069e-05, Batch size: 2, Momentum: 7.887e-01\n",
      "Initial loss:  935862.702772607\n",
      "best loss: 722.85\t\tLearning rate: 1.833e-04, Batch size: 9, Momentum: 0.000e+00\n",
      "Initial loss:  352595.19200945384\n",
      "best loss: 915.51\t\tLearning rate: 1.624e-03, Batch size: 37, Momentum: 5.784e-01\n",
      "Initial loss:  142268.52985626896\n",
      "best loss: 461.32\t\tLearning rate: 8.859e-08, Batch size: 22, Momentum: 2.629e-01\n",
      "Initial loss:  155037.67169528277\n",
      "best loss: 449.35\t\tLearning rate: 8.859e-08, Batch size: 47, Momentum: 9.464e-01\n",
      "Initial loss:  450.36937400429065\n",
      "best loss: 442.57\t\tLearning rate: 8.859e-08, Batch size: 9, Momentum: 8.413e-01\n",
      "Initial loss:  413044.72664008767\n",
      "best loss: 1369.79\t\tLearning rate: 1.129e+00, Batch size: 29, Momentum: 9.990e-01\n",
      "Initial loss:  750196.6452816452\n",
      "best loss: 666.40\t\tLearning rate: 2.069e-05, Batch size: 42, Momentum: 1.052e-01\n",
      "Initial loss:  203182.63395124883\n",
      "best loss: 1339.10\t\tLearning rate: 3.360e+00, Batch size: 2, Momentum: 4.206e-01\n",
      "Initial loss:  96261.55546981093\n",
      "best loss: 1280.22\t\tLearning rate: 3.360e+00, Batch size: 34, Momentum: 2.103e-01\n",
      "Initial loss:  259598.28112962685\n",
      "best loss: 453.05\t\tLearning rate: 6.952e-06, Batch size: 19, Momentum: 9.990e-01\n",
      "Initial loss:  454040.18290250434\n",
      "best loss: 10508472.68\t\tLearning rate: 3.793e-01, Batch size: 9, Momentum: 5.258e-02\n",
      "Initial loss:  208676.59912058336\n",
      "best loss: 487.38\t\tLearning rate: 2.976e-08, Batch size: 9, Momentum: 3.155e-01\n",
      "Initial loss:  457.19574142143745\n",
      "best loss: 451.31\t\tLearning rate: 8.859e-08, Batch size: 50, Momentum: 7.361e-01\n",
      "Initial loss:  243345.4374476718\n",
      "best loss: 553.39\t\tLearning rate: 2.637e-07, Batch size: 29, Momentum: 1.577e-01\n",
      "Initial loss:  600657.3163574702\n",
      "best loss: 1299.88\t\tLearning rate: 3.360e+00, Batch size: 27, Momentum: 6.309e-01\n",
      "Initial loss:  256540.66699473746\n",
      "best loss: 446.80\t\tLearning rate: 2.336e-06, Batch size: 47, Momentum: 8.938e-01\n",
      "Initial loss:  480.2904538243728\n",
      "best loss: 443.14\t\tLearning rate: 1.438e-02, Batch size: 19, Momentum: 3.155e-01\n",
      "Initial loss:  447.1981677645825\n",
      "best loss: 442.93\t\tLearning rate: 1.129e+00, Batch size: 14, Momentum: 8.413e-01\n",
      "Initial loss:  425256.8616527021\n",
      "best loss: 1241.69\t\tLearning rate: 1.274e-01, Batch size: 14, Momentum: 9.990e-01\n",
      "Initial loss:  89403.69869086915\n",
      "best loss: 1008.61\t\tLearning rate: 1.624e-03, Batch size: 17, Momentum: 9.990e-01\n",
      "Initial loss:  148141.28036206303\n",
      "best loss: 1245.43\t\tLearning rate: 3.793e-01, Batch size: 32, Momentum: 8.413e-01\n",
      "Initial loss:  425538.62318005133\n",
      "best loss: 1189.53\t\tLearning rate: 1.129e+00, Batch size: 22, Momentum: 1.052e-01\n",
      "Initial loss:  456.45518702663395\n",
      "best loss: 449.68\t\tLearning rate: 7.848e-07, Batch size: 50, Momentum: 9.990e-01\n",
      "Initial loss:  513.8450568402492\n",
      "best loss: 435.13\t\tLearning rate: 4.833e-03, Batch size: 4, Momentum: 2.103e-01\n",
      "Initial loss:  537602.7515429632\n",
      "best loss: 731.88\t\tLearning rate: 1.833e-04, Batch size: 22, Momentum: 7.887e-01\n",
      "Initial loss:  457.7620024301241\n",
      "best loss: 434.39\t\tLearning rate: 1.624e-03, Batch size: 2, Momentum: 1.052e-01\n",
      "Initial loss:  472008.6408236421\n",
      "best loss: 900.33\t\tLearning rate: 5.456e-04, Batch size: 37, Momentum: 7.887e-01\n",
      "Initial loss:  553103.1292078327\n",
      "best loss: 502.18\t\tLearning rate: 2.976e-08, Batch size: 7, Momentum: 5.258e-01\n",
      "Initial loss:  674134.2139952995\n",
      "best loss: 701.48\t\tLearning rate: 2.069e-05, Batch size: 44, Momentum: 5.258e-01\n",
      "Initial loss:  835528.5748285117\n",
      "best loss: 85056.45\t\tLearning rate: 8.859e-08, Batch size: 44, Momentum: 6.309e-01\n",
      "Initial loss:  482300.0264298239\n",
      "best loss: 122982.33\t\tLearning rate: 1.833e-04, Batch size: 29, Momentum: 1.052e-01\n",
      "Initial loss:  430998.71031199285\n",
      "best loss: 936.20\t\tLearning rate: 1.624e-03, Batch size: 37, Momentum: 3.681e-01\n",
      "Initial loss:  456.9009620791434\n",
      "best loss: 450.99\t\tLearning rate: 1.274e-01, Batch size: 44, Momentum: 8.413e-01\n",
      "Initial loss:  78163.50003269422\n",
      "best loss: 454.32\t\tLearning rate: 2.336e-06, Batch size: 24, Momentum: 0.000e+00\n",
      "Initial loss:  375104.59770682437\n",
      "best loss: 449.89\t\tLearning rate: 2.336e-06, Batch size: 29, Momentum: 1.052e-01\n",
      "Initial loss:  785119.2174338336\n",
      "best loss: 1155.68\t\tLearning rate: 2.637e-07, Batch size: 47, Momentum: 0.000e+00\n",
      "Initial loss:  682783.8514192551\n",
      "best loss: 451.05\t\tLearning rate: 2.336e-06, Batch size: 47, Momentum: 4.732e-01\n",
      "Initial loss:  463.05367848328444\n",
      "best loss: 441.53\t\tLearning rate: 3.360e+00, Batch size: 9, Momentum: 5.784e-01\n",
      "Initial loss:  274008.7259191104\n",
      "best loss: 74946.08\t\tLearning rate: 2.637e-07, Batch size: 39, Momentum: 1.577e-01\n",
      "Initial loss:  537373.9136171222\n",
      "best loss: 454.86\t\tLearning rate: 6.952e-06, Batch size: 29, Momentum: 9.464e-01\n",
      "Initial loss:  563238.9527620702\n",
      "best loss: 1344.39\t\tLearning rate: 1.000e+01, Batch size: 4, Momentum: 3.681e-01\n",
      "Initial loss:  471.8748192755602\n",
      "best loss: 434.91\t\tLearning rate: 1.000e+01, Batch size: 4, Momentum: 4.206e-01\n",
      "Initial loss:  575164.4105112168\n",
      "best loss: 448.81\t\tLearning rate: 2.637e-07, Batch size: 39, Momentum: 7.887e-01\n",
      "Initial loss:  328436.1029545099\n",
      "best loss: 940.34\t\tLearning rate: 1.624e-03, Batch size: 32, Momentum: 3.681e-01\n",
      "Initial loss:  700641.0289663606\n",
      "best loss: 1146.67\t\tLearning rate: 1.274e-01, Batch size: 17, Momentum: 5.784e-01\n",
      "Initial loss:  151183.17100876165\n",
      "best loss: 1341.96\t\tLearning rate: 3.360e+00, Batch size: 12, Momentum: 7.361e-01\n",
      "Initial loss:  276276.8626071798\n",
      "best loss: 1275.44\t\tLearning rate: 3.360e+00, Batch size: 29, Momentum: 5.258e-02\n",
      "Initial loss:  416255.26822235546\n",
      "best loss: 511.70\t\tLearning rate: 2.976e-08, Batch size: 29, Momentum: 5.258e-01\n",
      "Initial loss:  368173.42673276685\n",
      "best loss: 30181.32\t\tLearning rate: 2.637e-07, Batch size: 22, Momentum: 5.784e-01\n",
      "Initial loss:  166461.20827876258\n",
      "best loss: 26470.69\t\tLearning rate: 2.976e-08, Batch size: 22, Momentum: 4.732e-01\n",
      "Initial loss:  82889.40434487014\n",
      "best loss: 458.95\t\tLearning rate: 2.637e-07, Batch size: 37, Momentum: 1.052e-01\n",
      "Initial loss:  266267.81751195743\n",
      "best loss: 1328.95\t\tLearning rate: 3.360e+00, Batch size: 44, Momentum: 5.784e-01\n",
      "Initial loss:  218191.3124011665\n",
      "best loss: 1329.99\t\tLearning rate: 3.360e+00, Batch size: 27, Momentum: 5.258e-01\n",
      "Initial loss:  282062.63616891595\n",
      "best loss: 1131.95\t\tLearning rate: 1.274e-01, Batch size: 42, Momentum: 4.732e-01\n",
      "Initial loss:  1223277.6194174981\n",
      "best loss: 452.22\t\tLearning rate: 7.848e-07, Batch size: 47, Momentum: 8.938e-01\n",
      "Initial loss:  52446.43424949503\n",
      "best loss: 1379.49\t\tLearning rate: 1.000e+01, Batch size: 37, Momentum: 4.732e-01\n",
      "Initial loss:  462403.3924476073\n",
      "best loss: 92753.86\t\tLearning rate: 1.000e+01, Batch size: 14, Momentum: 2.103e-01\n",
      "Initial loss:  922260.4042798225\n",
      "best loss: 866.43\t\tLearning rate: 1.624e-03, Batch size: 27, Momentum: 5.258e-02\n",
      "Initial loss:  438.3942104301074\n",
      "best loss: 439.75\t\tLearning rate: 2.976e-08, Batch size: 7, Momentum: 3.155e-01\n",
      "Initial loss:  620803.6445853837\n",
      "best loss: 737.54\t\tLearning rate: 6.158e-05, Batch size: 29, Momentum: 4.732e-01\n",
      "Initial loss:  463.9289635457968\n",
      "best loss: 453.30\t\tLearning rate: 5.456e-04, Batch size: 27, Momentum: 9.464e-01\n",
      "Initial loss:  260562.4438333712\n",
      "best loss: 821.94\t\tLearning rate: 1.833e-04, Batch size: 7, Momentum: 4.732e-01\n",
      "Initial loss:  362336.10508700385\n",
      "best loss: 1184.57\t\tLearning rate: 3.793e-01, Batch size: 7, Momentum: 3.681e-01\n",
      "Initial loss:  243794.23972093675\n",
      "best loss: 851.92\t\tLearning rate: 1.624e-03, Batch size: 32, Momentum: 2.103e-01\n",
      "Initial loss:  156951.43841226803\n",
      "best loss: 775.69\t\tLearning rate: 6.158e-05, Batch size: 39, Momentum: 5.258e-01\n",
      "Initial loss:  968993.2042901472\n",
      "best loss: 875.51\t\tLearning rate: 5.456e-04, Batch size: 14, Momentum: 6.835e-01\n",
      "Initial loss:  684723.5286638805\n",
      "best loss: 1088.27\t\tLearning rate: 4.281e-02, Batch size: 39, Momentum: 8.413e-01\n",
      "Initial loss:  669886.4406307726\n",
      "best loss: 1037.39\t\tLearning rate: 4.833e-03, Batch size: 50, Momentum: 8.938e-01\n",
      "Initial loss:  708314.3080547036\n",
      "best loss: 444.58\t\tLearning rate: 7.848e-07, Batch size: 7, Momentum: 9.464e-01\n",
      "Initial loss:  65702.72592538537\n",
      "best loss: 1031.18\t\tLearning rate: 1.438e-02, Batch size: 37, Momentum: 6.309e-01\n",
      "Initial loss:  213539.72532083216\n",
      "best loss: 1138.55\t\tLearning rate: 4.281e-02, Batch size: 42, Momentum: 5.784e-01\n",
      "Initial loss:  367227.0919910914\n",
      "best loss: 751.22\t\tLearning rate: 6.158e-05, Batch size: 29, Momentum: 3.681e-01\n",
      "Initial loss:  365153.4026697157\n",
      "best loss: 1305.74\t\tLearning rate: 3.360e+00, Batch size: 29, Momentum: 2.629e-01\n",
      "Initial loss:  458.0137337876968\n",
      "best loss: 448.27\t\tLearning rate: 4.281e-02, Batch size: 24, Momentum: 9.990e-01\n",
      "Initial loss:  571888.0447620244\n",
      "best loss: 1040.82\t\tLearning rate: 4.281e-02, Batch size: 50, Momentum: 3.681e-01\n",
      "Initial loss:  641377.8815216897\n",
      "best loss: 511.96\t\tLearning rate: 1.000e-08, Batch size: 12, Momentum: 7.361e-01\n",
      "Initial loss:  412675.91150356253\n",
      "best loss: 961.55\t\tLearning rate: 1.624e-03, Batch size: 7, Momentum: 9.990e-01\n",
      "Initial loss:  749231.3927395928\n",
      "best loss: 1379.95\t\tLearning rate: 1.000e+01, Batch size: 42, Momentum: 4.206e-01\n",
      "Initial loss:  467.5799660341674\n",
      "best loss: 446.86\t\tLearning rate: 3.360e+00, Batch size: 42, Momentum: 9.990e-01\n",
      "Initial loss:  355158.464089965\n",
      "best loss: 816.35\t\tLearning rate: 5.456e-04, Batch size: 39, Momentum: 5.258e-02\n",
      "Initial loss:  575207.0015246854\n",
      "best loss: 1146.91\t\tLearning rate: 1.274e-01, Batch size: 24, Momentum: 4.206e-01\n",
      "Initial loss:  725597.1264178812\n",
      "best loss: 945.35\t\tLearning rate: 4.833e-03, Batch size: 39, Momentum: 1.052e-01\n",
      "Initial loss:  193080.24666457844\n",
      "best loss: 1406.89\t\tLearning rate: 1.000e+01, Batch size: 14, Momentum: 3.155e-01\n",
      "Initial loss:  459.84571935219094\n",
      "best loss: 452.34\t\tLearning rate: 3.360e+00, Batch size: 50, Momentum: 1.577e-01\n",
      "Initial loss:  769877.5595656142\n",
      "best loss: 1029.25\t\tLearning rate: 1.438e-02, Batch size: 9, Momentum: 6.835e-01\n",
      "Initial loss:  761600.1806244942\n",
      "best loss: 962.02\t\tLearning rate: 4.833e-03, Batch size: 17, Momentum: 4.206e-01\n",
      "Initial loss:  104971.54766854843\n",
      "best loss: 1345.80\t\tLearning rate: 3.360e+00, Batch size: 34, Momentum: 9.990e-01\n",
      "Initial loss:  146228.7295346961\n",
      "best loss: 881.67\t\tLearning rate: 1.833e-04, Batch size: 32, Momentum: 8.413e-01\n",
      "Initial loss:  270266.98424997745\n",
      "best loss: 1091.02\t\tLearning rate: 3.793e-01, Batch size: 4, Momentum: 0.000e+00\n",
      "Initial loss:  489289.0247937067\n",
      "best loss: 1248.63\t\tLearning rate: 3.360e+00, Batch size: 19, Momentum: 0.000e+00\n",
      "Initial loss:  301432.30525311496\n",
      "best loss: 1233.71\t\tLearning rate: 3.793e-01, Batch size: 32, Momentum: 1.052e-01\n",
      "Initial loss:  370993.2442098042\n",
      "best loss: 486.18\t\tLearning rate: 2.637e-07, Batch size: 37, Momentum: 4.206e-01\n",
      "Initial loss:  600484.4970119275\n",
      "best loss: 449.58\t\tLearning rate: 2.336e-06, Batch size: 47, Momentum: 7.887e-01\n",
      "Initial loss:  179042.88544016884\n",
      "best loss: 848.66\t\tLearning rate: 6.158e-05, Batch size: 24, Momentum: 9.990e-01\n",
      "Initial loss:  270043.5570700142\n",
      "best loss: 455.11\t\tLearning rate: 2.336e-06, Batch size: 37, Momentum: 6.835e-01\n",
      "Initial loss:  481820.12135466974\n",
      "best loss: 1278.22\t\tLearning rate: 3.360e+00, Batch size: 32, Momentum: 2.629e-01\n",
      "Initial loss:  484.8857254290485\n",
      "best loss: 445.76\t\tLearning rate: 1.000e+01, Batch size: 27, Momentum: 3.681e-01\n",
      "Initial loss:  652358.1888891592\n",
      "best loss: 1241.29\t\tLearning rate: 1.274e-01, Batch size: 19, Momentum: 8.938e-01\n",
      "Initial loss:  62223.38041883382\n",
      "best loss: 1073.72\t\tLearning rate: 3.793e-01, Batch size: 4, Momentum: 0.000e+00\n",
      "Initial loss:  353936.5491000087\n",
      "best loss: 1108.78\t\tLearning rate: 1.274e-01, Batch size: 2, Momentum: 2.103e-01\n",
      "Initial loss:  426981.68180818483\n",
      "best loss: 1223.70\t\tLearning rate: 1.129e+00, Batch size: 42, Momentum: 3.681e-01\n",
      "Initial loss:  461.07152764948415\n",
      "best loss: 446.63\t\tLearning rate: 3.793e-01, Batch size: 27, Momentum: 9.464e-01\n",
      "Initial loss:  578821.2896013147\n",
      "best loss: 446.19\t\tLearning rate: 2.336e-06, Batch size: 24, Momentum: 7.361e-01\n",
      "Initial loss:  290469.57618831145\n",
      "best loss: 762.38\t\tLearning rate: 1.833e-04, Batch size: 17, Momentum: 3.681e-01\n",
      "Initial loss:  413106.9347930146\n",
      "best loss: 456.15\t\tLearning rate: 2.069e-05, Batch size: 39, Momentum: 5.258e-02\n",
      "Initial loss:  935.4604223329798\n",
      "best loss: 690.69\t\tLearning rate: 1.000e-08, Batch size: 44, Momentum: 8.413e-01\n",
      "Initial loss:  463410.4635091209\n",
      "best loss: 963.03\t\tLearning rate: 1.438e-02, Batch size: 42, Momentum: 0.000e+00\n",
      "Initial loss:  455.1711899455361\n",
      "best loss: 441.75\t\tLearning rate: 2.336e-06, Batch size: 9, Momentum: 7.361e-01\n",
      "Initial loss:  458.0287665964241\n",
      "best loss: 447.57\t\tLearning rate: 1.624e-03, Batch size: 12, Momentum: 6.309e-01\n",
      "Initial loss:  372890.811297991\n",
      "best loss: 434.46\t\tLearning rate: 1.000e-08, Batch size: 7, Momentum: 9.990e-01\n",
      "Initial loss:  453.82492955077674\n",
      "best loss: 440.22\t\tLearning rate: 7.848e-07, Batch size: 9, Momentum: 4.732e-01\n",
      "Initial loss:  104443.14608200247\n",
      "best loss: 1015.51\t\tLearning rate: 1.438e-02, Batch size: 37, Momentum: 1.052e-01\n",
      "Initial loss:  717933.0154208468\n",
      "best loss: 1595.63\t\tLearning rate: 1.000e-08, Batch size: 50, Momentum: 5.258e-01\n",
      "Initial loss:  286878.6123025751\n",
      "best loss: 492.83\t\tLearning rate: 2.069e-05, Batch size: 17, Momentum: 0.000e+00\n",
      "Initial loss:  290696.9912187639\n",
      "best loss: 448.25\t\tLearning rate: 7.848e-07, Batch size: 34, Momentum: 8.938e-01\n",
      "Initial loss:  243246.97747416704\n",
      "best loss: 449.68\t\tLearning rate: 6.952e-06, Batch size: 50, Momentum: 5.784e-01\n",
      "Initial loss:  871301.2387676744\n",
      "best loss: 667.17\t\tLearning rate: 6.158e-05, Batch size: 14, Momentum: 4.206e-01\n",
      "Initial loss:  674777.5572354023\n",
      "best loss: 889.83\t\tLearning rate: 1.833e-04, Batch size: 37, Momentum: 7.887e-01\n",
      "Initial loss:  179022.485965395\n",
      "best loss: 104996.37\t\tLearning rate: 1.000e-08, Batch size: 2, Momentum: 2.629e-01\n",
      "Initial loss:  218737.67508229022\n",
      "best loss: 997.38\t\tLearning rate: 1.624e-03, Batch size: 27, Momentum: 7.887e-01\n",
      "Initial loss:  810259.3976924898\n",
      "best loss: 58681.16\t\tLearning rate: 1.000e-08, Batch size: 17, Momentum: 1.577e-01\n",
      "Initial loss:  227822.8336763225\n",
      "best loss: 485.46\t\tLearning rate: 8.859e-08, Batch size: 17, Momentum: 6.835e-01\n",
      "Initial loss:  66447.73771360365\n",
      "best loss: 947.08\t\tLearning rate: 5.456e-04, Batch size: 32, Momentum: 7.361e-01\n",
      "Initial loss:  1402166.740258844\n",
      "best loss: 1008.90\t\tLearning rate: 1.000e-08, Batch size: 42, Momentum: 5.258e-02\n",
      "Initial loss:  241672.96605323718\n",
      "best loss: 447.51\t\tLearning rate: 6.952e-06, Batch size: 32, Momentum: 1.577e-01\n",
      "Initial loss:  450.8998627413924\n",
      "best loss: 445.62\t\tLearning rate: 6.158e-05, Batch size: 19, Momentum: 8.938e-01\n",
      "Initial loss:  480230.50543829915\n",
      "best loss: 479.56\t\tLearning rate: 1.000e-08, Batch size: 17, Momentum: 8.938e-01\n",
      "Initial loss:  454.09374505608025\n",
      "best loss: 450.91\t\tLearning rate: 1.438e-02, Batch size: 37, Momentum: 9.990e-01\n",
      "Initial loss:  37839.92456868955\n",
      "best loss: 987.72\t\tLearning rate: 4.833e-03, Batch size: 50, Momentum: 5.784e-01\n",
      "Initial loss:  460567.7635655054\n",
      "best loss: 557.74\t\tLearning rate: 2.069e-05, Batch size: 9, Momentum: 4.732e-01\n",
      "Initial loss:  236082.94075830767\n",
      "best loss: 371561.95\t\tLearning rate: 4.833e-03, Batch size: 37, Momentum: 5.258e-02\n",
      "Initial loss:  197374.44439999506\n",
      "best loss: 447.14\t\tLearning rate: 2.336e-06, Batch size: 19, Momentum: 1.052e-01\n",
      "Initial loss:  1009566.8459069701\n",
      "best loss: 463.46\t\tLearning rate: 2.336e-06, Batch size: 37, Momentum: 2.629e-01\n",
      "Initial loss:  184270.47629841443\n",
      "best loss: 476.71\t\tLearning rate: 2.069e-05, Batch size: 27, Momentum: 5.258e-02\n",
      "Initial loss:  456.05900728907835\n",
      "best loss: 449.32\t\tLearning rate: 2.637e-07, Batch size: 17, Momentum: 4.206e-01\n",
      "Initial loss:  907577.5048628091\n",
      "best loss: 1083.38\t\tLearning rate: 1.274e-01, Batch size: 2, Momentum: 4.732e-01\n",
      "Initial loss:  179166.65914150552\n",
      "best loss: 472.18\t\tLearning rate: 2.976e-08, Batch size: 2, Momentum: 7.887e-01\n",
      "Initial loss:  247680.10790063703\n",
      "best loss: 869.27\t\tLearning rate: 5.456e-04, Batch size: 34, Momentum: 5.258e-01\n",
      "Initial loss:  242215.46247731207\n",
      "best loss: 1101.63\t\tLearning rate: 1.274e-01, Batch size: 2, Momentum: 5.258e-01\n",
      "Initial loss:  319661.84433056973\n",
      "best loss: 937.32\t\tLearning rate: 5.456e-04, Batch size: 7, Momentum: 8.413e-01\n",
      "Initial loss:  450763.6879962437\n",
      "best loss: 471.41\t\tLearning rate: 6.952e-06, Batch size: 47, Momentum: 0.000e+00\n",
      "Initial loss:  638934.1270587062\n",
      "best loss: 625.45\t\tLearning rate: 1.000e-08, Batch size: 47, Momentum: 6.835e-01\n",
      "Initial loss:  787272.8788314473\n",
      "best loss: 12938.69\t\tLearning rate: 2.976e-08, Batch size: 4, Momentum: 3.155e-01\n",
      "Initial loss:  912171.4677990122\n",
      "best loss: 1113.92\t\tLearning rate: 4.281e-02, Batch size: 9, Momentum: 6.835e-01\n",
      "Initial loss:  687226.638820641\n",
      "best loss: 1193.61\t\tLearning rate: 1.274e-01, Batch size: 24, Momentum: 8.413e-01\n",
      "Initial loss:  725199.190399628\n",
      "best loss: 504.77\t\tLearning rate: 2.637e-07, Batch size: 29, Momentum: 5.258e-01\n",
      "Initial loss:  188961.23286056466\n",
      "best loss: 1150.22\t\tLearning rate: 4.281e-02, Batch size: 2, Momentum: 7.887e-01\n",
      "Initial loss:  416510.15027819783\n",
      "best loss: 447.50\t\tLearning rate: 2.637e-07, Batch size: 19, Momentum: 7.887e-01\n",
      "Initial loss:  760591.1775812848\n",
      "best loss: 1199.39\t\tLearning rate: 3.793e-01, Batch size: 7, Momentum: 4.206e-01\n",
      "Initial loss:  278760.8164179232\n",
      "best loss: 461.74\t\tLearning rate: 8.859e-08, Batch size: 42, Momentum: 6.309e-01\n",
      "Initial loss:  261107.80973471652\n",
      "best loss: 1216.89\t\tLearning rate: 1.129e+00, Batch size: 42, Momentum: 1.052e-01\n",
      "Initial loss:  469406.1730190957\n",
      "best loss: 1156.60\t\tLearning rate: 4.281e-02, Batch size: 37, Momentum: 8.413e-01\n",
      "Initial loss:  433640.3864002122\n",
      "best loss: 876.27\t\tLearning rate: 5.456e-04, Batch size: 39, Momentum: 5.258e-01\n",
      "Initial loss:  46129.487880910616\n",
      "best loss: 468.83\t\tLearning rate: 6.158e-05, Batch size: 47, Momentum: 3.681e-01\n",
      "Initial loss:  405545.1979533334\n",
      "best loss: 1369.51\t\tLearning rate: 3.360e+00, Batch size: 29, Momentum: 9.464e-01\n",
      "Initial loss:  569945.1245994348\n",
      "best loss: 1245.56\t\tLearning rate: 3.793e-01, Batch size: 29, Momentum: 5.784e-01\n",
      "Initial loss:  621045.8101016186\n",
      "best loss: 1264.55\t\tLearning rate: 3.793e-01, Batch size: 44, Momentum: 8.413e-01\n",
      "Initial loss:  304311.4097278268\n",
      "best loss: 458.01\t\tLearning rate: 7.848e-07, Batch size: 19, Momentum: 2.103e-01\n",
      "Initial loss:  382981.5435550479\n",
      "best loss: 448.70\t\tLearning rate: 7.848e-07, Batch size: 34, Momentum: 2.629e-01\n",
      "Initial loss:  892127.2665401004\n",
      "best loss: 1343.65\t\tLearning rate: 1.129e+00, Batch size: 24, Momentum: 8.413e-01\n",
      "Initial loss:  444.2426083994777\n",
      "best loss: 432.48\t\tLearning rate: 2.069e-05, Batch size: 4, Momentum: 2.629e-01\n",
      "Initial loss:  700647.315051518\n",
      "best loss: 1260.51\t\tLearning rate: 3.360e+00, Batch size: 44, Momentum: 2.629e-01\n",
      "Initial loss:  677586.3892446834\n",
      "best loss: 735.07\t\tLearning rate: 2.069e-05, Batch size: 19, Momentum: 8.413e-01\n",
      "Initial loss:  1228763.3030542769\n",
      "best loss: 795.23\t\tLearning rate: 1.833e-04, Batch size: 4, Momentum: 3.681e-01\n",
      "Initial loss:  605527.9422228928\n",
      "best loss: 800.04\t\tLearning rate: 5.456e-04, Batch size: 4, Momentum: 3.681e-01\n",
      "Initial loss:  1021731.3042883046\n",
      "best loss: 32195.77\t\tLearning rate: 8.859e-08, Batch size: 12, Momentum: 9.464e-01\n",
      "Initial loss:  596551.8823691307\n",
      "best loss: 448.95\t\tLearning rate: 6.952e-06, Batch size: 9, Momentum: 6.835e-01\n",
      "Initial loss:  281143.09215592674\n",
      "best loss: 445.87\t\tLearning rate: 7.848e-07, Batch size: 37, Momentum: 8.938e-01\n",
      "Initial loss:  525.6346424347398\n",
      "best loss: 464.97\t\tLearning rate: 6.952e-06, Batch size: 12, Momentum: 7.887e-01\n",
      "Initial loss:  622412.3376195402\n",
      "best loss: 1113.88\t\tLearning rate: 1.274e-01, Batch size: 34, Momentum: 3.155e-01\n",
      "Initial loss:  228779.35764939274\n",
      "best loss: 454.54\t\tLearning rate: 6.952e-06, Batch size: 47, Momentum: 9.990e-01\n",
      "Initial loss:  291058.07123933703\n",
      "best loss: 449.82\t\tLearning rate: 7.848e-07, Batch size: 37, Momentum: 8.413e-01\n",
      "Initial loss:  322430.4806585048\n",
      "best loss: 1315.68\t\tLearning rate: 1.000e+01, Batch size: 37, Momentum: 1.577e-01\n",
      "Initial loss:  148146.07265438428\n",
      "best loss: 1357.11\t\tLearning rate: 3.360e+00, Batch size: 50, Momentum: 6.309e-01\n",
      "Initial loss:  457.9266074714163\n",
      "best loss: 449.32\t\tLearning rate: 7.848e-07, Batch size: 50, Momentum: 4.206e-01\n",
      "Initial loss:  526513.0897300921\n",
      "best loss: 450.82\t\tLearning rate: 2.637e-07, Batch size: 32, Momentum: 8.413e-01\n",
      "Initial loss:  154510.7592904156\n",
      "best loss: 1029.09\t\tLearning rate: 4.281e-02, Batch size: 29, Momentum: 0.000e+00\n",
      "Initial loss:  328122.515083374\n",
      "best loss: 417769.41\t\tLearning rate: 4.833e-03, Batch size: 50, Momentum: 0.000e+00\n",
      "Initial loss:  163253.16248106497\n",
      "best loss: 1340.87\t\tLearning rate: 3.360e+00, Batch size: 19, Momentum: 8.413e-01\n",
      "Initial loss:  558244.956036637\n",
      "best loss: 1268.82\t\tLearning rate: 1.129e+00, Batch size: 7, Momentum: 5.258e-01\n",
      "Initial loss:  284385.3914450808\n",
      "best loss: 446.27\t\tLearning rate: 6.952e-06, Batch size: 12, Momentum: 3.681e-01\n",
      "Initial loss:  228312.96564505622\n",
      "best loss: 508.42\t\tLearning rate: 1.000e-08, Batch size: 50, Momentum: 6.835e-01\n",
      "Initial loss:  518644.7958414779\n",
      "best loss: 1403.64\t\tLearning rate: 1.000e+01, Batch size: 29, Momentum: 8.413e-01\n",
      "Initial loss:  225529.16463839103\n",
      "best loss: 835.77\t\tLearning rate: 1.833e-04, Batch size: 22, Momentum: 9.464e-01\n",
      "Initial loss:  133741.86899919924\n",
      "best loss: 451.02\t\tLearning rate: 2.336e-06, Batch size: 29, Momentum: 0.000e+00\n",
      "Initial loss:  498.33780740926886\n",
      "best loss: 434.68\t\tLearning rate: 5.456e-04, Batch size: 2, Momentum: 1.052e-01\n",
      "Initial loss:  467807.1660384451\n",
      "best loss: 450.54\t\tLearning rate: 7.848e-07, Batch size: 47, Momentum: 8.938e-01\n",
      "Initial loss:  339115.9381133322\n",
      "best loss: 50351.91\t\tLearning rate: 1.000e-08, Batch size: 47, Momentum: 0.000e+00\n",
      "Initial loss:  459.1746392105371\n",
      "best loss: 449.60\t\tLearning rate: 4.281e-02, Batch size: 37, Momentum: 5.784e-01\n",
      "Initial loss:  190270.19900358244\n",
      "best loss: 1144.10\t\tLearning rate: 3.793e-01, Batch size: 50, Momentum: 1.577e-01\n",
      "Initial loss:  629005.7673500361\n",
      "best loss: 150883.87\t\tLearning rate: 2.637e-07, Batch size: 42, Momentum: 5.258e-02\n",
      "Initial loss:  598389.0413581524\n",
      "best loss: 441.74\t\tLearning rate: 2.637e-07, Batch size: 9, Momentum: 8.938e-01\n",
      "Initial loss:  632879.2221521891\n",
      "best loss: 447.93\t\tLearning rate: 2.976e-08, Batch size: 27, Momentum: 9.464e-01\n",
      "Initial loss:  1401952.173707431\n",
      "best loss: 1356.80\t\tLearning rate: 1.000e+01, Batch size: 2, Momentum: 4.732e-01\n",
      "Initial loss:  129488.68422302465\n",
      "best loss: 1376.86\t\tLearning rate: 1.000e+01, Batch size: 50, Momentum: 5.784e-01\n",
      "Initial loss:  256170.0468731245\n",
      "best loss: 455.99\t\tLearning rate: 6.952e-06, Batch size: 34, Momentum: 8.413e-01\n",
      "Initial loss:  457.46512834120557\n",
      "best loss: 448.44\t\tLearning rate: 1.000e+01, Batch size: 29, Momentum: 1.577e-01\n",
      "Initial loss:  452.5654493889304\n",
      "best loss: 448.74\t\tLearning rate: 4.281e-02, Batch size: 42, Momentum: 4.206e-01\n",
      "Initial loss:  298875.1032843017\n",
      "best loss: 1347.31\t\tLearning rate: 1.000e+01, Batch size: 32, Momentum: 3.155e-01\n",
      "Initial loss:  399680.7888505567\n",
      "best loss: 458.76\t\tLearning rate: 7.848e-07, Batch size: 19, Momentum: 3.681e-01\n",
      "Initial loss:  176355.4841918251\n",
      "best loss: 458.02\t\tLearning rate: 1.000e-08, Batch size: 4, Momentum: 7.887e-01\n",
      "Initial loss:  296799.9428350895\n",
      "best loss: 471.63\t\tLearning rate: 8.859e-08, Batch size: 12, Momentum: 1.052e-01\n",
      "Initial loss:  458.18227260209915\n",
      "best loss: 446.49\t\tLearning rate: 1.000e-08, Batch size: 19, Momentum: 1.577e-01\n",
      "Initial loss:  453.64361651262425\n",
      "best loss: 440.74\t\tLearning rate: 1.833e-04, Batch size: 9, Momentum: 2.629e-01\n",
      "Initial loss:  184911.74725961967\n",
      "best loss: 999.44\t\tLearning rate: 1.624e-03, Batch size: 29, Momentum: 7.887e-01\n",
      "Initial loss:  855373.5508401487\n",
      "best loss: 940.20\t\tLearning rate: 4.833e-03, Batch size: 14, Momentum: 3.155e-01\n",
      "Initial loss:  686056.894805399\n",
      "best loss: 457.12\t\tLearning rate: 7.848e-07, Batch size: 29, Momentum: 8.938e-01\n",
      "Initial loss:  463.64189944246874\n",
      "best loss: 452.55\t\tLearning rate: 3.793e-01, Batch size: 37, Momentum: 2.629e-01\n",
      "Initial loss:  454.7848057036245\n",
      "best loss: 451.06\t\tLearning rate: 1.833e-04, Batch size: 47, Momentum: 5.784e-01\n",
      "Initial loss:  376908.70436018327\n",
      "best loss: 458.97\t\tLearning rate: 7.848e-07, Batch size: 37, Momentum: 4.206e-01\n",
      "Initial loss:  335225.11460767203\n",
      "best loss: 1081.75\t\tLearning rate: 4.281e-02, Batch size: 34, Momentum: 5.784e-01\n",
      "Initial loss:  65599.01719618875\n",
      "best loss: 446.68\t\tLearning rate: 2.069e-05, Batch size: 17, Momentum: 5.258e-02\n",
      "Initial loss:  457.56406246380976\n",
      "best loss: 447.18\t\tLearning rate: 1.624e-03, Batch size: 24, Momentum: 3.681e-01\n",
      "Initial loss:  455.1213402779443\n",
      "best loss: 432.17\t\tLearning rate: 4.833e-03, Batch size: 4, Momentum: 0.000e+00\n",
      "Initial loss:  493807.42129887495\n",
      "best loss: 1146.54\t\tLearning rate: 4.281e-02, Batch size: 32, Momentum: 9.464e-01\n",
      "Initial loss:  158780.8897752117\n",
      "best loss: 1357.00\t\tLearning rate: 3.360e+00, Batch size: 2, Momentum: 9.990e-01\n",
      "Initial loss:  738875.9105310763\n",
      "best loss: 447.10\t\tLearning rate: 7.848e-07, Batch size: 9, Momentum: 5.258e-02\n",
      "Initial loss:  390659.1593077689\n",
      "best loss: 838912.13\t\tLearning rate: 1.624e-03, Batch size: 44, Momentum: 1.052e-01\n",
      "Initial loss:  779172.348234296\n",
      "best loss: 841.14\t\tLearning rate: 1.624e-03, Batch size: 32, Momentum: 0.000e+00\n",
      "Initial loss:  176497.12754914074\n",
      "best loss: 1013.27\t\tLearning rate: 1.438e-02, Batch size: 44, Momentum: 3.155e-01\n",
      "Initial loss:  216582.7986494612\n",
      "best loss: 497298.57\t\tLearning rate: 5.456e-04, Batch size: 17, Momentum: 0.000e+00\n",
      "Initial loss:  563754.7811852092\n",
      "best loss: 512.07\t\tLearning rate: 2.069e-05, Batch size: 9, Momentum: 4.206e-01\n",
      "Initial loss:  47912.830250355204\n",
      "best loss: 652.97\t\tLearning rate: 6.158e-05, Batch size: 29, Momentum: 4.206e-01\n",
      "Initial loss:  634407.2747386373\n",
      "best loss: 488.63\t\tLearning rate: 2.637e-07, Batch size: 17, Momentum: 4.206e-01\n",
      "Initial loss:  386872.0078749886\n",
      "best loss: 1020.27\t\tLearning rate: 1.438e-02, Batch size: 17, Momentum: 3.155e-01\n",
      "Initial loss:  291334.70459217345\n",
      "best loss: 1265.68\t\tLearning rate: 3.793e-01, Batch size: 9, Momentum: 8.413e-01\n",
      "Initial loss:  236405.93237697193\n",
      "best loss: 725.97\t\tLearning rate: 2.069e-05, Batch size: 9, Momentum: 8.413e-01\n",
      "Initial loss:  479.0707581544266\n",
      "best loss: 464.03\t\tLearning rate: 6.952e-06, Batch size: 50, Momentum: 1.577e-01\n",
      "Initial loss:  115733.57702753317\n",
      "best loss: 457.63\t\tLearning rate: 6.952e-06, Batch size: 9, Momentum: 7.887e-01\n",
      "Initial loss:  169324.63962459413\n",
      "best loss: 1305.53\t\tLearning rate: 1.129e+00, Batch size: 32, Momentum: 9.990e-01\n",
      "Initial loss:  452.4670666678484\n",
      "best loss: 448.83\t\tLearning rate: 4.833e-03, Batch size: 39, Momentum: 3.681e-01\n",
      "Initial loss:  515.3497797836224\n",
      "best loss: 484.49\t\tLearning rate: 5.456e-04, Batch size: 50, Momentum: 3.681e-01\n",
      "Initial loss:  48172.82825524729\n",
      "best loss: 448.18\t\tLearning rate: 6.952e-06, Batch size: 29, Momentum: 0.000e+00\n",
      "Initial loss:  469.1494685642324\n",
      "best loss: 444.18\t\tLearning rate: 1.274e-01, Batch size: 14, Momentum: 3.681e-01\n",
      "Initial loss:  367455.89007797075\n",
      "best loss: 858.98\t\tLearning rate: 5.456e-04, Batch size: 44, Momentum: 7.361e-01\n",
      "Initial loss:  374652.8060353645\n",
      "best loss: 535.63\t\tLearning rate: 1.000e-08, Batch size: 37, Momentum: 4.206e-01\n",
      "Initial loss:  175193.29117800368\n",
      "best loss: 1087.74\t\tLearning rate: 4.281e-02, Batch size: 37, Momentum: 5.784e-01\n",
      "Initial loss:  199041.5285753686\n",
      "best loss: 1291.43\t\tLearning rate: 3.360e+00, Batch size: 22, Momentum: 3.155e-01\n",
      "Initial loss:  268793.6302141349\n",
      "best loss: 460.29\t\tLearning rate: 7.848e-07, Batch size: 14, Momentum: 5.258e-02\n",
      "Initial loss:  114046.82372342472\n",
      "best loss: 1400.13\t\tLearning rate: 3.360e+00, Batch size: 22, Momentum: 8.413e-01\n",
      "Initial loss:  712265.6802793471\n",
      "best loss: 1282.47\t\tLearning rate: 1.129e+00, Batch size: 34, Momentum: 7.361e-01\n",
      "Initial loss:  219979.8032636772\n",
      "best loss: 798.14\t\tLearning rate: 6.158e-05, Batch size: 37, Momentum: 7.361e-01\n",
      "Initial loss:  458.62981195943996\n",
      "best loss: 447.94\t\tLearning rate: 6.952e-06, Batch size: 29, Momentum: 5.258e-01\n",
      "Initial loss:  850515.1546712945\n",
      "best loss: 446.95\t\tLearning rate: 2.637e-07, Batch size: 4, Momentum: 3.155e-01\n",
      "Initial loss:  115191.12441238703\n",
      "best loss: 456.48\t\tLearning rate: 2.336e-06, Batch size: 32, Momentum: 3.155e-01\n",
      "Initial loss:  132841.05371351942\n",
      "best loss: 1170.86\t\tLearning rate: 1.274e-01, Batch size: 12, Momentum: 7.361e-01\n",
      "Initial loss:  585155.6409570707\n",
      "best loss: 845.99\t\tLearning rate: 5.456e-04, Batch size: 19, Momentum: 2.103e-01\n",
      "Initial loss:  216605.21441850468\n",
      "best loss: 3681.10\t\tLearning rate: 1.000e-08, Batch size: 29, Momentum: 1.052e-01\n",
      "Initial loss:  536694.6971373871\n",
      "best loss: 863.35\t\tLearning rate: 1.833e-04, Batch size: 4, Momentum: 8.938e-01\n",
      "Initial loss:  458.57641186264374\n",
      "best loss: 445.61\t\tLearning rate: 8.859e-08, Batch size: 29, Momentum: 7.361e-01\n",
      "Initial loss:  867165.7336380023\n",
      "best loss: 531.25\t\tLearning rate: 8.859e-08, Batch size: 39, Momentum: 6.835e-01\n",
      "Initial loss:  453.38237755392987\n",
      "best loss: 449.95\t\tLearning rate: 1.624e-03, Batch size: 50, Momentum: 7.361e-01\n",
      "Initial loss:  905822.5977161191\n",
      "best loss: 509.37\t\tLearning rate: 1.000e-08, Batch size: 2, Momentum: 3.681e-01\n",
      "Initial loss:  458.3004102711152\n",
      "best loss: 439.43\t\tLearning rate: 1.833e-04, Batch size: 9, Momentum: 3.681e-01\n",
      "Initial loss:  841074.5627198598\n",
      "best loss: 504.68\t\tLearning rate: 2.069e-05, Batch size: 39, Momentum: 3.155e-01\n",
      "Initial loss:  451.27423951434724\n",
      "best loss: 434.28\t\tLearning rate: 1.129e+00, Batch size: 2, Momentum: 9.464e-01\n",
      "Initial loss:  690783.3215199544\n",
      "best loss: 453.49\t\tLearning rate: 2.336e-06, Batch size: 44, Momentum: 6.835e-01\n",
      "Initial loss:  126098.90161179584\n",
      "best loss: 970.53\t\tLearning rate: 4.833e-03, Batch size: 27, Momentum: 5.258e-01\n",
      "Initial loss:  155859.67891100558\n",
      "best loss: 1236.75\t\tLearning rate: 1.129e+00, Batch size: 34, Momentum: 3.155e-01\n",
      "Initial loss:  463.0881007177368\n",
      "best loss: 445.14\t\tLearning rate: 2.976e-08, Batch size: 14, Momentum: 7.887e-01\n",
      "Initial loss:  458.19303297937125\n",
      "best loss: 448.47\t\tLearning rate: 8.859e-08, Batch size: 39, Momentum: 5.784e-01\n",
      "Initial loss:  466.435045933593\n",
      "best loss: 433.21\t\tLearning rate: 2.637e-07, Batch size: 2, Momentum: 8.413e-01\n",
      "Initial loss:  615059.0579891836\n",
      "best loss: 1135.11\t\tLearning rate: 1.274e-01, Batch size: 32, Momentum: 1.577e-01\n",
      "Initial loss:  62077.64371716613\n",
      "best loss: 1200.15\t\tLearning rate: 1.274e-01, Batch size: 12, Momentum: 9.464e-01\n",
      "Initial loss:  412156.9716154736\n",
      "best loss: 445.63\t\tLearning rate: 7.848e-07, Batch size: 14, Momentum: 9.464e-01\n",
      "Initial loss:  216028.84541476\n",
      "best loss: 713.15\t\tLearning rate: 1.833e-04, Batch size: 27, Momentum: 5.258e-02\n",
      "Initial loss:  391974.11804230383\n",
      "best loss: 1000.52\t\tLearning rate: 1.438e-02, Batch size: 19, Momentum: 1.577e-01\n",
      "Initial loss:  457.7867951190696\n",
      "best loss: 450.72\t\tLearning rate: 5.456e-04, Batch size: 42, Momentum: 9.990e-01\n",
      "Initial loss:  801084.2145462139\n",
      "best loss: 456.45\t\tLearning rate: 6.952e-06, Batch size: 42, Momentum: 2.629e-01\n",
      "Initial loss:  327902.5087374588\n",
      "best loss: 446.07\t\tLearning rate: 2.637e-07, Batch size: 12, Momentum: 7.887e-01\n",
      "Initial loss:  277776.85741718486\n",
      "best loss: 1349.67\t\tLearning rate: 3.360e+00, Batch size: 32, Momentum: 6.309e-01\n",
      "Initial loss:  639025.5228461571\n",
      "best loss: 433.89\t\tLearning rate: 2.336e-06, Batch size: 2, Momentum: 7.361e-01\n",
      "Initial loss:  780719.863114019\n",
      "best loss: 447.90\t\tLearning rate: 2.336e-06, Batch size: 17, Momentum: 3.155e-01\n",
      "Initial loss:  645847.661534055\n",
      "best loss: 1014.63\t\tLearning rate: 1.000e-08, Batch size: 14, Momentum: 2.629e-01\n",
      "Initial loss:  256186.00571648305\n",
      "best loss: 1015.76\t\tLearning rate: 1.438e-02, Batch size: 42, Momentum: 3.155e-01\n",
      "Initial loss:  762646.6608051403\n",
      "best loss: 452.73\t\tLearning rate: 2.336e-06, Batch size: 47, Momentum: 7.887e-01\n",
      "Initial loss:  202924.65521104305\n",
      "best loss: 759.78\t\tLearning rate: 6.158e-05, Batch size: 22, Momentum: 3.681e-01\n",
      "Initial loss:  487666.9437133026\n",
      "best loss: 925.79\t\tLearning rate: 1.624e-03, Batch size: 39, Momentum: 3.155e-01\n",
      "Initial loss:  695616.4393748791\n",
      "best loss: 710.82\t\tLearning rate: 6.158e-05, Batch size: 32, Momentum: 9.990e-01\n",
      "Initial loss:  294016.0727817989\n",
      "best loss: 446.83\t\tLearning rate: 2.637e-07, Batch size: 9, Momentum: 6.835e-01\n",
      "Initial loss:  340152.360947557\n",
      "best loss: 1247.27\t\tLearning rate: 1.129e+00, Batch size: 32, Momentum: 4.206e-01\n",
      "Initial loss:  329461.1408700115\n",
      "best loss: 450.45\t\tLearning rate: 7.848e-07, Batch size: 47, Momentum: 7.887e-01\n",
      "Initial loss:  702020.2063622577\n",
      "best loss: 438.40\t\tLearning rate: 7.848e-07, Batch size: 4, Momentum: 4.732e-01\n",
      "Initial loss:  603404.9137223518\n",
      "best loss: 732.92\t\tLearning rate: 1.833e-04, Batch size: 50, Momentum: 1.577e-01\n",
      "Initial loss:  460.4239374327148\n",
      "best loss: 449.40\t\tLearning rate: 6.158e-05, Batch size: 50, Momentum: 7.361e-01\n",
      "Initial loss:  460.60644545581886\n",
      "best loss: 446.21\t\tLearning rate: 7.848e-07, Batch size: 22, Momentum: 3.681e-01\n",
      "Initial loss:  275736.43218916\n",
      "best loss: 450.54\t\tLearning rate: 2.069e-05, Batch size: 32, Momentum: 4.206e-01\n",
      "Initial loss:  815509.9560961336\n",
      "best loss: 1023.71\t\tLearning rate: 4.833e-03, Batch size: 34, Momentum: 6.835e-01\n",
      "Initial loss:  456.5578804935211\n",
      "best loss: 446.16\t\tLearning rate: 2.637e-07, Batch size: 27, Momentum: 8.413e-01\n",
      "Initial loss:  54242.12850203813\n",
      "best loss: 1256.64\t\tLearning rate: 3.360e+00, Batch size: 7, Momentum: 2.629e-01\n",
      "Initial loss:  150019.14291319007\n",
      "best loss: 450.63\t\tLearning rate: 2.069e-05, Batch size: 29, Momentum: 1.052e-01\n",
      "Initial loss:  682705.4739413538\n",
      "best loss: 845.50\t\tLearning rate: 1.833e-04, Batch size: 37, Momentum: 6.835e-01\n",
      "Initial loss:  177889.7850710555\n",
      "best loss: 762.42\t\tLearning rate: 6.158e-05, Batch size: 27, Momentum: 2.103e-01\n",
      "Initial loss:  427297.5319010367\n",
      "best loss: 857.65\t\tLearning rate: 1.624e-03, Batch size: 12, Momentum: 1.577e-01\n",
      "Initial loss:  1182926.1633315922\n",
      "best loss: 60186.27\t\tLearning rate: 1.000e-08, Batch size: 44, Momentum: 8.413e-01\n",
      "Initial loss:  1138532.4933973136\n",
      "best loss: 1281.65\t\tLearning rate: 3.360e+00, Batch size: 29, Momentum: 3.681e-01\n",
      "Initial loss:  239331.5847009676\n",
      "best loss: 1094.42\t\tLearning rate: 4.281e-02, Batch size: 12, Momentum: 5.258e-01\n",
      "Initial loss:  451.11781259174427\n",
      "best loss: 448.65\t\tLearning rate: 8.859e-08, Batch size: 19, Momentum: 1.052e-01\n",
      "Initial loss:  210670.90078991005\n",
      "best loss: 941.03\t\tLearning rate: 4.833e-03, Batch size: 32, Momentum: 2.103e-01\n",
      "Initial loss:  132397.66745714322\n",
      "best loss: 1260.44\t\tLearning rate: 1.129e+00, Batch size: 17, Momentum: 7.361e-01\n",
      "Initial loss:  485.63582038560537\n",
      "best loss: 429.96\t\tLearning rate: 1.129e+00, Batch size: 2, Momentum: 4.732e-01\n",
      "Initial loss:  172366.97549916222\n",
      "best loss: 442.54\t\tLearning rate: 8.859e-08, Batch size: 12, Momentum: 9.464e-01\n",
      "Initial loss:  330155.1215282796\n",
      "best loss: 752.09\t\tLearning rate: 1.833e-04, Batch size: 24, Momentum: 1.577e-01\n",
      "Initial loss:  138999.97157151782\n",
      "best loss: 1236.26\t\tLearning rate: 3.360e+00, Batch size: 7, Momentum: 1.052e-01\n",
      "Initial loss:  268157.96955082595\n",
      "best loss: 1309.01\t\tLearning rate: 3.360e+00, Batch size: 12, Momentum: 6.835e-01\n",
      "Initial loss:  448.42845232324316\n",
      "best loss: 445.98\t\tLearning rate: 2.637e-07, Batch size: 24, Momentum: 9.464e-01\n",
      "Initial loss:  568085.7714332893\n",
      "best loss: 1067.63\t\tLearning rate: 4.281e-02, Batch size: 29, Momentum: 3.681e-01\n",
      "Initial loss:  463.39413015651706\n",
      "best loss: 441.86\t\tLearning rate: 1.624e-03, Batch size: 7, Momentum: 8.938e-01\n",
      "Initial loss:  140930.073364042\n",
      "best loss: 1205.85\t\tLearning rate: 1.129e+00, Batch size: 4, Momentum: 0.000e+00\n",
      "Initial loss:  684547.7641953032\n",
      "best loss: 988.77\t\tLearning rate: 1.438e-02, Batch size: 29, Momentum: 5.258e-01\n",
      "Initial loss:  145243.5780383006\n",
      "best loss: 31560.00\t\tLearning rate: 8.859e-08, Batch size: 42, Momentum: 7.361e-01\n",
      "Initial loss:  451.36909831355507\n",
      "best loss: 445.56\t\tLearning rate: 3.793e-01, Batch size: 24, Momentum: 0.000e+00\n",
      "Initial loss:  664539.0891174248\n",
      "best loss: 449.58\t\tLearning rate: 6.952e-06, Batch size: 22, Momentum: 1.052e-01\n",
      "Initial loss:  451.6897734995515\n",
      "best loss: 450.22\t\tLearning rate: 1.000e+01, Batch size: 39, Momentum: 3.155e-01\n",
      "Initial loss:  452.8302202769618\n",
      "best loss: 448.87\t\tLearning rate: 7.848e-07, Batch size: 39, Momentum: 2.103e-01\n",
      "Initial loss:  463.3190882366337\n",
      "best loss: 443.04\t\tLearning rate: 5.456e-04, Batch size: 9, Momentum: 4.732e-01\n",
      "Initial loss:  98473.51648712144\n",
      "best loss: 1146.78\t\tLearning rate: 3.793e-01, Batch size: 2, Momentum: 2.629e-01\n",
      "Initial loss:  114526.50784833316\n",
      "best loss: 1021.37\t\tLearning rate: 4.833e-03, Batch size: 12, Momentum: 9.990e-01\n",
      "Initial loss:  182334.82895780067\n",
      "best loss: 675.87\t\tLearning rate: 6.158e-05, Batch size: 27, Momentum: 5.258e-02\n",
      "Initial loss:  1024766.9207600534\n",
      "best loss: 885.10\t\tLearning rate: 5.456e-04, Batch size: 17, Momentum: 5.258e-01\n",
      "Initial loss:  465.03984508357746\n",
      "best loss: 451.60\t\tLearning rate: 8.859e-08, Batch size: 42, Momentum: 8.938e-01\n",
      "Initial loss:  308013.7355919072\n",
      "best loss: 2828.88\t\tLearning rate: 2.637e-07, Batch size: 27, Momentum: 5.258e-02\n",
      "Initial loss:  449.5893557688727\n",
      "best loss: 449.59\t\tLearning rate: 1.274e-01, Batch size: 37, Momentum: 0.000e+00\n",
      "Initial loss:  453.6311534845563\n",
      "best loss: 448.37\t\tLearning rate: 2.336e-06, Batch size: 44, Momentum: 0.000e+00\n",
      "Initial loss:  655294.2212442274\n",
      "best loss: 1351.17\t\tLearning rate: 1.000e-08, Batch size: 24, Momentum: 3.681e-01\n",
      "Initial loss:  310184.73232752766\n",
      "best loss: 1084.97\t\tLearning rate: 4.281e-02, Batch size: 12, Momentum: 9.464e-01\n",
      "Initial loss:  427728.7452409782\n",
      "best loss: 432.59\t\tLearning rate: 8.859e-08, Batch size: 2, Momentum: 8.413e-01\n",
      "Initial loss:  514057.556533607\n",
      "best loss: 1019.76\t\tLearning rate: 4.281e-02, Batch size: 29, Momentum: 3.681e-01\n",
      "Initial loss:  231900.82151507176\n",
      "best loss: 1299.92\t\tLearning rate: 1.129e+00, Batch size: 50, Momentum: 6.835e-01\n",
      "Initial loss:  458.6923888145084\n",
      "best loss: 449.00\t\tLearning rate: 6.158e-05, Batch size: 34, Momentum: 5.258e-02\n",
      "Initial loss:  442128.6720599771\n",
      "best loss: 71069.01\t\tLearning rate: 1.000e-08, Batch size: 50, Momentum: 8.413e-01\n",
      "Initial loss:  651357.9650782526\n",
      "best loss: 460.78\t\tLearning rate: 6.952e-06, Batch size: 29, Momentum: 9.990e-01\n",
      "Initial loss:  489356.4921220629\n",
      "best loss: 1105.07\t\tLearning rate: 8.859e-08, Batch size: 39, Momentum: 1.577e-01\n",
      "Initial loss:  458.70589462438403\n",
      "best loss: 449.93\t\tLearning rate: 4.833e-03, Batch size: 37, Momentum: 9.464e-01\n",
      "Initial loss:  452.9031445298498\n",
      "best loss: 443.52\t\tLearning rate: 3.793e-01, Batch size: 17, Momentum: 0.000e+00\n",
      "Initial loss:  147867.97768905206\n",
      "best loss: 452.79\t\tLearning rate: 2.336e-06, Batch size: 17, Momentum: 3.681e-01\n",
      "Initial loss:  450798.27321901516\n",
      "best loss: 1213.47\t\tLearning rate: 1.274e-01, Batch size: 19, Momentum: 9.464e-01\n",
      "Initial loss:  463.80508061363287\n",
      "best loss: 448.19\t\tLearning rate: 4.281e-02, Batch size: 17, Momentum: 9.990e-01\n",
      "Initial loss:  447.8048524090288\n",
      "best loss: 444.68\t\tLearning rate: 1.000e-08, Batch size: 14, Momentum: 4.206e-01\n",
      "Initial loss:  71240.66200393849\n",
      "best loss: 957.74\t\tLearning rate: 4.833e-03, Batch size: 12, Momentum: 3.155e-01\n",
      "Initial loss:  603446.9933593902\n",
      "best loss: 512.75\t\tLearning rate: 2.069e-05, Batch size: 29, Momentum: 3.155e-01\n",
      "Initial loss:  393348.0883835007\n",
      "best loss: 745.67\t\tLearning rate: 1.833e-04, Batch size: 47, Momentum: 1.577e-01\n",
      "Initial loss:  187397.20448056626\n",
      "best loss: 1197.10\t\tLearning rate: 3.793e-01, Batch size: 22, Momentum: 6.309e-01\n",
      "Initial loss:  550915.1512825225\n",
      "best loss: 1000.99\t\tLearning rate: 4.833e-03, Batch size: 14, Momentum: 4.732e-01\n",
      "Initial loss:  565925.225069805\n",
      "best loss: 39160.87\t\tLearning rate: 3.793e-01, Batch size: 34, Momentum: 0.000e+00\n",
      "Initial loss:  518.7735905179773\n",
      "best loss: 1297.20\t\tLearning rate: 3.360e+00, Batch size: 39, Momentum: 4.732e-01\n",
      "Initial loss:  313812.47882842005\n",
      "best loss: 444.39\t\tLearning rate: 2.637e-07, Batch size: 17, Momentum: 9.464e-01\n",
      "Initial loss:  401605.90062370093\n",
      "best loss: 1040.70\t\tLearning rate: 1.438e-02, Batch size: 24, Momentum: 8.413e-01\n",
      "Initial loss:  456.1778076687184\n",
      "best loss: 445.41\t\tLearning rate: 1.129e+00, Batch size: 22, Momentum: 9.990e-01\n",
      "Initial loss:  226970.45731978674\n",
      "best loss: 812.88\t\tLearning rate: 1.833e-04, Batch size: 37, Momentum: 6.835e-01\n",
      "Initial loss:  94131.3359732522\n",
      "best loss: 925.32\t\tLearning rate: 1.624e-03, Batch size: 4, Momentum: 4.206e-01\n",
      "Initial loss:  333761.24517601315\n",
      "best loss: 1226.12\t\tLearning rate: 3.793e-01, Batch size: 47, Momentum: 6.309e-01\n",
      "Initial loss:  196237.64530725125\n",
      "best loss: 578.26\t\tLearning rate: 2.976e-08, Batch size: 29, Momentum: 7.361e-01\n",
      "Initial loss:  449.0428648170574\n",
      "best loss: 441.48\t\tLearning rate: 5.456e-04, Batch size: 14, Momentum: 4.206e-01\n",
      "Initial loss:  461.0813935803795\n",
      "best loss: 445.30\t\tLearning rate: 1.000e-08, Batch size: 19, Momentum: 6.835e-01\n",
      "Initial loss:  488405.6606601282\n",
      "best loss: 733.32\t\tLearning rate: 2.069e-05, Batch size: 4, Momentum: 7.887e-01\n",
      "Initial loss:  438650.9334839589\n",
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/hpinkard_waller/mambaforge/envs/phenotypes/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3378, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_9866/3563418900.py\", line 18, in <module>\n",
      "    best_cov_mat, cov_mat_initial, mean_vec, best_loss = run_optimization(patches, momentum, learning_rate, batch_size, eigenvalue_floor=1e-3)\n",
      "  File \"/home/hpinkard_waller/GitRepos/EncodingInformation/gaussian_process_utils.py\", line 488, in run_optimization\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hpinkard_waller/mambaforge/envs/phenotypes/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 1997, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/home/hpinkard_waller/mambaforge/envs/phenotypes/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1112, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/home/hpinkard_waller/mambaforge/envs/phenotypes/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1006, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/home/hpinkard_waller/mambaforge/envs/phenotypes/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 859, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/home/hpinkard_waller/mambaforge/envs/phenotypes/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 812, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(r))\n",
      "  File \"/home/hpinkard_waller/mambaforge/envs/phenotypes/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 730, in format_record\n",
      "    result += ''.join(_format_traceback_lines(frame_info.lines, Colors, self.has_colors, lvals))\n",
      "  File \"/home/hpinkard_waller/mambaforge/envs/phenotypes/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/hpinkard_waller/mambaforge/envs/phenotypes/lib/python3.10/site-packages/stack_data/core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/home/hpinkard_waller/mambaforge/envs/phenotypes/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/hpinkard_waller/mambaforge/envs/phenotypes/lib/python3.10/site-packages/stack_data/core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/home/hpinkard_waller/mambaforge/envs/phenotypes/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/hpinkard_waller/mambaforge/envs/phenotypes/lib/python3.10/site-packages/stack_data/core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "  File \"/home/hpinkard_waller/mambaforge/envs/phenotypes/lib/python3.10/site-packages/executing/executing.py\", line 168, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "learning_rates = np.logspace(1, -8, 20)\n",
    "batch_sizes = np.linspace(2, 50, 20).astype(int)\n",
    "momentums = np.linspace(0, 0.999, 20)\n",
    "\n",
    "# generate tuples of random hyperparameters\n",
    "hyperparameter_tuples = []\n",
    "for i in range(10000):\n",
    "    lr = onp.random.choice(learning_rates)\n",
    "    bs = onp.random.choice(batch_sizes)\n",
    "    m = onp.random.choice(momentums)\n",
    "    hyperparameter_tuples.append((lr, bs, m))\n",
    "\n",
    "results = {}\n",
    "for i, (learning_rate, batch_size, momentum) in enumerate(hyperparameter_tuples):\n",
    "    best_hp_loss = np.inf\n",
    "\n",
    "    patches = extract_patches(images, patch_size, num_patches=num_patches, seed=i)\n",
    "    best_cov_mat, cov_mat_initial, mean_vec, best_loss = run_optimization(patches, momentum, learning_rate, batch_size, eigenvalue_floor=1e-3)\n",
    "\n",
    "    if best_loss < best_hp_loss:\n",
    "        best_hp_loss = best_loss\n",
    "        best_hp = (learning_rate, batch_size, momentum)\n",
    "        \n",
    "    # collect results\n",
    "    results[(learning_rate, batch_size, momentum)] = best_loss\n",
    "\n",
    "    # print hyperparameters and their best loss\n",
    "    print(f\"best loss: {best_loss:.2f}\\t\\tLearning rate: {learning_rate:.3e}, Batch size: {batch_size}, Momentum: {momentum:.3e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best loss: 422.89\t\tLearning rate: 2.976e-08, Batch size: 2, Momentum: 9.990e-01\n",
      "best loss: 425.53\t\tLearning rate: 4.281e-02, Batch size: 2, Momentum: 1.052e-01\n",
      "best loss: 427.50\t\tLearning rate: 1.000e-08, Batch size: 2, Momentum: 8.413e-01\n",
      "best loss: 428.09\t\tLearning rate: 6.952e-06, Batch size: 2, Momentum: 3.681e-01\n",
      "best loss: 429.96\t\tLearning rate: 1.129e+00, Batch size: 2, Momentum: 4.732e-01\n",
      "best loss: 430.36\t\tLearning rate: 2.069e-05, Batch size: 2, Momentum: 7.887e-01\n",
      "best loss: 430.54\t\tLearning rate: 2.637e-07, Batch size: 2, Momentum: 8.938e-01\n",
      "best loss: 430.77\t\tLearning rate: 6.952e-06, Batch size: 2, Momentum: 0.000e+00\n",
      "best loss: 431.62\t\tLearning rate: 2.637e-07, Batch size: 2, Momentum: 1.577e-01\n",
      "best loss: 431.76\t\tLearning rate: 7.848e-07, Batch size: 2, Momentum: 7.361e-01\n",
      "best loss: 432.17\t\tLearning rate: 4.833e-03, Batch size: 4, Momentum: 0.000e+00\n",
      "best loss: 432.28\t\tLearning rate: 1.438e-02, Batch size: 4, Momentum: 4.206e-01\n",
      "best loss: 432.48\t\tLearning rate: 2.069e-05, Batch size: 4, Momentum: 2.629e-01\n",
      "best loss: 432.59\t\tLearning rate: 8.859e-08, Batch size: 2, Momentum: 8.413e-01\n",
      "best loss: 433.00\t\tLearning rate: 6.952e-06, Batch size: 2, Momentum: 4.732e-01\n",
      "best loss: 433.21\t\tLearning rate: 2.637e-07, Batch size: 2, Momentum: 8.413e-01\n",
      "best loss: 433.60\t\tLearning rate: 1.000e-08, Batch size: 4, Momentum: 9.990e-01\n",
      "best loss: 433.89\t\tLearning rate: 2.336e-06, Batch size: 2, Momentum: 7.361e-01\n",
      "best loss: 434.28\t\tLearning rate: 1.129e+00, Batch size: 2, Momentum: 9.464e-01\n",
      "best loss: 434.39\t\tLearning rate: 1.624e-03, Batch size: 2, Momentum: 1.052e-01\n",
      "best loss: 434.46\t\tLearning rate: 1.000e-08, Batch size: 7, Momentum: 9.990e-01\n",
      "best loss: 434.57\t\tLearning rate: 8.859e-08, Batch size: 2, Momentum: 4.732e-01\n",
      "best loss: 434.68\t\tLearning rate: 5.456e-04, Batch size: 2, Momentum: 1.052e-01\n",
      "best loss: 434.91\t\tLearning rate: 1.000e+01, Batch size: 4, Momentum: 4.206e-01\n",
      "best loss: 435.13\t\tLearning rate: 4.833e-03, Batch size: 4, Momentum: 2.103e-01\n",
      "best loss: 435.24\t\tLearning rate: 6.952e-06, Batch size: 2, Momentum: 4.206e-01\n",
      "best loss: 435.26\t\tLearning rate: 2.336e-06, Batch size: 2, Momentum: 3.155e-01\n",
      "best loss: 435.59\t\tLearning rate: 1.000e-08, Batch size: 2, Momentum: 9.464e-01\n",
      "best loss: 435.66\t\tLearning rate: 2.976e-08, Batch size: 4, Momentum: 7.887e-01\n",
      "best loss: 437.03\t\tLearning rate: 4.833e-03, Batch size: 7, Momentum: 9.990e-01\n",
      "best loss: 437.41\t\tLearning rate: 2.336e-06, Batch size: 7, Momentum: 7.887e-01\n",
      "best loss: 437.46\t\tLearning rate: 1.129e+00, Batch size: 4, Momentum: 8.413e-01\n",
      "best loss: 437.61\t\tLearning rate: 8.859e-08, Batch size: 7, Momentum: 8.413e-01\n",
      "best loss: 437.68\t\tLearning rate: 2.069e-05, Batch size: 4, Momentum: 4.732e-01\n",
      "best loss: 437.87\t\tLearning rate: 2.069e-05, Batch size: 4, Momentum: 1.052e-01\n",
      "best loss: 438.40\t\tLearning rate: 7.848e-07, Batch size: 4, Momentum: 4.732e-01\n",
      "best loss: 438.60\t\tLearning rate: 1.833e-04, Batch size: 7, Momentum: 3.681e-01\n",
      "best loss: 438.98\t\tLearning rate: 2.336e-06, Batch size: 4, Momentum: 3.155e-01\n",
      "best loss: 439.40\t\tLearning rate: 3.360e+00, Batch size: 9, Momentum: 9.464e-01\n",
      "best loss: 439.43\t\tLearning rate: 1.833e-04, Batch size: 9, Momentum: 3.681e-01\n",
      "best loss: 439.75\t\tLearning rate: 2.976e-08, Batch size: 7, Momentum: 3.155e-01\n",
      "best loss: 439.80\t\tLearning rate: 5.456e-04, Batch size: 9, Momentum: 6.309e-01\n",
      "best loss: 439.88\t\tLearning rate: 1.833e-04, Batch size: 4, Momentum: 8.413e-01\n",
      "best loss: 439.92\t\tLearning rate: 7.848e-07, Batch size: 9, Momentum: 7.887e-01\n",
      "best loss: 440.22\t\tLearning rate: 7.848e-07, Batch size: 9, Momentum: 4.732e-01\n",
      "best loss: 440.57\t\tLearning rate: 4.281e-02, Batch size: 9, Momentum: 3.155e-01\n",
      "best loss: 440.60\t\tLearning rate: 1.624e-03, Batch size: 12, Momentum: 3.681e-01\n",
      "best loss: 440.61\t\tLearning rate: 2.336e-06, Batch size: 7, Momentum: 3.681e-01\n",
      "best loss: 440.66\t\tLearning rate: 2.637e-07, Batch size: 9, Momentum: 7.361e-01\n",
      "best loss: 440.71\t\tLearning rate: 2.637e-07, Batch size: 9, Momentum: 5.784e-01\n",
      "best loss: 440.74\t\tLearning rate: 1.833e-04, Batch size: 9, Momentum: 2.629e-01\n",
      "best loss: 440.80\t\tLearning rate: 1.833e-04, Batch size: 9, Momentum: 8.938e-01\n",
      "best loss: 440.87\t\tLearning rate: 2.976e-08, Batch size: 9, Momentum: 2.629e-01\n",
      "best loss: 440.91\t\tLearning rate: 2.637e-07, Batch size: 12, Momentum: 3.681e-01\n",
      "best loss: 441.47\t\tLearning rate: 8.859e-08, Batch size: 4, Momentum: 3.681e-01\n",
      "best loss: 441.48\t\tLearning rate: 5.456e-04, Batch size: 14, Momentum: 4.206e-01\n",
      "best loss: 441.51\t\tLearning rate: 1.000e+01, Batch size: 14, Momentum: 5.784e-01\n",
      "best loss: 441.53\t\tLearning rate: 3.360e+00, Batch size: 9, Momentum: 5.784e-01\n",
      "best loss: 441.63\t\tLearning rate: 2.336e-06, Batch size: 7, Momentum: 6.309e-01\n",
      "best loss: 441.74\t\tLearning rate: 2.637e-07, Batch size: 9, Momentum: 8.938e-01\n",
      "best loss: 441.75\t\tLearning rate: 2.336e-06, Batch size: 9, Momentum: 7.361e-01\n",
      "best loss: 441.86\t\tLearning rate: 1.624e-03, Batch size: 7, Momentum: 8.938e-01\n",
      "best loss: 441.98\t\tLearning rate: 3.360e+00, Batch size: 9, Momentum: 9.990e-01\n",
      "best loss: 442.42\t\tLearning rate: 7.848e-07, Batch size: 9, Momentum: 2.629e-01\n",
      "best loss: 442.46\t\tLearning rate: 8.859e-08, Batch size: 9, Momentum: 9.464e-01\n",
      "best loss: 442.54\t\tLearning rate: 8.859e-08, Batch size: 12, Momentum: 9.464e-01\n",
      "best loss: 442.57\t\tLearning rate: 8.859e-08, Batch size: 9, Momentum: 8.413e-01\n",
      "best loss: 442.68\t\tLearning rate: 8.859e-08, Batch size: 7, Momentum: 6.309e-01\n",
      "best loss: 442.93\t\tLearning rate: 1.129e+00, Batch size: 14, Momentum: 8.413e-01\n",
      "best loss: 443.04\t\tLearning rate: 5.456e-04, Batch size: 9, Momentum: 4.732e-01\n",
      "best loss: 443.04\t\tLearning rate: 1.833e-04, Batch size: 12, Momentum: 8.413e-01\n",
      "best loss: 443.14\t\tLearning rate: 1.438e-02, Batch size: 19, Momentum: 3.155e-01\n",
      "best loss: 443.27\t\tLearning rate: 2.336e-06, Batch size: 12, Momentum: 1.052e-01\n",
      "best loss: 443.39\t\tLearning rate: 6.952e-06, Batch size: 7, Momentum: 5.784e-01\n",
      "best loss: 443.44\t\tLearning rate: 4.281e-02, Batch size: 12, Momentum: 8.413e-01\n",
      "best loss: 443.51\t\tLearning rate: 6.952e-06, Batch size: 7, Momentum: 4.206e-01\n",
      "best loss: 443.52\t\tLearning rate: 3.793e-01, Batch size: 17, Momentum: 0.000e+00\n",
      "best loss: 443.67\t\tLearning rate: 2.976e-08, Batch size: 4, Momentum: 8.413e-01\n",
      "best loss: 443.71\t\tLearning rate: 5.456e-04, Batch size: 14, Momentum: 3.681e-01\n",
      "best loss: 443.98\t\tLearning rate: 1.274e-01, Batch size: 14, Momentum: 8.938e-01\n",
      "best loss: 444.18\t\tLearning rate: 1.274e-01, Batch size: 14, Momentum: 3.681e-01\n",
      "best loss: 444.25\t\tLearning rate: 1.000e-08, Batch size: 27, Momentum: 9.990e-01\n",
      "best loss: 444.26\t\tLearning rate: 2.976e-08, Batch size: 9, Momentum: 9.464e-01\n",
      "best loss: 444.34\t\tLearning rate: 1.833e-04, Batch size: 22, Momentum: 5.258e-01\n",
      "best loss: 444.35\t\tLearning rate: 2.336e-06, Batch size: 14, Momentum: 2.629e-01\n",
      "best loss: 444.39\t\tLearning rate: 2.637e-07, Batch size: 17, Momentum: 9.464e-01\n",
      "best loss: 444.51\t\tLearning rate: 1.129e+00, Batch size: 19, Momentum: 9.990e-01\n",
      "best loss: 444.56\t\tLearning rate: 1.000e+01, Batch size: 22, Momentum: 9.990e-01\n",
      "best loss: 444.58\t\tLearning rate: 7.848e-07, Batch size: 7, Momentum: 9.464e-01\n",
      "best loss: 444.60\t\tLearning rate: 1.000e+01, Batch size: 27, Momentum: 9.464e-01\n",
      "best loss: 444.61\t\tLearning rate: 2.637e-07, Batch size: 2, Momentum: 0.000e+00\n",
      "best loss: 444.68\t\tLearning rate: 1.000e-08, Batch size: 14, Momentum: 4.206e-01\n",
      "best loss: 444.73\t\tLearning rate: 2.069e-05, Batch size: 9, Momentum: 2.103e-01\n",
      "best loss: 444.77\t\tLearning rate: 7.848e-07, Batch size: 19, Momentum: 9.464e-01\n",
      "best loss: 444.91\t\tLearning rate: 4.833e-03, Batch size: 9, Momentum: 6.835e-01\n",
      "best loss: 444.93\t\tLearning rate: 2.637e-07, Batch size: 17, Momentum: 7.361e-01\n",
      "best loss: 445.03\t\tLearning rate: 1.129e+00, Batch size: 7, Momentum: 1.577e-01\n",
      "best loss: 445.04\t\tLearning rate: 4.833e-03, Batch size: 27, Momentum: 5.784e-01\n",
      "best loss: 445.14\t\tLearning rate: 2.336e-06, Batch size: 12, Momentum: 8.938e-01\n",
      "best loss: 445.14\t\tLearning rate: 2.976e-08, Batch size: 14, Momentum: 7.887e-01\n",
      "best loss: 445.28\t\tLearning rate: 3.360e+00, Batch size: 19, Momentum: 9.464e-01\n",
      "best loss: 445.28\t\tLearning rate: 6.952e-06, Batch size: 42, Momentum: 2.103e-01\n",
      "best loss: 445.30\t\tLearning rate: 1.000e-08, Batch size: 19, Momentum: 6.835e-01\n",
      "best loss: 445.40\t\tLearning rate: 2.637e-07, Batch size: 27, Momentum: 7.887e-01\n",
      "best loss: 445.41\t\tLearning rate: 1.129e+00, Batch size: 22, Momentum: 9.990e-01\n",
      "best loss: 445.47\t\tLearning rate: 1.000e-08, Batch size: 22, Momentum: 9.464e-01\n",
      "best loss: 445.56\t\tLearning rate: 3.793e-01, Batch size: 24, Momentum: 0.000e+00\n",
      "best loss: 445.61\t\tLearning rate: 8.859e-08, Batch size: 29, Momentum: 7.361e-01\n",
      "best loss: 445.62\t\tLearning rate: 6.158e-05, Batch size: 19, Momentum: 8.938e-01\n",
      "best loss: 445.63\t\tLearning rate: 7.848e-07, Batch size: 14, Momentum: 9.464e-01\n",
      "best loss: 445.68\t\tLearning rate: 1.833e-04, Batch size: 22, Momentum: 9.990e-01\n",
      "best loss: 445.70\t\tLearning rate: 1.129e+00, Batch size: 17, Momentum: 1.052e-01\n",
      "best loss: 445.76\t\tLearning rate: 1.000e+01, Batch size: 27, Momentum: 3.681e-01\n",
      "best loss: 445.87\t\tLearning rate: 2.976e-08, Batch size: 14, Momentum: 3.155e-01\n",
      "best loss: 445.87\t\tLearning rate: 7.848e-07, Batch size: 37, Momentum: 8.938e-01\n",
      "best loss: 445.87\t\tLearning rate: 1.833e-04, Batch size: 27, Momentum: 0.000e+00\n",
      "best loss: 445.89\t\tLearning rate: 1.624e-03, Batch size: 17, Momentum: 3.155e-01\n",
      "best loss: 445.90\t\tLearning rate: 1.624e-03, Batch size: 17, Momentum: 1.052e-01\n",
      "best loss: 445.98\t\tLearning rate: 2.637e-07, Batch size: 24, Momentum: 9.464e-01\n",
      "best loss: 446.03\t\tLearning rate: 1.129e+00, Batch size: 27, Momentum: 8.938e-01\n",
      "best loss: 446.06\t\tLearning rate: 1.833e-04, Batch size: 14, Momentum: 7.361e-01\n",
      "best loss: 446.07\t\tLearning rate: 2.637e-07, Batch size: 12, Momentum: 7.887e-01\n",
      "best loss: 446.14\t\tLearning rate: 3.360e+00, Batch size: 14, Momentum: 6.309e-01\n",
      "best loss: 446.16\t\tLearning rate: 2.637e-07, Batch size: 27, Momentum: 8.413e-01\n",
      "best loss: 446.17\t\tLearning rate: 4.281e-02, Batch size: 14, Momentum: 2.629e-01\n",
      "best loss: 446.19\t\tLearning rate: 2.336e-06, Batch size: 24, Momentum: 7.361e-01\n",
      "best loss: 446.19\t\tLearning rate: 8.859e-08, Batch size: 22, Momentum: 8.938e-01\n",
      "best loss: 446.20\t\tLearning rate: 2.637e-07, Batch size: 14, Momentum: 9.990e-01\n",
      "best loss: 446.21\t\tLearning rate: 7.848e-07, Batch size: 22, Momentum: 3.681e-01\n",
      "best loss: 446.27\t\tLearning rate: 2.976e-08, Batch size: 4, Momentum: 5.784e-01\n",
      "best loss: 446.27\t\tLearning rate: 7.848e-07, Batch size: 27, Momentum: 2.103e-01\n",
      "best loss: 446.27\t\tLearning rate: 6.952e-06, Batch size: 12, Momentum: 3.681e-01\n",
      "best loss: 446.30\t\tLearning rate: 2.336e-06, Batch size: 12, Momentum: 3.155e-01\n",
      "best loss: 446.34\t\tLearning rate: 7.848e-07, Batch size: 19, Momentum: 3.155e-01\n",
      "best loss: 446.43\t\tLearning rate: 8.859e-08, Batch size: 19, Momentum: 7.361e-01\n",
      "best loss: 446.49\t\tLearning rate: 1.000e-08, Batch size: 19, Momentum: 1.577e-01\n",
      "best loss: 446.50\t\tLearning rate: 6.952e-06, Batch size: 29, Momentum: 1.577e-01\n",
      "best loss: 446.55\t\tLearning rate: 2.336e-06, Batch size: 34, Momentum: 9.990e-01\n",
      "best loss: 446.63\t\tLearning rate: 3.793e-01, Batch size: 27, Momentum: 9.464e-01\n",
      "best loss: 446.64\t\tLearning rate: 6.952e-06, Batch size: 44, Momentum: 3.155e-01\n",
      "best loss: 446.68\t\tLearning rate: 2.069e-05, Batch size: 17, Momentum: 5.258e-02\n",
      "best loss: 446.76\t\tLearning rate: 1.438e-02, Batch size: 17, Momentum: 9.464e-01\n",
      "best loss: 446.80\t\tLearning rate: 2.336e-06, Batch size: 47, Momentum: 8.938e-01\n",
      "best loss: 446.82\t\tLearning rate: 1.438e-02, Batch size: 32, Momentum: 4.206e-01\n",
      "best loss: 446.82\t\tLearning rate: 2.069e-05, Batch size: 37, Momentum: 0.000e+00\n",
      "best loss: 446.83\t\tLearning rate: 2.637e-07, Batch size: 9, Momentum: 6.835e-01\n",
      "best loss: 446.86\t\tLearning rate: 3.360e+00, Batch size: 42, Momentum: 9.990e-01\n",
      "best loss: 446.91\t\tLearning rate: 4.833e-03, Batch size: 37, Momentum: 1.577e-01\n",
      "best loss: 446.91\t\tLearning rate: 2.069e-05, Batch size: 14, Momentum: 6.309e-01\n",
      "best loss: 446.95\t\tLearning rate: 2.637e-07, Batch size: 4, Momentum: 3.155e-01\n",
      "best loss: 447.04\t\tLearning rate: 2.336e-06, Batch size: 39, Momentum: 7.887e-01\n",
      "best loss: 447.05\t\tLearning rate: 6.158e-05, Batch size: 47, Momentum: 8.413e-01\n",
      "best loss: 447.10\t\tLearning rate: 7.848e-07, Batch size: 9, Momentum: 5.258e-02\n",
      "best loss: 447.13\t\tLearning rate: 6.158e-05, Batch size: 44, Momentum: 4.732e-01\n",
      "best loss: 447.14\t\tLearning rate: 2.336e-06, Batch size: 19, Momentum: 1.052e-01\n",
      "best loss: 447.18\t\tLearning rate: 1.624e-03, Batch size: 24, Momentum: 3.681e-01\n",
      "best loss: 447.24\t\tLearning rate: 6.952e-06, Batch size: 34, Momentum: 2.103e-01\n",
      "best loss: 447.25\t\tLearning rate: 7.848e-07, Batch size: 22, Momentum: 8.413e-01\n",
      "best loss: 447.28\t\tLearning rate: 1.274e-01, Batch size: 39, Momentum: 7.887e-01\n",
      "best loss: 447.28\t\tLearning rate: 2.976e-08, Batch size: 34, Momentum: 3.155e-01\n",
      "best loss: 447.30\t\tLearning rate: 1.438e-02, Batch size: 39, Momentum: 1.577e-01\n",
      "best loss: 447.47\t\tLearning rate: 1.624e-03, Batch size: 47, Momentum: 8.413e-01\n",
      "best loss: 447.50\t\tLearning rate: 2.637e-07, Batch size: 19, Momentum: 7.887e-01\n",
      "best loss: 447.51\t\tLearning rate: 6.952e-06, Batch size: 32, Momentum: 1.577e-01\n",
      "best loss: 447.53\t\tLearning rate: 1.000e+01, Batch size: 37, Momentum: 8.413e-01\n",
      "best loss: 447.57\t\tLearning rate: 1.624e-03, Batch size: 12, Momentum: 6.309e-01\n",
      "best loss: 447.70\t\tLearning rate: 8.859e-08, Batch size: 14, Momentum: 7.887e-01\n",
      "best loss: 447.70\t\tLearning rate: 3.793e-01, Batch size: 39, Momentum: 9.990e-01\n",
      "best loss: 447.74\t\tLearning rate: 7.848e-07, Batch size: 27, Momentum: 7.361e-01\n",
      "best loss: 447.75\t\tLearning rate: 1.129e+00, Batch size: 37, Momentum: 1.577e-01\n",
      "best loss: 447.78\t\tLearning rate: 6.158e-05, Batch size: 34, Momentum: 9.464e-01\n",
      "best loss: 447.83\t\tLearning rate: 2.637e-07, Batch size: 39, Momentum: 8.413e-01\n",
      "best loss: 447.87\t\tLearning rate: 1.833e-04, Batch size: 42, Momentum: 5.258e-01\n",
      "best loss: 447.90\t\tLearning rate: 2.336e-06, Batch size: 17, Momentum: 3.155e-01\n",
      "best loss: 447.91\t\tLearning rate: 2.069e-05, Batch size: 7, Momentum: 5.784e-01\n",
      "best loss: 447.93\t\tLearning rate: 6.158e-05, Batch size: 27, Momentum: 8.938e-01\n",
      "best loss: 447.93\t\tLearning rate: 2.976e-08, Batch size: 27, Momentum: 9.464e-01\n",
      "best loss: 447.94\t\tLearning rate: 6.952e-06, Batch size: 29, Momentum: 5.258e-01\n",
      "best loss: 447.98\t\tLearning rate: 5.456e-04, Batch size: 44, Momentum: 5.258e-01\n",
      "best loss: 448.02\t\tLearning rate: 7.848e-07, Batch size: 34, Momentum: 7.887e-01\n",
      "best loss: 448.03\t\tLearning rate: 1.438e-02, Batch size: 34, Momentum: 2.629e-01\n",
      "best loss: 448.04\t\tLearning rate: 2.976e-08, Batch size: 47, Momentum: 8.413e-01\n",
      "best loss: 448.06\t\tLearning rate: 6.158e-05, Batch size: 37, Momentum: 2.103e-01\n",
      "best loss: 448.14\t\tLearning rate: 2.336e-06, Batch size: 9, Momentum: 1.052e-01\n",
      "best loss: 448.18\t\tLearning rate: 6.952e-06, Batch size: 29, Momentum: 0.000e+00\n",
      "best loss: 448.19\t\tLearning rate: 3.360e+00, Batch size: 34, Momentum: 7.887e-01\n",
      "best loss: 448.19\t\tLearning rate: 4.281e-02, Batch size: 17, Momentum: 9.990e-01\n",
      "best loss: 448.20\t\tLearning rate: 1.833e-04, Batch size: 34, Momentum: 7.361e-01\n",
      "best loss: 448.24\t\tLearning rate: 1.000e-08, Batch size: 27, Momentum: 4.732e-01\n",
      "best loss: 448.25\t\tLearning rate: 7.848e-07, Batch size: 34, Momentum: 8.938e-01\n",
      "best loss: 448.27\t\tLearning rate: 4.281e-02, Batch size: 24, Momentum: 9.990e-01\n",
      "best loss: 448.32\t\tLearning rate: 1.274e-01, Batch size: 22, Momentum: 8.938e-01\n",
      "best loss: 448.32\t\tLearning rate: 3.360e+00, Batch size: 37, Momentum: 3.155e-01\n",
      "best loss: 448.37\t\tLearning rate: 1.624e-03, Batch size: 37, Momentum: 8.938e-01\n",
      "best loss: 448.37\t\tLearning rate: 1.438e-02, Batch size: 27, Momentum: 4.206e-01\n",
      "best loss: 448.37\t\tLearning rate: 2.336e-06, Batch size: 44, Momentum: 0.000e+00\n",
      "best loss: 448.43\t\tLearning rate: 7.848e-07, Batch size: 22, Momentum: 7.887e-01\n",
      "best loss: 448.44\t\tLearning rate: 1.000e+01, Batch size: 29, Momentum: 1.577e-01\n",
      "best loss: 448.47\t\tLearning rate: 8.859e-08, Batch size: 39, Momentum: 5.784e-01\n",
      "best loss: 448.51\t\tLearning rate: 1.000e-08, Batch size: 4, Momentum: 8.938e-01\n",
      "best loss: 448.52\t\tLearning rate: 1.000e-08, Batch size: 37, Momentum: 7.887e-01\n",
      "best loss: 448.59\t\tLearning rate: 2.976e-08, Batch size: 50, Momentum: 1.577e-01\n",
      "best loss: 448.59\t\tLearning rate: 1.438e-02, Batch size: 29, Momentum: 4.732e-01\n",
      "best loss: 448.62\t\tLearning rate: 1.624e-03, Batch size: 17, Momentum: 3.681e-01\n",
      "best loss: 448.63\t\tLearning rate: 6.952e-06, Batch size: 39, Momentum: 6.835e-01\n",
      "best loss: 448.64\t\tLearning rate: 1.438e-02, Batch size: 39, Momentum: 6.309e-01\n",
      "best loss: 448.65\t\tLearning rate: 8.859e-08, Batch size: 19, Momentum: 1.052e-01\n",
      "best loss: 448.70\t\tLearning rate: 7.848e-07, Batch size: 34, Momentum: 2.629e-01\n",
      "best loss: 448.74\t\tLearning rate: 1.624e-03, Batch size: 39, Momentum: 4.206e-01\n",
      "best loss: 448.74\t\tLearning rate: 4.281e-02, Batch size: 42, Momentum: 4.206e-01\n",
      "best loss: 448.81\t\tLearning rate: 2.637e-07, Batch size: 39, Momentum: 7.887e-01\n",
      "best loss: 448.82\t\tLearning rate: 8.859e-08, Batch size: 34, Momentum: 9.990e-01\n",
      "best loss: 448.83\t\tLearning rate: 3.793e-01, Batch size: 42, Momentum: 9.990e-01\n",
      "best loss: 448.83\t\tLearning rate: 4.833e-03, Batch size: 39, Momentum: 3.681e-01\n",
      "best loss: 448.87\t\tLearning rate: 7.848e-07, Batch size: 39, Momentum: 2.103e-01\n",
      "best loss: 448.91\t\tLearning rate: 3.360e+00, Batch size: 29, Momentum: 0.000e+00\n",
      "best loss: 448.95\t\tLearning rate: 6.952e-06, Batch size: 9, Momentum: 6.835e-01\n",
      "best loss: 448.96\t\tLearning rate: 7.848e-07, Batch size: 17, Momentum: 9.464e-01\n",
      "best loss: 449.00\t\tLearning rate: 6.158e-05, Batch size: 34, Momentum: 5.258e-02\n",
      "best loss: 449.01\t\tLearning rate: 4.833e-03, Batch size: 17, Momentum: 7.887e-01\n",
      "best loss: 449.23\t\tLearning rate: 4.281e-02, Batch size: 42, Momentum: 4.732e-01\n",
      "best loss: 449.25\t\tLearning rate: 4.281e-02, Batch size: 34, Momentum: 0.000e+00\n",
      "best loss: 449.26\t\tLearning rate: 2.637e-07, Batch size: 27, Momentum: 5.784e-01\n",
      "best loss: 449.29\t\tLearning rate: 4.833e-03, Batch size: 47, Momentum: 3.681e-01\n",
      "best loss: 449.32\t\tLearning rate: 1.000e+01, Batch size: 44, Momentum: 7.887e-01\n",
      "best loss: 449.32\t\tLearning rate: 7.848e-07, Batch size: 50, Momentum: 4.206e-01\n",
      "best loss: 449.33\t\tLearning rate: 7.848e-07, Batch size: 12, Momentum: 5.784e-01\n",
      "best loss: 449.35\t\tLearning rate: 8.859e-08, Batch size: 47, Momentum: 9.464e-01\n",
      "best loss: 449.38\t\tLearning rate: 6.952e-06, Batch size: 24, Momentum: 8.938e-01\n",
      "best loss: 449.38\t\tLearning rate: 6.952e-06, Batch size: 4, Momentum: 9.990e-01\n",
      "best loss: 449.40\t\tLearning rate: 6.158e-05, Batch size: 50, Momentum: 7.361e-01\n",
      "best loss: 449.45\t\tLearning rate: 2.336e-06, Batch size: 29, Momentum: 6.835e-01\n",
      "best loss: 449.46\t\tLearning rate: 2.336e-06, Batch size: 24, Momentum: 8.413e-01\n",
      "best loss: 449.47\t\tLearning rate: 1.000e+01, Batch size: 42, Momentum: 9.990e-01\n",
      "best loss: 449.50\t\tLearning rate: 2.069e-05, Batch size: 50, Momentum: 2.629e-01\n",
      "best loss: 449.52\t\tLearning rate: 2.976e-08, Batch size: 44, Momentum: 3.155e-01\n",
      "best loss: 449.53\t\tLearning rate: 2.336e-06, Batch size: 50, Momentum: 4.732e-01\n",
      "best loss: 449.56\t\tLearning rate: 1.000e-08, Batch size: 47, Momentum: 7.361e-01\n",
      "best loss: 449.58\t\tLearning rate: 6.952e-06, Batch size: 22, Momentum: 1.052e-01\n",
      "best loss: 449.58\t\tLearning rate: 2.976e-08, Batch size: 27, Momentum: 2.629e-01\n",
      "best loss: 449.59\t\tLearning rate: 2.336e-06, Batch size: 50, Momentum: 5.258e-01\n",
      "best loss: 449.59\t\tLearning rate: 1.274e-01, Batch size: 37, Momentum: 0.000e+00\n",
      "best loss: 449.62\t\tLearning rate: 2.336e-06, Batch size: 34, Momentum: 1.577e-01\n",
      "best loss: 449.68\t\tLearning rate: 7.848e-07, Batch size: 50, Momentum: 9.990e-01\n",
      "best loss: 449.68\t\tLearning rate: 6.952e-06, Batch size: 50, Momentum: 5.784e-01\n",
      "best loss: 449.82\t\tLearning rate: 7.848e-07, Batch size: 37, Momentum: 8.413e-01\n",
      "best loss: 449.89\t\tLearning rate: 2.336e-06, Batch size: 29, Momentum: 1.052e-01\n",
      "best loss: 449.92\t\tLearning rate: 2.336e-06, Batch size: 17, Momentum: 4.732e-01\n",
      "best loss: 449.93\t\tLearning rate: 4.833e-03, Batch size: 37, Momentum: 9.464e-01\n",
      "best loss: 449.95\t\tLearning rate: 1.624e-03, Batch size: 50, Momentum: 7.361e-01\n",
      "best loss: 449.95\t\tLearning rate: 1.624e-03, Batch size: 39, Momentum: 9.990e-01\n",
      "best loss: 449.99\t\tLearning rate: 6.952e-06, Batch size: 17, Momentum: 1.577e-01\n",
      "best loss: 450.12\t\tLearning rate: 1.000e-08, Batch size: 34, Momentum: 9.464e-01\n",
      "best loss: 450.16\t\tLearning rate: 8.859e-08, Batch size: 34, Momentum: 8.413e-01\n",
      "best loss: 450.17\t\tLearning rate: 2.069e-05, Batch size: 44, Momentum: 5.784e-01\n",
      "best loss: 450.17\t\tLearning rate: 1.000e+01, Batch size: 50, Momentum: 8.938e-01\n",
      "best loss: 450.22\t\tLearning rate: 1.000e+01, Batch size: 39, Momentum: 3.155e-01\n",
      "best loss: 450.30\t\tLearning rate: 1.438e-02, Batch size: 19, Momentum: 2.103e-01\n",
      "best loss: 450.36\t\tLearning rate: 5.456e-04, Batch size: 37, Momentum: 0.000e+00\n",
      "best loss: 450.45\t\tLearning rate: 7.848e-07, Batch size: 47, Momentum: 7.887e-01\n",
      "best loss: 450.51\t\tLearning rate: 1.438e-02, Batch size: 50, Momentum: 6.309e-01\n",
      "best loss: 450.54\t\tLearning rate: 2.069e-05, Batch size: 32, Momentum: 4.206e-01\n",
      "best loss: 450.54\t\tLearning rate: 7.848e-07, Batch size: 47, Momentum: 8.938e-01\n",
      "best loss: 450.57\t\tLearning rate: 2.637e-07, Batch size: 32, Momentum: 9.464e-01\n",
      "best loss: 450.59\t\tLearning rate: 8.859e-08, Batch size: 27, Momentum: 7.887e-01\n",
      "best loss: 450.60\t\tLearning rate: 2.336e-06, Batch size: 44, Momentum: 7.361e-01\n",
      "best loss: 450.63\t\tLearning rate: 2.069e-05, Batch size: 29, Momentum: 1.052e-01\n",
      "best loss: 450.66\t\tLearning rate: 6.158e-05, Batch size: 29, Momentum: 1.052e-01\n",
      "best loss: 450.67\t\tLearning rate: 8.859e-08, Batch size: 42, Momentum: 4.206e-01\n",
      "best loss: 450.72\t\tLearning rate: 5.456e-04, Batch size: 42, Momentum: 9.990e-01\n",
      "best loss: 450.82\t\tLearning rate: 2.637e-07, Batch size: 32, Momentum: 8.413e-01\n",
      "best loss: 450.85\t\tLearning rate: 6.952e-06, Batch size: 50, Momentum: 5.258e-01\n",
      "best loss: 450.88\t\tLearning rate: 6.952e-06, Batch size: 42, Momentum: 7.887e-01\n",
      "best loss: 450.91\t\tLearning rate: 1.438e-02, Batch size: 37, Momentum: 9.990e-01\n",
      "best loss: 450.99\t\tLearning rate: 1.274e-01, Batch size: 44, Momentum: 8.413e-01\n",
      "best loss: 451.02\t\tLearning rate: 2.336e-06, Batch size: 29, Momentum: 0.000e+00\n",
      "best loss: 451.05\t\tLearning rate: 2.336e-06, Batch size: 47, Momentum: 4.732e-01\n",
      "best loss: 451.06\t\tLearning rate: 1.833e-04, Batch size: 47, Momentum: 5.784e-01\n",
      "best loss: 451.16\t\tLearning rate: 1.000e-08, Batch size: 17, Momentum: 4.206e-01\n",
      "best loss: 451.17\t\tLearning rate: 7.848e-07, Batch size: 9, Momentum: 1.052e-01\n",
      "best loss: 451.19\t\tLearning rate: 2.336e-06, Batch size: 24, Momentum: 5.258e-01\n",
      "best loss: 451.31\t\tLearning rate: 5.456e-04, Batch size: 34, Momentum: 4.732e-01\n",
      "best loss: 451.31\t\tLearning rate: 7.848e-07, Batch size: 19, Momentum: 8.413e-01\n",
      "best loss: 451.31\t\tLearning rate: 8.859e-08, Batch size: 50, Momentum: 7.361e-01\n",
      "best loss: 451.32\t\tLearning rate: 6.952e-06, Batch size: 9, Momentum: 1.052e-01\n",
      "best loss: 451.39\t\tLearning rate: 1.624e-03, Batch size: 44, Momentum: 2.629e-01\n",
      "best loss: 451.49\t\tLearning rate: 2.336e-06, Batch size: 27, Momentum: 2.629e-01\n",
      "best loss: 451.53\t\tLearning rate: 2.336e-06, Batch size: 22, Momentum: 8.413e-01\n",
      "best loss: 451.55\t\tLearning rate: 2.336e-06, Batch size: 29, Momentum: 9.464e-01\n",
      "best loss: 451.58\t\tLearning rate: 4.281e-02, Batch size: 50, Momentum: 5.258e-02\n",
      "best loss: 451.59\t\tLearning rate: 7.848e-07, Batch size: 12, Momentum: 0.000e+00\n",
      "best loss: 451.59\t\tLearning rate: 2.336e-06, Batch size: 50, Momentum: 7.887e-01\n",
      "best loss: 451.60\t\tLearning rate: 8.859e-08, Batch size: 42, Momentum: 8.938e-01\n",
      "best loss: 451.61\t\tLearning rate: 2.336e-06, Batch size: 44, Momentum: 2.103e-01\n",
      "best loss: 451.79\t\tLearning rate: 1.624e-03, Batch size: 19, Momentum: 1.577e-01\n",
      "best loss: 451.93\t\tLearning rate: 1.438e-02, Batch size: 37, Momentum: 9.464e-01\n",
      "best loss: 452.01\t\tLearning rate: 2.336e-06, Batch size: 44, Momentum: 9.990e-01\n",
      "best loss: 452.27\t\tLearning rate: 2.336e-06, Batch size: 27, Momentum: 6.309e-01\n",
      "best loss: 452.34\t\tLearning rate: 3.360e+00, Batch size: 50, Momentum: 1.577e-01\n",
      "best loss: 452.52\t\tLearning rate: 2.976e-08, Batch size: 47, Momentum: 9.990e-01\n",
      "best loss: 452.55\t\tLearning rate: 3.793e-01, Batch size: 37, Momentum: 2.629e-01\n",
      "best loss: 452.55\t\tLearning rate: 2.336e-06, Batch size: 47, Momentum: 9.464e-01\n",
      "best loss: 452.58\t\tLearning rate: 3.793e-01, Batch size: 32, Momentum: 4.732e-01\n",
      "best loss: 452.61\t\tLearning rate: 2.637e-07, Batch size: 37, Momentum: 9.990e-01\n",
      "best loss: 452.73\t\tLearning rate: 2.336e-06, Batch size: 47, Momentum: 7.887e-01\n",
      "best loss: 452.79\t\tLearning rate: 2.336e-06, Batch size: 17, Momentum: 3.681e-01\n",
      "best loss: 452.85\t\tLearning rate: 3.793e-01, Batch size: 44, Momentum: 1.577e-01\n",
      "best loss: 452.90\t\tLearning rate: 1.000e-08, Batch size: 12, Momentum: 8.938e-01\n",
      "best loss: 453.05\t\tLearning rate: 6.952e-06, Batch size: 19, Momentum: 9.990e-01\n",
      "best loss: 453.09\t\tLearning rate: 7.848e-07, Batch size: 27, Momentum: 5.258e-02\n",
      "best loss: 453.14\t\tLearning rate: 1.129e+00, Batch size: 50, Momentum: 8.413e-01\n",
      "best loss: 453.30\t\tLearning rate: 5.456e-04, Batch size: 27, Momentum: 9.464e-01\n",
      "best loss: 453.32\t\tLearning rate: 8.859e-08, Batch size: 29, Momentum: 6.835e-01\n",
      "best loss: 453.36\t\tLearning rate: 6.952e-06, Batch size: 50, Momentum: 4.206e-01\n",
      "best loss: 453.49\t\tLearning rate: 2.336e-06, Batch size: 44, Momentum: 6.835e-01\n",
      "best loss: 453.70\t\tLearning rate: 2.637e-07, Batch size: 42, Momentum: 6.309e-01\n",
      "best loss: 453.81\t\tLearning rate: 2.069e-05, Batch size: 39, Momentum: 4.732e-01\n",
      "best loss: 453.92\t\tLearning rate: 7.848e-07, Batch size: 22, Momentum: 4.732e-01\n",
      "best loss: 454.01\t\tLearning rate: 7.848e-07, Batch size: 50, Momentum: 5.784e-01\n",
      "best loss: 454.04\t\tLearning rate: 2.336e-06, Batch size: 22, Momentum: 9.464e-01\n",
      "best loss: 454.32\t\tLearning rate: 2.336e-06, Batch size: 24, Momentum: 0.000e+00\n",
      "best loss: 454.47\t\tLearning rate: 7.848e-07, Batch size: 12, Momentum: 1.577e-01\n",
      "best loss: 454.54\t\tLearning rate: 6.952e-06, Batch size: 47, Momentum: 9.990e-01\n",
      "best loss: 454.62\t\tLearning rate: 1.274e-01, Batch size: 47, Momentum: 6.835e-01\n",
      "best loss: 454.67\t\tLearning rate: 2.336e-06, Batch size: 39, Momentum: 9.464e-01\n",
      "best loss: 454.72\t\tLearning rate: 2.976e-08, Batch size: 47, Momentum: 8.938e-01\n",
      "best loss: 454.81\t\tLearning rate: 2.637e-07, Batch size: 7, Momentum: 4.206e-01\n",
      "best loss: 454.86\t\tLearning rate: 6.952e-06, Batch size: 29, Momentum: 9.464e-01\n",
      "best loss: 455.03\t\tLearning rate: 1.000e-08, Batch size: 14, Momentum: 9.464e-01\n",
      "best loss: 455.11\t\tLearning rate: 2.336e-06, Batch size: 37, Momentum: 6.835e-01\n",
      "best loss: 455.62\t\tLearning rate: 8.859e-08, Batch size: 37, Momentum: 7.887e-01\n",
      "best loss: 455.87\t\tLearning rate: 7.848e-07, Batch size: 50, Momentum: 5.258e-01\n",
      "best loss: 455.90\t\tLearning rate: 2.637e-07, Batch size: 27, Momentum: 4.206e-01\n",
      "best loss: 455.99\t\tLearning rate: 6.952e-06, Batch size: 34, Momentum: 8.413e-01\n",
      "best loss: 456.15\t\tLearning rate: 2.069e-05, Batch size: 39, Momentum: 5.258e-02\n",
      "best loss: 456.41\t\tLearning rate: 6.952e-06, Batch size: 27, Momentum: 6.309e-01\n",
      "best loss: 456.42\t\tLearning rate: 8.859e-08, Batch size: 44, Momentum: 7.361e-01\n",
      "best loss: 456.45\t\tLearning rate: 6.952e-06, Batch size: 42, Momentum: 2.629e-01\n",
      "best loss: 456.48\t\tLearning rate: 2.336e-06, Batch size: 32, Momentum: 3.155e-01\n",
      "best loss: 456.64\t\tLearning rate: 8.859e-08, Batch size: 12, Momentum: 5.258e-01\n",
      "best loss: 456.67\t\tLearning rate: 2.976e-08, Batch size: 42, Momentum: 8.938e-01\n",
      "best loss: 456.73\t\tLearning rate: 2.976e-08, Batch size: 37, Momentum: 2.629e-01\n",
      "best loss: 457.12\t\tLearning rate: 7.848e-07, Batch size: 29, Momentum: 8.938e-01\n",
      "best loss: 457.24\t\tLearning rate: 1.000e-08, Batch size: 9, Momentum: 9.464e-01\n",
      "best loss: 457.26\t\tLearning rate: 8.859e-08, Batch size: 14, Momentum: 7.361e-01\n",
      "best loss: 457.55\t\tLearning rate: 2.336e-06, Batch size: 50, Momentum: 9.990e-01\n",
      "best loss: 457.63\t\tLearning rate: 6.952e-06, Batch size: 9, Momentum: 7.887e-01\n",
      "best loss: 457.75\t\tLearning rate: 2.637e-07, Batch size: 12, Momentum: 3.155e-01\n",
      "best loss: 458.01\t\tLearning rate: 7.848e-07, Batch size: 19, Momentum: 2.103e-01\n",
      "best loss: 458.02\t\tLearning rate: 1.000e-08, Batch size: 4, Momentum: 7.887e-01\n",
      "best loss: 458.33\t\tLearning rate: 2.637e-07, Batch size: 7, Momentum: 1.577e-01\n",
      "best loss: 458.37\t\tLearning rate: 2.069e-05, Batch size: 12, Momentum: 2.103e-01\n",
      "best loss: 458.43\t\tLearning rate: 2.336e-06, Batch size: 39, Momentum: 8.413e-01\n",
      "best loss: 458.76\t\tLearning rate: 7.848e-07, Batch size: 19, Momentum: 3.681e-01\n",
      "best loss: 458.79\t\tLearning rate: 6.952e-06, Batch size: 2, Momentum: 9.990e-01\n",
      "best loss: 458.91\t\tLearning rate: 2.069e-05, Batch size: 34, Momentum: 1.052e-01\n",
      "best loss: 458.95\t\tLearning rate: 2.637e-07, Batch size: 37, Momentum: 1.052e-01\n",
      "best loss: 458.97\t\tLearning rate: 7.848e-07, Batch size: 37, Momentum: 4.206e-01\n",
      "best loss: 459.12\t\tLearning rate: 1.833e-04, Batch size: 42, Momentum: 6.309e-01\n",
      "best loss: 459.43\t\tLearning rate: 1.833e-04, Batch size: 29, Momentum: 3.155e-01\n",
      "best loss: 459.49\t\tLearning rate: 2.336e-06, Batch size: 27, Momentum: 5.258e-02\n",
      "best loss: 459.64\t\tLearning rate: 2.336e-06, Batch size: 27, Momentum: 0.000e+00\n",
      "best loss: 459.75\t\tLearning rate: 2.637e-07, Batch size: 42, Momentum: 3.155e-01\n",
      "best loss: 460.10\t\tLearning rate: 6.952e-06, Batch size: 19, Momentum: 7.361e-01\n",
      "best loss: 460.29\t\tLearning rate: 7.848e-07, Batch size: 14, Momentum: 5.258e-02\n",
      "best loss: 460.68\t\tLearning rate: 2.976e-08, Batch size: 50, Momentum: 8.938e-01\n",
      "best loss: 460.78\t\tLearning rate: 6.952e-06, Batch size: 29, Momentum: 9.990e-01\n",
      "best loss: 460.82\t\tLearning rate: 2.637e-07, Batch size: 4, Momentum: 4.206e-01\n",
      "best loss: 461.07\t\tLearning rate: 2.976e-08, Batch size: 42, Momentum: 9.990e-01\n",
      "best loss: 461.08\t\tLearning rate: 2.069e-05, Batch size: 27, Momentum: 5.784e-01\n",
      "best loss: 461.32\t\tLearning rate: 8.859e-08, Batch size: 22, Momentum: 2.629e-01\n",
      "best loss: 461.66\t\tLearning rate: 8.859e-08, Batch size: 47, Momentum: 7.887e-01\n",
      "best loss: 461.74\t\tLearning rate: 8.859e-08, Batch size: 42, Momentum: 6.309e-01\n",
      "best loss: 462.25\t\tLearning rate: 2.637e-07, Batch size: 14, Momentum: 4.732e-01\n",
      "best loss: 462.45\t\tLearning rate: 2.637e-07, Batch size: 22, Momentum: 3.681e-01\n",
      "best loss: 462.50\t\tLearning rate: 6.952e-06, Batch size: 14, Momentum: 9.464e-01\n",
      "best loss: 462.56\t\tLearning rate: 6.952e-06, Batch size: 32, Momentum: 6.835e-01\n",
      "best loss: 462.76\t\tLearning rate: 7.848e-07, Batch size: 47, Momentum: 3.681e-01\n",
      "best loss: 462.80\t\tLearning rate: 2.637e-07, Batch size: 34, Momentum: 5.784e-01\n",
      "best loss: 462.88\t\tLearning rate: 6.952e-06, Batch size: 22, Momentum: 6.835e-01\n",
      "best loss: 463.46\t\tLearning rate: 2.336e-06, Batch size: 37, Momentum: 2.629e-01\n",
      "best loss: 464.03\t\tLearning rate: 6.952e-06, Batch size: 50, Momentum: 1.577e-01\n",
      "best loss: 464.18\t\tLearning rate: 6.952e-06, Batch size: 4, Momentum: 2.103e-01\n",
      "best loss: 464.60\t\tLearning rate: 7.848e-07, Batch size: 47, Momentum: 4.206e-01\n",
      "best loss: 464.97\t\tLearning rate: 6.952e-06, Batch size: 12, Momentum: 7.887e-01\n",
      "best loss: 465.58\t\tLearning rate: 6.952e-06, Batch size: 9, Momentum: 3.681e-01\n",
      "best loss: 465.73\t\tLearning rate: 7.848e-07, Batch size: 50, Momentum: 2.629e-01\n",
      "best loss: 466.09\t\tLearning rate: 2.069e-05, Batch size: 12, Momentum: 8.938e-01\n",
      "best loss: 466.39\t\tLearning rate: 1.000e-08, Batch size: 27, Momentum: 9.464e-01\n",
      "best loss: 466.90\t\tLearning rate: 2.637e-07, Batch size: 37, Momentum: 7.361e-01\n",
      "best loss: 467.03\t\tLearning rate: 2.637e-07, Batch size: 22, Momentum: 3.155e-01\n",
      "best loss: 468.41\t\tLearning rate: 2.637e-07, Batch size: 29, Momentum: 5.784e-01\n",
      "best loss: 468.83\t\tLearning rate: 6.158e-05, Batch size: 47, Momentum: 3.681e-01\n",
      "best loss: 469.31\t\tLearning rate: 6.158e-05, Batch size: 2, Momentum: 6.309e-01\n",
      "best loss: 469.70\t\tLearning rate: 1.000e-08, Batch size: 37, Momentum: 8.938e-01\n",
      "best loss: 470.96\t\tLearning rate: 2.069e-05, Batch size: 19, Momentum: 2.629e-01\n",
      "best loss: 471.41\t\tLearning rate: 6.952e-06, Batch size: 47, Momentum: 0.000e+00\n",
      "best loss: 471.63\t\tLearning rate: 8.859e-08, Batch size: 12, Momentum: 1.052e-01\n",
      "best loss: 472.18\t\tLearning rate: 2.976e-08, Batch size: 2, Momentum: 7.887e-01\n",
      "best loss: 472.48\t\tLearning rate: 2.637e-07, Batch size: 42, Momentum: 2.103e-01\n",
      "best loss: 472.71\t\tLearning rate: 2.069e-05, Batch size: 32, Momentum: 5.258e-02\n",
      "best loss: 473.82\t\tLearning rate: 7.848e-07, Batch size: 32, Momentum: 1.577e-01\n",
      "best loss: 474.37\t\tLearning rate: 6.952e-06, Batch size: 47, Momentum: 1.577e-01\n",
      "best loss: 474.90\t\tLearning rate: 6.952e-06, Batch size: 17, Momentum: 7.361e-01\n",
      "best loss: 476.71\t\tLearning rate: 2.069e-05, Batch size: 27, Momentum: 5.258e-02\n",
      "best loss: 477.67\t\tLearning rate: 1.000e-08, Batch size: 12, Momentum: 5.258e-01\n",
      "best loss: 477.80\t\tLearning rate: 2.637e-07, Batch size: 27, Momentum: 1.577e-01\n",
      "best loss: 479.56\t\tLearning rate: 1.000e-08, Batch size: 17, Momentum: 8.938e-01\n",
      "best loss: 481.95\t\tLearning rate: 8.859e-08, Batch size: 19, Momentum: 4.206e-01\n",
      "best loss: 482.78\t\tLearning rate: 8.859e-08, Batch size: 44, Momentum: 4.206e-01\n",
      "best loss: 483.51\t\tLearning rate: 8.859e-08, Batch size: 14, Momentum: 8.413e-01\n",
      "best loss: 484.49\t\tLearning rate: 5.456e-04, Batch size: 50, Momentum: 3.681e-01\n",
      "best loss: 484.91\t\tLearning rate: 2.069e-05, Batch size: 42, Momentum: 5.258e-02\n",
      "best loss: 485.32\t\tLearning rate: 2.069e-05, Batch size: 2, Momentum: 3.681e-01\n",
      "best loss: 485.46\t\tLearning rate: 8.859e-08, Batch size: 17, Momentum: 6.835e-01\n",
      "best loss: 486.06\t\tLearning rate: 2.069e-05, Batch size: 47, Momentum: 3.681e-01\n",
      "best loss: 486.18\t\tLearning rate: 2.637e-07, Batch size: 37, Momentum: 4.206e-01\n",
      "best loss: 487.38\t\tLearning rate: 2.976e-08, Batch size: 9, Momentum: 3.155e-01\n",
      "best loss: 488.63\t\tLearning rate: 2.637e-07, Batch size: 17, Momentum: 4.206e-01\n",
      "best loss: 489.11\t\tLearning rate: 8.859e-08, Batch size: 50, Momentum: 5.258e-01\n",
      "best loss: 489.13\t\tLearning rate: 2.637e-07, Batch size: 22, Momentum: 2.629e-01\n",
      "best loss: 491.23\t\tLearning rate: 8.859e-08, Batch size: 47, Momentum: 5.258e-02\n",
      "best loss: 492.83\t\tLearning rate: 2.069e-05, Batch size: 17, Momentum: 0.000e+00\n",
      "best loss: 493.11\t\tLearning rate: 1.000e-08, Batch size: 32, Momentum: 5.258e-01\n",
      "best loss: 496.33\t\tLearning rate: 8.859e-08, Batch size: 50, Momentum: 1.577e-01\n",
      "best loss: 497.64\t\tLearning rate: 2.336e-06, Batch size: 9, Momentum: 2.103e-01\n",
      "best loss: 497.83\t\tLearning rate: 1.000e-08, Batch size: 19, Momentum: 6.309e-01\n",
      "best loss: 499.29\t\tLearning rate: 1.000e-08, Batch size: 12, Momentum: 7.887e-01\n",
      "best loss: 502.18\t\tLearning rate: 2.976e-08, Batch size: 7, Momentum: 5.258e-01\n",
      "best loss: 502.74\t\tLearning rate: 2.637e-07, Batch size: 50, Momentum: 6.309e-01\n",
      "best loss: 504.68\t\tLearning rate: 2.069e-05, Batch size: 39, Momentum: 3.155e-01\n",
      "best loss: 504.77\t\tLearning rate: 2.637e-07, Batch size: 29, Momentum: 5.258e-01\n",
      "best loss: 506.94\t\tLearning rate: 1.000e-08, Batch size: 9, Momentum: 5.784e-01\n",
      "best loss: 508.42\t\tLearning rate: 1.000e-08, Batch size: 50, Momentum: 6.835e-01\n",
      "best loss: 509.37\t\tLearning rate: 1.000e-08, Batch size: 2, Momentum: 3.681e-01\n",
      "best loss: 511.70\t\tLearning rate: 2.976e-08, Batch size: 29, Momentum: 5.258e-01\n",
      "best loss: 511.96\t\tLearning rate: 1.000e-08, Batch size: 12, Momentum: 7.361e-01\n",
      "best loss: 512.07\t\tLearning rate: 2.069e-05, Batch size: 9, Momentum: 4.206e-01\n",
      "best loss: 512.75\t\tLearning rate: 2.069e-05, Batch size: 29, Momentum: 3.155e-01\n",
      "best loss: 513.45\t\tLearning rate: 2.069e-05, Batch size: 17, Momentum: 1.577e-01\n",
      "best loss: 515.98\t\tLearning rate: 6.952e-06, Batch size: 39, Momentum: 5.258e-02\n",
      "best loss: 520.13\t\tLearning rate: 2.976e-08, Batch size: 22, Momentum: 5.784e-01\n",
      "best loss: 526.15\t\tLearning rate: 1.000e-08, Batch size: 44, Momentum: 8.938e-01\n",
      "best loss: 526.17\t\tLearning rate: 2.069e-05, Batch size: 42, Momentum: 2.629e-01\n",
      "best loss: 528.78\t\tLearning rate: 2.976e-08, Batch size: 29, Momentum: 2.103e-01\n",
      "best loss: 529.50\t\tLearning rate: 8.859e-08, Batch size: 4, Momentum: 1.052e-01\n",
      "best loss: 531.25\t\tLearning rate: 8.859e-08, Batch size: 39, Momentum: 6.835e-01\n",
      "best loss: 535.63\t\tLearning rate: 1.000e-08, Batch size: 37, Momentum: 4.206e-01\n",
      "best loss: 536.28\t\tLearning rate: 2.976e-08, Batch size: 9, Momentum: 3.681e-01\n",
      "best loss: 537.55\t\tLearning rate: 6.952e-06, Batch size: 17, Momentum: 9.464e-01\n",
      "best loss: 553.39\t\tLearning rate: 2.637e-07, Batch size: 29, Momentum: 1.577e-01\n",
      "best loss: 556.59\t\tLearning rate: 2.976e-08, Batch size: 12, Momentum: 2.103e-01\n",
      "best loss: 557.74\t\tLearning rate: 2.069e-05, Batch size: 9, Momentum: 4.732e-01\n",
      "best loss: 559.32\t\tLearning rate: 7.848e-07, Batch size: 22, Momentum: 1.577e-01\n",
      "best loss: 566.07\t\tLearning rate: 1.000e-08, Batch size: 32, Momentum: 2.629e-01\n",
      "best loss: 573.43\t\tLearning rate: 2.069e-05, Batch size: 44, Momentum: 3.155e-01\n",
      "best loss: 578.26\t\tLearning rate: 2.976e-08, Batch size: 29, Momentum: 7.361e-01\n",
      "best loss: 591.32\t\tLearning rate: 6.158e-05, Batch size: 19, Momentum: 5.258e-02\n",
      "best loss: 594.19\t\tLearning rate: 2.637e-07, Batch size: 19, Momentum: 1.577e-01\n",
      "best loss: 608.16\t\tLearning rate: 2.069e-05, Batch size: 4, Momentum: 7.361e-01\n",
      "best loss: 613.51\t\tLearning rate: 6.158e-05, Batch size: 4, Momentum: 1.577e-01\n",
      "best loss: 625.45\t\tLearning rate: 1.000e-08, Batch size: 47, Momentum: 6.835e-01\n",
      "best loss: 630.47\t\tLearning rate: 8.859e-08, Batch size: 29, Momentum: 6.309e-01\n",
      "best loss: 637.78\t\tLearning rate: 2.637e-07, Batch size: 27, Momentum: 0.000e+00\n",
      "best loss: 652.97\t\tLearning rate: 6.158e-05, Batch size: 29, Momentum: 4.206e-01\n",
      "best loss: 656.26\t\tLearning rate: 2.976e-08, Batch size: 42, Momentum: 2.629e-01\n",
      "best loss: 656.82\t\tLearning rate: 2.976e-08, Batch size: 39, Momentum: 0.000e+00\n",
      "best loss: 658.48\t\tLearning rate: 8.859e-08, Batch size: 17, Momentum: 5.258e-01\n",
      "best loss: 664.70\t\tLearning rate: 2.069e-05, Batch size: 9, Momentum: 5.258e-01\n",
      "best loss: 666.40\t\tLearning rate: 2.069e-05, Batch size: 42, Momentum: 1.052e-01\n",
      "best loss: 667.17\t\tLearning rate: 6.158e-05, Batch size: 14, Momentum: 4.206e-01\n",
      "best loss: 667.50\t\tLearning rate: 8.859e-08, Batch size: 14, Momentum: 3.681e-01\n",
      "best loss: 669.52\t\tLearning rate: 2.976e-08, Batch size: 14, Momentum: 4.206e-01\n",
      "best loss: 673.73\t\tLearning rate: 2.069e-05, Batch size: 24, Momentum: 9.464e-01\n",
      "best loss: 675.87\t\tLearning rate: 6.158e-05, Batch size: 27, Momentum: 5.258e-02\n",
      "best loss: 677.15\t\tLearning rate: 2.069e-05, Batch size: 12, Momentum: 4.732e-01\n",
      "best loss: 679.37\t\tLearning rate: 6.158e-05, Batch size: 4, Momentum: 5.784e-01\n",
      "best loss: 688.08\t\tLearning rate: 6.158e-05, Batch size: 24, Momentum: 6.309e-01\n",
      "best loss: 694.21\t\tLearning rate: 6.158e-05, Batch size: 7, Momentum: 0.000e+00\n",
      "best loss: 696.78\t\tLearning rate: 6.158e-05, Batch size: 12, Momentum: 5.258e-02\n",
      "best loss: 701.48\t\tLearning rate: 2.069e-05, Batch size: 44, Momentum: 5.258e-01\n",
      "best loss: 703.19\t\tLearning rate: 6.158e-05, Batch size: 32, Momentum: 1.577e-01\n",
      "best loss: 710.82\t\tLearning rate: 6.158e-05, Batch size: 32, Momentum: 9.990e-01\n",
      "best loss: 712.73\t\tLearning rate: 2.069e-05, Batch size: 39, Momentum: 3.681e-01\n",
      "best loss: 713.15\t\tLearning rate: 1.833e-04, Batch size: 27, Momentum: 5.258e-02\n",
      "best loss: 717.35\t\tLearning rate: 6.158e-05, Batch size: 29, Momentum: 9.990e-01\n",
      "best loss: 722.85\t\tLearning rate: 1.833e-04, Batch size: 9, Momentum: 0.000e+00\n",
      "best loss: 723.34\t\tLearning rate: 2.069e-05, Batch size: 14, Momentum: 8.413e-01\n",
      "best loss: 724.42\t\tLearning rate: 2.069e-05, Batch size: 17, Momentum: 6.835e-01\n",
      "best loss: 725.97\t\tLearning rate: 2.069e-05, Batch size: 9, Momentum: 8.413e-01\n",
      "best loss: 731.88\t\tLearning rate: 1.833e-04, Batch size: 22, Momentum: 7.887e-01\n",
      "best loss: 732.36\t\tLearning rate: 6.158e-05, Batch size: 2, Momentum: 5.784e-01\n",
      "best loss: 732.92\t\tLearning rate: 1.833e-04, Batch size: 50, Momentum: 1.577e-01\n",
      "best loss: 733.32\t\tLearning rate: 2.069e-05, Batch size: 4, Momentum: 7.887e-01\n",
      "best loss: 735.07\t\tLearning rate: 2.069e-05, Batch size: 19, Momentum: 8.413e-01\n",
      "best loss: 737.54\t\tLearning rate: 6.158e-05, Batch size: 29, Momentum: 4.732e-01\n",
      "best loss: 740.62\t\tLearning rate: 6.158e-05, Batch size: 32, Momentum: 4.732e-01\n",
      "best loss: 744.31\t\tLearning rate: 2.976e-08, Batch size: 24, Momentum: 1.577e-01\n",
      "best loss: 744.90\t\tLearning rate: 6.158e-05, Batch size: 32, Momentum: 4.206e-01\n",
      "best loss: 745.67\t\tLearning rate: 1.833e-04, Batch size: 47, Momentum: 1.577e-01\n",
      "best loss: 747.85\t\tLearning rate: 2.976e-08, Batch size: 27, Momentum: 5.258e-01\n",
      "best loss: 751.22\t\tLearning rate: 6.158e-05, Batch size: 29, Momentum: 3.681e-01\n",
      "best loss: 752.09\t\tLearning rate: 1.833e-04, Batch size: 24, Momentum: 1.577e-01\n",
      "best loss: 753.11\t\tLearning rate: 1.833e-04, Batch size: 32, Momentum: 1.577e-01\n",
      "best loss: 754.21\t\tLearning rate: 2.069e-05, Batch size: 17, Momentum: 5.784e-01\n",
      "best loss: 759.78\t\tLearning rate: 6.158e-05, Batch size: 22, Momentum: 3.681e-01\n",
      "best loss: 762.38\t\tLearning rate: 1.833e-04, Batch size: 17, Momentum: 3.681e-01\n",
      "best loss: 762.42\t\tLearning rate: 6.158e-05, Batch size: 27, Momentum: 2.103e-01\n",
      "best loss: 763.57\t\tLearning rate: 6.158e-05, Batch size: 4, Momentum: 4.206e-01\n",
      "best loss: 765.57\t\tLearning rate: 2.069e-05, Batch size: 50, Momentum: 9.990e-01\n",
      "best loss: 766.29\t\tLearning rate: 1.833e-04, Batch size: 39, Momentum: 6.835e-01\n",
      "best loss: 770.22\t\tLearning rate: 1.833e-04, Batch size: 14, Momentum: 8.413e-01\n",
      "best loss: 771.35\t\tLearning rate: 6.158e-05, Batch size: 19, Momentum: 5.784e-01\n",
      "best loss: 775.69\t\tLearning rate: 6.158e-05, Batch size: 39, Momentum: 5.258e-01\n",
      "best loss: 780.64\t\tLearning rate: 1.000e-08, Batch size: 47, Momentum: 3.155e-01\n",
      "best loss: 784.04\t\tLearning rate: 1.833e-04, Batch size: 42, Momentum: 7.361e-01\n",
      "best loss: 785.77\t\tLearning rate: 8.859e-08, Batch size: 22, Momentum: 0.000e+00\n",
      "best loss: 787.10\t\tLearning rate: 6.158e-05, Batch size: 17, Momentum: 5.784e-01\n",
      "best loss: 790.21\t\tLearning rate: 1.833e-04, Batch size: 39, Momentum: 9.990e-01\n",
      "best loss: 791.37\t\tLearning rate: 1.833e-04, Batch size: 17, Momentum: 8.413e-01\n",
      "best loss: 791.85\t\tLearning rate: 6.158e-05, Batch size: 19, Momentum: 7.361e-01\n",
      "best loss: 795.23\t\tLearning rate: 1.833e-04, Batch size: 4, Momentum: 3.681e-01\n",
      "best loss: 795.97\t\tLearning rate: 1.833e-04, Batch size: 39, Momentum: 4.732e-01\n",
      "best loss: 796.51\t\tLearning rate: 2.069e-05, Batch size: 47, Momentum: 7.361e-01\n",
      "best loss: 798.14\t\tLearning rate: 6.158e-05, Batch size: 37, Momentum: 7.361e-01\n",
      "best loss: 798.49\t\tLearning rate: 1.833e-04, Batch size: 4, Momentum: 3.155e-01\n",
      "best loss: 799.12\t\tLearning rate: 1.833e-04, Batch size: 14, Momentum: 3.681e-01\n",
      "best loss: 800.04\t\tLearning rate: 5.456e-04, Batch size: 4, Momentum: 3.681e-01\n",
      "best loss: 805.03\t\tLearning rate: 1.833e-04, Batch size: 37, Momentum: 2.629e-01\n",
      "best loss: 807.49\t\tLearning rate: 6.158e-05, Batch size: 32, Momentum: 8.938e-01\n",
      "best loss: 808.27\t\tLearning rate: 6.158e-05, Batch size: 29, Momentum: 6.835e-01\n",
      "best loss: 811.74\t\tLearning rate: 5.456e-04, Batch size: 42, Momentum: 2.103e-01\n",
      "best loss: 812.35\t\tLearning rate: 1.833e-04, Batch size: 42, Momentum: 3.681e-01\n",
      "best loss: 812.88\t\tLearning rate: 1.833e-04, Batch size: 37, Momentum: 6.835e-01\n",
      "best loss: 813.69\t\tLearning rate: 1.833e-04, Batch size: 17, Momentum: 5.784e-01\n",
      "best loss: 816.35\t\tLearning rate: 5.456e-04, Batch size: 39, Momentum: 5.258e-02\n",
      "best loss: 816.48\t\tLearning rate: 6.158e-05, Batch size: 19, Momentum: 6.835e-01\n",
      "best loss: 816.70\t\tLearning rate: 5.456e-04, Batch size: 17, Momentum: 4.206e-01\n",
      "best loss: 819.09\t\tLearning rate: 1.833e-04, Batch size: 27, Momentum: 9.464e-01\n",
      "best loss: 821.94\t\tLearning rate: 1.833e-04, Batch size: 7, Momentum: 4.732e-01\n",
      "best loss: 822.24\t\tLearning rate: 1.833e-04, Batch size: 50, Momentum: 5.258e-01\n",
      "best loss: 822.42\t\tLearning rate: 1.833e-04, Batch size: 19, Momentum: 5.258e-01\n",
      "best loss: 822.72\t\tLearning rate: 1.624e-03, Batch size: 17, Momentum: 0.000e+00\n",
      "best loss: 822.84\t\tLearning rate: 1.833e-04, Batch size: 4, Momentum: 5.258e-01\n",
      "best loss: 824.29\t\tLearning rate: 1.833e-04, Batch size: 24, Momentum: 5.258e-01\n",
      "best loss: 824.89\t\tLearning rate: 6.158e-05, Batch size: 50, Momentum: 8.938e-01\n",
      "best loss: 826.02\t\tLearning rate: 1.833e-04, Batch size: 27, Momentum: 5.784e-01\n",
      "best loss: 828.97\t\tLearning rate: 2.976e-08, Batch size: 14, Momentum: 4.732e-01\n",
      "best loss: 829.08\t\tLearning rate: 5.456e-04, Batch size: 17, Momentum: 6.309e-01\n",
      "best loss: 831.90\t\tLearning rate: 1.833e-04, Batch size: 12, Momentum: 4.732e-01\n",
      "best loss: 835.77\t\tLearning rate: 1.833e-04, Batch size: 22, Momentum: 9.464e-01\n",
      "best loss: 836.91\t\tLearning rate: 1.833e-04, Batch size: 12, Momentum: 5.258e-01\n",
      "best loss: 840.95\t\tLearning rate: 6.158e-05, Batch size: 39, Momentum: 7.887e-01\n",
      "best loss: 841.14\t\tLearning rate: 1.624e-03, Batch size: 32, Momentum: 0.000e+00\n",
      "best loss: 842.40\t\tLearning rate: 5.456e-04, Batch size: 4, Momentum: 2.103e-01\n",
      "best loss: 845.99\t\tLearning rate: 5.456e-04, Batch size: 19, Momentum: 2.103e-01\n",
      "best loss: 848.66\t\tLearning rate: 6.158e-05, Batch size: 24, Momentum: 9.990e-01\n",
      "best loss: 850.74\t\tLearning rate: 1.833e-04, Batch size: 4, Momentum: 7.361e-01\n",
      "best loss: 851.92\t\tLearning rate: 1.624e-03, Batch size: 32, Momentum: 2.103e-01\n",
      "best loss: 852.88\t\tLearning rate: 5.456e-04, Batch size: 47, Momentum: 2.103e-01\n",
      "best loss: 853.06\t\tLearning rate: 5.456e-04, Batch size: 34, Momentum: 5.784e-01\n",
      "best loss: 853.10\t\tLearning rate: 5.456e-04, Batch size: 42, Momentum: 4.206e-01\n",
      "best loss: 853.50\t\tLearning rate: 5.456e-04, Batch size: 14, Momentum: 7.361e-01\n",
      "best loss: 855.06\t\tLearning rate: 1.624e-03, Batch size: 14, Momentum: 7.361e-01\n",
      "best loss: 855.62\t\tLearning rate: 1.833e-04, Batch size: 34, Momentum: 9.990e-01\n",
      "best loss: 856.29\t\tLearning rate: 5.456e-04, Batch size: 27, Momentum: 7.361e-01\n",
      "best loss: 857.65\t\tLearning rate: 1.624e-03, Batch size: 12, Momentum: 1.577e-01\n",
      "best loss: 858.98\t\tLearning rate: 5.456e-04, Batch size: 44, Momentum: 7.361e-01\n",
      "best loss: 862.34\t\tLearning rate: 5.456e-04, Batch size: 34, Momentum: 2.629e-01\n",
      "best loss: 863.35\t\tLearning rate: 1.833e-04, Batch size: 4, Momentum: 8.938e-01\n",
      "best loss: 865.66\t\tLearning rate: 1.624e-03, Batch size: 9, Momentum: 2.629e-01\n",
      "best loss: 866.43\t\tLearning rate: 1.624e-03, Batch size: 27, Momentum: 5.258e-02\n",
      "best loss: 868.08\t\tLearning rate: 5.456e-04, Batch size: 29, Momentum: 5.784e-01\n",
      "best loss: 868.15\t\tLearning rate: 1.624e-03, Batch size: 50, Momentum: 1.577e-01\n",
      "best loss: 869.27\t\tLearning rate: 5.456e-04, Batch size: 34, Momentum: 5.258e-01\n",
      "best loss: 870.60\t\tLearning rate: 1.833e-04, Batch size: 42, Momentum: 9.990e-01\n",
      "best loss: 872.61\t\tLearning rate: 1.624e-03, Batch size: 27, Momentum: 1.577e-01\n",
      "best loss: 874.65\t\tLearning rate: 1.624e-03, Batch size: 27, Momentum: 2.103e-01\n",
      "best loss: 875.51\t\tLearning rate: 5.456e-04, Batch size: 14, Momentum: 6.835e-01\n",
      "best loss: 876.27\t\tLearning rate: 5.456e-04, Batch size: 39, Momentum: 5.258e-01\n",
      "best loss: 876.67\t\tLearning rate: 5.456e-04, Batch size: 29, Momentum: 8.938e-01\n",
      "best loss: 876.71\t\tLearning rate: 1.000e-08, Batch size: 47, Momentum: 6.309e-01\n",
      "best loss: 877.56\t\tLearning rate: 5.456e-04, Batch size: 4, Momentum: 3.155e-01\n",
      "best loss: 880.04\t\tLearning rate: 1.624e-03, Batch size: 37, Momentum: 2.103e-01\n",
      "best loss: 881.41\t\tLearning rate: 5.456e-04, Batch size: 42, Momentum: 8.413e-01\n",
      "best loss: 881.67\t\tLearning rate: 1.833e-04, Batch size: 32, Momentum: 8.413e-01\n",
      "best loss: 882.06\t\tLearning rate: 5.456e-04, Batch size: 12, Momentum: 4.732e-01\n",
      "best loss: 883.43\t\tLearning rate: 1.833e-04, Batch size: 14, Momentum: 9.464e-01\n",
      "best loss: 883.49\t\tLearning rate: 5.456e-04, Batch size: 29, Momentum: 8.413e-01\n",
      "best loss: 885.10\t\tLearning rate: 5.456e-04, Batch size: 17, Momentum: 5.258e-01\n",
      "best loss: 889.47\t\tLearning rate: 1.624e-03, Batch size: 14, Momentum: 8.938e-01\n",
      "best loss: 889.83\t\tLearning rate: 1.833e-04, Batch size: 37, Momentum: 7.887e-01\n",
      "best loss: 891.19\t\tLearning rate: 1.833e-04, Batch size: 19, Momentum: 8.413e-01\n",
      "best loss: 892.61\t\tLearning rate: 5.456e-04, Batch size: 29, Momentum: 4.732e-01\n",
      "best loss: 894.29\t\tLearning rate: 4.833e-03, Batch size: 19, Momentum: 0.000e+00\n",
      "best loss: 895.53\t\tLearning rate: 1.624e-03, Batch size: 42, Momentum: 2.103e-01\n",
      "best loss: 900.23\t\tLearning rate: 1.624e-03, Batch size: 9, Momentum: 6.309e-01\n",
      "best loss: 900.33\t\tLearning rate: 5.456e-04, Batch size: 37, Momentum: 7.887e-01\n",
      "best loss: 902.28\t\tLearning rate: 5.456e-04, Batch size: 22, Momentum: 6.835e-01\n",
      "best loss: 903.78\t\tLearning rate: 5.456e-04, Batch size: 12, Momentum: 5.784e-01\n",
      "best loss: 905.87\t\tLearning rate: 1.624e-03, Batch size: 17, Momentum: 5.784e-01\n",
      "best loss: 906.34\t\tLearning rate: 1.833e-04, Batch size: 50, Momentum: 9.990e-01\n",
      "best loss: 912.17\t\tLearning rate: 1.624e-03, Batch size: 32, Momentum: 6.309e-01\n",
      "best loss: 913.38\t\tLearning rate: 5.456e-04, Batch size: 12, Momentum: 9.464e-01\n",
      "best loss: 914.11\t\tLearning rate: 1.624e-03, Batch size: 4, Momentum: 4.732e-01\n",
      "best loss: 914.13\t\tLearning rate: 5.456e-04, Batch size: 50, Momentum: 8.413e-01\n",
      "best loss: 914.93\t\tLearning rate: 4.833e-03, Batch size: 24, Momentum: 0.000e+00\n",
      "best loss: 915.51\t\tLearning rate: 1.624e-03, Batch size: 37, Momentum: 5.784e-01\n",
      "best loss: 916.01\t\tLearning rate: 1.624e-03, Batch size: 17, Momentum: 5.258e-01\n",
      "best loss: 918.80\t\tLearning rate: 5.456e-04, Batch size: 19, Momentum: 9.990e-01\n",
      "best loss: 921.51\t\tLearning rate: 1.624e-03, Batch size: 24, Momentum: 6.309e-01\n",
      "best loss: 922.63\t\tLearning rate: 1.624e-03, Batch size: 32, Momentum: 7.361e-01\n",
      "best loss: 924.14\t\tLearning rate: 4.833e-03, Batch size: 44, Momentum: 1.577e-01\n",
      "best loss: 925.09\t\tLearning rate: 1.624e-03, Batch size: 2, Momentum: 5.258e-01\n",
      "best loss: 925.14\t\tLearning rate: 1.624e-03, Batch size: 34, Momentum: 6.309e-01\n",
      "best loss: 925.32\t\tLearning rate: 1.624e-03, Batch size: 4, Momentum: 4.206e-01\n",
      "best loss: 925.55\t\tLearning rate: 5.456e-04, Batch size: 39, Momentum: 8.938e-01\n",
      "best loss: 925.55\t\tLearning rate: 1.624e-03, Batch size: 19, Momentum: 8.938e-01\n",
      "best loss: 925.79\t\tLearning rate: 1.624e-03, Batch size: 39, Momentum: 3.155e-01\n",
      "best loss: 928.05\t\tLearning rate: 1.438e-02, Batch size: 2, Momentum: 5.258e-02\n",
      "best loss: 928.30\t\tLearning rate: 4.833e-03, Batch size: 4, Momentum: 5.258e-02\n",
      "best loss: 930.38\t\tLearning rate: 1.833e-04, Batch size: 2, Momentum: 9.464e-01\n",
      "best loss: 930.57\t\tLearning rate: 4.833e-03, Batch size: 47, Momentum: 2.103e-01\n",
      "best loss: 933.66\t\tLearning rate: 1.624e-03, Batch size: 34, Momentum: 7.361e-01\n",
      "best loss: 936.20\t\tLearning rate: 1.624e-03, Batch size: 37, Momentum: 3.681e-01\n",
      "best loss: 937.32\t\tLearning rate: 5.456e-04, Batch size: 7, Momentum: 8.413e-01\n",
      "best loss: 940.20\t\tLearning rate: 4.833e-03, Batch size: 14, Momentum: 3.155e-01\n",
      "best loss: 940.34\t\tLearning rate: 1.624e-03, Batch size: 32, Momentum: 3.681e-01\n",
      "best loss: 940.40\t\tLearning rate: 1.624e-03, Batch size: 29, Momentum: 5.784e-01\n",
      "best loss: 941.03\t\tLearning rate: 4.833e-03, Batch size: 32, Momentum: 2.103e-01\n",
      "best loss: 943.90\t\tLearning rate: 1.438e-02, Batch size: 14, Momentum: 5.258e-02\n",
      "best loss: 945.35\t\tLearning rate: 4.833e-03, Batch size: 39, Momentum: 1.052e-01\n",
      "best loss: 946.04\t\tLearning rate: 4.833e-03, Batch size: 2, Momentum: 3.681e-01\n",
      "best loss: 947.08\t\tLearning rate: 5.456e-04, Batch size: 32, Momentum: 7.361e-01\n",
      "best loss: 951.41\t\tLearning rate: 1.624e-03, Batch size: 12, Momentum: 6.835e-01\n",
      "best loss: 955.11\t\tLearning rate: 1.438e-02, Batch size: 9, Momentum: 0.000e+00\n",
      "best loss: 955.21\t\tLearning rate: 4.833e-03, Batch size: 50, Momentum: 3.681e-01\n",
      "best loss: 957.74\t\tLearning rate: 4.833e-03, Batch size: 12, Momentum: 3.155e-01\n",
      "best loss: 959.75\t\tLearning rate: 5.456e-04, Batch size: 29, Momentum: 9.990e-01\n",
      "best loss: 960.91\t\tLearning rate: 1.438e-02, Batch size: 29, Momentum: 0.000e+00\n",
      "best loss: 961.55\t\tLearning rate: 1.624e-03, Batch size: 7, Momentum: 9.990e-01\n",
      "best loss: 962.02\t\tLearning rate: 4.833e-03, Batch size: 17, Momentum: 4.206e-01\n",
      "best loss: 962.39\t\tLearning rate: 4.833e-03, Batch size: 9, Momentum: 2.103e-01\n",
      "best loss: 962.50\t\tLearning rate: 1.624e-03, Batch size: 44, Momentum: 8.413e-01\n",
      "best loss: 963.01\t\tLearning rate: 1.438e-02, Batch size: 7, Momentum: 2.103e-01\n",
      "best loss: 963.03\t\tLearning rate: 1.438e-02, Batch size: 42, Momentum: 0.000e+00\n",
      "best loss: 963.18\t\tLearning rate: 1.438e-02, Batch size: 14, Momentum: 1.052e-01\n",
      "best loss: 965.90\t\tLearning rate: 4.833e-03, Batch size: 32, Momentum: 3.681e-01\n",
      "best loss: 966.17\t\tLearning rate: 1.624e-03, Batch size: 27, Momentum: 7.361e-01\n",
      "best loss: 969.81\t\tLearning rate: 5.456e-04, Batch size: 44, Momentum: 8.938e-01\n",
      "best loss: 970.53\t\tLearning rate: 4.833e-03, Batch size: 27, Momentum: 5.258e-01\n",
      "best loss: 972.69\t\tLearning rate: 4.833e-03, Batch size: 12, Momentum: 4.732e-01\n",
      "best loss: 975.83\t\tLearning rate: 4.833e-03, Batch size: 24, Momentum: 4.206e-01\n",
      "best loss: 976.67\t\tLearning rate: 1.624e-03, Batch size: 14, Momentum: 6.309e-01\n",
      "best loss: 980.22\t\tLearning rate: 4.833e-03, Batch size: 17, Momentum: 5.258e-01\n",
      "best loss: 981.21\t\tLearning rate: 1.438e-02, Batch size: 42, Momentum: 1.577e-01\n",
      "best loss: 981.70\t\tLearning rate: 4.833e-03, Batch size: 44, Momentum: 5.784e-01\n",
      "best loss: 984.46\t\tLearning rate: 1.624e-03, Batch size: 29, Momentum: 8.413e-01\n",
      "best loss: 985.15\t\tLearning rate: 1.438e-02, Batch size: 32, Momentum: 1.052e-01\n",
      "best loss: 986.78\t\tLearning rate: 1.438e-02, Batch size: 44, Momentum: 1.577e-01\n",
      "best loss: 987.72\t\tLearning rate: 4.833e-03, Batch size: 50, Momentum: 5.784e-01\n",
      "best loss: 988.33\t\tLearning rate: 4.833e-03, Batch size: 44, Momentum: 4.206e-01\n",
      "best loss: 988.77\t\tLearning rate: 1.438e-02, Batch size: 29, Momentum: 5.258e-01\n",
      "best loss: 991.03\t\tLearning rate: 4.833e-03, Batch size: 42, Momentum: 4.206e-01\n",
      "best loss: 991.86\t\tLearning rate: 4.833e-03, Batch size: 47, Momentum: 4.732e-01\n",
      "best loss: 992.10\t\tLearning rate: 4.833e-03, Batch size: 17, Momentum: 3.681e-01\n",
      "best loss: 995.25\t\tLearning rate: 1.438e-02, Batch size: 19, Momentum: 5.258e-02\n",
      "best loss: 997.38\t\tLearning rate: 1.624e-03, Batch size: 27, Momentum: 7.887e-01\n",
      "best loss: 997.99\t\tLearning rate: 1.438e-02, Batch size: 39, Momentum: 2.629e-01\n",
      "best loss: 998.82\t\tLearning rate: 4.833e-03, Batch size: 14, Momentum: 7.887e-01\n",
      "best loss: 999.44\t\tLearning rate: 1.624e-03, Batch size: 29, Momentum: 7.887e-01\n",
      "best loss: 1000.52\t\tLearning rate: 1.438e-02, Batch size: 19, Momentum: 1.577e-01\n",
      "best loss: 1000.99\t\tLearning rate: 4.833e-03, Batch size: 14, Momentum: 4.732e-01\n",
      "best loss: 1004.31\t\tLearning rate: 1.438e-02, Batch size: 17, Momentum: 2.629e-01\n",
      "best loss: 1008.56\t\tLearning rate: 4.833e-03, Batch size: 2, Momentum: 8.413e-01\n",
      "best loss: 1008.61\t\tLearning rate: 1.624e-03, Batch size: 17, Momentum: 9.990e-01\n",
      "best loss: 1008.90\t\tLearning rate: 1.000e-08, Batch size: 42, Momentum: 5.258e-02\n",
      "best loss: 1013.27\t\tLearning rate: 1.438e-02, Batch size: 44, Momentum: 3.155e-01\n",
      "best loss: 1014.63\t\tLearning rate: 1.000e-08, Batch size: 14, Momentum: 2.629e-01\n",
      "best loss: 1014.78\t\tLearning rate: 1.438e-02, Batch size: 24, Momentum: 2.103e-01\n",
      "best loss: 1015.51\t\tLearning rate: 1.438e-02, Batch size: 37, Momentum: 1.052e-01\n",
      "best loss: 1015.76\t\tLearning rate: 1.438e-02, Batch size: 42, Momentum: 3.155e-01\n",
      "best loss: 1016.19\t\tLearning rate: 1.000e-08, Batch size: 22, Momentum: 4.206e-01\n",
      "best loss: 1018.45\t\tLearning rate: 4.833e-03, Batch size: 9, Momentum: 8.938e-01\n",
      "best loss: 1019.76\t\tLearning rate: 4.281e-02, Batch size: 29, Momentum: 3.681e-01\n",
      "best loss: 1020.27\t\tLearning rate: 1.438e-02, Batch size: 17, Momentum: 3.155e-01\n",
      "best loss: 1021.37\t\tLearning rate: 4.833e-03, Batch size: 12, Momentum: 9.990e-01\n",
      "best loss: 1022.77\t\tLearning rate: 4.833e-03, Batch size: 32, Momentum: 7.887e-01\n",
      "best loss: 1023.71\t\tLearning rate: 4.833e-03, Batch size: 34, Momentum: 6.835e-01\n",
      "best loss: 1024.63\t\tLearning rate: 4.833e-03, Batch size: 4, Momentum: 7.361e-01\n",
      "best loss: 1025.48\t\tLearning rate: 4.281e-02, Batch size: 19, Momentum: 1.052e-01\n",
      "best loss: 1028.20\t\tLearning rate: 1.438e-02, Batch size: 4, Momentum: 2.103e-01\n",
      "best loss: 1029.09\t\tLearning rate: 4.281e-02, Batch size: 29, Momentum: 0.000e+00\n",
      "best loss: 1029.25\t\tLearning rate: 1.438e-02, Batch size: 9, Momentum: 6.835e-01\n",
      "best loss: 1031.18\t\tLearning rate: 1.438e-02, Batch size: 37, Momentum: 6.309e-01\n",
      "best loss: 1031.68\t\tLearning rate: 4.281e-02, Batch size: 44, Momentum: 2.629e-01\n",
      "best loss: 1032.98\t\tLearning rate: 1.438e-02, Batch size: 39, Momentum: 4.206e-01\n",
      "best loss: 1033.70\t\tLearning rate: 4.281e-02, Batch size: 29, Momentum: 6.309e-01\n",
      "best loss: 1037.28\t\tLearning rate: 4.281e-02, Batch size: 44, Momentum: 1.052e-01\n",
      "best loss: 1037.39\t\tLearning rate: 4.833e-03, Batch size: 50, Momentum: 8.938e-01\n",
      "best loss: 1038.10\t\tLearning rate: 4.281e-02, Batch size: 12, Momentum: 6.835e-01\n",
      "best loss: 1040.70\t\tLearning rate: 1.438e-02, Batch size: 24, Momentum: 8.413e-01\n",
      "best loss: 1040.82\t\tLearning rate: 4.281e-02, Batch size: 50, Momentum: 3.681e-01\n",
      "best loss: 1040.93\t\tLearning rate: 1.438e-02, Batch size: 47, Momentum: 9.464e-01\n",
      "best loss: 1041.56\t\tLearning rate: 4.833e-03, Batch size: 4, Momentum: 8.938e-01\n",
      "best loss: 1045.11\t\tLearning rate: 4.281e-02, Batch size: 29, Momentum: 1.577e-01\n",
      "best loss: 1046.97\t\tLearning rate: 1.438e-02, Batch size: 42, Momentum: 7.887e-01\n",
      "best loss: 1047.62\t\tLearning rate: 4.833e-03, Batch size: 39, Momentum: 9.464e-01\n",
      "best loss: 1049.09\t\tLearning rate: 4.833e-03, Batch size: 12, Momentum: 9.464e-01\n",
      "best loss: 1049.24\t\tLearning rate: 4.281e-02, Batch size: 7, Momentum: 3.155e-01\n",
      "best loss: 1051.99\t\tLearning rate: 1.624e-03, Batch size: 27, Momentum: 9.990e-01\n",
      "best loss: 1053.63\t\tLearning rate: 1.438e-02, Batch size: 22, Momentum: 6.835e-01\n",
      "best loss: 1054.35\t\tLearning rate: 1.438e-02, Batch size: 37, Momentum: 6.835e-01\n",
      "best loss: 1056.28\t\tLearning rate: 1.274e-01, Batch size: 32, Momentum: 0.000e+00\n",
      "best loss: 1056.54\t\tLearning rate: 4.281e-02, Batch size: 29, Momentum: 7.887e-01\n",
      "best loss: 1057.23\t\tLearning rate: 4.281e-02, Batch size: 44, Momentum: 5.258e-02\n",
      "best loss: 1059.03\t\tLearning rate: 4.281e-02, Batch size: 22, Momentum: 2.629e-01\n",
      "best loss: 1059.45\t\tLearning rate: 4.281e-02, Batch size: 17, Momentum: 5.258e-01\n",
      "best loss: 1060.66\t\tLearning rate: 1.274e-01, Batch size: 19, Momentum: 1.577e-01\n",
      "best loss: 1062.30\t\tLearning rate: 4.281e-02, Batch size: 24, Momentum: 3.681e-01\n",
      "best loss: 1062.65\t\tLearning rate: 1.438e-02, Batch size: 17, Momentum: 7.361e-01\n",
      "best loss: 1069.59\t\tLearning rate: 4.281e-02, Batch size: 2, Momentum: 7.361e-01\n",
      "best loss: 1072.88\t\tLearning rate: 4.281e-02, Batch size: 22, Momentum: 4.732e-01\n",
      "best loss: 1073.72\t\tLearning rate: 3.793e-01, Batch size: 4, Momentum: 0.000e+00\n",
      "best loss: 1074.47\t\tLearning rate: 4.281e-02, Batch size: 47, Momentum: 2.103e-01\n",
      "best loss: 1077.00\t\tLearning rate: 4.281e-02, Batch size: 50, Momentum: 5.784e-01\n",
      "best loss: 1077.89\t\tLearning rate: 1.438e-02, Batch size: 12, Momentum: 6.835e-01\n",
      "best loss: 1081.15\t\tLearning rate: 1.438e-02, Batch size: 27, Momentum: 7.361e-01\n",
      "best loss: 1081.55\t\tLearning rate: 4.281e-02, Batch size: 32, Momentum: 5.784e-01\n",
      "best loss: 1081.75\t\tLearning rate: 4.281e-02, Batch size: 34, Momentum: 5.784e-01\n",
      "best loss: 1083.38\t\tLearning rate: 1.274e-01, Batch size: 2, Momentum: 4.732e-01\n",
      "best loss: 1084.97\t\tLearning rate: 4.281e-02, Batch size: 12, Momentum: 9.464e-01\n",
      "best loss: 1087.74\t\tLearning rate: 4.281e-02, Batch size: 37, Momentum: 5.784e-01\n",
      "best loss: 1087.75\t\tLearning rate: 1.438e-02, Batch size: 32, Momentum: 8.413e-01\n",
      "best loss: 1087.96\t\tLearning rate: 1.438e-02, Batch size: 34, Momentum: 6.835e-01\n",
      "best loss: 1088.27\t\tLearning rate: 4.281e-02, Batch size: 39, Momentum: 8.413e-01\n",
      "best loss: 1088.53\t\tLearning rate: 4.281e-02, Batch size: 29, Momentum: 2.629e-01\n",
      "best loss: 1089.81\t\tLearning rate: 4.281e-02, Batch size: 14, Momentum: 3.681e-01\n",
      "best loss: 1092.80\t\tLearning rate: 4.281e-02, Batch size: 50, Momentum: 7.361e-01\n",
      "best loss: 1094.42\t\tLearning rate: 4.281e-02, Batch size: 12, Momentum: 5.258e-01\n",
      "best loss: 1094.70\t\tLearning rate: 4.281e-02, Batch size: 4, Momentum: 8.938e-01\n",
      "best loss: 1096.31\t\tLearning rate: 1.274e-01, Batch size: 22, Momentum: 1.577e-01\n",
      "best loss: 1096.76\t\tLearning rate: 1.438e-02, Batch size: 14, Momentum: 8.413e-01\n",
      "best loss: 1100.19\t\tLearning rate: 1.274e-01, Batch size: 42, Momentum: 1.577e-01\n",
      "best loss: 1101.17\t\tLearning rate: 4.281e-02, Batch size: 12, Momentum: 7.361e-01\n",
      "best loss: 1101.63\t\tLearning rate: 1.274e-01, Batch size: 2, Momentum: 5.258e-01\n",
      "best loss: 1103.76\t\tLearning rate: 1.274e-01, Batch size: 14, Momentum: 1.577e-01\n",
      "best loss: 1105.07\t\tLearning rate: 8.859e-08, Batch size: 39, Momentum: 1.577e-01\n",
      "best loss: 1106.92\t\tLearning rate: 1.274e-01, Batch size: 39, Momentum: 2.103e-01\n",
      "best loss: 1108.78\t\tLearning rate: 1.274e-01, Batch size: 2, Momentum: 2.103e-01\n",
      "best loss: 1111.88\t\tLearning rate: 4.281e-02, Batch size: 34, Momentum: 8.938e-01\n",
      "best loss: 1113.88\t\tLearning rate: 1.274e-01, Batch size: 34, Momentum: 3.155e-01\n",
      "best loss: 1113.92\t\tLearning rate: 4.281e-02, Batch size: 9, Momentum: 6.835e-01\n",
      "best loss: 1114.08\t\tLearning rate: 1.274e-01, Batch size: 37, Momentum: 1.577e-01\n",
      "best loss: 1115.17\t\tLearning rate: 4.281e-02, Batch size: 39, Momentum: 7.361e-01\n",
      "best loss: 1115.39\t\tLearning rate: 4.281e-02, Batch size: 42, Momentum: 7.887e-01\n",
      "best loss: 1116.08\t\tLearning rate: 1.274e-01, Batch size: 19, Momentum: 2.103e-01\n",
      "best loss: 1122.59\t\tLearning rate: 1.274e-01, Batch size: 47, Momentum: 5.258e-02\n",
      "best loss: 1129.82\t\tLearning rate: 1.274e-01, Batch size: 17, Momentum: 3.681e-01\n",
      "best loss: 1130.79\t\tLearning rate: 1.274e-01, Batch size: 14, Momentum: 2.103e-01\n",
      "best loss: 1131.95\t\tLearning rate: 1.274e-01, Batch size: 42, Momentum: 4.732e-01\n",
      "best loss: 1135.11\t\tLearning rate: 1.274e-01, Batch size: 32, Momentum: 1.577e-01\n",
      "best loss: 1135.22\t\tLearning rate: 1.274e-01, Batch size: 37, Momentum: 3.155e-01\n",
      "best loss: 1136.21\t\tLearning rate: 1.274e-01, Batch size: 14, Momentum: 5.258e-01\n",
      "best loss: 1138.55\t\tLearning rate: 4.281e-02, Batch size: 42, Momentum: 5.784e-01\n",
      "best loss: 1138.84\t\tLearning rate: 3.793e-01, Batch size: 9, Momentum: 3.681e-01\n",
      "best loss: 1139.90\t\tLearning rate: 4.281e-02, Batch size: 9, Momentum: 8.938e-01\n",
      "best loss: 1140.61\t\tLearning rate: 1.274e-01, Batch size: 19, Momentum: 4.732e-01\n",
      "best loss: 1141.22\t\tLearning rate: 4.281e-02, Batch size: 27, Momentum: 8.938e-01\n",
      "best loss: 1141.42\t\tLearning rate: 1.274e-01, Batch size: 27, Momentum: 6.309e-01\n",
      "best loss: 1144.10\t\tLearning rate: 3.793e-01, Batch size: 50, Momentum: 1.577e-01\n",
      "best loss: 1144.87\t\tLearning rate: 3.793e-01, Batch size: 7, Momentum: 2.629e-01\n",
      "best loss: 1146.54\t\tLearning rate: 4.281e-02, Batch size: 32, Momentum: 9.464e-01\n",
      "best loss: 1146.67\t\tLearning rate: 1.274e-01, Batch size: 17, Momentum: 5.784e-01\n",
      "best loss: 1146.78\t\tLearning rate: 3.793e-01, Batch size: 2, Momentum: 2.629e-01\n",
      "best loss: 1146.91\t\tLearning rate: 1.274e-01, Batch size: 24, Momentum: 4.206e-01\n",
      "best loss: 1150.22\t\tLearning rate: 4.281e-02, Batch size: 2, Momentum: 7.887e-01\n",
      "best loss: 1151.72\t\tLearning rate: 3.793e-01, Batch size: 2, Momentum: 3.681e-01\n",
      "best loss: 1153.22\t\tLearning rate: 3.793e-01, Batch size: 19, Momentum: 2.629e-01\n",
      "best loss: 1155.68\t\tLearning rate: 2.637e-07, Batch size: 47, Momentum: 0.000e+00\n",
      "best loss: 1156.60\t\tLearning rate: 4.281e-02, Batch size: 37, Momentum: 8.413e-01\n",
      "best loss: 1158.71\t\tLearning rate: 1.438e-02, Batch size: 2, Momentum: 9.464e-01\n",
      "best loss: 1164.20\t\tLearning rate: 3.793e-01, Batch size: 50, Momentum: 2.629e-01\n",
      "best loss: 1167.76\t\tLearning rate: 1.274e-01, Batch size: 50, Momentum: 4.206e-01\n",
      "best loss: 1169.29\t\tLearning rate: 3.793e-01, Batch size: 39, Momentum: 2.103e-01\n",
      "best loss: 1170.17\t\tLearning rate: 3.793e-01, Batch size: 2, Momentum: 4.732e-01\n",
      "best loss: 1170.52\t\tLearning rate: 3.793e-01, Batch size: 14, Momentum: 7.887e-01\n",
      "best loss: 1170.86\t\tLearning rate: 1.274e-01, Batch size: 12, Momentum: 7.361e-01\n",
      "best loss: 1174.09\t\tLearning rate: 3.793e-01, Batch size: 29, Momentum: 3.155e-01\n",
      "best loss: 1175.40\t\tLearning rate: 4.281e-02, Batch size: 37, Momentum: 8.938e-01\n",
      "best loss: 1176.95\t\tLearning rate: 3.793e-01, Batch size: 17, Momentum: 2.629e-01\n",
      "best loss: 1177.01\t\tLearning rate: 3.793e-01, Batch size: 27, Momentum: 2.103e-01\n",
      "best loss: 1179.25\t\tLearning rate: 3.793e-01, Batch size: 9, Momentum: 1.577e-01\n",
      "best loss: 1179.50\t\tLearning rate: 3.793e-01, Batch size: 9, Momentum: 2.103e-01\n",
      "best loss: 1179.54\t\tLearning rate: 1.274e-01, Batch size: 34, Momentum: 7.361e-01\n",
      "best loss: 1180.42\t\tLearning rate: 3.793e-01, Batch size: 50, Momentum: 3.681e-01\n",
      "best loss: 1184.25\t\tLearning rate: 1.274e-01, Batch size: 47, Momentum: 5.784e-01\n",
      "best loss: 1184.57\t\tLearning rate: 3.793e-01, Batch size: 7, Momentum: 3.681e-01\n",
      "best loss: 1189.53\t\tLearning rate: 1.129e+00, Batch size: 22, Momentum: 1.052e-01\n",
      "best loss: 1190.17\t\tLearning rate: 1.274e-01, Batch size: 4, Momentum: 8.413e-01\n",
      "best loss: 1191.42\t\tLearning rate: 1.129e+00, Batch size: 44, Momentum: 2.103e-01\n",
      "best loss: 1193.61\t\tLearning rate: 1.274e-01, Batch size: 24, Momentum: 8.413e-01\n",
      "best loss: 1197.10\t\tLearning rate: 3.793e-01, Batch size: 22, Momentum: 6.309e-01\n",
      "best loss: 1199.39\t\tLearning rate: 3.793e-01, Batch size: 7, Momentum: 4.206e-01\n",
      "best loss: 1200.15\t\tLearning rate: 1.274e-01, Batch size: 12, Momentum: 9.464e-01\n",
      "best loss: 1205.06\t\tLearning rate: 3.793e-01, Batch size: 42, Momentum: 2.103e-01\n",
      "best loss: 1205.85\t\tLearning rate: 1.129e+00, Batch size: 4, Momentum: 0.000e+00\n",
      "best loss: 1207.95\t\tLearning rate: 3.793e-01, Batch size: 7, Momentum: 6.835e-01\n",
      "best loss: 1208.00\t\tLearning rate: 1.129e+00, Batch size: 29, Momentum: 5.258e-02\n",
      "best loss: 1209.07\t\tLearning rate: 1.274e-01, Batch size: 22, Momentum: 8.413e-01\n",
      "best loss: 1209.21\t\tLearning rate: 3.793e-01, Batch size: 4, Momentum: 4.732e-01\n",
      "best loss: 1210.29\t\tLearning rate: 1.129e+00, Batch size: 12, Momentum: 2.103e-01\n",
      "best loss: 1211.86\t\tLearning rate: 1.129e+00, Batch size: 4, Momentum: 4.206e-01\n",
      "best loss: 1213.08\t\tLearning rate: 1.129e+00, Batch size: 39, Momentum: 0.000e+00\n",
      "best loss: 1213.47\t\tLearning rate: 1.274e-01, Batch size: 19, Momentum: 9.464e-01\n",
      "best loss: 1213.47\t\tLearning rate: 1.129e+00, Batch size: 9, Momentum: 2.103e-01\n",
      "best loss: 1215.01\t\tLearning rate: 1.274e-01, Batch size: 9, Momentum: 7.887e-01\n",
      "best loss: 1215.12\t\tLearning rate: 3.793e-01, Batch size: 24, Momentum: 5.258e-01\n",
      "best loss: 1215.65\t\tLearning rate: 3.793e-01, Batch size: 34, Momentum: 4.732e-01\n",
      "best loss: 1216.80\t\tLearning rate: 1.129e+00, Batch size: 24, Momentum: 1.577e-01\n",
      "best loss: 1216.89\t\tLearning rate: 1.129e+00, Batch size: 42, Momentum: 1.052e-01\n",
      "best loss: 1223.70\t\tLearning rate: 1.129e+00, Batch size: 42, Momentum: 3.681e-01\n",
      "best loss: 1223.84\t\tLearning rate: 1.274e-01, Batch size: 2, Momentum: 8.938e-01\n",
      "best loss: 1224.02\t\tLearning rate: 1.129e+00, Batch size: 32, Momentum: 5.258e-01\n",
      "best loss: 1225.37\t\tLearning rate: 3.793e-01, Batch size: 9, Momentum: 7.361e-01\n",
      "best loss: 1226.12\t\tLearning rate: 3.793e-01, Batch size: 47, Momentum: 6.309e-01\n",
      "best loss: 1228.72\t\tLearning rate: 1.000e-08, Batch size: 47, Momentum: 1.577e-01\n",
      "best loss: 1229.78\t\tLearning rate: 1.129e+00, Batch size: 9, Momentum: 6.835e-01\n",
      "best loss: 1229.93\t\tLearning rate: 1.129e+00, Batch size: 29, Momentum: 3.155e-01\n",
      "best loss: 1231.67\t\tLearning rate: 1.129e+00, Batch size: 44, Momentum: 3.155e-01\n",
      "best loss: 1231.83\t\tLearning rate: 1.129e+00, Batch size: 24, Momentum: 3.155e-01\n",
      "best loss: 1233.71\t\tLearning rate: 3.793e-01, Batch size: 32, Momentum: 1.052e-01\n",
      "best loss: 1236.26\t\tLearning rate: 3.360e+00, Batch size: 7, Momentum: 1.052e-01\n",
      "best loss: 1236.75\t\tLearning rate: 1.129e+00, Batch size: 34, Momentum: 3.155e-01\n",
      "best loss: 1237.78\t\tLearning rate: 3.360e+00, Batch size: 44, Momentum: 5.258e-02\n",
      "best loss: 1238.09\t\tLearning rate: 1.129e+00, Batch size: 7, Momentum: 3.155e-01\n",
      "best loss: 1239.29\t\tLearning rate: 1.129e+00, Batch size: 7, Momentum: 6.309e-01\n",
      "best loss: 1239.65\t\tLearning rate: 1.129e+00, Batch size: 19, Momentum: 4.206e-01\n",
      "best loss: 1239.96\t\tLearning rate: 1.129e+00, Batch size: 47, Momentum: 4.732e-01\n",
      "best loss: 1241.29\t\tLearning rate: 1.274e-01, Batch size: 19, Momentum: 8.938e-01\n",
      "best loss: 1241.69\t\tLearning rate: 1.274e-01, Batch size: 14, Momentum: 9.990e-01\n",
      "best loss: 1241.79\t\tLearning rate: 1.129e+00, Batch size: 7, Momentum: 4.206e-01\n",
      "best loss: 1243.39\t\tLearning rate: 1.129e+00, Batch size: 47, Momentum: 5.258e-01\n",
      "best loss: 1244.54\t\tLearning rate: 1.129e+00, Batch size: 47, Momentum: 1.577e-01\n",
      "best loss: 1245.43\t\tLearning rate: 3.793e-01, Batch size: 32, Momentum: 8.413e-01\n",
      "best loss: 1245.56\t\tLearning rate: 3.793e-01, Batch size: 29, Momentum: 5.784e-01\n",
      "best loss: 1246.51\t\tLearning rate: 3.360e+00, Batch size: 22, Momentum: 0.000e+00\n",
      "best loss: 1247.27\t\tLearning rate: 1.129e+00, Batch size: 32, Momentum: 4.206e-01\n",
      "best loss: 1248.63\t\tLearning rate: 3.360e+00, Batch size: 19, Momentum: 0.000e+00\n",
      "best loss: 1249.40\t\tLearning rate: 3.793e-01, Batch size: 2, Momentum: 9.464e-01\n",
      "best loss: 1249.68\t\tLearning rate: 3.360e+00, Batch size: 47, Momentum: 5.258e-02\n",
      "best loss: 1250.52\t\tLearning rate: 3.360e+00, Batch size: 12, Momentum: 4.732e-01\n",
      "best loss: 1256.64\t\tLearning rate: 3.360e+00, Batch size: 7, Momentum: 2.629e-01\n",
      "best loss: 1257.27\t\tLearning rate: 3.793e-01, Batch size: 19, Momentum: 9.990e-01\n",
      "best loss: 1260.44\t\tLearning rate: 1.129e+00, Batch size: 17, Momentum: 7.361e-01\n",
      "best loss: 1260.51\t\tLearning rate: 3.360e+00, Batch size: 44, Momentum: 2.629e-01\n",
      "best loss: 1261.08\t\tLearning rate: 1.129e+00, Batch size: 19, Momentum: 4.732e-01\n",
      "best loss: 1261.33\t\tLearning rate: 3.360e+00, Batch size: 4, Momentum: 0.000e+00\n",
      "best loss: 1264.39\t\tLearning rate: 1.129e+00, Batch size: 12, Momentum: 5.258e-01\n",
      "best loss: 1264.55\t\tLearning rate: 3.793e-01, Batch size: 44, Momentum: 8.413e-01\n",
      "best loss: 1265.68\t\tLearning rate: 3.793e-01, Batch size: 9, Momentum: 8.413e-01\n",
      "best loss: 1268.82\t\tLearning rate: 1.129e+00, Batch size: 7, Momentum: 5.258e-01\n",
      "best loss: 1275.44\t\tLearning rate: 3.360e+00, Batch size: 29, Momentum: 5.258e-02\n",
      "best loss: 1278.22\t\tLearning rate: 3.360e+00, Batch size: 32, Momentum: 2.629e-01\n",
      "best loss: 1280.22\t\tLearning rate: 3.360e+00, Batch size: 34, Momentum: 2.103e-01\n",
      "best loss: 1281.65\t\tLearning rate: 3.360e+00, Batch size: 29, Momentum: 3.681e-01\n",
      "best loss: 1282.47\t\tLearning rate: 1.129e+00, Batch size: 34, Momentum: 7.361e-01\n",
      "best loss: 1284.59\t\tLearning rate: 3.793e-01, Batch size: 4, Momentum: 8.938e-01\n",
      "best loss: 1288.46\t\tLearning rate: 3.360e+00, Batch size: 9, Momentum: 4.206e-01\n",
      "best loss: 1289.63\t\tLearning rate: 1.000e+01, Batch size: 37, Momentum: 1.052e-01\n",
      "best loss: 1289.76\t\tLearning rate: 3.360e+00, Batch size: 22, Momentum: 1.577e-01\n",
      "best loss: 1290.22\t\tLearning rate: 1.000e+01, Batch size: 50, Momentum: 5.258e-02\n",
      "best loss: 1291.43\t\tLearning rate: 3.360e+00, Batch size: 22, Momentum: 3.155e-01\n",
      "best loss: 1297.20\t\tLearning rate: 3.360e+00, Batch size: 39, Momentum: 4.732e-01\n",
      "best loss: 1297.42\t\tLearning rate: 1.129e+00, Batch size: 12, Momentum: 7.361e-01\n",
      "best loss: 1297.96\t\tLearning rate: 3.360e+00, Batch size: 27, Momentum: 4.206e-01\n",
      "best loss: 1299.88\t\tLearning rate: 3.360e+00, Batch size: 27, Momentum: 6.309e-01\n",
      "best loss: 1299.92\t\tLearning rate: 1.129e+00, Batch size: 50, Momentum: 6.835e-01\n",
      "best loss: 1300.70\t\tLearning rate: 1.000e+01, Batch size: 19, Momentum: 1.052e-01\n",
      "best loss: 1303.23\t\tLearning rate: 1.000e+01, Batch size: 47, Momentum: 0.000e+00\n",
      "best loss: 1305.53\t\tLearning rate: 1.129e+00, Batch size: 32, Momentum: 9.990e-01\n",
      "best loss: 1305.74\t\tLearning rate: 3.360e+00, Batch size: 29, Momentum: 2.629e-01\n",
      "best loss: 1309.01\t\tLearning rate: 3.360e+00, Batch size: 12, Momentum: 6.835e-01\n",
      "best loss: 1309.29\t\tLearning rate: 3.360e+00, Batch size: 37, Momentum: 3.681e-01\n",
      "best loss: 1311.39\t\tLearning rate: 1.129e+00, Batch size: 22, Momentum: 8.413e-01\n",
      "best loss: 1311.94\t\tLearning rate: 3.360e+00, Batch size: 39, Momentum: 6.309e-01\n",
      "best loss: 1312.37\t\tLearning rate: 1.000e+01, Batch size: 7, Momentum: 2.103e-01\n",
      "best loss: 1313.01\t\tLearning rate: 3.793e-01, Batch size: 39, Momentum: 9.464e-01\n",
      "best loss: 1313.84\t\tLearning rate: 3.360e+00, Batch size: 9, Momentum: 2.629e-01\n",
      "best loss: 1313.88\t\tLearning rate: 3.793e-01, Batch size: 37, Momentum: 9.990e-01\n",
      "best loss: 1315.57\t\tLearning rate: 3.360e+00, Batch size: 47, Momentum: 6.835e-01\n",
      "best loss: 1315.68\t\tLearning rate: 1.000e+01, Batch size: 37, Momentum: 1.577e-01\n",
      "best loss: 1315.78\t\tLearning rate: 3.360e+00, Batch size: 24, Momentum: 4.206e-01\n",
      "best loss: 1325.94\t\tLearning rate: 1.000e+01, Batch size: 39, Momentum: 2.103e-01\n",
      "best loss: 1326.84\t\tLearning rate: 1.000e+01, Batch size: 47, Momentum: 3.681e-01\n",
      "best loss: 1326.88\t\tLearning rate: 3.360e+00, Batch size: 7, Momentum: 6.835e-01\n",
      "best loss: 1328.52\t\tLearning rate: 1.000e+01, Batch size: 39, Momentum: 2.629e-01\n",
      "best loss: 1328.95\t\tLearning rate: 3.360e+00, Batch size: 44, Momentum: 5.784e-01\n",
      "best loss: 1329.99\t\tLearning rate: 3.360e+00, Batch size: 27, Momentum: 5.258e-01\n",
      "best loss: 1330.54\t\tLearning rate: 1.000e+01, Batch size: 37, Momentum: 4.206e-01\n",
      "best loss: 1331.09\t\tLearning rate: 3.360e+00, Batch size: 22, Momentum: 7.361e-01\n",
      "best loss: 1332.62\t\tLearning rate: 3.360e+00, Batch size: 29, Momentum: 6.835e-01\n",
      "best loss: 1337.00\t\tLearning rate: 1.129e+00, Batch size: 22, Momentum: 9.464e-01\n",
      "best loss: 1339.10\t\tLearning rate: 3.360e+00, Batch size: 2, Momentum: 4.206e-01\n",
      "best loss: 1340.87\t\tLearning rate: 3.360e+00, Batch size: 19, Momentum: 8.413e-01\n",
      "best loss: 1341.84\t\tLearning rate: 1.000e+01, Batch size: 12, Momentum: 1.577e-01\n",
      "best loss: 1341.96\t\tLearning rate: 3.360e+00, Batch size: 12, Momentum: 7.361e-01\n",
      "best loss: 1343.65\t\tLearning rate: 1.129e+00, Batch size: 24, Momentum: 8.413e-01\n",
      "best loss: 1344.13\t\tLearning rate: 1.129e+00, Batch size: 47, Momentum: 8.938e-01\n",
      "best loss: 1344.39\t\tLearning rate: 1.000e+01, Batch size: 4, Momentum: 3.681e-01\n",
      "best loss: 1345.80\t\tLearning rate: 3.360e+00, Batch size: 34, Momentum: 9.990e-01\n",
      "best loss: 1346.89\t\tLearning rate: 1.000e+01, Batch size: 34, Momentum: 3.681e-01\n",
      "best loss: 1347.31\t\tLearning rate: 1.000e+01, Batch size: 32, Momentum: 3.155e-01\n",
      "best loss: 1349.07\t\tLearning rate: 3.360e+00, Batch size: 37, Momentum: 6.309e-01\n",
      "best loss: 1349.67\t\tLearning rate: 3.360e+00, Batch size: 32, Momentum: 6.309e-01\n",
      "best loss: 1351.17\t\tLearning rate: 1.000e-08, Batch size: 24, Momentum: 3.681e-01\n",
      "best loss: 1356.80\t\tLearning rate: 1.000e+01, Batch size: 2, Momentum: 4.732e-01\n",
      "best loss: 1356.82\t\tLearning rate: 3.360e+00, Batch size: 44, Momentum: 8.938e-01\n",
      "best loss: 1357.00\t\tLearning rate: 3.360e+00, Batch size: 2, Momentum: 9.990e-01\n",
      "best loss: 1357.11\t\tLearning rate: 3.360e+00, Batch size: 50, Momentum: 6.309e-01\n",
      "best loss: 1357.69\t\tLearning rate: 3.360e+00, Batch size: 50, Momentum: 7.887e-01\n",
      "best loss: 1358.34\t\tLearning rate: 1.129e+00, Batch size: 24, Momentum: 9.990e-01\n",
      "best loss: 1361.13\t\tLearning rate: 1.000e+01, Batch size: 44, Momentum: 4.732e-01\n",
      "best loss: 1364.07\t\tLearning rate: 1.000e+01, Batch size: 19, Momentum: 2.103e-01\n",
      "best loss: 1364.23\t\tLearning rate: 1.000e+01, Batch size: 32, Momentum: 5.258e-01\n",
      "best loss: 1365.45\t\tLearning rate: 1.000e+01, Batch size: 47, Momentum: 2.629e-01\n",
      "best loss: 1368.29\t\tLearning rate: 1.000e+01, Batch size: 4, Momentum: 5.784e-01\n",
      "best loss: 1369.51\t\tLearning rate: 3.360e+00, Batch size: 29, Momentum: 9.464e-01\n",
      "best loss: 1369.79\t\tLearning rate: 1.129e+00, Batch size: 29, Momentum: 9.990e-01\n",
      "best loss: 1370.08\t\tLearning rate: 3.360e+00, Batch size: 17, Momentum: 7.887e-01\n",
      "best loss: 1374.99\t\tLearning rate: 1.000e+01, Batch size: 39, Momentum: 5.784e-01\n",
      "best loss: 1376.86\t\tLearning rate: 1.000e+01, Batch size: 50, Momentum: 5.784e-01\n",
      "best loss: 1379.49\t\tLearning rate: 1.000e+01, Batch size: 37, Momentum: 4.732e-01\n",
      "best loss: 1379.95\t\tLearning rate: 1.000e+01, Batch size: 42, Momentum: 4.206e-01\n",
      "best loss: 1380.20\t\tLearning rate: 3.360e+00, Batch size: 14, Momentum: 7.887e-01\n",
      "best loss: 1386.31\t\tLearning rate: 1.000e+01, Batch size: 44, Momentum: 6.309e-01\n",
      "best loss: 1394.69\t\tLearning rate: 1.000e+01, Batch size: 39, Momentum: 6.309e-01\n",
      "best loss: 1395.45\t\tLearning rate: 1.000e+01, Batch size: 29, Momentum: 6.309e-01\n",
      "best loss: 1400.13\t\tLearning rate: 3.360e+00, Batch size: 22, Momentum: 8.413e-01\n",
      "best loss: 1403.64\t\tLearning rate: 1.000e+01, Batch size: 29, Momentum: 8.413e-01\n",
      "best loss: 1405.02\t\tLearning rate: 3.360e+00, Batch size: 14, Momentum: 9.464e-01\n",
      "best loss: 1406.89\t\tLearning rate: 1.000e+01, Batch size: 14, Momentum: 3.155e-01\n",
      "best loss: 1409.59\t\tLearning rate: 3.360e+00, Batch size: 44, Momentum: 9.990e-01\n",
      "best loss: 1410.58\t\tLearning rate: 3.360e+00, Batch size: 22, Momentum: 9.990e-01\n",
      "best loss: 1416.20\t\tLearning rate: 1.000e+01, Batch size: 27, Momentum: 7.887e-01\n",
      "best loss: 1416.33\t\tLearning rate: 1.000e+01, Batch size: 12, Momentum: 8.413e-01\n",
      "best loss: 1422.02\t\tLearning rate: 8.859e-08, Batch size: 4, Momentum: 1.577e-01\n",
      "best loss: 1426.83\t\tLearning rate: 1.000e+01, Batch size: 44, Momentum: 8.938e-01\n",
      "best loss: 1432.37\t\tLearning rate: 1.000e+01, Batch size: 37, Momentum: 8.938e-01\n",
      "best loss: 1447.27\t\tLearning rate: 1.000e+01, Batch size: 24, Momentum: 9.464e-01\n",
      "best loss: 1460.12\t\tLearning rate: 1.000e+01, Batch size: 2, Momentum: 8.938e-01\n",
      "best loss: 1595.63\t\tLearning rate: 1.000e-08, Batch size: 50, Momentum: 5.258e-01\n",
      "best loss: 1638.48\t\tLearning rate: 2.976e-08, Batch size: 42, Momentum: 1.052e-01\n",
      "best loss: 1685.15\t\tLearning rate: 2.069e-05, Batch size: 39, Momentum: 5.258e-01\n",
      "best loss: 2828.88\t\tLearning rate: 2.637e-07, Batch size: 27, Momentum: 5.258e-02\n",
      "best loss: 3399.05\t\tLearning rate: 1.000e-08, Batch size: 39, Momentum: 1.577e-01\n",
      "best loss: 3681.10\t\tLearning rate: 1.000e-08, Batch size: 29, Momentum: 1.052e-01\n",
      "best loss: 4382.84\t\tLearning rate: 1.129e+00, Batch size: 4, Momentum: 2.103e-01\n",
      "best loss: 6211.74\t\tLearning rate: 8.859e-08, Batch size: 4, Momentum: 5.258e-02\n",
      "best loss: 12938.69\t\tLearning rate: 2.976e-08, Batch size: 4, Momentum: 3.155e-01\n",
      "best loss: 15457.30\t\tLearning rate: 2.976e-08, Batch size: 4, Momentum: 5.258e-01\n",
      "best loss: 18872.60\t\tLearning rate: 2.637e-07, Batch size: 7, Momentum: 3.155e-01\n",
      "best loss: 22153.52\t\tLearning rate: 7.848e-07, Batch size: 9, Momentum: 5.258e-01\n",
      "best loss: 26470.69\t\tLearning rate: 2.976e-08, Batch size: 22, Momentum: 4.732e-01\n",
      "best loss: 29604.84\t\tLearning rate: 7.848e-07, Batch size: 50, Momentum: 3.681e-01\n",
      "best loss: 30181.32\t\tLearning rate: 2.637e-07, Batch size: 22, Momentum: 5.784e-01\n",
      "best loss: 30941.47\t\tLearning rate: 1.000e+01, Batch size: 7, Momentum: 2.629e-01\n",
      "best loss: 31332.00\t\tLearning rate: 6.158e-05, Batch size: 22, Momentum: 0.000e+00\n",
      "best loss: 31560.00\t\tLearning rate: 8.859e-08, Batch size: 42, Momentum: 7.361e-01\n",
      "best loss: 32615.09\t\tLearning rate: 1.000e-08, Batch size: 17, Momentum: 5.258e-02\n",
      "best loss: 33895.40\t\tLearning rate: 8.859e-08, Batch size: 47, Momentum: 2.629e-01\n",
      "best loss: 38392.33\t\tLearning rate: 1.000e-08, Batch size: 50, Momentum: 7.361e-01\n",
      "best loss: 38697.91\t\tLearning rate: 1.000e-08, Batch size: 24, Momentum: 1.052e-01\n",
      "best loss: 39160.87\t\tLearning rate: 3.793e-01, Batch size: 34, Momentum: 0.000e+00\n",
      "best loss: 50351.91\t\tLearning rate: 1.000e-08, Batch size: 47, Momentum: 0.000e+00\n",
      "best loss: 50564.41\t\tLearning rate: 1.000e-08, Batch size: 39, Momentum: 3.155e-01\n",
      "best loss: 53325.47\t\tLearning rate: 2.637e-07, Batch size: 32, Momentum: 2.629e-01\n",
      "best loss: 54165.33\t\tLearning rate: 8.859e-08, Batch size: 14, Momentum: 1.577e-01\n",
      "best loss: 55033.64\t\tLearning rate: 2.976e-08, Batch size: 22, Momentum: 7.361e-01\n",
      "best loss: 55038.09\t\tLearning rate: 8.859e-08, Batch size: 24, Momentum: 4.732e-01\n",
      "best loss: 56757.34\t\tLearning rate: 1.833e-04, Batch size: 37, Momentum: 1.052e-01\n",
      "best loss: 58681.16\t\tLearning rate: 1.000e-08, Batch size: 17, Momentum: 1.577e-01\n",
      "best loss: 60186.27\t\tLearning rate: 1.000e-08, Batch size: 44, Momentum: 8.413e-01\n",
      "best loss: 61214.26\t\tLearning rate: 8.859e-08, Batch size: 24, Momentum: 2.629e-01\n",
      "best loss: 61612.37\t\tLearning rate: 1.000e-08, Batch size: 29, Momentum: 0.000e+00\n",
      "best loss: 63074.09\t\tLearning rate: 2.976e-08, Batch size: 39, Momentum: 1.577e-01\n",
      "best loss: 68995.53\t\tLearning rate: 1.000e-08, Batch size: 19, Momentum: 4.206e-01\n",
      "best loss: 71069.01\t\tLearning rate: 1.000e-08, Batch size: 50, Momentum: 8.413e-01\n",
      "best loss: 71962.97\t\tLearning rate: 2.976e-08, Batch size: 19, Momentum: 2.103e-01\n",
      "best loss: 74946.08\t\tLearning rate: 2.637e-07, Batch size: 39, Momentum: 1.577e-01\n",
      "best loss: 75031.16\t\tLearning rate: 2.637e-07, Batch size: 32, Momentum: 6.309e-01\n",
      "best loss: 78979.63\t\tLearning rate: 1.000e-08, Batch size: 37, Momentum: 7.361e-01\n",
      "best loss: 85056.45\t\tLearning rate: 8.859e-08, Batch size: 44, Momentum: 6.309e-01\n",
      "best loss: 87656.31\t\tLearning rate: 1.000e-08, Batch size: 37, Momentum: 3.681e-01\n",
      "best loss: 88337.08\t\tLearning rate: 2.637e-07, Batch size: 32, Momentum: 4.732e-01\n",
      "best loss: 89566.20\t\tLearning rate: 1.000e+01, Batch size: 22, Momentum: 0.000e+00\n",
      "best loss: 89583.66\t\tLearning rate: 1.000e-08, Batch size: 37, Momentum: 2.629e-01\n",
      "best loss: 91511.20\t\tLearning rate: 8.859e-08, Batch size: 24, Momentum: 3.155e-01\n",
      "best loss: 92753.86\t\tLearning rate: 1.000e+01, Batch size: 14, Momentum: 2.103e-01\n",
      "best loss: 92994.19\t\tLearning rate: 1.000e-08, Batch size: 27, Momentum: 5.258e-01\n",
      "best loss: 95197.97\t\tLearning rate: 2.976e-08, Batch size: 32, Momentum: 0.000e+00\n",
      "best loss: 104526.56\t\tLearning rate: 8.859e-08, Batch size: 47, Momentum: 7.361e-01\n",
      "best loss: 104582.81\t\tLearning rate: 1.000e-08, Batch size: 42, Momentum: 2.103e-01\n",
      "best loss: 104996.37\t\tLearning rate: 1.000e-08, Batch size: 2, Momentum: 2.629e-01\n",
      "best loss: 108135.68\t\tLearning rate: 4.833e-03, Batch size: 37, Momentum: 2.103e-01\n",
      "best loss: 117959.71\t\tLearning rate: 1.000e-08, Batch size: 24, Momentum: 3.155e-01\n",
      "best loss: 122982.33\t\tLearning rate: 1.833e-04, Batch size: 29, Momentum: 1.052e-01\n",
      "best loss: 129780.39\t\tLearning rate: 4.833e-03, Batch size: 34, Momentum: 1.052e-01\n",
      "best loss: 150883.87\t\tLearning rate: 2.637e-07, Batch size: 42, Momentum: 5.258e-02\n",
      "best loss: 157669.67\t\tLearning rate: 1.000e-08, Batch size: 19, Momentum: 5.258e-01\n",
      "best loss: 160255.71\t\tLearning rate: 2.637e-07, Batch size: 14, Momentum: 1.052e-01\n",
      "best loss: 161389.66\t\tLearning rate: 2.336e-06, Batch size: 34, Momentum: 4.732e-01\n",
      "best loss: 162376.57\t\tLearning rate: 2.976e-08, Batch size: 22, Momentum: 6.309e-01\n",
      "best loss: 181934.00\t\tLearning rate: 5.456e-04, Batch size: 50, Momentum: 5.258e-02\n",
      "best loss: 201592.60\t\tLearning rate: 2.637e-07, Batch size: 24, Momentum: 2.629e-01\n",
      "best loss: 214387.48\t\tLearning rate: 2.976e-08, Batch size: 39, Momentum: 5.258e-02\n",
      "best loss: 258346.63\t\tLearning rate: 1.274e-01, Batch size: 17, Momentum: 0.000e+00\n",
      "best loss: 315889.03\t\tLearning rate: 2.976e-08, Batch size: 42, Momentum: 1.577e-01\n",
      "best loss: 371561.95\t\tLearning rate: 4.833e-03, Batch size: 37, Momentum: 5.258e-02\n",
      "best loss: 417769.41\t\tLearning rate: 4.833e-03, Batch size: 50, Momentum: 0.000e+00\n",
      "best loss: 497298.57\t\tLearning rate: 5.456e-04, Batch size: 17, Momentum: 0.000e+00\n",
      "best loss: 731292.35\t\tLearning rate: 4.833e-03, Batch size: 27, Momentum: 2.629e-01\n",
      "best loss: 816671.59\t\tLearning rate: 1.438e-02, Batch size: 19, Momentum: 0.000e+00\n",
      "best loss: 838912.13\t\tLearning rate: 1.624e-03, Batch size: 44, Momentum: 1.052e-01\n",
      "best loss: 871169.13\t\tLearning rate: 3.793e-01, Batch size: 50, Momentum: 0.000e+00\n",
      "best loss: 10508472.68\t\tLearning rate: 3.793e-01, Batch size: 9, Momentum: 5.258e-02\n"
     ]
    }
   ],
   "source": [
    "# print the hyperparameters ranked from best to worst\n",
    "sorted_results = sorted(results.items(), key=lambda x: x[1])\n",
    "for hp, loss in sorted_results:\n",
    "    print(f\"best loss: {loss:.2f}\\t\\tLearning rate: {hp[0]:.3e}, Batch size: {hp[1]}, Momentum: {hp[2]:.3e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phenotypes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
