{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Opening BSCCM\n",
      "Opened BSCCM\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# this only works on startup!\n",
    "from jax import config\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '3'\n",
    "from encoding_information.gpu_utils import limit_gpu_memory_growth\n",
    "limit_gpu_memory_growth()\n",
    "\n",
    "from cleanplots import *\n",
    "from tqdm import tqdm\n",
    "from encoding_information.information_estimation import *\n",
    "from encoding_information.image_utils import *\n",
    "from encoding_information.bsccm_utils import *\n",
    "from bsccm import BSCCM\n",
    "from jax import jit\n",
    "import numpy as onp\n",
    "import jax.numpy as np\n",
    "\n",
    "bsccm = BSCCM('/home/hpinkard_waller/data/BSCCM/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MI vs num photons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hpinkard_waller/GitRepos/EncodingInformation/encoding_information/information_estimation.py:203: UserWarning: Mean pixel value is 19.87. More accurate results can probably be obtainedby setting estimate_conditional_from_model_samples=True\n",
      "  warnings.warn(f\"Mean pixel value is {np.mean(clean_images_if_available):.2f}. More accurate results can probably be obtained\"\n",
      "/home/hpinkard_waller/GitRepos/EncodingInformation/encoding_information/information_estimation.py:203: UserWarning: Mean pixel value is 19.80. More accurate results can probably be obtainedby setting estimate_conditional_from_model_samples=True\n",
      "  warnings.warn(f\"Mean pixel value is {np.mean(clean_images_if_available):.2f}. More accurate results can probably be obtained\"\n",
      "Running bootstraps: 100%|██████████| 3/3 [00:09<00:00,  3.12s/it]\n",
      "/home/hpinkard_waller/GitRepos/EncodingInformation/encoding_information/information_estimation.py:203: UserWarning: Mean pixel value is 19.88. More accurate results can probably be obtainedby setting estimate_conditional_from_model_samples=True\n",
      "  warnings.warn(f\"Mean pixel value is {np.mean(clean_images_if_available):.2f}. More accurate results can probably be obtained\"\n",
      "Running bootstraps:   0%|          | 0/3 [00:05<?, ?it/s]\n",
      "  0%|          | 0/3 [00:20<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of validation samples must be less than the number of training samples",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/hpinkard_waller/GitRepos/EncodingInformation/mi_estimator_experiments/analytic_gaussian_entropy_vs_test_set_nll.ipynb Cell 3\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B169.229.228.36/home/hpinkard_waller/GitRepos/EncodingInformation/mi_estimator_experiments/analytic_gaussian_entropy_vs_test_set_nll.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m mi_means_by_channel_photons[channel_name]\u001b[39m.\u001b[39mappend(mi_mean)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B169.229.228.36/home/hpinkard_waller/GitRepos/EncodingInformation/mi_estimator_experiments/analytic_gaussian_entropy_vs_test_set_nll.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m mi_confidences_by_channel_photons[channel_name]\u001b[39m.\u001b[39mappend(mi_confidence)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B169.229.228.36/home/hpinkard_waller/GitRepos/EncodingInformation/mi_estimator_experiments/analytic_gaussian_entropy_vs_test_set_nll.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m mi_mean_pixel_cnn, mi_confidence_pixel_cnn \u001b[39m=\u001b[39m run_bootstrap(noisy_patches, num_bootstrap_samples\u001b[39m=\u001b[39;49mnum_bootstrap_samples, confidence_interval\u001b[39m=\u001b[39;49mconfidence_interval,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B169.229.228.36/home/hpinkard_waller/GitRepos/EncodingInformation/mi_estimator_experiments/analytic_gaussian_entropy_vs_test_set_nll.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=41'>42</a>\u001b[0m             estimation_fn\u001b[39m=\u001b[39;49m\u001b[39mlambda\u001b[39;49;00m noisy_images: estimate_mutual_information(noisy_images\u001b[39m=\u001b[39;49mnoisy_images, entropy_model\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mpixel_cnn\u001b[39;49m\u001b[39m'\u001b[39;49m,verbose\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B169.229.228.36/home/hpinkard_waller/GitRepos/EncodingInformation/mi_estimator_experiments/analytic_gaussian_entropy_vs_test_set_nll.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=42'>43</a>\u001b[0m               verbose\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B169.229.228.36/home/hpinkard_waller/GitRepos/EncodingInformation/mi_estimator_experiments/analytic_gaussian_entropy_vs_test_set_nll.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=43'>44</a>\u001b[0m mi_means_by_channel_photons_pixel_cnn[channel_name]\u001b[39m.\u001b[39mappend(mi_mean_pixel_cnn)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B169.229.228.36/home/hpinkard_waller/GitRepos/EncodingInformation/mi_estimator_experiments/analytic_gaussian_entropy_vs_test_set_nll.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=44'>45</a>\u001b[0m mi_confidences_by_channel_photons_pixel_cnn[channel_name]\u001b[39m.\u001b[39mappend(mi_confidence_pixel_cnn)\n",
      "File \u001b[0;32m~/GitRepos/EncodingInformation/encoding_information/information_estimation.py:141\u001b[0m, in \u001b[0;36mrun_bootstrap\u001b[0;34m(data, estimation_fn, num_bootstrap_samples, confidence_interval, seed, verbose)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(data, \u001b[39mdict\u001b[39m):\n\u001b[1;32m    140\u001b[0m     data_sample \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mchoice(subkey, data, shape\u001b[39m=\u001b[39m(N,), replace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 141\u001b[0m     results\u001b[39m.\u001b[39mappend(estimation_fn(data_sample))\n\u001b[1;32m    142\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    143\u001b[0m     data_samples \u001b[39m=\u001b[39m {}\n",
      "\u001b[1;32m/home/hpinkard_waller/GitRepos/EncodingInformation/mi_estimator_experiments/analytic_gaussian_entropy_vs_test_set_nll.ipynb Cell 3\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B169.229.228.36/home/hpinkard_waller/GitRepos/EncodingInformation/mi_estimator_experiments/analytic_gaussian_entropy_vs_test_set_nll.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m mi_means_by_channel_photons[channel_name]\u001b[39m.\u001b[39mappend(mi_mean)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B169.229.228.36/home/hpinkard_waller/GitRepos/EncodingInformation/mi_estimator_experiments/analytic_gaussian_entropy_vs_test_set_nll.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m mi_confidences_by_channel_photons[channel_name]\u001b[39m.\u001b[39mappend(mi_confidence)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B169.229.228.36/home/hpinkard_waller/GitRepos/EncodingInformation/mi_estimator_experiments/analytic_gaussian_entropy_vs_test_set_nll.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m mi_mean_pixel_cnn, mi_confidence_pixel_cnn \u001b[39m=\u001b[39m run_bootstrap(noisy_patches, num_bootstrap_samples\u001b[39m=\u001b[39mnum_bootstrap_samples, confidence_interval\u001b[39m=\u001b[39mconfidence_interval,\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B169.229.228.36/home/hpinkard_waller/GitRepos/EncodingInformation/mi_estimator_experiments/analytic_gaussian_entropy_vs_test_set_nll.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=41'>42</a>\u001b[0m             estimation_fn\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m noisy_images: estimate_mutual_information(noisy_images\u001b[39m=\u001b[39;49mnoisy_images, entropy_model\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mpixel_cnn\u001b[39;49m\u001b[39m'\u001b[39;49m,verbose\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B169.229.228.36/home/hpinkard_waller/GitRepos/EncodingInformation/mi_estimator_experiments/analytic_gaussian_entropy_vs_test_set_nll.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=42'>43</a>\u001b[0m               verbose\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B169.229.228.36/home/hpinkard_waller/GitRepos/EncodingInformation/mi_estimator_experiments/analytic_gaussian_entropy_vs_test_set_nll.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=43'>44</a>\u001b[0m mi_means_by_channel_photons_pixel_cnn[channel_name]\u001b[39m.\u001b[39mappend(mi_mean_pixel_cnn)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B169.229.228.36/home/hpinkard_waller/GitRepos/EncodingInformation/mi_estimator_experiments/analytic_gaussian_entropy_vs_test_set_nll.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=44'>45</a>\u001b[0m mi_confidences_by_channel_photons_pixel_cnn[channel_name]\u001b[39m.\u001b[39mappend(mi_confidence_pixel_cnn)\n",
      "File \u001b[0;32m~/GitRepos/EncodingInformation/encoding_information/information_estimation.py:244\u001b[0m, in \u001b[0;36mestimate_mutual_information\u001b[0;34m(noisy_images, clean_images, entropy_model, test_set_fraction, gaussian_noise_sigma, estimate_conditional_from_model_samples, patience, num_val_samples, batch_size, max_epochs, learning_rate, use_iterative_optimization, eigenvalue_floor, gradient_clip, momentum, analytic_marginal_entropy, steps_per_epoch, num_hidden_channels, num_mixture_components, return_entropy_model, verbose)\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[39mif\u001b[39;00m v \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    243\u001b[0m              hyperparams[k] \u001b[39m=\u001b[39m v\n\u001b[0;32m--> 244\u001b[0m     noisy_image_model\u001b[39m.\u001b[39;49mfit(training_set, verbose\u001b[39m=\u001b[39;49mverbose, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mhyperparams)\n\u001b[1;32m    245\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    246\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnrecognized entropy model \u001b[39m\u001b[39m{\u001b[39;00mentropy_model\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/GitRepos/EncodingInformation/encoding_information/models/pixel_cnn.py:293\u001b[0m, in \u001b[0;36mPixelCNN.fit\u001b[0;34m(self, train_images, learning_rate, max_epochs, steps_per_epoch, patience, sigma_min, batch_size, num_val_samples, seed, verbose)\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flax_model\u001b[39m.\u001b[39mcompute_loss(\u001b[39m*\u001b[39moutput, x)\n\u001b[1;32m    291\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m=\u001b[39m TrainState\u001b[39m.\u001b[39mcreate(apply_fn\u001b[39m=\u001b[39mapply_fn, params\u001b[39m=\u001b[39minitial_params, tx\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer)        \n\u001b[0;32m--> 293\u001b[0m best_params, val_loss_history \u001b[39m=\u001b[39m train_model(train_images\u001b[39m=\u001b[39;49mtrain_images, state\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_state, batch_size\u001b[39m=\u001b[39;49mbatch_size, num_val_samples\u001b[39m=\u001b[39;49m\u001b[39mint\u001b[39;49m(num_val_samples),\n\u001b[1;32m    294\u001b[0m                                             steps_per_epoch\u001b[39m=\u001b[39;49msteps_per_epoch, num_epochs\u001b[39m=\u001b[39;49mmax_epochs, patience\u001b[39m=\u001b[39;49mpatience, verbose\u001b[39m=\u001b[39;49mverbose)\n\u001b[1;32m    295\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state\u001b[39m.\u001b[39mreplace(params\u001b[39m=\u001b[39mbest_params)\n\u001b[1;32m    296\u001b[0m \u001b[39mreturn\u001b[39;00m val_loss_history\n",
      "File \u001b[0;32m~/GitRepos/EncodingInformation/encoding_information/models/image_distribution_models.py:173\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(train_images, state, batch_size, num_val_samples, steps_per_epoch, num_epochs, patience, train_step, verbose)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[39mTraining loop with early stopping. Returns a callable with \u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39mif\u001b[39;00m num_val_samples \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m train_images\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]:\n\u001b[0;32m--> 173\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNumber of validation samples must be less than the number of training samples\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    174\u001b[0m train_ds_iterator, val_loader_maker_fn \u001b[39m=\u001b[39m _make_dataset_generators(train_images, batch_size\u001b[39m=\u001b[39mbatch_size, num_val_samples\u001b[39m=\u001b[39mnum_val_samples)\n\u001b[1;32m    176\u001b[0m \u001b[39mif\u001b[39;00m train_step \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Number of validation samples must be less than the number of training samples"
     ]
    }
   ],
   "source": [
    "channel_names = ['Brightfield', 'DPC_Right', 'LED119' ]\n",
    "edge_crop = 32\n",
    "num_images = 5000\n",
    "num_patches = 5000\n",
    "photons_per_pixel = [20, 40, 80, 160, 300]\n",
    "num_bootstrap_samples = 20\n",
    "confidence_interval = 90\n",
    "patch_size = 20\n",
    "\n",
    "# patch_size = 5\n",
    "# num_bootstrap_samples = 3\n",
    "# num_images = 500\n",
    "# num_patches = 500\n",
    "# photons_per_pixel = [20, 200]\n",
    "\n",
    "mi_means_by_channel_photons = {}\n",
    "mi_confidences_by_channel_photons = {}\n",
    "mi_means_by_channel_photons_pixel_cnn = {}\n",
    "mi_confidences_by_channel_photons_pixel_cnn = {}\n",
    "mi_means_by_channel_photons_analytic = {}\n",
    "mi_confidences_by_channel_photons_analytic = {}\n",
    "for channel_name in tqdm(channel_names):\n",
    "    mi_means_by_channel_photons[channel_name] = []\n",
    "    mi_confidences_by_channel_photons[channel_name] = []\n",
    "    mi_means_by_channel_photons_pixel_cnn[channel_name] = []\n",
    "    mi_confidences_by_channel_photons_pixel_cnn[channel_name] = []\n",
    "    mi_means_by_channel_photons_analytic[channel_name] = []\n",
    "    mi_confidences_by_channel_photons_analytic[channel_name] = []\n",
    "\n",
    "    images = load_bsccm_images(bsccm, channel_name, num_images=num_images, edge_crop=edge_crop, convert_units_to_photons=True, median_filter=False, verbose=False)\n",
    "    for num_photons in photons_per_pixel:\n",
    "        patches = extract_patches(images, patch_size=patch_size, num_patches=num_patches, verbose=False)\n",
    "        noisy_patches = add_shot_noise_to_experimenal_data(patches, num_photons / np.mean(images))\n",
    "\n",
    "        mi_mean, mi_confidence = run_bootstrap(noisy_patches, num_bootstrap_samples=num_bootstrap_samples, confidence_interval=confidence_interval, \n",
    "                    estimation_fn=lambda noisy_images: estimate_mutual_information(noisy_images=noisy_images, verbose=False),\n",
    "                      verbose=True)\n",
    "        mi_means_by_channel_photons[channel_name].append(mi_mean)\n",
    "        mi_confidences_by_channel_photons[channel_name].append(mi_confidence)\n",
    "\n",
    "        mi_mean_pixel_cnn, mi_confidence_pixel_cnn = run_bootstrap(noisy_patches, num_bootstrap_samples=num_bootstrap_samples, confidence_interval=confidence_interval,\n",
    "                    estimation_fn=lambda noisy_images: estimate_mutual_information(noisy_images=noisy_images, entropy_model='pixel_cnn',verbose=False),\n",
    "                      verbose=True)\n",
    "        mi_means_by_channel_photons_pixel_cnn[channel_name].append(mi_mean_pixel_cnn)\n",
    "        mi_confidences_by_channel_photons_pixel_cnn[channel_name].append(mi_confidence_pixel_cnn)\n",
    "\n",
    "        mi_mean_analytic, mi_confidence_analytic =  run_bootstrap(noisy_patches, num_bootstrap_samples=num_bootstrap_samples, confidence_interval=confidence_interval, \n",
    "                    estimation_fn=lambda noisy_images: estimate_mutual_information(noisy_images=noisy_images, verbose=False,  analytic_marginal_entropy=True),\n",
    "                      verbose=True)\n",
    "        mi_means_by_channel_photons_analytic[channel_name].append(mi_mean_analytic)\n",
    "        mi_confidences_by_channel_photons_analytic[channel_name].append(mi_confidence_analytic)\n",
    "    \n",
    "mi_means_by_channel_photons = {channel: np.array(v) for channel, v in mi_means_by_channel_photons.items()}\n",
    "mi_confidences_by_channel_photons = {channel: np.array(v) for channel, v in mi_confidences_by_channel_photons.items()}\n",
    "mi_means_by_channel_photons_pixel_cnn = {channel: np.array(v) for channel, v in mi_means_by_channel_photons_pixel_cnn.items()}\n",
    "mi_confidences_by_channel_photons_pixel_cnn = {channel: np.array(v) for channel, v in mi_confidences_by_channel_photons_pixel_cnn.items()}\n",
    "mi_means_by_channel_photons_analytic = {channel: np.array(v) for channel, v in mi_means_by_channel_photons_analytic.items()}\n",
    "mi_confidences_by_channel_photons_analytic = {channel: np.array(v) for channel, v in mi_confidences_by_channel_photons_analytic.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mi_means_by_channel_photons' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/hpinkard_waller/GitRepos/EncodingInformation/mi_estimator_experiments/analytic_gaussian_entropy_vs_test_set_nll.ipynb Cell 4\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B169.229.228.36/home/hpinkard_waller/GitRepos/EncodingInformation/mi_estimator_experiments/analytic_gaussian_entropy_vs_test_set_nll.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m colors \u001b[39m=\u001b[39m  get_color_cycle()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B169.229.228.36/home/hpinkard_waller/GitRepos/EncodingInformation/mi_estimator_experiments/analytic_gaussian_entropy_vs_test_set_nll.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m fig, ax \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplots(\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, figsize\u001b[39m=\u001b[39m(\u001b[39m5\u001b[39m, \u001b[39m5\u001b[39m))\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B169.229.228.36/home/hpinkard_waller/GitRepos/EncodingInformation/mi_estimator_experiments/analytic_gaussian_entropy_vs_test_set_nll.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m ax\u001b[39m.\u001b[39mplot(photons_per_pixel, mi_means_by_channel_photons[\u001b[39m'\u001b[39m\u001b[39mBrightfield\u001b[39m\u001b[39m'\u001b[39m], label\u001b[39m=\u001b[39mget_display_channel_names(\u001b[39m'\u001b[39m\u001b[39mBrightfield\u001b[39m\u001b[39m'\u001b[39m), color\u001b[39m=\u001b[39mcolors[\u001b[39m0\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B169.229.228.36/home/hpinkard_waller/GitRepos/EncodingInformation/mi_estimator_experiments/analytic_gaussian_entropy_vs_test_set_nll.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m ax\u001b[39m.\u001b[39mfill_between(photons_per_pixel, mi_confidences_by_channel_photons[\u001b[39m'\u001b[39m\u001b[39mBrightfield\u001b[39m\u001b[39m'\u001b[39m][:, \u001b[39m0\u001b[39m], mi_confidences_by_channel_photons[\u001b[39m'\u001b[39m\u001b[39mBrightfield\u001b[39m\u001b[39m'\u001b[39m][:, \u001b[39m1\u001b[39m], alpha\u001b[39m=\u001b[39m\u001b[39m0.25\u001b[39m, color\u001b[39m=\u001b[39mcolors[\u001b[39m0\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B169.229.228.36/home/hpinkard_waller/GitRepos/EncodingInformation/mi_estimator_experiments/analytic_gaussian_entropy_vs_test_set_nll.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m ax\u001b[39m.\u001b[39mplot(photons_per_pixel, mi_means_by_channel_photons_analytic[\u001b[39m'\u001b[39m\u001b[39mBrightfield\u001b[39m\u001b[39m'\u001b[39m], label\u001b[39m=\u001b[39mget_display_channel_names(\u001b[39m'\u001b[39m\u001b[39mBrightfield\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m (analytic)\u001b[39m\u001b[39m'\u001b[39m, color\u001b[39m=\u001b[39mcolors[\u001b[39m0\u001b[39m], linestyle\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m--\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mi_means_by_channel_photons' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcsAAAG5CAYAAADh6B+NAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAmHklEQVR4nO3df3DV1YH//9cNIb9vYBctXO8NCbaLpGoiOxQsW1ysBnRdQKVaGX6YFtQqREKA3RHqgOvyGxPWtaCWRUj4YexMtOtUSpUx69hKAHGSEUiLbjS5IS5DxBuSUIHkfP/wm3yM9yaHd25uCPH5mMk/5+TcnHtI5sn97TLGGAEAgE5FXe4NAADQ1xFLAAAsiCUAABbEEgAAC2IJAIAFsQQAwIJYAgBgQSwBALAglgAAWIQVy7KyMkVHR+utt9665DU7duzQ6NGjlZiYKI/Ho/nz5+vMmTPhbAMAgIjqdixPnDihe+65Ry0tLZe8Zs2aNcrOztaQIUO0fv16zZw5U1u3btWtt96qc+fOdXcrAABEVHR3Fr366quaO3euo1uENTU1Wrlype644w797ne/U1TUV52+6aabNHv2bP3nf/6n/uVf/qU72wEAIKIc37K86667dO+998rj8WjGjBmXvG7Pnj06f/68Fi5c2B5KSZo5c6a8Xq9eeuklp1sBAKBXOI5lZWWlVq9erSNHjmjkyJGXvO7AgQOSpJtvvrnDuMvl0tixY1VZWalAIOB0OwAARJzju2GPHTum2NhYxz/I7/crKSlJgwcPDprz+XySpE8++USZmZkh1+fn5ys/Pz9o/OTJk5Kk6Ohofec733G8LwDAle/UqVNqaWlRXFycmpqaevzyHceyO6GUpEAgoKSkpJBzCQkJktTlFWxoaFBtbW2n8xcuXOhyHgDQ//31r3+NyOV26wk+3dHVZ0y3zX39scxvSk5OltfrDRpvC2RUVJQ8Hk+YuwQAXInq6urU2tqqAQMGROTyey2Wbrdb//d//xdyrrm5WZJC3kXbJi8vT3l5eUHjPp9PtbW18ng88vv9PbJXAMCVpa0FkXo4rtfewWfEiBFqaGjQ2bNng+b8fr+ioqJC3nIEAOBy67VYjhs3TpJ08ODBDuPGGB08eFA33HCD3G53b20HAIBL1muxvP/++zVw4EBt3Lixw+OXO3fu1MmTJ5Wdnd1bWwEAwJGIPGb5v//7v/rTn/6k7373u/rhD38oSUpNTdXy5cu1cuVKTZo0Sffff7/+8pe/6Nlnn9UPfvAD/eIXv4jEVgAACFtEblm+8847mj17tl544YUO4ytWrNCWLVt08uRJLViwQMXFxXr44Ye1b98+xcfHR2IrAACEzWW6ek3HFaDtGVBer5dnwwLAt1SkW8DnWQIAYEEsAQCwIJYAAFgQSwAALIglAAAWxBIAAAtiCQCABbEEAMCCWAIAYEEsAQCwIJYAAFgQSwAALIglAAAWxBIAAAtiCQCABbEEAMCCWAIAYEEsAQCwIJYAAFgQSwAALIglAAAWxBIAAAtiCQCABbEEAMCCWAIAYEEsAQCwIJYAAFgQSwAALIglAAAWxBIAAAtiCQCABbEEAMCCWAIAYEEsAQCwIJYAAFgQSwAALIglAAAWxBIAAAtiCQCABbEEAMCCWAIAYEEsAQCwIJYAAFgQSwAALIglAAAWxBIAAAtiCQCABbEEAMCCWAIAYEEsAQCwIJYAAFgQSwAALIglAAAWxBIAAAtiCQCABbEEAMCCWAIAYEEsAQCwIJYAAFgQSwAALIglAAAWxBIAAItuxbK+vl45OTlKTU1VfHy8MjMztW3btktae/bsWS1atEipqamKiYmRz+dTTk6OAoFAd7YCAEDERTtd0NTUpKysLH344YeaP3++Ro0apVdeeUVz587VZ599pmXLlnW69uLFi7r99tt18OBB/fSnP9XEiRP1/vvva/PmzXr33Xf13nvvKS4uLqwrBABAjzMOrV271kgyu3btah9raWkxWVlZJiYmxlRXV3e69je/+Y2RZObNm9dhfMWKFUaSef75551ux3i9XiPJeL1ex2sBAP1DpFvg+G7YHTt2yOPxaMaMGe1jUVFRWrp0qc6fP6/du3d3uvbEiROSpH/+53/uMD5t2jRJ0gcffOB0OwAARJyjWAYCAVVWVmrs2LFyuVwd5saNGydJKisr63R9enq6JOno0aMdxtsi6vP5nGwHAIBe4egxy9raWhljlJKSEjSXnJwst9utqqqqTtdPnTpV06dP15o1a+Tz+fSP//iPqqio0KJFi+Tz+TRv3rxO1+bn5ys/Pz9ovK6uzslVAADAMUexbHvGalJSUsj5hIQENTU1dbo+KipKTz75pI4dO6YHH3ywfXzYsGF66623NGzYsE7XNjQ0qLa21sl2AQDoEY5iaYyxzkdFdX7Pbmlpqe68805FR0drxYoVGj16tKqqqvTMM89o/Pjxev311/WjH/0o5Nrk5GR5vd6g8bq6OrW2tjq5GgAAOOIolm63W5LU3Nwccr65uVkjRozodP3y5cv15Zdfat++fbrlllvaxx944AFlZGRo5syZ+uijjzRw4MCgtXl5ecrLywsa9/l83OIEAESUoyf4pKWlyeVyye/3B80FAgE1NjaGfDyzTXl5uUaOHNkhlNJXd8NOmzZN1dXVOn78uJMtAQAQcY5i6Xa7lZ6erkOHDgXNtT0Ldvz48Z2uj4uLU0tLS8i5tnHuUgUA9DWOX2c5a9Ys1dTUaM+ePe1jra2t2rhxo2JjYzu8/vKb7rrrLn300Uf67//+7w7j1dXVevXVV3XNNdfoxhtvdLolAAAiyvHb3eXm5mrnzp3Kzs7WkSNHNHLkSBUXF2v//v3asGFD+zNaKyoqVFFRoYyMDGVkZEiS1q5dq9LSUv3kJz/Rz3/+c40ZM0affvqptmzZoqamJu3evVsDBgzo2WsIAECYHN+yjI+PV2lpqebMmaPCwkItXLhQ9fX1Kiws1JIlS9q/r6SkRLNnz1ZJSUn7mMfj0eHDh/XII49o7969evTRR7V582ZNmDBB7733nu68886euVYAAPQgl7G9HqSPa3s2rNfrDfnEIwBA/xfpFvB5lgAAWBBLAAAsiCUAABbEEgAAC2IJAIAFsQQAwIJYAgBgQSwBALAglgAAWBBLAAAsiCUAABbEEgAAC2IJAIAFsQQAwIJYAgBgQSwBALAglgAAWBBLAAAsiCUAABbEEgAAC2IJAIAFsQQAwIJYAgBgQSwBALAglgAAWBBLAAAsiCUAABbEEgAAC2IJAIAFsQQAwIJYAgBgQSwBALAglgAAWBBLAAAsiCUAABbEEgAAC2IJAIAFsQQAwIJYAgBgQSwBALAglgAAWBBLAAAsiCUAABbEEgAAC2IJAIAFsQQAwIJYAgBgQSwBALAglgAAWBBLAAAsiCUAABbEEgAAC2IJAIAFsQQAwIJYAgBgQSwBALAglgAAWBBLAAAsiCUAABbEEgAAC2IJAIAFsQQAwKJbsayvr1dOTo5SU1MVHx+vzMxMbdu27ZLX79u3T7feequSk5M1ZMgQTZ48WYcOHerOVgAAiDjHsWxqalJWVpZeeOEF3Xvvvdq0aZOuuuoqzZ07V6tXr7au/6//+i/deeed+vzzz7Vq1SotWbJE5eXluuWWW/T+++9360oAABBRxqG1a9caSWbXrl3tYy0tLSYrK8vExMSY6urqTtf6/X6TkJBgxowZY5qamtrHT5w4YQYOHGjuuOMOp9sxXq/XSDJer9fxWgBA/xDpFji+Zbljxw55PB7NmDGjfSwqKkpLly7V+fPntXv37i7XNjc3a8OGDUpISGgf/973vqdnnnlGWVlZTrcDAEDERTv55kAgoMrKSk2dOlUul6vD3Lhx4yRJZWVlna5/++235Xa7NWHCBEnSxYsXdf78eSUkJCgnJ8fp3gEA6BWOblnW1tbKGKOUlJSgueTkZLndblVVVXW6/vjx40pJSdHRo0c1adIkxcXFKTExUTfeeKPeeOONLn92fn6+fD5f0FddXZ2TqwAAgGOOYhkIBCRJSUlJIecTEhLU1NTU6fozZ87oiy++0IQJEzR06FC9/PLL2rx5s86ePaspU6botdde63RtQ0ODamtrg75aW1udXAUAABxzdDesMcY6HxXVeX+//PJLnTx5Urm5uSooKGgfv/vuu3Xdddfp8ccf17Rp04Lu4pW+uuXq9XqDxuvq6ggmACCiHN2ydLvdkqTm5uaQ883NzRo8eHCn6xMTEyVJ8+fP7zDu8Xg0ZcoU1dTUqLKyMuTavLw8+f3+oC+Px+PkKgAA4JijWKalpcnlcsnv9wfNBQIBNTY2hnw8s83w4cMlScOGDQuaGzp0aPvlAADQlzi+ZZmenh7y3XbangU7fvz4Tte3PWO2oqIiaO6jjz6Sy+VSWlqaky0BABBxjl9nOWvWLNXU1GjPnj3tY62trdq4caNiY2M7vP7ym372s59Jkp566im1tLS0j1dUVGjv3r269dZbQ97qBADgcnL0BB9Jys3N1c6dO5Wdna0jR45o5MiRKi4u1v79+7Vhw4b22FVUVKiiokIZGRnKyMiQJP3DP/yDFi9erGeeeUYTJkzQrFmzdOrUKW3atEmJiYl67rnnevbaAQDQAxzfsoyPj1dpaanmzJmjwsJCLVy4UPX19SosLNSSJUvav6+kpESzZ89WSUlJh/UbN27Ujh07dOHCBS1evFjPPfecJk+erIMHDyo9PT38awQAQA9zGdvrQfo4n8+n2tpaeb3ekE88AgD0f5FuAZ9nCQCABbEEAMCCWAIAYEEsAQCwIJYAAFgQSwAALIglAAAWxBIAAAtiCQCABbEEAMCCWAIAYEEsAQCwIJYAAFgQSwAALIglAAAWxBIAAAtiCQCABbEEAMCCWAIAYEEsAQCwIJYAAFgQSwAALIglAAAWxBIAAAtiCQCABbEEAMCCWAIAYEEsAQCwIJYAAFgQSwAALIglAAAWxBIAAAtiCQCABbEEAMCCWAIAYEEsAQCwIJYAAFgQSwAALIglAAAWxBIAAAtiCQCABbEEAMCCWAIAYEEsAQCwIJYAAFgQSwAALIglAAAWxBIAAAtiCQCABbEEAMCCWAIAYEEsAQCwIJYAAFgQSwAALIglAAAWxBIAAAtiCQCABbEEAMCCWAIAYEEsAQCwIJYAAFgQSwAALLoVy/r6euXk5Cg1NVXx8fHKzMzUtm3burWBJ554Qi6XS2+99Va31gMAEGnRThc0NTUpKytLH374oebPn69Ro0bplVde0dy5c/XZZ59p2bJll3xZ//M//6P169c73QIAAL3K8S3L5557Th988IG2b9+ugoICPfLII3rzzTeVlZWlp556SjU1NZd0OV988YXmzJmjgQMHOt40AAC9yXEsd+zYIY/HoxkzZvy/C4mK0tKlS3X+/Hnt3r37ki7n0UcfVWtrq37xi1843QIAAL3KUSwDgYAqKys1duxYuVyuDnPjxo2TJJWVlVkvp6ioSMXFxdq+fbsGDx7sZAsAAPQ6R7Gsra2VMUYpKSlBc8nJyXK73aqqquryMqqqqrRgwQLl5ubqtttuu+SfnZ+fL5/PF/RVV1fn5CoAAOCYoyf4BAIBSVJSUlLI+YSEBDU1NXW6vqWlRbNmzVJKSorWrFnj5EeroaFBtbW1jtYAANATHMXSGGOdj4rq/MbqqlWrdPjwYZWVlSk2NtbJj1ZycrK8Xm/QeF1dnVpbWx1dFgAATji6G9btdkuSmpubQ843Nzd3+hhkWVmZnn76aS1atEg+n0+nT5/W6dOn2y+roaFBp0+f7jR8eXl58vv9QV8ej8fJVQAAwDFHtyzT0tLkcrnk9/uD5gKBgBobG0M+nilJe/fu1cWLF7Vu3TqtW7cuaH769OmSvnpMMy0tzcm2AACIKEexdLvdSk9P16FDh4Lm2p4FO378+JBr58yZox/96EdB44WFhSoqKtL69es1evRoDRs2zMmWAACIOMfv4DNr1iwtW7ZMe/bsaX+tZWtrqzZu3KjY2NgOr7/8umuvvVbXXntt0Pi7774rSRo9erRuv/12p9sBACDiHMcyNzdXO3fuVHZ2to4cOaKRI0equLhY+/fv14YNG9pvGVZUVKiiokIZGRnKyMjo8Y0DANBbHL+DT3x8vEpLSzVnzhwVFhZq4cKFqq+vV2FhoZYsWdL+fSUlJZo9e7ZKSkp6dMMAAPQ2l7G9HqSP8/l8qq2tldfrDfnEIwBA/xfpFvB5lgAAWBBLAAAsiCUAABbEEgAAC2IJAIAFsQQAwIJYAgBgQSwBALAglgAAWBBLAAAsiCUAABbEEgAAC2IJAIAFsQQAwIJYAgBgQSwBALAglgAAWBBLAAAsiCUAABbEEgAAC2IJAIAFsQQAwIJYAgBgQSwBALAglgAAWBBLAAAsiCUAABbEEgAAC2IJAIAFsQQAwIJYAgBgQSwBALAglgAAWBBLAAAsiCUAABbEEgAAC2IJAIAFsQQAwIJYAgBgQSwBALAglgAAWBBLAAAsiCUAABbEEgAAC2IJAIAFsQQAwIJYAgBgQSwBALAglgAAWBBLAAAsiCUAABbEEgAAC2IJAIAFsQQAwIJYAgBgQSwBALAglgAAWBBLAAAsiCUAABbEEgAAC2IJAIAFsQQAwKJbsayvr1dOTo5SU1MVHx+vzMxMbdu2zdHatLQ0xcTE6Oqrr9Z9992n48ePd2crAABEXLTTBU1NTcrKytKHH36o+fPna9SoUXrllVc0d+5cffbZZ1q2bFmna//6179q4sSJOn78uH72s59pzJgxqqqq0ubNm/X73/9ef/zjH5WRkRHWFQIAoMcZh9auXWskmV27drWPtbS0mKysLBMTE2Oqq6s7Xbtq1SojyWzdurXD+Pvvv2+io6PNpEmTnG7HeL1eI8l4vV7HawEA/UOkW+D4btgdO3bI4/FoxowZ7WNRUVFaunSpzp8/r927d3e6dt++fYqJiVF2dnaH8b//+7/X9ddfr3feecfpdgAAiDhHd8MGAgFVVlZq6tSpcrlcHebGjRsnSSorK+t0/csvv6xTp05pwIABHcaNMSHHAQDoCxzFsra2VsYYpaSkBM0lJyfL7Xarqqqq0/Uej0cejydovKioSHV1dbrrrrs6XZufn6/8/Pyg8bq6ukvcPQAA3eP4lqUkJSUlhZxPSEhQU1OTow2Ul5crJydH0dHRWrlyZaff19DQoNraWkeXDQBAT3AUS2OMdT4q6tIfBj18+LDuvPNONTQ06Fe/+pXGjBnT6fcmJyfL6/UGjdfV1am1tfWSfyYAAE45eoKP2+2WJDU3N4ecb25u1uDBgy/psl5//XVNnDhR9fX12rRpkx577LEuvz8vL09+vz/oK9TdugAA9CRHsUxLS5PL5ZLf7w+aCwQCamxsDPl45jdt2bJF99xzjy5cuKCioiItXLjQyTYAAOhVju6GdbvdSk9P16FDh4Lm2p4FO378+C4vo6CgQHl5eRo8eLBeffVVTZw40ckWAADodY5fZzlr1izV1NRoz5497WOtra3auHGjYmNjO7z+8pt+//vfa/HixRoyZIjeeecdQgkAuCI4fru73Nxc7dy5U9nZ2Tpy5IhGjhyp4uJi7d+/Xxs2bNCwYcMkSRUVFaqoqFBGRoYyMjLU2tqqxx9/XMYYTZkyReXl5SovLw+6/JkzZwa9hhMAgMvJcSzj4+NVWlqqZcuWqbCwUGfPntV1112nwsJCzZ49u/37SkpK9NRTT2nFihXKyMjQn//8Z504cUKStH37dm3fvj3k5T/wwAOKjna8LQAAIsZlbK8H6eN8Pp9qa2vl9XpDPvEIAND/RboFfJ4lAAAWxBIAAAtiCQCABbEEAMCCWAIAYEEsAQCwIJYAAFgQSwAALIglAAAWxBIAAAtiCQCABbEEAMCCWAIAYEEsAQCwIJYAAFgQSwAALIglAAAWxBIAAAtiCQCABbEEAMCCWAIAYEEsAQCwIJYAAFgQSwAALIglAAAWxBIAAAtiCQCABbEEAMCCWAIAYEEsAQCwIJYAAFgQSwAALIglAAAWxBIAAAtiCQCABbEEAMCCWAIAYEEsAQCwIJYAAFgQSwAALIglAAAWxBIAAAtiCQCABbEEAMCCWAIAYEEsAQCwIJYAAFgQSwAALIglAAAWxBIAAAtiCQCABbEEAMCCWAIAYEEsAQCwIJYAAFgQSwAALIglAAAWxBIAAAtiCQCABbEEAMCCWAIAYEEsAQCw6FYs6+vrlZOTo9TUVMXHxyszM1Pbtm27pLUtLS0qKChQenq64uPjlZaWpuXLl+vcuXPd2QoAABHnOJZNTU3KysrSCy+8oHvvvVebNm3SVVddpblz52r16tXW9Y899pjy8vJ0/fXXq6CgQJMmTdKaNWt0zz33yBjTrSsBAEBEGYfWrl1rJJldu3a1j7W0tJisrCwTExNjqqurO1174MABI8k89NBDHcaffvppI8kUFxc73Y7xer1GkvF6vY7XAgD6h0i3wPEtyx07dsjj8WjGjBntY1FRUVq6dKnOnz+v3bt3d7lWkvLy8jqML1q0SDExMXrppZecbgcAgIhzFMtAIKDKykqNHTtWLperw9y4ceMkSWVlZZ2uP3DggAYNGqRRo0Z1GE9MTNT111/f5VoAAC6XaCffXFtbK2OMUlJSguaSk5PldrtVVVXV6Xq/3x9yrST5fD598MEHCgQCGjRoUNB8fn6+8vPzQ+5Jkurq6uTz+S71qgAA+pG6ujpJ0qlTpyJy+Y5iGQgEJElJSUkh5xMSEtTU1NTl+u9+97udrpW+egJRqFg2NDS0hzGU1tbWLucBAP3fxYsXI3K5jmJpLM9WNcYoKqrze3a7Wt8219n65ORkeb3eoPGvBzLUPILV1dWptbVVUVFR8ng8l3s7VwzOzTnOrHs4N+cifWPJUSzdbrckqbm5OeR8c3OzRowY0eX6rtZK0uDBg0PO5+XlBT0xSPrq7tva2lp5vV75/f6uto//X9uZeTwezswBzs05zqx7ODfn2s7smmuuicjlO3qCT1pamlwuV8h/vEAgoMbGxk4fk5SkESNGdPoP7/f7ddVVVykuLs7JlgAAiDhHsXS73UpPT9ehQ4eC5tqeyTp+/PhO148bN06ff/65Pv744w7jjY2NOnr0aJdrAQC4XBy/znLWrFmqqanRnj172sdaW1u1ceNGxcbGdnj95TfNnDlTkrR+/foO4wUFBbpw4YKys7OdbgcAgIhz9JilJOXm5mrnzp3Kzs7WkSNHNHLkSBUXF2v//v3asGGDhg0bJkmqqKhQRUWFMjIylJGRIemrW53Z2dl68cUXdebMGU2ePFllZWXaunWrpkyZorvvvrtHrxwAAD3BcSzj4+NVWlqqZcuWqbCwUGfPntV1112nwsJCzZ49u/37SkpK9NRTT2nFihXtsZSkX//61/re976nbdu26be//a18Pp9++ctf6oknngh6o4NLkZeXp4aGBiUnJzte+23FmXUP5+YcZ9Y9nJtzkT4zl7G9HgQAgG85Ps8SAAALYgkAgAWxBADAglgCAGDRZ2NZX1+vnJwcpaamKj4+XpmZmdq2bdslrW1paVFBQYHS09MVHx+vtLQ0LV++XOfOnYvwri+/cM6tbW1aWppiYmJ09dVX67777tPx48cjvOvLK5wz+6a2Z3W/9dZbPbzLvifcc9u3b59uvfVWJScna8iQIZo8eXLINzzpT8I5s7Nnz2rRokVKTU1VTEyMfD6fcnJy2j/g4tugrKxM0dHRjv6+duzYodGjRysxMVEej0fz58/XmTNnnP/wiHykdJgaGxvN6NGjzcCBA01ubq55/vnnzY9//GMjyaxatcq6/uGHHzaSzPTp082WLVvMQw89ZFwul5k8ebJpbW3thWtweYRzbufOnTM33HCDGTBggJk3b555/vnnzb/+678at9ttkpKSTHl5eS9di94V7u/a15WWlpqoqCgjybz55psR2nHfEO65bd261bhcLpORkWGeffZZs3r1ajN06FATFxdnDh8+3AvXoPeFc2YXLlwwY8eONZLMT3/6U7NlyxYzb948ExUVZW666SZz7ty5XroWl89f/vIX4/F4HP19rV692kgyt912m3nuuefM4sWLTUxMjMnMzDTNzc2Ofn6fjOXatWuNJLNr1672sZaWFpOVlWViYmJMdXV1p2sPHDhgJJmHHnqow/jTTz9tJJni4uKI7ftyC+fcVq1aZSSZrVu3dhh///33TXR0tJk0aVLE9n05hXNmX3fmzBkzfPhwExsb+62IZTjn5vf7TUJCghkzZoxpampqHz9x4oQZOHCgueOOOyK698slnDP7zW9+YySZefPmdRhfsWKFkWSef/75iO27LygpKTF/8zd/YyRd8t9XdXW1iYmJMXfccYdpaWlpHy8qKjKSzLp16xztoU/GMj093Xg8nqBbgX/4wx+MJLN27dpO1z766KNGkjl+/HiH8cbGxvaD66/CObdbbrnFxMTEmIsXLwbNZWZmmri4uB7fb18Qzpl93QMPPGB8Pp9ZuHDhtyKW4Zxb23/M3n777aC5Z5991jzzzDM9vd0+IZwza7uF9Nprr3UYP3LkiJFkHnnkkYjsuS/4p3/6JyPJfP/73zczZsy45L+vdevWGUlm7969HcZbW1uN1+s1o0aNcrSPPveYZSAQUGVlpcaOHRv0jj7jxo2T9P/etD2UAwcOaNCgQRo1alSH8cTERF1//fVdrr2ShXtuL7/8sg4ePKgBAwZ0GDfG6NSpU0Hj/UG4Z9amqKhIxcXF2r59e6cfMdefhHtub7/9ttxutyZMmCDpqw/rbfuIvpycnJAfxXelC/fM0tPTJUlHjx7tMH7ixAlJX308VX9VWVmp1atXt7+96qU6cOCAJOnmm2/uMO5yuTR27FhVVlY6ery3z8WytrZWxpiQH/WVnJwst9utqqqqTtf7/f5OPybM5/PpzJkz/fIB8XDPzePxKDMzM2i8qKhIdXV1mjhxYk9ut08I98wkqaqqSgsWLFBubq5uu+22SG21Twn33I4fP66UlBQdPXpUkyZNUlxcnBITE3XjjTfqjTfeiOTWL5twz2zq1KmaPn261qxZo8LCQn366ad6/fXXtWjRIvl8Ps2bNy+S27+sjh07pieeeEKxsbGO1vn9fiUlJYX8D2zbfy4++eSTS768PhfLtpAlJSWFnE9ISFBTU1OX67taK6nL9VeqcM8tlPLycuXk5Cg6OlorV64Md4t9Trhn1tLSolmzZiklJUVr1qyJyB77onDP7cyZM/riiy80YcIEDR06VC+//LI2b96ss2fPasqUKXrttdcise3LKtwzi4qK0pNPPqmUlBQ9+OCDSktL09SpU9Xa2qo//OEP7R9g0R85jWSbnm5Bn4ulsbxVrTFGUVGdb7ur9W1zXa2/UoV7bt90+PBh3X777WpoaNB//Md/aMyYMeFusc8J98xWrVqlw4cPa+fOnd3+g74ShXtuX375pU6ePKmf//znKioq0k9+8hM9+uijeu+995SYmKjHH3/c+jOuNOGeWWlpqW6++WbV1NRoxYoVeu2111RQUKDo6GiNHz9e7777bk9v+YrX0y3oc9Vwu92S1P4Yxjc1Nzd3+biQ2+3ucq2kfvm4Urjn9nWvv/66Jk6cqPr6em3atEmPPfZYT22zTwnnzMrKyvT000+33w12+vRpnT59uv2yGhoadPr0abW2tkZk75dTuL9riYmJkqT58+d3GPd4PJoyZYpqampUWVnZM5vtI8I9s+XLl+vLL7/U7373O61cuVLTpk1Tbm6uDh06pIEDB2rmzJm6cOFCJLZ+xerpFvS5WKalpcnlcsnv9wfNBQIBNTY2dvqYpCSNGDEi5Frpq/uwr7rqKsXFxfXYfvuKcM+tzZYtW3TPPffowoULKioq0sKFCyOx3T4hnDPbu3evLl68qHXr1unqq69u/9qwYYMkafr06br66qtVXV0d0etwOYT7uzZ8+HBJCnnX4dChQ9svpz8J98zKy8s1cuRI3XLLLR3Ghw0bpmnTpqm6urrfv3mIUyNGjFBDQ4POnj0bNOf3+xUVFSWv13vJl9fnYul2u5Wenh7ynTzani02fvz4TtePGzdOn3/+uT7++OMO442NjTp69GiXa69k4Z6bJBUUFOixxx6T2+3Wvn37NHPmzIjsta8I58zmzJmjN998M+ir7TNd169frzfffLNfPpbUE3+j0lcfEP9NH330kVwul9LS0npms31EuGcWFxenlpaWkHNt4/3xXoxwtP2eHTx4sMO4MUYHDx7UDTfc0H6L/5I4eqFJL2l7TdHu3bvbx9pevBsbG2vq6uo6XfvHP/7RSDIPP/xwh/F/+7d/M5JMSUlJxPZ9uYVzbnv37jUul8sMGTLEVFRU9MZ2+4RwziyUtheJ9/fXWYZzbu+++66RZCZNmtThdb3l5eUmOjra/PjHP47o3i+XcM5szpw5RpL57W9/22H8008/NYMHDzbXXHNNyNdI9zdO/r4++eST9je5+PprWwsLC40kk5+f7+hn98lYNjc3m+9///smJibGLFmyxLz44ovmtttuM5LMhg0b2r+vvLzcFBUVBb0VW3Z2tpFk7rvvPrN169b2t7ubMmVKv367u+6eW0tLi/m7v/s7I8lkZ2eboqKikF/98ezC/V37pm9LLMM9t8WLFxtJ5oc//KH51a9+ZVasWGEGDRpkBg0aZI4dO9bbV6dXhHNmJ0+eNMOHDzcDBw40jzzyiPn1r39tfvnLX5ohQ4aYgQMHmjfeeONyXKVe19nf18cff2yKiorMn/70pw7jK1euNJLM7bffbl588UWzZMkSExMTY37wgx/0j7e7M8aYU6dOmXnz5pnvfOc7Jj4+3tx0002msLCww/e0HdyKFSs6jF+4cMH8+7//u7n22mtNTEyMufbaa82TTz7p+HCuRN05t2PHjrW/jVRXXxcuXLgM1yjywvld+6ZvSyyNCf/cduzYYcaMGWPi4uLMkCFDzP3332/+/Oc/99LuL49wzuzUqVNmwYIFZvjw4SY6Otr87d/+rbn77rv77XvphtLZ39dLL71kJJkHH3wwaM2WLVva/5OSkpJiFixYYD7//HPHP9tlTD97jjYAAD2szz3BBwCAvoZYAgBgQSwBALAglgAAWBBLAAAsiCUAABbEEgAAC2IJAIAFsQQAwIJYAgBgQSwBALAglgAAWPx/OmRY/+Xnh9MAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from cleanplots import *\n",
    "\n",
    "colors =  get_color_cycle()\n",
    "markers = ['o', 'x', 's']\n",
    "models = ['gaussian (upper bound)', 'pixel_cnn', 'analytic']\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "for i, (means, confidences) in enumerate(zip([mi_means_by_channel_photons, mi_means_by_channel_photons_pixel_cnn, mi_means_by_channel_photons_analytic], \n",
    "                              [mi_confidences_by_channel_photons, mi_confidences_by_channel_photons_pixel_cnn, mi_confidences_by_channel_photons_analytic])):\n",
    "    for channel, color in zip(channel_names, colors):\n",
    "        ax.plot(photons_per_pixel, means[channel], label=get_display_channel_names(channel) + ' ' + models[i],\n",
    "                color=color, linestyle='-', marker=markers[i])\n",
    "        ax.fill_between(photons_per_pixel, confidences[channel][:, 0], confidences[channel][:, 1], alpha=0.25, color=color)\n",
    "\n",
    "ax.set(xlabel='Photons per pixel', ylabel='Estimated information\\n(bits/pixel)')\n",
    "ax.legend()\n",
    "clear_spines(ax)\n",
    "ax.title.set_text(f'{confidence_interval}% confidence interval')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phenotypes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
