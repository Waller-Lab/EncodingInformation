{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-31 15:10:38.529991: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening BSCCM\n",
      "Opened BSCCM\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# this only works on startup!\n",
    "from jax import config\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '2'\n",
    "from encoding_information.gpu_utils import limit_gpu_memory_growth\n",
    "limit_gpu_memory_growth()\n",
    "\n",
    "from cleanplots import *\n",
    "from tqdm import tqdm\n",
    "from encoding_information.information_estimation import *\n",
    "from encoding_information.image_utils import *\n",
    "from encoding_information.models.gaussian_process import StationaryGaussianProcess\n",
    "\n",
    "from encoding_information.bsccm_utils import *\n",
    "from bsccm import BSCCM\n",
    "from jax import jit\n",
    "import numpy as np\n",
    "import yaml\n",
    "from led_array.tf_util import prepare_test_dataset\n",
    "import tensorflow.keras as tfk\n",
    "\n",
    "bsccm = BSCCM('/home/hpinkard_waller/data/BSCCM/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset, test_dataset_size = prepare_test_dataset(config['hyperparameters']['test_fraction'], image_target_generator, dataset_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_marker_index(target_row):\n",
    "    return np.flatnonzero(np.logical_not(np.isnan(target_row)))[0]\n",
    "\n",
    "#compute negative log_likelihood over test set\n",
    "def compute_nlls(model, test_dataset, max_num, markers):\n",
    "    negative_log_likelihoods = []\n",
    "    marker_indices = []\n",
    "    for i, (image, target) in tqdm(enumerate(test_dataset), total=max_num):\n",
    "        if max_num is not None and i > max_num:\n",
    "            break\n",
    "        marker_index = get_marker_index(target)\n",
    "        marker_indices.append(marker_index)\n",
    "        marker = markers[marker_index]\n",
    "        mixture = model(image[None])[marker]\n",
    "        nll = -mixture.log_prob(target[marker_index]).numpy() \n",
    "        negative_log_likelihoods.append(nll)\n",
    "    return np.array(negative_log_likelihoods), np.array(marker_indices)\n",
    "\n",
    "\n",
    "def estimate_mi(model_name, config, patch_size):\n",
    "    saving_name = f'{model_name}_{patch_size}patch_mi_estimates'\n",
    "\n",
    "        # check if already cached\n",
    "    if os.path.exists(f'.cached/{saving_name}.npz'):\n",
    "        print(f'Loading cached results for {model_name} MI estimates')\n",
    "        return np.load(f'.cached/{saving_name}.npz')\n",
    "\n",
    "    median_filter = config['data']['synthetic_noise']['median_filter']\n",
    "\n",
    "    markers, image_target_generator, dataset_size, display_range, indices = get_bsccm_image_marker_generator(bsccm, **config['data'])\n",
    "    images = load_bsccm_images(bsccm, indices=indices[:dataset_size], channel=config['data']['channels'][0], \n",
    "                convert_units_to_photons=True, edge_crop=config['data']['synthetic_noise']['edge_crop'],\n",
    "                median_filter=median_filter)\n",
    "\n",
    "    mean_photons_per_pixel = np.mean(images)\n",
    "    rescale_fraction = config['data']['synthetic_noise']['photons_per_pixel'] / mean_photons_per_pixel\n",
    "    if rescale_fraction > 1:\n",
    "        raise Exception('Rescale fraction must be less than 1')\n",
    "\n",
    "    patches = extract_patches(images, patch_size=patch_size, num_patches=int(dataset_size * 2))\n",
    "\n",
    "    if median_filter:\n",
    "        # assume noiseless\n",
    "        noisy_patches = add_noise(patches * rescale_fraction)\n",
    "    else:\n",
    "        noisy_patches = add_shot_noise_to_experimenal_data(patches, rescale_fraction)\n",
    "    \n",
    "    mi_pixel_cnn = estimate_mutual_information(noisy_patches, clean_images=patches if median_filter else None, \n",
    "                    entropy_model='pixel_cnn', verbose=True)\n",
    "    mi_gp = estimate_mutual_information(noisy_patches, clean_images=patches if median_filter else None,\n",
    "                     entropy_model='gaussian', verbose=True)\n",
    "\n",
    "    # save the cached results (both nlls and marker indices in a single file)\n",
    "    np.savez(f'.cached/{saving_name}', mi_pixel_cnn=mi_pixel_cnn, mi_gp=mi_gp)\n",
    "    return np.load(f'.cached/{saving_name}.npz')\n",
    "    \n",
    "\n",
    "def test_set_phenotyping_nll(model_name, config):\n",
    "    saving_name = f'{model_name}_phenotyping_nll'\n",
    "\n",
    "    # check if already cached\n",
    "    if os.path.exists(f'.cached/{saving_name}.npz'):\n",
    "        print(f'Loading cached results for {model_name} phenotyping nlls')\n",
    "        return np.load(f'.cached/{saving_name}.npz')\n",
    "    \n",
    "    markers, image_target_generator, dataset_size, display_range, indices = get_bsccm_image_marker_generator(bsccm, **config['data'])\n",
    "    test_dataset, test_dataset_size = prepare_test_dataset(config['hyperparameters']['test_fraction'], image_target_generator, dataset_size)\n",
    "    \n",
    "    model = tfk.models.load_model(config['saving_dir'] + model_name + os.sep + 'model/saved_model.h5', compile=False)\n",
    "\n",
    "    nlls, marker_indices = compute_nlls(model, test_dataset, max_num=test_dataset_size, markers=markers)\n",
    "\n",
    "    # save the cached results (both nlls and marker indices in a single file)\n",
    "    np.savez(f'.cached/{saving_name}', nlls=nlls, marker_indices=marker_indices)\n",
    "    return np.load(f'.cached/{saving_name}.npz')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute and cache protein prediction performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file 0 of 24\n",
      "Loading cached results for Synthetic_Noise_DPC_Right_50_photons_replicate_0 MI estimates\n",
      "Loading cached results for Synthetic_Noise_DPC_Right_50_photons_replicate_0 phenotyping nlls\n",
      "file 1 of 24\n",
      "Loading cached results for Synthetic_Noise_LED119_100_photons_replicate_0 MI estimates\n",
      "Loading cached results for Synthetic_Noise_LED119_100_photons_replicate_0 phenotyping nlls\n",
      "file 2 of 24\n",
      "Loading cached results for Synthetic_Noise_LED119_200_photons_replicate_1 MI estimates\n",
      "Loading cached results for Synthetic_Noise_LED119_200_photons_replicate_1 phenotyping nlls\n",
      "file 3 of 24\n",
      "Loading cached results for Synthetic_Noise_Brightfield_300_photons_replicate_0 MI estimates\n",
      "Loading cached results for Synthetic_Noise_Brightfield_300_photons_replicate_0 phenotyping nlls\n",
      "file 4 of 24\n",
      "Loading cached results for Synthetic_Noise_LED119_100_photons_replicate_1 MI estimates\n",
      "Loading cached results for Synthetic_Noise_LED119_100_photons_replicate_1 phenotyping nlls\n",
      "file 5 of 24\n",
      "Loading cached results for Synthetic_Noise_LED119_50_photons_replicate_0 MI estimates\n",
      "Loading cached results for Synthetic_Noise_LED119_50_photons_replicate_0 phenotyping nlls\n",
      "file 6 of 24\n",
      "Loading cached results for Synthetic_Noise_DPC_Right_200_photons_replicate_1 MI estimates\n",
      "Loading cached results for Synthetic_Noise_DPC_Right_200_photons_replicate_1 phenotyping nlls\n",
      "file 7 of 24\n",
      "Loading cached results for Synthetic_Noise_DPC_Right_100_photons_replicate_1 MI estimates\n",
      "Loading cached results for Synthetic_Noise_DPC_Right_100_photons_replicate_1 phenotyping nlls\n",
      "file 8 of 24\n",
      "Loading cached results for Synthetic_Noise_Brightfield_100_photons_replicate_1 MI estimates\n",
      "Loading cached results for Synthetic_Noise_Brightfield_100_photons_replicate_1 phenotyping nlls\n",
      "file 9 of 24\n",
      "Loading cached results for Synthetic_Noise_Brightfield_200_photons_replicate_1 MI estimates\n",
      "Loading cached results for Synthetic_Noise_Brightfield_200_photons_replicate_1 phenotyping nlls\n",
      "file 10 of 24\n",
      "Loading cached results for Synthetic_Noise_Brightfield_200_photons_replicate_0 MI estimates\n",
      "Loading cached results for Synthetic_Noise_Brightfield_200_photons_replicate_0 phenotyping nlls\n",
      "file 11 of 24\n",
      "Loading cached results for Synthetic_Noise_DPC_Right_50_photons_replicate_1 MI estimates\n",
      "Loading cached results for Synthetic_Noise_DPC_Right_50_photons_replicate_1 phenotyping nlls\n",
      "file 12 of 24\n",
      "[129105 320642 110814 241044 364183 310019 236212 321522 162712 314609\n",
      " 361578 309656  70987 110626 128779 111555 233214 115273 384338 384292\n",
      " 241953 386303 130082  71486 232538  71770 237468 319370  72428 378777\n",
      " 128937 156835 231393 239336 154407 107277 147901  73712 313694 237554\n",
      " 313087 121163 319463 145929 120129 157461 307075  79365 130117 113623\n",
      " 127222 305165 361411 321850 310445 305772 236973 118855 357850 318516\n",
      " 111873 118439 308188 360634 122660  69510 322278 241332 235109 361101\n",
      " 162897  71377 148448 233337 118082 159334  69956  70679  74070 117597\n",
      " 124223 159718  75194 117970 132780 308466 318616 156722 317764 110914\n",
      " 122332 117584  69931 383656 361392 116935 129263 242498 156287 151668]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _xla_gc_callback at 0x7f7840a4b7f0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hpinkard_waller/mambaforge/envs/encoding_info/lib/python3.10/site-packages/jax/_src/lib/__init__.py\", line 101, in _xla_gc_callback\n",
      "    def _xla_gc_callback(*args):\n",
      "  File \"_pydevd_bundle/pydevd_cython.pyx\", line 1457, in _pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\n",
      "  File \"_pydevd_bundle/pydevd_cython.pyx\", line 1758, in _pydevd_bundle.pydevd_cython.ThreadTracer.__call__\n",
      "  File \"/home/hpinkard_waller/mambaforge/envs/encoding_info/lib/python3.10/site-packages/debugpy/_vendored/pydevd/_pydev_bundle/pydev_is_thread_alive.py\", line 9, in is_thread_alive\n",
      "    def is_thread_alive(t):\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Rescale fraction must be less than 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/hpinkard_waller/GitRepos/EncodingInformation/led_array/phenotyping_experiments/phenotyping_and_mi_analysis__.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B169.229.228.36/home/hpinkard_waller/GitRepos/EncodingInformation/led_array/phenotyping_experiments/phenotyping_and_mi_analysis__.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(config_dir \u001b[39m+\u001b[39m file, \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B169.229.228.36/home/hpinkard_waller/GitRepos/EncodingInformation/led_array/phenotyping_experiments/phenotyping_and_mi_analysis__.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m     config \u001b[39m=\u001b[39m yaml\u001b[39m.\u001b[39msafe_load(f)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B169.229.228.36/home/hpinkard_waller/GitRepos/EncodingInformation/led_array/phenotyping_experiments/phenotyping_and_mi_analysis__.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m mi \u001b[39m=\u001b[39m estimate_mi(model_name, config,  patch_size)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B169.229.228.36/home/hpinkard_waller/GitRepos/EncodingInformation/led_array/phenotyping_experiments/phenotyping_and_mi_analysis__.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m results \u001b[39m=\u001b[39m {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mresults, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmi}\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B169.229.228.36/home/hpinkard_waller/GitRepos/EncodingInformation/led_array/phenotyping_experiments/phenotyping_and_mi_analysis__.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m phenotyping_nll \u001b[39m=\u001b[39m test_set_phenotyping_nll(model_name, config)\n",
      "\u001b[1;32m/home/hpinkard_waller/GitRepos/EncodingInformation/led_array/phenotyping_experiments/phenotyping_and_mi_analysis__.ipynb Cell 4\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B169.229.228.36/home/hpinkard_waller/GitRepos/EncodingInformation/led_array/phenotyping_experiments/phenotyping_and_mi_analysis__.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=35'>36</a>\u001b[0m rescale_fraction \u001b[39m=\u001b[39m config[\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39msynthetic_noise\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mphotons_per_pixel\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m/\u001b[39m mean_photons_per_pixel\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B169.229.228.36/home/hpinkard_waller/GitRepos/EncodingInformation/led_array/phenotyping_experiments/phenotyping_and_mi_analysis__.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39mif\u001b[39;00m rescale_fraction \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B169.229.228.36/home/hpinkard_waller/GitRepos/EncodingInformation/led_array/phenotyping_experiments/phenotyping_and_mi_analysis__.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mRescale fraction must be less than 1\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B169.229.228.36/home/hpinkard_waller/GitRepos/EncodingInformation/led_array/phenotyping_experiments/phenotyping_and_mi_analysis__.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=39'>40</a>\u001b[0m patches \u001b[39m=\u001b[39m extract_patches(images, patch_size\u001b[39m=\u001b[39mpatch_size, num_patches\u001b[39m=\u001b[39m\u001b[39mint\u001b[39m(dataset_size \u001b[39m*\u001b[39m \u001b[39m2\u001b[39m))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B169.229.228.36/home/hpinkard_waller/GitRepos/EncodingInformation/led_array/phenotyping_experiments/phenotyping_and_mi_analysis__.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=41'>42</a>\u001b[0m \u001b[39mif\u001b[39;00m median_filter:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B169.229.228.36/home/hpinkard_waller/GitRepos/EncodingInformation/led_array/phenotyping_experiments/phenotyping_and_mi_analysis__.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=42'>43</a>\u001b[0m     \u001b[39m# assume noiseless\u001b[39;00m\n",
      "\u001b[0;31mException\u001b[0m: Rescale fraction must be less than 1"
     ]
    }
   ],
   "source": [
    "patch_size = 25\n",
    "\n",
    "config_dir = '/home/hpinkard_waller/GitRepos/EncodingInformation/led_array/phenotyping_experiments/config_files/complete/'\n",
    "# config_name = 'Synthetic_Noise_Brightfield_300_photons_replicate_1.yaml'\n",
    "# TODO: when theyre all in subfolders, this will need to be changed\n",
    "config_prefix = 'Synthetic_Noise'\n",
    "\n",
    "# make a cached_results directory if it doesn't exist\n",
    "if not os.path.exists('.cached'):\n",
    "    os.makedirs('.cached')\n",
    "\n",
    "results = {}\n",
    "files = os.listdir(config_dir)\n",
    "for i, file in enumerate(files):\n",
    "    print(f'file {i} of {len(files)}')\n",
    "    if not file.startswith(config_prefix):\n",
    "        continue # TODO remove this once subfolders\n",
    "\n",
    "    model_name = file.split('.')[0]\n",
    "\n",
    "    with open(config_dir + file, 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "\n",
    "    mi = estimate_mi(model_name, config,  patch_size)\n",
    "    results = {**results, **mi}\n",
    "\n",
    "    phenotyping_nll = test_set_phenotyping_nll(model_name, config)\n",
    "    results = {**results, **phenotyping_nll}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compute and cache MI estimates"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phenotypes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
